{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Run The Agent on Car Racing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import skimage as ski\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from conv_vae import ConvVAE, create_conv_encoder, create_conv_decoder\n",
    "from transition_gru import TransitionGRU\n",
    "from recurrent_agent import DAIFAgentRecurrent\n",
    "from prior_model import PriorModelBellman\n",
    "\n",
    "from train_agent import train_single_agent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from util import random_observation_sequence, transform_observations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from identity_vae import IdentityVAE, identity_encoder, identity_decoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What does the agent do?\n",
    "- The agent plans using a policy then executes that policy for 12 simulation timesteps, the first two actions of the policy are executed for 6 steps each\n",
    "\n",
    "What data does it accumulate?\n",
    "- It accumulates 12 observation actions pairs\n",
    "\n",
    "How is it trained?\n",
    "- VAE is trained to reproduce observations using the latent states\n",
    "- Transition is trained by taking previous hidden state and previous latent state and trying to predict the next latent state"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Online learning For all tasks, we initialize all the agents with random weights and learn online only. Training an agent for 150 epochs takes about 3 minutes on a single CPU core (Intel I7-4870HQ). In contrast, previous approaches using active inference [Ueltzh√∂ffer, 2018, Tschantz et al., 2019, 2020] and policy gradient methods (e.g., [Liu et al., 2017]) use (offline) policy replay and typically need hours of GPU-accelerated compute while achieving similar convergence. To our knowledge, this is the first model-based RL method to learn online using neural network representations. This is afforded by the high sample efficiency of the FEEF, which directs exploration towards states that are uncertain for both the encoder and transition models.\n",
    "\n",
    "\n",
    "Why this is true?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Hide GPU from visible devices\n",
    "# tf.config.set_visible_devices([], 'GPU')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test with no prior model FEEF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_stddev) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_stddev = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "\n",
    "        return z_mean + z_stddev * epsilon\n",
    "\n",
    "\n",
    "def create_conv_encoder(input_dim, latent_dim, conv_shapes=[3, 3, 3], num_filters=[32, 64, 64], dense_units=[16]):\n",
    "\n",
    "    encoder_inputs = keras.Input(shape=input_dim)\n",
    "\n",
    "    x = encoder_inputs\n",
    "    for n in range(len(conv_shapes)):\n",
    "        filter_shape = conv_shapes[n]\n",
    "        num = num_filters[n]\n",
    "        x = layers.Conv2D(num, filter_shape, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    for d in dense_units:\n",
    "        x = layers.Dense(d, activation=\"relu\")(x)\n",
    "\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "    z_log_std = layers.Dense(latent_dim, name=\"z_stddev\")(x)  # output log of sd\n",
    "    z_stddev = tf.exp(z_log_std)  # exponentiate to get sd\n",
    "    z = Sampling()([z_mean, z_stddev])\n",
    "    encoder = keras.Model(encoder_inputs, [z_mean, z_stddev, z], name=\"encoder\")\n",
    "\n",
    "    return encoder\n",
    "\n",
    "\n",
    "def create_conv_decoder(latent_dim, output_shape, deconv_shapes=[3, 3, 3], num_filters=[64, 64, 32], dense_units=[16], rgb=True):\n",
    "\n",
    "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "    x = latent_inputs\n",
    "\n",
    "    for d in dense_units:\n",
    "        x = layers.Dense(d, activation=\"relu\")(x)\n",
    "\n",
    "    first_shape = (deconv_shapes[0], deconv_shapes[0], num_filters[0])\n",
    "    x = layers.Reshape(first_shape)(x)\n",
    "\n",
    "    for n in range(len(deconv_shapes)):\n",
    "        filter_shape = deconv_shapes[n]\n",
    "        num = num_filters[n]\n",
    "        x = layers.Conv2DTranspose(num, filter_shape, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "\n",
    "    if rgb:\n",
    "        decoder_outputs = x\n",
    "    else:\n",
    "        decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "    decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "    return decoder\n",
    "\n",
    "\n",
    "class ConvVAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, latent_dim, reg_mean, reg_stddev, recon_stddev=0.05, llik_scaling=1, kl_scaling=1, **kwargs):\n",
    "        super(ConvVAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.reg_mean = reg_mean\n",
    "        self.reg_stddev = reg_stddev\n",
    "\n",
    "        self.reconstruction_stddev = recon_stddev\n",
    "\n",
    "        self.llik_scaling = llik_scaling\n",
    "        self.kl_scaling = kl_scaling\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        _, _, z = self.encoder(inputs)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return reconstruction\n",
    "\n",
    "\n",
    "    def train_step(self, data):\n",
    "\n",
    "        # unpack data\n",
    "        # x, reg_vals = data\n",
    "        x = data\n",
    "        # reg_mean, reg_stddev = reg_vals\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_stddev, z = self.encoder(x)\n",
    "            reconstruction = self.decoder(z)\n",
    "\n",
    "            # TODO Fix this to be a real loss function\n",
    "            reconstruction_loss = nll_gaussian(reconstruction, x, self.reconstruction_stddev, use_consts=False)\n",
    "\n",
    "            posterior_dist = tfp.distributions.MultivariateNormalDiag(loc=z_mean, scale_diag=z_stddev)\n",
    "            reg_dist = tfp.distributions.MultivariateNormalDiag(loc=self.reg_mean, scale_diag=self.reg_stddev)\n",
    "            kl_loss = tfp.distributions.kl_divergence(posterior_dist, reg_dist) * self.kl_scaling\n",
    "\n",
    "            # kl_loss = tf.reduce_sum(kl_loss, axis=1)\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),  # TODO should this be total_loss not loss\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "\n",
    "def nll_gaussian(pred, target, variance, use_consts=True):\n",
    "\n",
    "    neg_log_prob = ((pred - target)**2/(2*variance))\n",
    "\n",
    "    if use_consts:\n",
    "        const = 0.5*np.log(2*np.pi*variance)\n",
    "        neg_log_prob += const\n",
    "\n",
    "    return tf.reduce_sum(neg_log_prob)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n \n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n \n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n \n        ...,\n \n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n \n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n \n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]]], dtype=uint8),\n 5.680346820809249,\n False,\n False,\n {})"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"CarRacing-v2\", new_step_api=True)\n",
    "\n",
    "env.reset()\n",
    "action = env.action_space.sample()\n",
    "env.step(action)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def random_observation_sequence(env, length, epsilon=0.5):\n",
    "\n",
    "    observation = env.reset()\n",
    "\n",
    "    observations = [observation]\n",
    "    actions = []\n",
    "    rewards = []\n",
    "\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    for _ in range(length):\n",
    "\n",
    "        # change action with epsilon change action, else repeat the same action\n",
    "        if np.random.uniform(0, 1) < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "\n",
    "        observation, reward, done, *rest = env.step(action)\n",
    "\n",
    "        actions.append(action)\n",
    "        observations.append(observation)\n",
    "        rewards.append(reward)\n",
    "\n",
    "        # pad the end\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "\n",
    "    return np.array(observations), np.array(actions), np.array(rewards)\n",
    "\n",
    "\n",
    "def transform_observations(observations, observation_max, observation_min, noise_stddev):\n",
    "    \"\"\"\n",
    "    Transform mountain car observations to be in the range 0 to 1\n",
    "    :param observations:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # https://www.gymlibrary.ml/environments/classic_control/mountain_car_continuous/\n",
    "    # the standard max and min values\n",
    "    # observation_max = np.array([0.6, 0.07])\n",
    "    # observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "    # Need to increase the max and min to allow for random noise to be added\n",
    "    # observation_max = np.array([1.2, 0.14])\n",
    "    # observation_min = np.array([-2.4, -0.14])\n",
    "\n",
    "    observations_scaled = (observations - observation_min)/(observation_max - observation_min)\n",
    "\n",
    "    observations_scaled = 2*observations_scaled - 1\n",
    "\n",
    "    # add noise\n",
    "    observation_noisy = observations_scaled + np.random.normal(loc=0, scale=noise_stddev, size=observations_scaled.shape)\n",
    "\n",
    "    observations_clipped = np.clip(observation_noisy, -1, 1)\n",
    "\n",
    "    return observations_clipped"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "(40020, 72, 72, 3)"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_seqs = 20\n",
    "seq_length = 2000\n",
    "ob_dim = 2\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "observations = []\n",
    "\n",
    "env = gym.make(\"CarRacing-v2\", new_step_api=True)\n",
    "\n",
    "observation_max = np.ones((96))\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, seq_length, epsilon=0.1)\n",
    "\n",
    "    # o = transform_observations(o, observation_max, observation_min, observation_noise_stddev)\n",
    "\n",
    "    # train = np.concatenate([o[:-1], a], axis=1)\n",
    "    # train = o[:-1]\n",
    "    # test = o[-1]\n",
    "\n",
    "    observations.append(o)\n",
    "    # ob_seqs.append(train)\n",
    "    # next_obs.append(test)\n",
    "\n",
    "observations = np.vstack(observations)\n",
    "# observations = observations/255\n",
    "\n",
    "\n",
    "x_min = 12\n",
    "x_max = 84\n",
    "y_min = 12\n",
    "y_max = 84\n",
    "\n",
    "observations = observations[:, x_min:x_max, y_min:y_max, :]\n",
    "\n",
    "observations.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "observations_scaled = ski.transform.resize(observations, (observations.shape[0], 64, 64, 3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x2c95d9c40>"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(observations_scaled[900], cmap=\"gray\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_44 (InputLayer)          [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 32, 32, 16)   448         ['input_44[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 16, 16, 32)   4640        ['conv2d_66[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 8, 8, 32)     9248        ['conv2d_67[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_22 (Flatten)           (None, 2048)         0           ['conv2d_68[0][0]']              \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 32)           65568       ['flatten_22[0][0]']             \n",
      "                                                                                                  \n",
      " z_stddev (Dense)               (None, 32)           1056        ['dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 32)           1056        ['dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.exp_22 (TFOpLambda)    (None, 32)           0           ['z_stddev[0][0]']               \n",
      "                                                                                                  \n",
      " sampling_22 (Sampling)         (None, 32)           0           ['z_mean[0][0]',                 \n",
      "                                                                  'tf.math.exp_22[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 82,016\n",
      "Trainable params: 82,016\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_45 (InputLayer)       [(None, 32)]              0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1024)              33792     \n",
      "                                                                 \n",
      " reshape_21 (Reshape)        (None, 8, 8, 16)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_57 (Conv2D  (None, 16, 16, 16)       16400     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_58 (Conv2D  (None, 32, 32, 16)       65552     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_59 (Conv2D  (None, 64, 64, 3)        49155     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164,899\n",
      "Trainable params: 164,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 32\n",
    "e = create_conv_encoder(input_dim=(64, 64, 3), latent_dim=latent_dim, num_filters=[16, 32, 32], dense_units=[32])\n",
    "e.summary()\n",
    "d = create_conv_decoder(latent_dim=latent_dim, output_shape=(64, 64, 3), deconv_shapes=[8, 16, 32], num_filters=[16, 16, 3], dense_units=[8 * 8 * 16])\n",
    "d.summary()\n",
    "cvae = ConvVAE(e, d, latent_dim=latent_dim, reg_mean=[0] * latent_dim, reg_stddev=[1] * latent_dim)\n",
    "cvae.compile(optimizer=tf.keras.optimizers.Adam())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "626/626 [==============================] - 44s 71ms/step - loss: 7217.7020 - reconstruction_loss: 6852.2725 - kl_loss: 164.6676\n",
      "Epoch 2/5\n",
      "626/626 [==============================] - 44s 71ms/step - loss: 6755.3426 - reconstruction_loss: 6400.2744 - kl_loss: 157.6488\n",
      "Epoch 3/5\n",
      "626/626 [==============================] - 44s 71ms/step - loss: 6165.7882 - reconstruction_loss: 6006.8389 - kl_loss: 152.2671\n",
      "Epoch 4/5\n",
      "626/626 [==============================] - 45s 72ms/step - loss: 6188.2274 - reconstruction_loss: 5805.0474 - kl_loss: 146.0637\n",
      "Epoch 5/5\n",
      "626/626 [==============================] - 44s 71ms/step - loss: 5882.8734 - reconstruction_loss: 5475.0366 - kl_loss: 143.1380\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2b8c1aa30>"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvae.fit(observations_scaled, epochs=5, batch_size=64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1000, 64, 64, 3), dtype=float32, numpy=\narray([[[[0.10163755, 0.08710617, 0.10615166],\n         [0.10822736, 0.07152979, 0.10790016],\n         [0.10393709, 0.06270713, 0.104606  ],\n         ...,\n         [0.05655741, 0.06449572, 0.06849591],\n         [0.05679156, 0.05912433, 0.06614723],\n         [0.05918418, 0.05878132, 0.07126828]],\n\n        [[0.10353954, 0.08694787, 0.10721067],\n         [0.10626154, 0.06507824, 0.10672563],\n         [0.09768938, 0.05649228, 0.10567817],\n         ...,\n         [0.05611872, 0.06658863, 0.06970102],\n         [0.05609376, 0.06390461, 0.06934007],\n         [0.05638633, 0.05809105, 0.07250793]],\n\n        [[0.10608158, 0.08743504, 0.10519463],\n         [0.10458615, 0.06081173, 0.10273746],\n         [0.09905308, 0.05153751, 0.10254117],\n         ...,\n         [0.05433555, 0.06802258, 0.06722931],\n         [0.05419179, 0.06418359, 0.06781083],\n         [0.05743573, 0.05584339, 0.07200748]],\n\n        ...,\n\n        [[0.4048331 , 0.7782724 , 0.39219156],\n         [0.3955186 , 0.7838071 , 0.39036041],\n         [0.4001169 , 0.7848474 , 0.39753535],\n         ...,\n         [0.05047016, 0.03140298, 0.07035882],\n         [0.05216757, 0.03336427, 0.07092635],\n         [0.05356364, 0.03564144, 0.07228965]],\n\n        [[0.40272525, 0.7906647 , 0.39693642],\n         [0.39736104, 0.7911444 , 0.39335445],\n         [0.40374088, 0.80899227, 0.39117405],\n         ...,\n         [0.05544414, 0.03929042, 0.07427795],\n         [0.05539301, 0.03814814, 0.07333229],\n         [0.05890772, 0.04082802, 0.07472907]],\n\n        [[0.40023467, 0.7946624 , 0.38833877],\n         [0.39970824, 0.78825563, 0.40223762],\n         [0.40402383, 0.7954585 , 0.3926411 ],\n         ...,\n         [0.05527631, 0.0255747 , 0.07218556],\n         [0.05629384, 0.02663447, 0.07061126],\n         [0.05722919, 0.03183997, 0.07332879]]],\n\n\n       [[[0.2164965 , 0.2706435 , 0.2226803 ],\n         [0.21312454, 0.22184911, 0.22173163],\n         [0.20466188, 0.17392448, 0.21229342],\n         ...,\n         [0.05445199, 0.0704162 , 0.06061951],\n         [0.05735877, 0.06612791, 0.05980148],\n         [0.05745777, 0.06161211, 0.06911678]],\n\n        [[0.2311555 , 0.28564093, 0.23163003],\n         [0.22062427, 0.22892196, 0.23074445],\n         [0.20988885, 0.1864382 , 0.22775826],\n         ...,\n         [0.05450031, 0.06842636, 0.06140486],\n         [0.05675906, 0.06810077, 0.0623613 ],\n         [0.05580005, 0.06072236, 0.06921814]],\n\n        [[0.24453013, 0.3148268 , 0.2372826 ],\n         [0.23500061, 0.26140538, 0.2399424 ],\n         [0.2281142 , 0.21961635, 0.23897845],\n         ...,\n         [0.05389908, 0.06342938, 0.05920891],\n         [0.05357473, 0.06435226, 0.06136149],\n         [0.05608261, 0.06000562, 0.07014921]],\n\n        ...,\n\n        [[0.38522157, 0.73473924, 0.37866893],\n         [0.3791718 , 0.75962114, 0.37459657],\n         [0.38389644, 0.76219785, 0.37851933],\n         ...,\n         [0.05174581, 0.05113782, 0.06452762],\n         [0.0545867 , 0.05520737, 0.06633795],\n         [0.05616836, 0.04457575, 0.07337429]],\n\n        [[0.38059503, 0.7159762 , 0.37495708],\n         [0.37403154, 0.7405211 , 0.36516875],\n         [0.38055292, 0.7545272 , 0.3692598 ],\n         ...,\n         [0.05523479, 0.05369992, 0.06871382],\n         [0.0573601 , 0.05618484, 0.0697054 ],\n         [0.0612586 , 0.04680177, 0.07283   ]],\n\n        [[0.37456807, 0.7016534 , 0.36370325],\n         [0.37584084, 0.71898067, 0.37153587],\n         [0.38183832, 0.727847  , 0.37025234],\n         ...,\n         [0.05547094, 0.04420226, 0.06688493],\n         [0.0592389 , 0.04576034, 0.06533261],\n         [0.06269386, 0.03888812, 0.07184579]]],\n\n\n       [[[0.36469913, 0.8067495 , 0.37788022],\n         [0.3687683 , 0.7875928 , 0.37599748],\n         [0.3663519 , 0.7656224 , 0.37150642],\n         ...,\n         [0.05752541, 0.04931627, 0.06576084],\n         [0.05726882, 0.05108308, 0.06180318],\n         [0.05717428, 0.05270718, 0.06826938]],\n\n        [[0.3709839 , 0.81110406, 0.3803067 ],\n         [0.36701024, 0.791752  , 0.38170007],\n         [0.36790633, 0.7722254 , 0.37722844],\n         ...,\n         [0.05284762, 0.04291242, 0.06502716],\n         [0.0538608 , 0.04709461, 0.06237416],\n         [0.05467083, 0.05236549, 0.06813996]],\n\n        [[0.3714841 , 0.8228681 , 0.38045928],\n         [0.36916903, 0.8008751 , 0.3830398 ],\n         [0.37270087, 0.7735581 , 0.3787678 ],\n         ...,\n         [0.04714464, 0.03565373, 0.05722262],\n         [0.04859269, 0.04099569, 0.05830432],\n         [0.05560165, 0.04852535, 0.06704531]],\n\n        ...,\n\n        [[0.39626446, 0.7144094 , 0.39275053],\n         [0.39433417, 0.7327391 , 0.3896732 ],\n         [0.40040374, 0.7414316 , 0.39466885],\n         ...,\n         [0.04217161, 0.02189252, 0.05830587],\n         [0.04805708, 0.04493864, 0.0610744 ],\n         [0.05445032, 0.04816544, 0.07202899]],\n\n        [[0.39176995, 0.6851191 , 0.38692942],\n         [0.3904986 , 0.71001923, 0.38005868],\n         [0.39606985, 0.7166089 , 0.3894695 ],\n         ...,\n         [0.04896135, 0.0271736 , 0.06634457],\n         [0.05279258, 0.04736944, 0.06546102],\n         [0.06038949, 0.0497913 , 0.07334425]],\n\n        [[0.38464472, 0.6671226 , 0.3807358 ],\n         [0.39261228, 0.6856947 , 0.3850637 ],\n         [0.39530703, 0.6981853 , 0.3871496 ],\n         ...,\n         [0.05199851, 0.01438819, 0.06694285],\n         [0.05656288, 0.0350504 , 0.06352065],\n         [0.06083532, 0.04124988, 0.07173961]]],\n\n\n       ...,\n\n\n       [[[0.38475147, 0.81399864, 0.3835811 ],\n         [0.38336998, 0.8143617 , 0.38520208],\n         [0.38552776, 0.8228359 , 0.38855007],\n         ...,\n         [0.3972965 , 0.8268055 , 0.39546075],\n         [0.4007691 , 0.8294587 , 0.39458475],\n         [0.39858052, 0.8232948 , 0.39391315]],\n\n        [[0.3852462 , 0.81561685, 0.38452137],\n         [0.384993  , 0.82279605, 0.38570586],\n         [0.38913858, 0.8228742 , 0.38618815],\n         ...,\n         [0.3976994 , 0.8260361 , 0.3975614 ],\n         [0.400524  , 0.8282251 , 0.39163768],\n         [0.40261972, 0.824769  , 0.39396262]],\n\n        [[0.3858578 , 0.8230512 , 0.38690946],\n         [0.38594705, 0.82792675, 0.38770103],\n         [0.3862228 , 0.82477766, 0.38721895],\n         ...,\n         [0.39927045, 0.82401824, 0.3951684 ],\n         [0.3995439 , 0.82424927, 0.39272356],\n         [0.40317354, 0.822827  , 0.39743516]],\n\n        ...,\n\n        [[0.38379183, 0.4488722 , 0.38013506],\n         [0.39244428, 0.39594805, 0.38217604],\n         [0.3922908 , 0.3653995 , 0.38067022],\n         ...,\n         [0.39279458, 0.81688035, 0.3917681 ],\n         [0.39148813, 0.81835693, 0.3926068 ],\n         [0.39714652, 0.81264746, 0.39055344]],\n\n        [[0.38556996, 0.4588871 , 0.37852433],\n         [0.39464897, 0.41677985, 0.38108546],\n         [0.39247712, 0.38714966, 0.38772243],\n         ...,\n         [0.3923711 , 0.8191403 , 0.39295715],\n         [0.39423403, 0.8230717 , 0.39378047],\n         [0.3958904 , 0.82276326, 0.39118135]],\n\n        [[0.38553014, 0.4707986 , 0.38036644],\n         [0.39231884, 0.43174514, 0.38250694],\n         [0.39109427, 0.41178587, 0.38704786],\n         ...,\n         [0.38968286, 0.81530887, 0.39078388],\n         [0.39263153, 0.81786436, 0.38996306],\n         [0.3930801 , 0.81651056, 0.3882221 ]]],\n\n\n       [[[0.3848257 , 0.8118717 , 0.3837135 ],\n         [0.38363004, 0.812217  , 0.38542563],\n         [0.3859242 , 0.8210011 , 0.38876748],\n         ...,\n         [0.39744395, 0.8256681 , 0.39553082],\n         [0.4009634 , 0.82855827, 0.39468387],\n         [0.3987514 , 0.82262737, 0.39407107]],\n\n        [[0.38542286, 0.81347287, 0.38471925],\n         [0.3853086 , 0.82045716, 0.3859542 ],\n         [0.38955542, 0.8209344 , 0.38640058],\n         ...,\n         [0.39778417, 0.82478464, 0.39757642],\n         [0.4006576 , 0.8272037 , 0.39169642],\n         [0.4026928 , 0.82411754, 0.39410532]],\n\n        [[0.386154  , 0.8208405 , 0.3870723 ],\n         [0.38632885, 0.8255036 , 0.38789666],\n         [0.3866182 , 0.8226142 , 0.38748056],\n         ...,\n         [0.39937195, 0.82262474, 0.39521873],\n         [0.39964062, 0.82317257, 0.39276096],\n         [0.40327024, 0.82213956, 0.39749572]],\n\n        ...,\n\n        [[0.3848701 , 0.45005357, 0.38088065],\n         [0.3933806 , 0.39663616, 0.3827753 ],\n         [0.39278182, 0.36575225, 0.38135102],\n         ...,\n         [0.39359304, 0.8181312 , 0.3923571 ],\n         [0.3924008 , 0.8196021 , 0.39321664],\n         [0.39805007, 0.8139256 , 0.3911202 ]],\n\n        [[0.3863187 , 0.46053606, 0.3792284 ],\n         [0.3952701 , 0.41764462, 0.38161457],\n         [0.3927616 , 0.38755035, 0.38818538],\n         ...,\n         [0.39327347, 0.8204757 , 0.39367655],\n         [0.3952614 , 0.8244227 , 0.39454755],\n         [0.3968992 , 0.824055  , 0.39184907]],\n\n        [[0.38637426, 0.4725543 , 0.3811386 ],\n         [0.39289418, 0.43299672, 0.3830394 ],\n         [0.39157978, 0.4123561 , 0.3875604 ],\n         ...,\n         [0.39060903, 0.8167267 , 0.39157414],\n         [0.39363664, 0.8193662 , 0.39074612],\n         [0.3941076 , 0.81785053, 0.38892007]]],\n\n\n       [[[0.3845956 , 0.8117415 , 0.38346684],\n         [0.38338807, 0.81219333, 0.38516182],\n         [0.3856929 , 0.821306  , 0.38852865],\n         ...,\n         [0.39676455, 0.82621485, 0.39489076],\n         [0.4001175 , 0.82844317, 0.39389616],\n         [0.3978404 , 0.82173854, 0.39320675]],\n\n        [[0.385258  , 0.8135055 , 0.38448232],\n         [0.38513985, 0.8206229 , 0.38573796],\n         [0.38934538, 0.8215228 , 0.38615558],\n         ...,\n         [0.39708263, 0.82596064, 0.39697996],\n         [0.39986885, 0.82759017, 0.39094824],\n         [0.40175244, 0.8237442 , 0.39328063]],\n\n        [[0.386015  , 0.8210906 , 0.38692495],\n         [0.3861649 , 0.82595986, 0.38772917],\n         [0.38646895, 0.823469  , 0.38729337],\n         ...,\n         [0.39869395, 0.82462204, 0.3947438 ],\n         [0.39884928, 0.8242931 , 0.3921726 ],\n         [0.40245637, 0.8223353 , 0.39682433]],\n\n        ...,\n\n        [[0.3843849 , 0.45398223, 0.3803001 ],\n         [0.39288348, 0.40097526, 0.38204718],\n         [0.392235  , 0.36894906, 0.38059762],\n         ...,\n         [0.39289236, 0.811186  , 0.39194065],\n         [0.3916012 , 0.81216615, 0.39281836],\n         [0.39739737, 0.8069905 , 0.3907198 ]],\n\n        [[0.3856988 , 0.4640473 , 0.3786676 ],\n         [0.39460889, 0.42128196, 0.38080114],\n         [0.3920999 , 0.39029068, 0.38728812],\n         ...,\n         [0.39265853, 0.8137063 , 0.39314726],\n         [0.3945697 , 0.8170168 , 0.39401022],\n         [0.3962681 , 0.81699073, 0.39130035]],\n\n        [[0.3857371 , 0.47577238, 0.3804686 ],\n         [0.3920814 , 0.43630493, 0.38221896],\n         [0.39076516, 0.41456777, 0.3867182 ],\n         ...,\n         [0.3899651 , 0.8100989 , 0.3911457 ],\n         [0.39294383, 0.81231034, 0.3902574 ],\n         [0.3934027 , 0.8110843 , 0.3883363 ]]]], dtype=float32)>"
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = cvae(observations_scaled[0:1000])\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x2f63b67c0>"
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(observations_scaled[200], cmap=\"gray\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x2c3eea2b0>"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(res[200], cmap=\"gray\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test with the prior model FEEF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "enc = create_encoder(2, 2, [20])\n",
    "dec = create_decoder(2, 2, [20])\n",
    "vae = VAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=1, recon_stddev=0.05)\n",
    "\n",
    "pl_hoz = 5\n",
    "latent_dim = 2\n",
    "\n",
    "tran = TransitionGRU(2, 1, 12, 2*latent_dim*pl_hoz, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_model = PriorModelBellman(2)\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "# observation_noise_stddev = [0, 0]\n",
    "observation_noise_stddev = [0.05, 0.05]\n",
    "\n",
    "daifa = DAIFAgentRecurrent(prior_model,\n",
    "                           vae,\n",
    "                           tran,\n",
    "                           None,\n",
    "                           None,\n",
    "                           train_prior_model=True,\n",
    "                           planning_horizon=pl_hoz,\n",
    "                           use_kl_extrinsic=True,\n",
    "                           use_kl_intrinsic=True,\n",
    "                           use_FEEF=True,\n",
    "                           vae_train_epochs=1,\n",
    "                           tran_train_epochs=1,\n",
    "                           show_vae_training=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train the agent on the env\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "agent, results = train_agent(env, daifa, observation_max, observation_min, observation_noise_stddev, num_episodes=40, action_repeats=6, num_actions_to_execute=5, train_on_full_data=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test the models produced"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_seqs = 20\n",
    "seq_length = 300\n",
    "ob_dim = 2\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "observations = []\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, 1000, epsilon=0.1)\n",
    "\n",
    "    o = transform_observations(o, observation_max, observation_min, observation_noise_stddev)\n",
    "\n",
    "    train = np.concatenate([o[:-1], a], axis=1)\n",
    "    # train = o[:-1]\n",
    "    test = o[-1]\n",
    "\n",
    "    observations.append(o)\n",
    "    ob_seqs.append(train)\n",
    "    next_obs.append(test)\n",
    "\n",
    "# ob_seqs = np.array(ob_seqs)\n",
    "# next_obs = np.array(next_obs)\n",
    "\n",
    "observations = np.vstack(observations)\n",
    "# observations = observations.reshape((num_seqs*(seq_length+1), ob_dim))\n",
    "\n",
    "# ob_seqs_stddev = np.ones_like(ob_seqs_flat)\n",
    "# next_obs_stddev = np.ones_like(ob_seqs_flat)\n",
    "\n",
    "observations.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "observations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agent.model_vae(observations)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Test the models produced\n",
    "num_seqs = 20\n",
    "seq_length = 300\n",
    "ob_dim = 2\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "observations = []\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, 1000, epsilon=0.1)\n",
    "\n",
    "    o = transform_observations(o, observation_max, observation_min, observation_noise_stddev)\n",
    "\n",
    "    train = np.concatenate([o[:-1], a], axis=1)\n",
    "    # train = o[:-1]\n",
    "    test = o[-1]\n",
    "\n",
    "    observations.append(o)\n",
    "    ob_seqs.append(train)\n",
    "    next_obs.append(test)\n",
    "\n",
    "# ob_seqs = np.array(ob_seqs)\n",
    "# next_obs = np.array(next_obs)\n",
    "\n",
    "observations = np.vstack(observations)\n",
    "# observations = observations.reshape((num_seqs*(seq_length+1), ob_dim))\n",
    "\n",
    "# ob_seqs_stddev = np.ones_like(ob_seqs_flat)\n",
    "# next_obs_stddev = np.ones_like(ob_seqs_flat)\n",
    "\n",
    "observations.shape\n",
    "observations\n",
    "agent.model_vae(observations)\n",
    "## Test EFE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test EFE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "enc = create_encoder(2, 2, [20])\n",
    "dec = create_decoder(2, 2, [20])\n",
    "vae = VAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=1)\n",
    "\n",
    "pl_hoz = 5\n",
    "latent_dim = 2\n",
    "\n",
    "tran = TransitionGRU(2, 1, 12, 2*pl_hoz*latent_dim, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.45, 0]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_model = PriorModelBellman(2)\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "observation_noise_stddev = [0, 0]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0,0])  # no noise on prior\n",
    "\n",
    "# without prior model\n",
    "daifa = DAIFAgentRecurrent(None,\n",
    "                           vae,\n",
    "                           tran,\n",
    "                           scaled_prior_mean,\n",
    "                           prior_stddev,\n",
    "                           planning_horizon=pl_hoz,\n",
    "                           use_kl_extrinsic=True,\n",
    "                           use_kl_intrinsic=True,\n",
    "                           use_FEEF=False,\n",
    "                           vae_train_epochs=1,\n",
    "                           tran_train_epochs=1,\n",
    "                           show_vae_training=False)\n",
    "\n",
    "# with prior model\n",
    "daifa = DAIFAgentRecurrent(prior_model,\n",
    "                           vae,\n",
    "                           tran,\n",
    "                           None,\n",
    "                           None,\n",
    "                           planning_horizon=pl_hoz,\n",
    "                           use_kl_extrinsic=True,\n",
    "                           use_kl_intrinsic=True,\n",
    "                           use_FEEF=False,\n",
    "                           vae_train_epochs=1,\n",
    "                           tran_train_epochs=1,\n",
    "                           show_vae_training=False)\n",
    "\n",
    "scaled_prior_mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train the agent on the env\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "agent, results = train_agent(env, daifa, observation_max, observation_min, observation_noise_stddev, num_episodes=20, action_repeats=10, num_actions_to_execute=2, train_on_full_data=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Test the models produced\n",
    "num_seqs = 20\n",
    "seq_length = 300\n",
    "ob_dim = 2\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "observations = []\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, 1000, epsilon=0.1)\n",
    "\n",
    "    o = transform_observations(o, observation_max, observation_min, observation_noise_stddev)\n",
    "\n",
    "    train = np.concatenate([o[:-1], a], axis=1)\n",
    "    # train = o[:-1]\n",
    "    test = o[-1]\n",
    "\n",
    "    observations.append(o)\n",
    "    ob_seqs.append(train)\n",
    "    next_obs.append(test)\n",
    "\n",
    "# ob_seqs = np.array(ob_seqs)\n",
    "# next_obs = np.array(next_obs)\n",
    "\n",
    "observations = np.vstack(observations)\n",
    "# observations = observations.reshape((num_seqs*(seq_length+1), ob_dim))\n",
    "\n",
    "# ob_seqs_stddev = np.ones_like(ob_seqs_flat)\n",
    "# next_obs_stddev = np.ones_like(ob_seqs_flat)\n",
    "\n",
    "observations.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "observations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agent.model_vae(observations)\n",
    "## Test EFE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing the Identity VAE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "enc = identity_encoder\n",
    "dec = identity_decoder\n",
    "idvae = IdentityVAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "hidden_size = 2*2*15  # 2*latent_dim * planning_size\n",
    "tran = TransitionGRU(2, 1, 12, hidden_size, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.6, 0]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "observation_noise_stddev = [0, 0]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0,0])  # no noise on prior\n",
    "\n",
    "daifa = DAIFAgentRecurrent(None, idvae, tran, scaled_prior_mean, prior_stddev)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "agent, succeeded, time_to_success = train_agent(env, daifa, observation_max, observation_min, observation_noise_stddev, num_episodes=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out = agent.tran((ob_seqs[0:1], None))\n",
    "out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = ob_seqs[0:1, -1].reshape(1,1,3)\n",
    "h = out[3]\n",
    "h = h[0, -2, :]\n",
    "h = h.numpy().reshape(1,30)\n",
    "h"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agent.tran((t, h))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ob_seqs[0:1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test to see how the agent trains on standard observation data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "enc = identity_encoder\n",
    "dec = identity_decoder\n",
    "idvae = IdentityVAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "hidden_size = 2*2*15  # 2*latent_dim * planning_size\n",
    "tran = TransitionGRU(2, 1, 12, hidden_size, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.45, 0]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "observation_noise_stddev = [0, 0]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0,0])  # no noise on prior\n",
    "\n",
    "daifa = DAIFAgentRecurrent(None, idvae, tran, scaled_prior_mean, prior_stddev, vae_train_epochs=1, tran_train_epochs=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "success, agent, t, pre_obs, post_obs, acts = run_episode(env, daifa, observation_max, observation_min, observation_noise_stddev)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pre_np = np.array(pre_obs)\n",
    "a = np.array(acts)\n",
    "a.shape\n",
    "pre_a = np.concatenate([pre_np, a], axis=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(a.max(), a.min())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pre_a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "post_obs_to_predict = np.array(post_obs)[:, 14, :]\n",
    "post_obs_to_predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agent.tran((pre_a, None))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "post_obs_to_predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Examine training the model on the observation data\n",
    "\n",
    "Does it eventually converge to a good model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_train_runs = 1\n",
    "for i in range(num_train_runs):\n",
    "\n",
    "    for j in range(len(pre)):\n",
    "        pre = pre_obs[j]\n",
    "        post = post_obs[j]\n",
    "        actions = acts[j]\n",
    "\n",
    "        daifa.train(pre, post, actions, None, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daifa.cem_policy_optimisation(np.array([0.5, 0.1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daifa.cem_policy_optimisation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test the FEEF computations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# enc = create_encoder(2, 2, [20])\n",
    "# dec = create_decoder(2, 2, [20])\n",
    "# vae = VAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "enc = identity_encoder\n",
    "dec = identity_decoder\n",
    "idvae = IdentityVAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "tran = TransitionGRU(2, 1, 12, 60, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.6, 0]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "observation_noise_stddev = [0, 0]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0, 0])  # no noise on prior\n",
    "\n",
    "print(scaled_prior_mean)\n",
    "\n",
    "daifa = DAIFAgentRecurrent(None, idvae, tran, scaled_prior_mean, prior_stddev, planning_horizon=15, n_policy_candidates=70, n_policies=1500, n_cem_policy_iterations=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "agent, succeeded, time_to_success = train_agent(env, daifa, observation_max, observation_min, observation_noise_stddev,\n",
    "                                                num_episodes=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_policy(agent, env, policy, action_repeats):\n",
    "\n",
    "    observation = env.reset()\n",
    "    obs = transform_observations(observation, observation_max, observation_min, [0, 0])\n",
    "\n",
    "    z_t_minus_1 = obs\n",
    "    p, s = agent.cem_policy_optimisation(z_t_minus_1)\n",
    "    p\n",
    "    print(obs)\n",
    "    print(p)\n",
    "\n",
    "    for action in p:\n",
    "        for t in range(action_repeats):\n",
    "            res = env.step(np.array([action]))\n",
    "            print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "z_t_minus_1 = np.array([0, 0])\n",
    "p, s = agent.cem_policy_optimisation(z_t_minus_1)\n",
    "p\n",
    "\n",
    "agent.forward_policies(p, z_t_minus_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "test_policy(agent, env, p.numpy(), 6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "z_t_minus_1 = np.array([-0.27691475,  0.01688306])\n",
    "p, s = agent.cem_policy_optimisation(z_t_minus_1)\n",
    "p"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "\n",
    "from vae_recurrent import VAE\n",
    "\n",
    "\n",
    "class DAIFAgentRecurrent:\n",
    "\n",
    "    def __init__(self,\n",
    "                 prior_model,\n",
    "                 vae,\n",
    "                 tran,\n",
    "                 given_prior_mean,\n",
    "                 given_prior_stddev,\n",
    "                 planning_horizon=15,\n",
    "                 n_policies=1500,\n",
    "                 n_cem_policy_iterations=2,\n",
    "                 n_policy_candidates=70,\n",
    "                 tran_train_epochs=1,\n",
    "                 vae_train_epochs=1,\n",
    "                 agent_time_ratio=6,\n",
    "                 train_vae=True,\n",
    "                 train_tran=True):\n",
    "\n",
    "        super(DAIFAgentRecurrent, self).__init__()\n",
    "\n",
    "        self.prior_model = prior_model\n",
    "        self.planning_horizon = planning_horizon\n",
    "        self.n_policy_candidates = n_policy_candidates\n",
    "        self.n_policies = n_policies\n",
    "        self.n_cem_policy_iterations = n_cem_policy_iterations\n",
    "\n",
    "        self.vae_train_epochs = vae_train_epochs\n",
    "        self.tran_train_epochs = tran_train_epochs\n",
    "        self.train_vae = train_vae\n",
    "        self.train_tran = train_tran\n",
    "\n",
    "        self.given_prior_mean = given_prior_mean\n",
    "        self.given_prior_stddev = given_prior_stddev\n",
    "\n",
    "        # full vae\n",
    "        self.model_vae = vae\n",
    "        self.model_vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "        # transition\n",
    "        # takes action plus last state and outputs next latent state\n",
    "        self.tran = tran\n",
    "        self.tran.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "        self.hidden_state = None\n",
    "\n",
    "        # how much is the agents planning time compressed compared to the simulation time\n",
    "        self.agent_time_ratio = agent_time_ratio\n",
    "\n",
    "\n",
    "    def select_policy(self, observation):\n",
    "\n",
    "        policy_mean, policy_stddev = self.cem_policy_optimisation(observation)\n",
    "\n",
    "        # return a distribution that we can sample from\n",
    "        return tfp.distributions.MultivariateNormalDiag(loc=policy_mean, scale_diag=policy_stddev)\n",
    "\n",
    "\n",
    "    def train(self, pre_observations_raw, post_observations_raw, actions_complete, rewards, verbose=0):\n",
    "\n",
    "        # compress the observations based on the agents time compression factor\n",
    "        # pre_observations = pre_observations_raw[::self.agent_time_ratio]  # for example take every 6th element\n",
    "        # post_observations = np.array([post_observations_raw[i] for i in range(len(post_observations_raw)) if i % self.agent_time_ratio == self.agent_time_ratio - 1])\n",
    "        #\n",
    "        # print(pre_observations_raw)\n",
    "        # print(pre_observations)\n",
    "        # print(post_observations_raw)\n",
    "        # print(post_observations)\n",
    "\n",
    "        pre_observations = pre_observations_raw\n",
    "        post_observations = post_observations_raw\n",
    "\n",
    "        # only look at the first n actions that we took\n",
    "        actions = actions_complete[0: len(pre_observations)]\n",
    "\n",
    "        num_observations = pre_observations.shape[0]\n",
    "        observation_dim = pre_observations.shape[1]\n",
    "        action_dim = actions.shape[1]\n",
    "        # action_dim = 1  # TODO fix this to allow different actions\n",
    "\n",
    "        # find the actual observed latent states using the vae\n",
    "        pre_latent_mean, pre_latent_stddev, pre_latent = self.model_vae.encoder(pre_observations)\n",
    "        post_latent_mean, post_latent_stddev, post_latent = self.model_vae.encoder(post_observations)\n",
    "\n",
    "        # set up the input training data that we use to train the transition model\n",
    "        z_train = np.concatenate([np.array(pre_latent_mean), np.array(actions)], axis=1)\n",
    "\n",
    "        # we use the sequence to find the right hidden states to use as input\n",
    "        z_train_seq = z_train.reshape((1, num_observations, observation_dim + action_dim))\n",
    "        z_train_singles = z_train.reshape(num_observations, 1, observation_dim + action_dim)\n",
    "\n",
    "        # the previous hidden state is the memory after observing some sequences but it might be None\n",
    "        if self.hidden_state is None:\n",
    "            self.hidden_state = np.zeros((1, self.tran.hidden_units))\n",
    "\n",
    "        if self.train_tran:\n",
    "            # find the hidden states at t=0, t=1, t=2, ..., t=num_observations - 1\n",
    "            _, _, _, h_states = self.tran((z_train_seq, self.hidden_state))\n",
    "\n",
    "\n",
    "            # squeeze so we make the shape [num_observations, hidden_units]\n",
    "            h_states = tf.squeeze(h_states)\n",
    "\n",
    "            # exclude the last state as this will become the hidden state later on. next hidden state will become our new memory\n",
    "            h_states_for_training = h_states[:-1]\n",
    "            # next_hidden_state = h_states[-1]\n",
    "\n",
    "            # add the current hidden state we saved to the start. This has h0, h1, h2, .. h=num_observations - 1\n",
    "            h_states_for_training = tf.concat([self.hidden_state, h_states_for_training], axis=0)\n",
    "\n",
    "\n",
    "            # use the hidden states with the pre and post observations to train transition model\n",
    "            self.tran.fit((z_train_singles, h_states_for_training), (post_latent_mean, post_latent_stddev), epochs=self.tran_train_epochs, verbose=verbose)\n",
    "\n",
    "        # now find the new predicted hidden state that we will use for finding the policy\n",
    "        # TODO not sure if I should pass the old hidden state or reset it to 0\n",
    "        _, _, final_hidden_state, _ = self.tran((z_train_seq, self.hidden_state))\n",
    "        # _, _, final_hidden_state, _ = self.tran((z_train_seq, None))\n",
    "\n",
    "        self.hidden_state = final_hidden_state\n",
    "\n",
    "        #### TRAIN THE VAE ####\n",
    "        if self.train_vae:\n",
    "            # train the vae model on post_observations because these are all new\n",
    "            self.model_vae.fit(post_observations, epochs=self.vae_train_epochs, verbose=verbose)\n",
    "\n",
    "\n",
    "\n",
    "    def cem_policy_optimisation(self, z_t_minus_one):\n",
    "\n",
    "        # need to change these two if the policy dimension changes\n",
    "        mean_best_policies = tf.zeros(self.planning_horizon)\n",
    "        std_best_policies = tf.ones(self.planning_horizon)\n",
    "\n",
    "        for i in range(self.n_cem_policy_iterations):\n",
    "            policy_distr = tfp.distributions.MultivariateNormalDiag(loc=mean_best_policies, scale_diag=std_best_policies)\n",
    "            policies = policy_distr.sample([self.n_policies])\n",
    "            policies = tf.clip_by_value(policies, clip_value_min=-1, clip_value_max=1)\n",
    "\n",
    "            # project trajectory into the future using transition model and calculate FEEF for each policy\n",
    "            policy_results = self.forward_policies(policies.numpy(), z_t_minus_one)\n",
    "            FEEFs = self.evaluate_policy(*policy_results)\n",
    "\n",
    "            FEEFs = tf.convert_to_tensor(FEEFs)\n",
    "\n",
    "            # sum over the timesteps to get the FEEF for each policy\n",
    "            FEEFs_sum = tf.reduce_sum(FEEFs, axis=0)\n",
    "\n",
    "            # multiply by one to find largest value which is euqivalent to smallest FEEF with top_k\n",
    "            neg_FEEF_sum = -1*FEEFs_sum\n",
    "\n",
    "            result = tf.math.top_k(neg_FEEF_sum, self.n_policy_candidates, sorted=False)\n",
    "            min_FEEF_indices = result.indices\n",
    "\n",
    "            # update the policy distributions\n",
    "            mean_best_policies = tf.reduce_mean(tf.gather(policies, min_FEEF_indices), axis=0)\n",
    "            std_best_policies = tf.math.reduce_std(tf.gather(policies, min_FEEF_indices), axis=0)\n",
    "\n",
    "\n",
    "        # TODO not sure why we need all of this is with the x means? I think it's for training but maybe not\n",
    "\n",
    "        # One last forward pass to gather the stats of the policy mean\n",
    "        #FEEFs, next_x_means, next_x_stds = self._forward_policies(mean_best_policies.unsqueeze(1))\n",
    "        # return mean_best_policies, std_best_policies, FEEFs.detach().squeeze(1), next_x_means.detach().squeeze(1), next_x_stds.detach().squeeze(1)\n",
    "\n",
    "        print(z_t_minus_one)\n",
    "        print(mean_best_policies)\n",
    "        return mean_best_policies, std_best_policies\n",
    "\n",
    "\n",
    "    def forward_policies(self, policies, z_t_minus_one):\n",
    "        \"\"\"\n",
    "        Forward propogate a policy and compute the FEEF of each policy\n",
    "        :param z_t_minus_one:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # stack up the new observation to have shape [self.n_policies, len(z_t_minus_one)]\n",
    "        prev_latent_mean = np.stack([z_t_minus_one]*self.n_policies)\n",
    "\n",
    "        policy_posteriors = []\n",
    "        policy_sds = []\n",
    "        likelihoods = []\n",
    "        z_means = []\n",
    "        z_sds = []\n",
    "\n",
    "        # get the starting hidden state that coressponds to the memory stored by the previous sequences. Should have shape (1, self.tran.num_hidden_units) for the observed sequence\n",
    "        # extend the current hidden state to the number of policies present\n",
    "        if self.hidden_state is None:\n",
    "            cur_hidden_state = np.zeros((self.n_policies, self.tran.hidden_units))\n",
    "        else:\n",
    "            cur_hidden_state = np.vstack([self.hidden_state]*self.n_policies)\n",
    "\n",
    "        # print(cur_hidden_state)\n",
    "\n",
    "        # find the predicted latent states from the transition model\n",
    "        for t in range(self.planning_horizon):\n",
    "\n",
    "            ob_plus_action = np.concatenate([prev_latent_mean, policies[:, t].reshape(self.n_policies, 1)], axis=1)\n",
    "            tran_input = ob_plus_action.reshape((self.n_policies, 1, ob_plus_action.shape[1]))  # reshape to pass to GRU\n",
    "\n",
    "            next_latent_mean, next_latent_sd, next_hidden_state, _ = self.tran((tran_input, cur_hidden_state))  # shape = [num policies, latent dim\n",
    "\n",
    "            # update the hidden state for use with the next policies\n",
    "            cur_hidden_state = next_hidden_state\n",
    "\n",
    "            policy_posteriors.append(next_latent_mean)\n",
    "            policy_sds.append(next_latent_sd)\n",
    "\n",
    "            next_likelihoods = self.model_vae.decoder(next_latent_mean)\n",
    "            likelihoods.append(next_likelihoods)\n",
    "\n",
    "            next_posterior_means, next_posteriors_sds, next_posteriors_z = self.model_vae.encoder(next_likelihoods)\n",
    "            z_means.append(next_posterior_means)\n",
    "            z_sds.append(next_posteriors_sds)\n",
    "\n",
    "            prev_latent_mean = next_latent_mean\n",
    "\n",
    "        return policy_posteriors, policy_sds, likelihoods, z_means, z_sds\n",
    "\n",
    "\n",
    "    def evaluate_policy(self, policy_posteriors, policy_sd, predicted_likelihood, predicted_posterior, predicted_posterior_sd):\n",
    "\n",
    "        return self.FEEF(policy_posteriors, policy_sd, predicted_likelihood, predicted_posterior, predicted_posterior_sd)\n",
    "\n",
    "\n",
    "    def FEEF(self, policy_posteriors_list, policy_sd_list, predicted_likelihood_list, predicted_posterior_list, predicted_posterior_sd_list):\n",
    "        \"\"\"\n",
    "        Compute the FEEF for policy selection\n",
    "        :param policy_posteriors:\n",
    "        :param predicted_likelihood:\n",
    "        :param predicted_posterior:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        FEEFs = []\n",
    "\n",
    "        for t in range(self.planning_horizon):\n",
    "\n",
    "            # extract the values for each time step\n",
    "            predicted_likelihood = predicted_likelihood_list[t]\n",
    "            policy_posteriors = policy_posteriors_list[t]\n",
    "            policy_sd = policy_sd_list[t]\n",
    "            predicted_posterior = predicted_posterior_list[t]\n",
    "            predicted_posterior_sd = predicted_posterior_sd_list[t]\n",
    "\n",
    "            # !!!! evaluate the EXTRINSIC KL divergence !!!!\n",
    "\n",
    "            # convert to normal distributions\n",
    "            # TODO Why is the stddev 1s here? I think because we assume it is on the true state of the world.\n",
    "            likelihood_dist = tfp.distributions.MultivariateNormalDiag(loc=predicted_likelihood, scale_diag=np.ones_like(predicted_likelihood))\n",
    "\n",
    "            if self.prior_model is None:\n",
    "\n",
    "                # TODO how exactly is the prior defined? After you apply transformations what is the prior\n",
    "                # create the prior distribution\n",
    "                prior_preferences_mean = tf.convert_to_tensor(np.stack([self.given_prior_mean]*self.n_policies), dtype=\"float32\")\n",
    "                prior_preferences_stddev = tf.convert_to_tensor(np.stack([self.given_prior_stddev]*self.n_policies), dtype=\"float32\")\n",
    "\n",
    "                prior_dist = tfp.distributions.MultivariateNormalDiag(loc=prior_preferences_mean, scale_diag=prior_preferences_stddev)\n",
    "\n",
    "            # TODO Fix the learned prior model\n",
    "            else:\n",
    "                prior_dist = self.prior_model()\n",
    "\n",
    "            kl_extrinsic = tfp.distributions.kl_divergence(likelihood_dist, prior_dist)\n",
    "\n",
    "            # !!!! evaluate the KL INTRINSIC part !!!!\n",
    "            policy_posteriors_dist = tfp.distributions.MultivariateNormalDiag(loc=policy_posteriors, scale_diag=policy_sd)\n",
    "            predicted_posterior_dist = tfp.distributions.MultivariateNormalDiag(loc=predicted_posterior, scale_diag=predicted_posterior_sd)\n",
    "\n",
    "            kl_intrinsic = tfp.distributions.kl_divergence(predicted_posterior_dist, policy_posteriors_dist)\n",
    "\n",
    "            FEEF = kl_extrinsic - kl_intrinsic\n",
    "\n",
    "            FEEFs.append(FEEF)\n",
    "\n",
    "        return FEEFs\n",
    "\n",
    "\n",
    "    def EFE(self, policy_posteriors, predicted_likelihood, predicted_posterior):\n",
    "        \"\"\"\n",
    "        Compute the EFE for policy selection\n",
    "        :param policy_posteriors:\n",
    "        :param predicted_likelihood:\n",
    "        :param predicted_posterior:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing with a pretrained transition model\n",
    "\n",
    "This works well! So the problem can't lie with the transition model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# enc = create_encoder(2, 2, [20])\n",
    "# dec = create_decoder(2, 2, [20])\n",
    "# vae = VAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "enc = identity_encoder\n",
    "dec = identity_decoder\n",
    "idvae = IdentityVAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "tran = TransitionGRU(2, 1, 12, 60, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.6, 0.07]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "observation_noise_stddev = [0, 0]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0, 0])  # no noise on prior\n",
    "\n",
    "print(scaled_prior_mean)\n",
    "\n",
    "daifa = DAIFAgentRecurrent(None, idvae, tran, scaled_prior_mean, prior_stddev, train_vae=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_seqs = 200\n",
    "seq_length = 500\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "next_obs_stddev = []\n",
    "actions = []\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, seq_length, epsilon=0.2)\n",
    "\n",
    "    o = transform_observations(o, observation_max, observation_min, [0, 0])\n",
    "\n",
    "    # train = np.concatenate([o[:-1], a], axis=1)\n",
    "    train = o[:-1]\n",
    "    test = o[1:]\n",
    "\n",
    "    actions.append(a)\n",
    "    ob_seqs.append(train)\n",
    "    next_obs.append(test)\n",
    "\n",
    "    ob_seqs_stddev = np.ones_like(train)\n",
    "    next_stddev = np.ones_like(test)\n",
    "\n",
    "    next_obs_stddev.append(next_stddev)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(num_seqs):\n",
    "\n",
    "    pre = ob_seqs[i]\n",
    "    next = next_obs[i]\n",
    "    acts = actions[i]\n",
    "\n",
    "    next_sd = next_obs_stddev[i]\n",
    "\n",
    "    daifa.train(pre, next, acts, None, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_seqs = 20\n",
    "seq_length = 150\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, seq_length, epsilon=0.1)\n",
    "\n",
    "    o = transform_observations(o, observation_max, observation_min, [0, 0])\n",
    "\n",
    "    train = np.concatenate([o[:-1], a], axis=1)\n",
    "    test = o[-1]\n",
    "\n",
    "    ob_seqs.append(train)\n",
    "    next_obs.append(test)\n",
    "\n",
    "ob_seqs = np.array(ob_seqs)[:, -5:, :]\n",
    "next_obs = np.array(next_obs)\n",
    "ob_seqs.shape\n",
    "\n",
    "ob_seqs_stddev = np.ones_like(ob_seqs)\n",
    "next_obs_stddev = np.ones_like(next_obs)\n",
    "\n",
    "ob_seqs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daifa.tran((ob_seqs, None))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "next_obs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "That looks fantastic!!! With enough data the transition model is training very well"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daifa.hidden_state"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "z_t_minus_1 = np.array([0.4, 0.5])\n",
    "daifa.hidden_state = None\n",
    "p, s = daifa.cem_policy_optimisation(z_t_minus_1)\n",
    "p"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daifa.tran((np.array([[[0.4, 0.5, 1]]]), None))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "daifa.train_tran = False\n",
    "daifa.train_vae = False\n",
    "\n",
    "daifa.hidden_state = None\n",
    "\n",
    "agent, succeeded, time_to_success = train_agent(env, daifa, observation_max, observation_min, observation_noise_stddev,\n",
    "                                                num_episodes=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}