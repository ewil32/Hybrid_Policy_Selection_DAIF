{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Run The Agent on Car Racing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CarRacing' from 'gym.envs.box2d' (/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/gym/envs/box2d/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgym\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgym\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01menvs\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbox2d\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CarRacing\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'CarRacing' from 'gym.envs.box2d' (/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/gym/envs/box2d/__init__.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gym\n",
    "from gym.envs.box2d import CarRacing\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from conv_vae import ConvVAE, create_conv_encoder, create_conv_decoder\n",
    "from transition_gru import TransitionGRU\n",
    "from recurrent_agent import DAIFAgentRecurrent\n",
    "from prior_model import PriorModelBellman\n",
    "\n",
    "from train_agent import train_single_agent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from util import random_observation_sequence, transform_observations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from identity_vae import IdentityVAE, identity_encoder, identity_decoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What does the agent do?\n",
    "- The agent plans using a policy then executes that policy for 12 simulation timesteps, the first two actions of the policy are executed for 6 steps each\n",
    "\n",
    "What data does it accumulate?\n",
    "- It accumulates 12 observation actions pairs\n",
    "\n",
    "How is it trained?\n",
    "- VAE is trained to reproduce observations using the latent states\n",
    "- Transition is trained by taking previous hidden state and previous latent state and trying to predict the next latent state"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Online learning For all tasks, we initialize all the agents with random weights and learn online only. Training an agent for 150 epochs takes about 3 minutes on a single CPU core (Intel I7-4870HQ). In contrast, previous approaches using active inference [Ueltzh√∂ffer, 2018, Tschantz et al., 2019, 2020] and policy gradient methods (e.g., [Liu et al., 2017]) use (offline) policy replay and typically need hours of GPU-accelerated compute while achieving similar convergence. To our knowledge, this is the first model-based RL method to learn online using neural network representations. This is afforded by the high sample efficiency of the FEEF, which directs exploration towards states that are uncertain for both the encoder and transition models.\n",
    "\n",
    "\n",
    "Why this is true?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Hide GPU from visible devices\n",
    "# tf.config.set_visible_devices([], 'GPU')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test with no prior model FEEF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 96, 96, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 48, 48, 32)   896         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 24, 24, 64)   18496       ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 12, 12, 64)   36928       ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 9216)         0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 16)           147472      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " z_stddev (Dense)               (None, 10)           170         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 10)           170         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.exp_1 (TFOpLambda)     (None, 10)           0           ['z_stddev[0][0]']               \n",
      "                                                                                                  \n",
      " sampling_1 (Sampling)          (None, 10)           0           ['z_mean[0][0]',                 \n",
      "                                                                  'tf.math.exp_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 204,132\n",
      "Trainable params: 204,132\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 9216)              101376    \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 24, 24, 64)       589888    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 48, 48, 32)       1179680   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 96, 96, 3)        221187    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,092,131\n",
      "Trainable params: 2,092,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "e = create_conv_encoder((96, 96, 3), 10)\n",
    "e.summary()\n",
    "d = create_conv_decoder(10, (96, 96, 3), conv_shapes=[12, 24, 48], num_filters=[64, 32, 3], dense_units=[12 * 12 * 64])\n",
    "d.summary()\n",
    "cvae = ConvVAE(e, d, latent_dim=10, reg_mean=[0] * 10, reg_stddev=[1] * 10)\n",
    "cvae.compile(optimizer=tf.keras.optimizers.Adam())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'gym.envs.box2d' has no attribute 'CarRacing'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [19]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m env \u001B[38;5;241m=\u001B[39m \u001B[43mgym\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mCarRacing-v0\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf_daif/lib/python3.8/site-packages/gym/envs/registration.py:235\u001B[0m, in \u001B[0;36mmake\u001B[0;34m(id, **kwargs)\u001B[0m\n\u001B[1;32m    234\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmake\u001B[39m(\u001B[38;5;28mid\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 235\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mregistry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mid\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf_daif/lib/python3.8/site-packages/gym/envs/registration.py:129\u001B[0m, in \u001B[0;36mEnvRegistry.make\u001B[0;34m(self, path, **kwargs)\u001B[0m\n\u001B[1;32m    127\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMaking new env: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, path)\n\u001B[1;32m    128\u001B[0m spec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspec(path)\n\u001B[0;32m--> 129\u001B[0m env \u001B[38;5;241m=\u001B[39m \u001B[43mspec\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m env\n",
      "File \u001B[0;32m~/miniconda3/envs/tf_daif/lib/python3.8/site-packages/gym/envs/registration.py:89\u001B[0m, in \u001B[0;36mEnvSpec.make\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m     87\u001B[0m     env \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentry_point(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_kwargs)\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 89\u001B[0m     \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mentry_point\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     90\u001B[0m     env \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_kwargs)\n\u001B[1;32m     92\u001B[0m \u001B[38;5;66;03m# Make the environment aware of which spec it came from.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf_daif/lib/python3.8/site-packages/gym/envs/registration.py:28\u001B[0m, in \u001B[0;36mload\u001B[0;34m(name)\u001B[0m\n\u001B[1;32m     26\u001B[0m mod_name, attr_name \u001B[38;5;241m=\u001B[39m name\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     27\u001B[0m mod \u001B[38;5;241m=\u001B[39m importlib\u001B[38;5;241m.\u001B[39mimport_module(mod_name)\n\u001B[0;32m---> 28\u001B[0m fn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattr_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fn\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'gym.envs.box2d' has no attribute 'CarRacing'"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CarRacing-v0\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'gym.envs.box2d' has no attribute 'CarRacing'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [18]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m next_obs \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      6\u001B[0m observations \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m----> 8\u001B[0m env \u001B[38;5;241m=\u001B[39m \u001B[43mgym\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mCarRacing-v0\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_seqs):\n\u001B[1;32m     11\u001B[0m     o, a, r \u001B[38;5;241m=\u001B[39m random_observation_sequence(env, \u001B[38;5;241m1000\u001B[39m, epsilon\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/tf_daif/lib/python3.8/site-packages/gym/envs/registration.py:235\u001B[0m, in \u001B[0;36mmake\u001B[0;34m(id, **kwargs)\u001B[0m\n\u001B[1;32m    234\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmake\u001B[39m(\u001B[38;5;28mid\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 235\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mregistry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mid\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf_daif/lib/python3.8/site-packages/gym/envs/registration.py:129\u001B[0m, in \u001B[0;36mEnvRegistry.make\u001B[0;34m(self, path, **kwargs)\u001B[0m\n\u001B[1;32m    127\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMaking new env: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, path)\n\u001B[1;32m    128\u001B[0m spec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspec(path)\n\u001B[0;32m--> 129\u001B[0m env \u001B[38;5;241m=\u001B[39m \u001B[43mspec\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m env\n",
      "File \u001B[0;32m~/miniconda3/envs/tf_daif/lib/python3.8/site-packages/gym/envs/registration.py:89\u001B[0m, in \u001B[0;36mEnvSpec.make\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m     87\u001B[0m     env \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentry_point(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_kwargs)\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 89\u001B[0m     \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mentry_point\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     90\u001B[0m     env \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_kwargs)\n\u001B[1;32m     92\u001B[0m \u001B[38;5;66;03m# Make the environment aware of which spec it came from.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf_daif/lib/python3.8/site-packages/gym/envs/registration.py:28\u001B[0m, in \u001B[0;36mload\u001B[0;34m(name)\u001B[0m\n\u001B[1;32m     26\u001B[0m mod_name, attr_name \u001B[38;5;241m=\u001B[39m name\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     27\u001B[0m mod \u001B[38;5;241m=\u001B[39m importlib\u001B[38;5;241m.\u001B[39mimport_module(mod_name)\n\u001B[0;32m---> 28\u001B[0m fn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattr_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fn\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'gym.envs.box2d' has no attribute 'CarRacing'"
     ]
    }
   ],
   "source": [
    "num_seqs = 20\n",
    "seq_length = 500\n",
    "ob_dim = 2\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "observations = []\n",
    "\n",
    "env = gym.make(\"CarRacing-v0\")\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, 1000, epsilon=0.1)\n",
    "\n",
    "    o = transform_observations(o, observation_max, observation_min, observation_noise_stddev)\n",
    "\n",
    "    train = np.concatenate([o[:-1], a], axis=1)\n",
    "    # train = o[:-1]\n",
    "    test = o[-1]\n",
    "\n",
    "    observations.append(o)\n",
    "    ob_seqs.append(train)\n",
    "    next_obs.append(test)\n",
    "\n",
    "observations = np.vstack(observations)\n",
    "\n",
    "\n",
    "observations.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.10504782, -0.0574682 ],\n       [-0.12732393, -0.08779236],\n       [-0.20319903, -0.07086513],\n       ...,\n       [ 0.8376457 ,  0.5014828 ],\n       [ 0.83929724,  0.52571157],\n       [ 0.81324907,  0.49765166]])"
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(11048, 2), dtype=float32, numpy=\narray([[-0.19076669,  0.07344449],\n       [-0.23712383, -0.06916357],\n       [-0.15090114, -0.06382605],\n       ...,\n       [ 0.5270464 ,  0.30454534],\n       [ 0.42979696,  0.29984707],\n       [ 0.41444647,  0.33361655]], dtype=float32)>"
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = agent.model_vae(observations)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test with the prior model FEEF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [],
   "source": [
    "enc = create_encoder(2, 2, [20])\n",
    "dec = create_decoder(2, 2, [20])\n",
    "vae = VAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=1, recon_stddev=0.05)\n",
    "\n",
    "pl_hoz = 5\n",
    "latent_dim = 2\n",
    "\n",
    "tran = TransitionGRU(2, 1, 12, 2*latent_dim*pl_hoz, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_model = PriorModelBellman(2)\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "# observation_noise_stddev = [0, 0]\n",
    "observation_noise_stddev = [0.05, 0.05]\n",
    "\n",
    "daifa = DAIFAgentRecurrent(prior_model,\n",
    "                           vae,\n",
    "                           tran,\n",
    "                           None,\n",
    "                           None,\n",
    "                           train_prior_model=True,\n",
    "                           planning_horizon=pl_hoz,\n",
    "                           use_kl_extrinsic=True,\n",
    "                           use_kl_intrinsic=True,\n",
    "                           use_FEEF=True,\n",
    "                           vae_train_epochs=1,\n",
    "                           tran_train_epochs=1,\n",
    "                           show_vae_training=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 541us/step - loss: 43.2122 - reconstruction_loss: 35.4409 - kl_loss: 4.9613\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 502us/step - loss: 34.9228 - reconstruction_loss: 30.3794 - kl_loss: 3.6021\n",
      "No Success\n",
      "Episode 2\n",
      "[0.72734511 0.41475897]\n",
      "tf.Tensor([-0.9416446  -0.37238172  0.92281723  0.9492423   0.9222937 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "12/12 [==============================] - 0s 579us/step - loss: 51.3675 - reconstruction_loss: 47.5108 - kl_loss: 3.1092\n",
      "Epoch 2/2\n",
      "12/12 [==============================] - 0s 517us/step - loss: 45.3729 - reconstruction_loss: 40.0032 - kl_loss: 2.6902\n",
      "Success in episode 2 at time step 363\n",
      "Episode 3\n",
      "[0.76087501 0.55071429]\n",
      "tf.Tensor([-0.9362564  -0.73097473  0.7953698   0.9418834   0.93040663], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "7/7 [==============================] - 0s 639us/step - loss: 53.8416 - reconstruction_loss: 51.0142 - kl_loss: 2.4034\n",
      "Epoch 2/2\n",
      "7/7 [==============================] - 0s 679us/step - loss: 51.1595 - reconstruction_loss: 49.4748 - kl_loss: 2.3550\n",
      "Success in episode 3 at time step 212\n",
      "Episode 4\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 429us/step - loss: 19.8572 - reconstruction_loss: 17.2837 - kl_loss: 1.4257\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 421us/step - loss: 17.3546 - reconstruction_loss: 16.1065 - kl_loss: 1.1099\n",
      "No Success\n",
      "Episode 5\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 455us/step - loss: 11.8221 - reconstruction_loss: 8.8199 - kl_loss: 1.9815\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 528us/step - loss: 8.3936 - reconstruction_loss: 6.5185 - kl_loss: 1.5884\n",
      "No Success\n",
      "Episode 6\n",
      "[-0.54825692  0.48895188]\n",
      "tf.Tensor([0.8816843 0.8845639 0.9279901 0.893922  0.7808714], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "9/9 [==============================] - 0s 591us/step - loss: 17.1007 - reconstruction_loss: 15.3005 - kl_loss: 1.4347\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 0s 511us/step - loss: 15.0931 - reconstruction_loss: 14.2229 - kl_loss: 1.4134\n",
      "Success in episode 6 at time step 299\n",
      "Episode 7\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 464us/step - loss: 16.0911 - reconstruction_loss: 13.4555 - kl_loss: 1.9102\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 472us/step - loss: 14.2934 - reconstruction_loss: 11.8847 - kl_loss: 2.1998\n",
      "No Success\n",
      "Episode 8\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 435us/step - loss: 19.4124 - reconstruction_loss: 16.0197 - kl_loss: 2.4323\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 442us/step - loss: 12.6774 - reconstruction_loss: 8.0589 - kl_loss: 3.0206\n",
      "No Success\n",
      "Episode 9\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 459us/step - loss: 8.6865 - reconstruction_loss: 3.7277 - kl_loss: 4.6067\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 455us/step - loss: 7.0164 - reconstruction_loss: 2.3176 - kl_loss: 4.5972\n",
      "No Success\n",
      "Episode 10\n",
      "[0.47022985 0.29242612]\n",
      "tf.Tensor([ 0.9472133   0.9301758  -0.06242004 -0.9026594  -0.9709959 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "12/12 [==============================] - 0s 532us/step - loss: 8.3832 - reconstruction_loss: 2.5348 - kl_loss: 5.7053\n",
      "Epoch 2/2\n",
      "12/12 [==============================] - 0s 492us/step - loss: 7.9709 - reconstruction_loss: 2.4659 - kl_loss: 5.5861\n",
      "Success in episode 10 at time step 377\n",
      "Episode 11\n",
      "[-0.50643347  0.8157402 ]\n",
      "tf.Tensor([ 0.97792655  0.9812067   0.96021533 -0.22961976 -0.7676331 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "9/9 [==============================] - 0s 584us/step - loss: 10.3076 - reconstruction_loss: 2.4627 - kl_loss: 8.0214\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 0s 546us/step - loss: 10.4431 - reconstruction_loss: 2.1299 - kl_loss: 7.8325\n",
      "Success in episode 11 at time step 290\n",
      "Episode 12\n",
      "[0.57586431 0.43796273]\n",
      "tf.Tensor([ 0.9638286   0.9396531  -0.2744222  -0.901354   -0.97019356], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "22/22 [==============================] - 0s 490us/step - loss: 7.9836 - reconstruction_loss: 1.8751 - kl_loss: 6.2644\n",
      "Epoch 2/2\n",
      "22/22 [==============================] - 0s 453us/step - loss: 7.9074 - reconstruction_loss: 1.8164 - kl_loss: 5.8754\n",
      "Success in episode 12 at time step 703\n",
      "Episode 13\n",
      "[0.77744547 0.5496738 ]\n",
      "tf.Tensor([ 0.6266486 -0.8778409 -0.9346353 -0.963947  -0.9439268], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 0s 677us/step - loss: 8.8690 - reconstruction_loss: 2.1370 - kl_loss: 6.8183\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 0s 637us/step - loss: 8.5746 - reconstruction_loss: 1.9175 - kl_loss: 6.7525\n",
      "Success in episode 13 at time step 181\n",
      "Episode 14\n",
      "[0.6948038  0.42620983]\n",
      "tf.Tensor([ 0.7490133   0.9632068   0.85674983 -0.50001407 -0.9723508 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "9/9 [==============================] - 0s 531us/step - loss: 6.0607 - reconstruction_loss: 1.7622 - kl_loss: 4.2970\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 0s 560us/step - loss: 5.9823 - reconstruction_loss: 1.5170 - kl_loss: 4.3056\n",
      "Success in episode 14 at time step 273\n",
      "Episode 15\n",
      "[-0.95150426  0.36615973]\n",
      "tf.Tensor([ 0.97900337  0.9727792   0.9771309  -0.00585001 -0.4262442 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "22/22 [==============================] - 0s 482us/step - loss: 4.3134 - reconstruction_loss: 1.4201 - kl_loss: 3.0169\n",
      "Epoch 2/2\n",
      "22/22 [==============================] - 0s 487us/step - loss: 4.3865 - reconstruction_loss: 1.3053 - kl_loss: 3.0916\n",
      "Success in episode 15 at time step 719\n",
      "Episode 16\n",
      "[-0.70467415  0.64628086]\n",
      "tf.Tensor([ 0.9593811   0.97211045  0.9515818   0.17695577 -0.78676546], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 639us/step - loss: 7.6459 - reconstruction_loss: 1.6003 - kl_loss: 5.9134\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 584us/step - loss: 7.2766 - reconstruction_loss: 1.4472 - kl_loss: 5.9532\n",
      "Success in episode 16 at time step 262\n",
      "Episode 17\n",
      "[0.84478583 0.49427607]\n",
      "tf.Tensor([-0.15286566 -0.9198607  -0.89115554  0.9903879   0.9688096 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 462us/step - loss: 4.0648 - reconstruction_loss: 1.1240 - kl_loss: 2.8940\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 495us/step - loss: 3.9907 - reconstruction_loss: 1.1002 - kl_loss: 2.9147\n",
      "Success in episode 17 at time step 992\n",
      "Episode 18\n",
      "[0.48262134 0.60646976]\n",
      "tf.Tensor([ 0.382781   -0.9075246  -0.95081615 -0.50680196  0.4195272 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "18/18 [==============================] - 0s 502us/step - loss: 7.4396 - reconstruction_loss: 1.4101 - kl_loss: 6.1881\n",
      "Epoch 2/2\n",
      "18/18 [==============================] - 0s 479us/step - loss: 7.3520 - reconstruction_loss: 1.3094 - kl_loss: 5.9424\n",
      "Success in episode 18 at time step 577\n",
      "Episode 19\n",
      "[0.76424747 0.21704342]\n",
      "tf.Tensor([ 0.95272404  0.9447682   0.14897755 -0.87428534 -0.97612065], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "28/28 [==============================] - 0s 450us/step - loss: 5.4385 - reconstruction_loss: 1.2758 - kl_loss: 4.1368\n",
      "Epoch 2/2\n",
      "28/28 [==============================] - 0s 418us/step - loss: 5.3705 - reconstruction_loss: 1.2284 - kl_loss: 4.1500\n",
      "Success in episode 19 at time step 872\n",
      "Episode 20\n",
      "[-0.85821448  0.31461916]\n",
      "tf.Tensor([0.97657514 0.95757556 0.8875779  0.6577654  0.5134638 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 545us/step - loss: 4.9066 - reconstruction_loss: 1.0451 - kl_loss: 3.8553\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 554us/step - loss: 5.1277 - reconstruction_loss: 1.1552 - kl_loss: 3.8474\n",
      "Success in episode 20 at time step 268\n",
      "Episode 21\n",
      "[0.53800753 0.72500167]\n",
      "tf.Tensor([-0.4453677  -0.9660521   0.5231939   0.9150976   0.73108095], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "11/11 [==============================] - 0s 557us/step - loss: 5.2490 - reconstruction_loss: 1.1690 - kl_loss: 4.0966\n",
      "Epoch 2/2\n",
      "11/11 [==============================] - 0s 517us/step - loss: 5.2116 - reconstruction_loss: 1.0509 - kl_loss: 4.0904\n",
      "Success in episode 21 at time step 337\n",
      "Episode 22\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 546us/step - loss: 3.8823 - reconstruction_loss: 1.0796 - kl_loss: 2.8191\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 484us/step - loss: 3.9291 - reconstruction_loss: 1.0261 - kl_loss: 2.8507\n",
      "No Success\n",
      "Episode 23\n",
      "[-0.75925083  0.39387052]\n",
      "tf.Tensor([ 0.9765866   0.97211534  0.92452526 -0.03982253 -0.15301335], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "7/7 [==============================] - 0s 616us/step - loss: 5.1638 - reconstruction_loss: 1.1085 - kl_loss: 3.8723\n",
      "Epoch 2/2\n",
      "7/7 [==============================] - 0s 576us/step - loss: 4.9579 - reconstruction_loss: 1.0296 - kl_loss: 3.8903\n",
      "Success in episode 23 at time step 238\n",
      "Episode 24\n",
      "[-0.86188767  0.35618707]\n",
      "tf.Tensor([ 0.98422056  0.9539748   0.76464933 -0.01857606  0.7713051 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "9/9 [==============================] - 0s 576us/step - loss: 5.4851 - reconstruction_loss: 0.9640 - kl_loss: 4.5257\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 0s 541us/step - loss: 5.7312 - reconstruction_loss: 1.2008 - kl_loss: 4.4864\n",
      "Success in episode 24 at time step 299\n",
      "Episode 25\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 459us/step - loss: 3.8007 - reconstruction_loss: 1.0403 - kl_loss: 2.7344\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 438us/step - loss: 3.8578 - reconstruction_loss: 1.0268 - kl_loss: 2.7633\n",
      "No Success\n",
      "Episode 26\n",
      "[0.69042481 0.20041067]\n",
      "tf.Tensor([ 0.8367145   0.43625998 -0.761107   -0.9520717   0.69731617], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "16/16 [==============================] - 0s 538us/step - loss: 6.1944 - reconstruction_loss: 1.0675 - kl_loss: 4.9407\n",
      "Epoch 2/2\n",
      "16/16 [==============================] - 0s 472us/step - loss: 5.9537 - reconstruction_loss: 0.9833 - kl_loss: 4.8731\n",
      "Success in episode 26 at time step 516\n",
      "Episode 27\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 455us/step - loss: 4.5236 - reconstruction_loss: 1.1035 - kl_loss: 3.3763\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 455us/step - loss: 4.4619 - reconstruction_loss: 1.0445 - kl_loss: 3.3988\n",
      "No Success\n",
      "Episode 28\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 442us/step - loss: 4.3779 - reconstruction_loss: 1.0583 - kl_loss: 3.2578\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 484us/step - loss: 4.2948 - reconstruction_loss: 1.0795 - kl_loss: 3.2674\n",
      "No Success\n",
      "Episode 29\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 451us/step - loss: 4.3039 - reconstruction_loss: 1.0159 - kl_loss: 3.2545\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 443us/step - loss: 4.1683 - reconstruction_loss: 0.9760 - kl_loss: 3.2339\n",
      "No Success\n",
      "Episode 30\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 470us/step - loss: 4.0202 - reconstruction_loss: 1.0366 - kl_loss: 2.9458\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 482us/step - loss: 3.9289 - reconstruction_loss: 0.9752 - kl_loss: 2.9551\n",
      "No Success\n",
      "Episode 31\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 444us/step - loss: 4.4282 - reconstruction_loss: 0.9535 - kl_loss: 3.4520\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 452us/step - loss: 4.4562 - reconstruction_loss: 0.9991 - kl_loss: 3.4235\n",
      "No Success\n",
      "Episode 32\n",
      "[0.80460431 0.56904991]\n",
      "tf.Tensor([-0.06710112 -0.95509154 -0.86668473  0.96172965  0.970596  ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "13/13 [==============================] - 0s 489us/step - loss: 4.9543 - reconstruction_loss: 1.1325 - kl_loss: 3.8224\n",
      "Epoch 2/2\n",
      "13/13 [==============================] - 0s 468us/step - loss: 4.9144 - reconstruction_loss: 1.1374 - kl_loss: 3.8082\n",
      "Success in episode 32 at time step 392\n",
      "Episode 33\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 459us/step - loss: 3.9866 - reconstruction_loss: 1.0121 - kl_loss: 2.9053\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 464us/step - loss: 3.8966 - reconstruction_loss: 1.0165 - kl_loss: 2.9144\n",
      "No Success\n",
      "Episode 34\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 493us/step - loss: 4.2330 - reconstruction_loss: 1.0049 - kl_loss: 3.2260\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 499us/step - loss: 4.2742 - reconstruction_loss: 0.9687 - kl_loss: 3.2279\n",
      "No Success\n",
      "Episode 35\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 471us/step - loss: 4.4462 - reconstruction_loss: 1.0508 - kl_loss: 3.4487\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 456us/step - loss: 4.3876 - reconstruction_loss: 0.9820 - kl_loss: 3.4413\n",
      "No Success\n",
      "Episode 36\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 454us/step - loss: 3.9240 - reconstruction_loss: 1.0218 - kl_loss: 2.9264\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 420us/step - loss: 3.9812 - reconstruction_loss: 0.9792 - kl_loss: 2.9422\n",
      "No Success\n",
      "Episode 37\n",
      "[0.72318434 0.41653738]\n",
      "tf.Tensor([ 0.53986955 -0.42233637 -0.66949624  0.7568507   0.9342028 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "30/30 [==============================] - 0s 550us/step - loss: 5.2477 - reconstruction_loss: 1.0569 - kl_loss: 4.1518\n",
      "Epoch 2/2\n",
      "30/30 [==============================] - 0s 466us/step - loss: 5.2011 - reconstruction_loss: 1.0852 - kl_loss: 4.0685\n",
      "Success in episode 37 at time step 933\n",
      "Episode 38\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 438us/step - loss: 4.6742 - reconstruction_loss: 1.0881 - kl_loss: 3.6004\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 431us/step - loss: 4.7439 - reconstruction_loss: 1.0388 - kl_loss: 3.6339\n",
      "No Success\n",
      "Episode 39\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 436us/step - loss: 4.6000 - reconstruction_loss: 1.0970 - kl_loss: 3.6193\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 467us/step - loss: 4.5858 - reconstruction_loss: 0.9751 - kl_loss: 3.6080\n",
      "No Success\n",
      "Episode 40\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 470us/step - loss: 5.0936 - reconstruction_loss: 1.0371 - kl_loss: 3.9437\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 432us/step - loss: 4.9308 - reconstruction_loss: 1.0947 - kl_loss: 3.8823\n",
      "No Success\n"
     ]
    }
   ],
   "source": [
    "# train the agent on the env\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "agent, results = train_agent(env, daifa, observation_max, observation_min, observation_noise_stddev, num_episodes=40, action_repeats=6, num_actions_to_execute=5, train_on_full_data=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test the models produced"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "data": {
      "text/plain": "(13402, 2)"
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_seqs = 20\n",
    "seq_length = 300\n",
    "ob_dim = 2\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "observations = []\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, 1000, epsilon=0.1)\n",
    "\n",
    "    o = transform_observations(o, observation_max, observation_min, observation_noise_stddev)\n",
    "\n",
    "    train = np.concatenate([o[:-1], a], axis=1)\n",
    "    # train = o[:-1]\n",
    "    test = o[-1]\n",
    "\n",
    "    observations.append(o)\n",
    "    ob_seqs.append(train)\n",
    "    next_obs.append(test)\n",
    "\n",
    "# ob_seqs = np.array(ob_seqs)\n",
    "# next_obs = np.array(next_obs)\n",
    "\n",
    "observations = np.vstack(observations)\n",
    "# observations = observations.reshape((num_seqs*(seq_length+1), ob_dim))\n",
    "\n",
    "# ob_seqs_stddev = np.ones_like(ob_seqs_flat)\n",
    "# next_obs_stddev = np.ones_like(ob_seqs_flat)\n",
    "\n",
    "observations.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.44774185e-01, -4.39785311e-02],\n       [-1.43215282e-01,  1.57184764e-05],\n       [-2.24771912e-02, -6.89451929e-02],\n       ...,\n       [ 7.06167146e-01,  4.30008805e-01],\n       [ 7.73477039e-01,  3.34660014e-01],\n       [ 9.20895826e-01,  3.92316347e-01]])"
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(13402, 2), dtype=float32, numpy=\narray([[-0.05715735, -0.05501917],\n       [-0.16295776, -0.01840568],\n       [ 0.01132495, -0.01889868],\n       ...,\n       [ 0.6116016 ,  0.32351437],\n       [ 0.7279861 ,  0.3238115 ],\n       [ 0.92589873,  0.27601212]], dtype=float32)>"
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.model_vae(observations)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Test the models produced\n",
    "num_seqs = 20\n",
    "seq_length = 300\n",
    "ob_dim = 2\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "observations = []\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, 1000, epsilon=0.1)\n",
    "\n",
    "    o = transform_observations(o, observation_max, observation_min, observation_noise_stddev)\n",
    "\n",
    "    train = np.concatenate([o[:-1], a], axis=1)\n",
    "    # train = o[:-1]\n",
    "    test = o[-1]\n",
    "\n",
    "    observations.append(o)\n",
    "    ob_seqs.append(train)\n",
    "    next_obs.append(test)\n",
    "\n",
    "# ob_seqs = np.array(ob_seqs)\n",
    "# next_obs = np.array(next_obs)\n",
    "\n",
    "observations = np.vstack(observations)\n",
    "# observations = observations.reshape((num_seqs*(seq_length+1), ob_dim))\n",
    "\n",
    "# ob_seqs_stddev = np.ones_like(ob_seqs_flat)\n",
    "# next_obs_stddev = np.ones_like(ob_seqs_flat)\n",
    "\n",
    "observations.shape\n",
    "observations\n",
    "agent.model_vae(observations)\n",
    "## Test EFE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test EFE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.83333333, 0.        ])"
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = create_encoder(2, 2, [20])\n",
    "dec = create_decoder(2, 2, [20])\n",
    "vae = VAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=1)\n",
    "\n",
    "pl_hoz = 5\n",
    "latent_dim = 2\n",
    "\n",
    "tran = TransitionGRU(2, 1, 12, 2*pl_hoz*latent_dim, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.45, 0]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_model = PriorModelBellman(2)\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "observation_noise_stddev = [0, 0]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0,0])  # no noise on prior\n",
    "\n",
    "# without prior model\n",
    "daifa = DAIFAgentRecurrent(None,\n",
    "                           vae,\n",
    "                           tran,\n",
    "                           scaled_prior_mean,\n",
    "                           prior_stddev,\n",
    "                           planning_horizon=pl_hoz,\n",
    "                           use_kl_extrinsic=True,\n",
    "                           use_kl_intrinsic=True,\n",
    "                           use_FEEF=False,\n",
    "                           vae_train_epochs=1,\n",
    "                           tran_train_epochs=1,\n",
    "                           show_vae_training=False)\n",
    "\n",
    "# with prior model\n",
    "daifa = DAIFAgentRecurrent(prior_model,\n",
    "                           vae,\n",
    "                           tran,\n",
    "                           None,\n",
    "                           None,\n",
    "                           planning_horizon=pl_hoz,\n",
    "                           use_kl_extrinsic=True,\n",
    "                           use_kl_intrinsic=True,\n",
    "                           use_FEEF=False,\n",
    "                           vae_train_epochs=1,\n",
    "                           tran_train_epochs=1,\n",
    "                           show_vae_training=False)\n",
    "\n",
    "scaled_prior_mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "[0.32907545 0.81204165]\n",
      "tf.Tensor([0.93988144 0.9176549  0.9576125  0.92440426 0.50135976], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "12/12 [==============================] - 0s 647us/step - loss: 79.1247 - reconstruction_loss: 66.5922 - kl_loss: 6.1959\n",
      "Epoch 2/2\n",
      "12/12 [==============================] - 0s 544us/step - loss: 56.3993 - reconstruction_loss: 49.0732 - kl_loss: 5.4928\n",
      "Success in episode 1 at time step 389\n",
      "Episode 2\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 438us/step - loss: 70.1578 - reconstruction_loss: 65.3552 - kl_loss: 3.8945\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 442us/step - loss: 62.2310 - reconstruction_loss: 58.4824 - kl_loss: 3.3635\n",
      "No Success\n",
      "Episode 3\n",
      "[0.69670431 0.33783742]\n",
      "tf.Tensor([ 0.9314696  -0.9435271   0.9645834   0.8415556   0.56516707], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "10/10 [==============================] - 0s 606us/step - loss: 52.3677 - reconstruction_loss: 45.6785 - kl_loss: 3.5939\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 0s 501us/step - loss: 46.2414 - reconstruction_loss: 41.3540 - kl_loss: 3.5405\n",
      "Success in episode 3 at time step 306\n",
      "Episode 4\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 490us/step - loss: 17.5091 - reconstruction_loss: 12.6776 - kl_loss: 1.7703\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 470us/step - loss: 9.0485 - reconstruction_loss: 6.6526 - kl_loss: 1.8981\n",
      "No Success\n",
      "Episode 5\n",
      "[0.49734786 0.77757351]\n",
      "tf.Tensor([ 0.98152953 -0.9801048   0.346932    0.32506007 -0.20486811], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 0s 522us/step - loss: 51.1933 - reconstruction_loss: 45.8139 - kl_loss: 2.3554\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 0s 481us/step - loss: 39.7211 - reconstruction_loss: 36.3924 - kl_loss: 2.5372\n",
      "Success in episode 5 at time step 426\n",
      "Episode 6\n",
      "[-0.08916565  0.69457532]\n",
      "tf.Tensor([ 0.86979437  0.9163867   0.45106322 -0.9567182  -0.96376824], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "17/17 [==============================] - 0s 620us/step - loss: 30.2887 - reconstruction_loss: 26.7621 - kl_loss: 1.6930\n",
      "Epoch 2/2\n",
      "17/17 [==============================] - 0s 506us/step - loss: 24.3142 - reconstruction_loss: 21.4270 - kl_loss: 2.6086\n",
      "Success in episode 6 at time step 560\n",
      "Episode 7\n",
      "[0.7740761  0.43105478]\n",
      "tf.Tensor([-0.8406548   0.22958903 -0.86530244  0.16205291  0.9585254 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 502us/step - loss: 51.1668 - reconstruction_loss: 44.3108 - kl_loss: 4.4013\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 642us/step - loss: 43.8689 - reconstruction_loss: 40.3531 - kl_loss: 4.6428\n",
      "Success in episode 7 at time step 242\n",
      "Episode 8\n",
      "[0.60109328 0.73302718]\n",
      "tf.Tensor([-0.9034789  -0.93242174 -0.9142734  -0.9228895  -0.82804745], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "30/30 [==============================] - 0s 599us/step - loss: 26.6581 - reconstruction_loss: 23.5741 - kl_loss: 3.7185\n",
      "Epoch 2/2\n",
      "30/30 [==============================] - 0s 631us/step - loss: 25.3964 - reconstruction_loss: 22.4093 - kl_loss: 3.5270\n",
      "Success in episode 8 at time step 945\n",
      "Episode 9\n",
      "[0.58582333 0.70690177]\n",
      "tf.Tensor([-0.7801693  -0.82969654 -0.92583454 -0.9501423  -0.8357265 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 0s 526us/step - loss: 37.6207 - reconstruction_loss: 32.8728 - kl_loss: 5.0782\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 0s 585us/step - loss: 35.9430 - reconstruction_loss: 31.7605 - kl_loss: 4.9600\n",
      "Success in episode 9 at time step 446\n",
      "Episode 10\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 468us/step - loss: 30.1776 - reconstruction_loss: 25.5544 - kl_loss: 3.9946\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 503us/step - loss: 26.9137 - reconstruction_loss: 18.8948 - kl_loss: 4.4838\n",
      "No Success\n",
      "Episode 11\n",
      "[-0.13406156  0.91068   ]\n",
      "tf.Tensor([0.9825429  0.450113   0.8094051  0.96760887 0.9726515 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "15/15 [==============================] - 0s 635us/step - loss: 19.5421 - reconstruction_loss: 12.5481 - kl_loss: 6.4961\n",
      "Epoch 2/2\n",
      "15/15 [==============================] - 0s 612us/step - loss: 15.8965 - reconstruction_loss: 7.9619 - kl_loss: 6.8670\n",
      "Success in episode 11 at time step 495\n",
      "Episode 12\n",
      "[-0.26456655  0.80451077]\n",
      "tf.Tensor([0.9721597  0.9052161  0.9302739  0.83734506 0.75346595], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "25/25 [==============================] - 0s 580us/step - loss: 12.4143 - reconstruction_loss: 5.5323 - kl_loss: 7.1294\n",
      "Epoch 2/2\n",
      "25/25 [==============================] - 0s 607us/step - loss: 11.0802 - reconstruction_loss: 3.7463 - kl_loss: 6.8431\n",
      "Success in episode 12 at time step 818\n",
      "Episode 13\n",
      "[0.11189345 0.84674417]\n",
      "tf.Tensor([ 0.9897314   0.5497189  -0.90938026  0.67785156  0.9646587 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 0s 638us/step - loss: 8.1991 - reconstruction_loss: 3.2571 - kl_loss: 4.5878\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 0s 620us/step - loss: 7.5046 - reconstruction_loss: 2.8409 - kl_loss: 4.5775\n",
      "Success in episode 13 at time step 192\n",
      "Episode 14\n",
      "[0.50627537 0.85736673]\n",
      "tf.Tensor([-0.95708704 -0.93841213 -0.939945   -0.30885416  0.9591544 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "10/10 [==============================] - 0s 524us/step - loss: 12.8243 - reconstruction_loss: 3.9857 - kl_loss: 8.7120\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 0s 645us/step - loss: 11.9485 - reconstruction_loss: 3.3041 - kl_loss: 8.4940\n",
      "Success in episode 14 at time step 307\n",
      "Episode 15\n",
      "[0.40779439 0.87726324]\n",
      "tf.Tensor([-0.89853    -0.92443955 -0.9282573   0.4178334   0.95529646], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "16/16 [==============================] - 0s 541us/step - loss: 6.3207 - reconstruction_loss: 1.3305 - kl_loss: 5.0124\n",
      "Epoch 2/2\n",
      "16/16 [==============================] - 0s 582us/step - loss: 6.2795 - reconstruction_loss: 1.4447 - kl_loss: 4.9020\n",
      "Success in episode 15 at time step 509\n",
      "Episode 16\n",
      "[-0.12792678  0.90065215]\n",
      "tf.Tensor([ 0.97663975  0.85461074 -0.6157359  -0.80765086  0.89361745], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 784us/step - loss: 9.5037 - reconstruction_loss: 3.4068 - kl_loss: 6.1400\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 830us/step - loss: 9.5505 - reconstruction_loss: 2.9323 - kl_loss: 6.2233\n",
      "Success in episode 16 at time step 175\n",
      "Episode 17\n",
      "[0.34461867 0.76592857]\n",
      "tf.Tensor([-0.71878654 -0.7026098  -0.9614596   0.92464733  0.9633947 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 0s 636us/step - loss: 10.0144 - reconstruction_loss: 2.2789 - kl_loss: 7.3443\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 0s 611us/step - loss: 9.1990 - reconstruction_loss: 2.2846 - kl_loss: 7.2655\n",
      "Success in episode 17 at time step 195\n",
      "Episode 18\n",
      "[0.22763537 0.87905425]\n",
      "tf.Tensor([-0.50013196 -0.8199611  -0.9188756  -0.9499112   0.9782911 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 0s 474us/step - loss: 6.2820 - reconstruction_loss: 1.0543 - kl_loss: 5.1769\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 0s 524us/step - loss: 6.0942 - reconstruction_loss: 1.0928 - kl_loss: 5.0239\n",
      "Success in episode 18 at time step 434\n",
      "Episode 19\n",
      "[0.82519335 0.04704075]\n",
      "tf.Tensor([ 0.9419391  -0.95463955 -0.9360158  -0.943113    0.44610092], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 587us/step - loss: 9.0316 - reconstruction_loss: 2.9396 - kl_loss: 6.2023\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 541us/step - loss: 8.5861 - reconstruction_loss: 2.1607 - kl_loss: 6.2835\n",
      "Success in episode 19 at time step 242\n",
      "Episode 20\n",
      "[0.56574249 0.72304362]\n",
      "tf.Tensor([-0.9569217  -0.91001046 -0.92691606 -0.58486927  0.96289206], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 598us/step - loss: 6.3744 - reconstruction_loss: 1.6380 - kl_loss: 4.6993\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 674us/step - loss: 6.1429 - reconstruction_loss: 1.4956 - kl_loss: 4.6901\n",
      "Success in episode 20 at time step 147\n"
     ]
    }
   ],
   "source": [
    "# train the agent on the env\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "agent, results = train_agent(env, daifa, observation_max, observation_min, observation_noise_stddev, num_episodes=20, action_repeats=10, num_actions_to_execute=2, train_on_full_data=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "data": {
      "text/plain": "(12806, 2)"
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test the models produced\n",
    "num_seqs = 20\n",
    "seq_length = 300\n",
    "ob_dim = 2\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "observations = []\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, 1000, epsilon=0.1)\n",
    "\n",
    "    o = transform_observations(o, observation_max, observation_min, observation_noise_stddev)\n",
    "\n",
    "    train = np.concatenate([o[:-1], a], axis=1)\n",
    "    # train = o[:-1]\n",
    "    test = o[-1]\n",
    "\n",
    "    observations.append(o)\n",
    "    ob_seqs.append(train)\n",
    "    next_obs.append(test)\n",
    "\n",
    "# ob_seqs = np.array(ob_seqs)\n",
    "# next_obs = np.array(next_obs)\n",
    "\n",
    "observations = np.vstack(observations)\n",
    "# observations = observations.reshape((num_seqs*(seq_length+1), ob_dim))\n",
    "\n",
    "# ob_seqs_stddev = np.ones_like(ob_seqs_flat)\n",
    "# next_obs_stddev = np.ones_like(ob_seqs_flat)\n",
    "\n",
    "observations.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.27734923,  0.        ],\n       [-0.27835019, -0.01286914],\n       [-0.28034457, -0.02564205],\n       ...,\n       [ 0.78566315,  0.35808382],\n       [ 0.81395161,  0.36370895],\n       [ 0.8428795 ,  0.37193014]])"
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(12806, 2), dtype=float32, numpy=\narray([[-0.26162374, -0.03878228],\n       [-0.27726045, -0.06711522],\n       [-0.24541792, -0.04369228],\n       ...,\n       [ 0.7668527 ,  0.39962938],\n       [ 0.93341327,  0.4722877 ],\n       [ 0.8112131 ,  0.41610983]], dtype=float32)>"
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.model_vae(observations)\n",
    "## Test EFE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing the Identity VAE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "enc = identity_encoder\n",
    "dec = identity_decoder\n",
    "idvae = IdentityVAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "hidden_size = 2*2*15  # 2*latent_dim * planning_size\n",
    "tran = TransitionGRU(2, 1, 12, hidden_size, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.6, 0]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "observation_noise_stddev = [0, 0]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0,0])  # no noise on prior\n",
    "\n",
    "daifa = DAIFAgentRecurrent(None, idvae, tran, scaled_prior_mean, prior_stddev)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "agent, succeeded, time_to_success = train_agent(env, daifa, observation_max, observation_min, observation_noise_stddev, num_episodes=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out = agent.tran((ob_seqs[0:1], None))\n",
    "out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = ob_seqs[0:1, -1].reshape(1,1,3)\n",
    "h = out[3]\n",
    "h = h[0, -2, :]\n",
    "h = h.numpy().reshape(1,30)\n",
    "h"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agent.tran((t, h))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ob_seqs[0:1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test to see how the agent trains on standard observation data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "enc = identity_encoder\n",
    "dec = identity_decoder\n",
    "idvae = IdentityVAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "hidden_size = 2*2*15  # 2*latent_dim * planning_size\n",
    "tran = TransitionGRU(2, 1, 12, hidden_size, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.45, 0]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "observation_noise_stddev = [0, 0]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0,0])  # no noise on prior\n",
    "\n",
    "daifa = DAIFAgentRecurrent(None, idvae, tran, scaled_prior_mean, prior_stddev, vae_train_epochs=1, tran_train_epochs=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "success, agent, t, pre_obs, post_obs, acts = run_episode(env, daifa, observation_max, observation_min, observation_noise_stddev)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pre_np = np.array(pre_obs)\n",
    "a = np.array(acts)\n",
    "a.shape\n",
    "pre_a = np.concatenate([pre_np, a], axis=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(a.max(), a.min())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pre_a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "post_obs_to_predict = np.array(post_obs)[:, 14, :]\n",
    "post_obs_to_predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agent.tran((pre_a, None))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "post_obs_to_predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Examine training the model on the observation data\n",
    "\n",
    "Does it eventually converge to a good model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_train_runs = 1\n",
    "for i in range(num_train_runs):\n",
    "\n",
    "    for j in range(len(pre)):\n",
    "        pre = pre_obs[j]\n",
    "        post = post_obs[j]\n",
    "        actions = acts[j]\n",
    "\n",
    "        daifa.train(pre, post, actions, None, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daifa.cem_policy_optimisation(np.array([0.5, 0.1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daifa.cem_policy_optimisation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test the FEEF computations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  0.5]\n"
     ]
    }
   ],
   "source": [
    "# enc = create_encoder(2, 2, [20])\n",
    "# dec = create_decoder(2, 2, [20])\n",
    "# vae = VAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "enc = identity_encoder\n",
    "dec = identity_decoder\n",
    "idvae = IdentityVAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "tran = TransitionGRU(2, 1, 12, 60, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.6, 0]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "observation_noise_stddev = [0, 0]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0, 0])  # no noise on prior\n",
    "\n",
    "print(scaled_prior_mean)\n",
    "\n",
    "daifa = DAIFAgentRecurrent(None, idvae, tran, scaled_prior_mean, prior_stddev, planning_horizon=15, n_policy_candidates=70, n_policies=1500, n_cem_policy_iterations=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "WARNING:tensorflow:From /Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/tensorflow_probability/python/distributions/distribution.py:345: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`scale_identity_multiplier` is deprecated; please combine it into `scale_diag` directly instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-06 15:23:48.777636: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "agent, succeeded, time_to_success = train_agent(env, daifa, observation_max, observation_min, observation_noise_stddev,\n",
    "                                                num_episodes=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_policy(agent, env, policy, action_repeats):\n",
    "\n",
    "    observation = env.reset()\n",
    "    obs = transform_observations(observation, observation_max, observation_min, [0, 0])\n",
    "\n",
    "    z_t_minus_1 = obs\n",
    "    p, s = agent.cem_policy_optimisation(z_t_minus_1)\n",
    "    p\n",
    "    print(obs)\n",
    "    print(p)\n",
    "\n",
    "    for action in p:\n",
    "        for t in range(action_repeats):\n",
    "            res = env.step(np.array([action]))\n",
    "            print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "z_t_minus_1 = np.array([0, 0])\n",
    "p, s = agent.cem_policy_optimisation(z_t_minus_1)\n",
    "p\n",
    "\n",
    "agent.forward_policies(p, z_t_minus_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "test_policy(agent, env, p.numpy(), 6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "z_t_minus_1 = np.array([-0.27691475,  0.01688306])\n",
    "p, s = agent.cem_policy_optimisation(z_t_minus_1)\n",
    "p"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "\n",
    "from vae_recurrent import VAE\n",
    "\n",
    "\n",
    "class DAIFAgentRecurrent:\n",
    "\n",
    "    def __init__(self,\n",
    "                 prior_model,\n",
    "                 vae,\n",
    "                 tran,\n",
    "                 given_prior_mean,\n",
    "                 given_prior_stddev,\n",
    "                 planning_horizon=15,\n",
    "                 n_policies=1500,\n",
    "                 n_cem_policy_iterations=2,\n",
    "                 n_policy_candidates=70,\n",
    "                 tran_train_epochs=1,\n",
    "                 vae_train_epochs=1,\n",
    "                 agent_time_ratio=6,\n",
    "                 train_vae=True,\n",
    "                 train_tran=True):\n",
    "\n",
    "        super(DAIFAgentRecurrent, self).__init__()\n",
    "\n",
    "        self.prior_model = prior_model\n",
    "        self.planning_horizon = planning_horizon\n",
    "        self.n_policy_candidates = n_policy_candidates\n",
    "        self.n_policies = n_policies\n",
    "        self.n_cem_policy_iterations = n_cem_policy_iterations\n",
    "\n",
    "        self.vae_train_epochs = vae_train_epochs\n",
    "        self.tran_train_epochs = tran_train_epochs\n",
    "        self.train_vae = train_vae\n",
    "        self.train_tran = train_tran\n",
    "\n",
    "        self.given_prior_mean = given_prior_mean\n",
    "        self.given_prior_stddev = given_prior_stddev\n",
    "\n",
    "        # full vae\n",
    "        self.model_vae = vae\n",
    "        self.model_vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "        # transition\n",
    "        # takes action plus last state and outputs next latent state\n",
    "        self.tran = tran\n",
    "        self.tran.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "        self.hidden_state = None\n",
    "\n",
    "        # how much is the agents planning time compressed compared to the simulation time\n",
    "        self.agent_time_ratio = agent_time_ratio\n",
    "\n",
    "\n",
    "    def select_policy(self, observation):\n",
    "\n",
    "        policy_mean, policy_stddev = self.cem_policy_optimisation(observation)\n",
    "\n",
    "        # return a distribution that we can sample from\n",
    "        return tfp.distributions.MultivariateNormalDiag(loc=policy_mean, scale_diag=policy_stddev)\n",
    "\n",
    "\n",
    "    def train(self, pre_observations_raw, post_observations_raw, actions_complete, rewards, verbose=0):\n",
    "\n",
    "        # compress the observations based on the agents time compression factor\n",
    "        # pre_observations = pre_observations_raw[::self.agent_time_ratio]  # for example take every 6th element\n",
    "        # post_observations = np.array([post_observations_raw[i] for i in range(len(post_observations_raw)) if i % self.agent_time_ratio == self.agent_time_ratio - 1])\n",
    "        #\n",
    "        # print(pre_observations_raw)\n",
    "        # print(pre_observations)\n",
    "        # print(post_observations_raw)\n",
    "        # print(post_observations)\n",
    "\n",
    "        pre_observations = pre_observations_raw\n",
    "        post_observations = post_observations_raw\n",
    "\n",
    "        # only look at the first n actions that we took\n",
    "        actions = actions_complete[0: len(pre_observations)]\n",
    "\n",
    "        num_observations = pre_observations.shape[0]\n",
    "        observation_dim = pre_observations.shape[1]\n",
    "        action_dim = actions.shape[1]\n",
    "        # action_dim = 1  # TODO fix this to allow different actions\n",
    "\n",
    "        # find the actual observed latent states using the vae\n",
    "        pre_latent_mean, pre_latent_stddev, pre_latent = self.model_vae.encoder(pre_observations)\n",
    "        post_latent_mean, post_latent_stddev, post_latent = self.model_vae.encoder(post_observations)\n",
    "\n",
    "        # set up the input training data that we use to train the transition model\n",
    "        z_train = np.concatenate([np.array(pre_latent_mean), np.array(actions)], axis=1)\n",
    "\n",
    "        # we use the sequence to find the right hidden states to use as input\n",
    "        z_train_seq = z_train.reshape((1, num_observations, observation_dim + action_dim))\n",
    "        z_train_singles = z_train.reshape(num_observations, 1, observation_dim + action_dim)\n",
    "\n",
    "        # the previous hidden state is the memory after observing some sequences but it might be None\n",
    "        if self.hidden_state is None:\n",
    "            self.hidden_state = np.zeros((1, self.tran.hidden_units))\n",
    "\n",
    "        if self.train_tran:\n",
    "            # find the hidden states at t=0, t=1, t=2, ..., t=num_observations - 1\n",
    "            _, _, _, h_states = self.tran((z_train_seq, self.hidden_state))\n",
    "\n",
    "\n",
    "            # squeeze so we make the shape [num_observations, hidden_units]\n",
    "            h_states = tf.squeeze(h_states)\n",
    "\n",
    "            # exclude the last state as this will become the hidden state later on. next hidden state will become our new memory\n",
    "            h_states_for_training = h_states[:-1]\n",
    "            # next_hidden_state = h_states[-1]\n",
    "\n",
    "            # add the current hidden state we saved to the start. This has h0, h1, h2, .. h=num_observations - 1\n",
    "            h_states_for_training = tf.concat([self.hidden_state, h_states_for_training], axis=0)\n",
    "\n",
    "\n",
    "            # use the hidden states with the pre and post observations to train transition model\n",
    "            self.tran.fit((z_train_singles, h_states_for_training), (post_latent_mean, post_latent_stddev), epochs=self.tran_train_epochs, verbose=verbose)\n",
    "\n",
    "        # now find the new predicted hidden state that we will use for finding the policy\n",
    "        # TODO not sure if I should pass the old hidden state or reset it to 0\n",
    "        _, _, final_hidden_state, _ = self.tran((z_train_seq, self.hidden_state))\n",
    "        # _, _, final_hidden_state, _ = self.tran((z_train_seq, None))\n",
    "\n",
    "        self.hidden_state = final_hidden_state\n",
    "\n",
    "        #### TRAIN THE VAE ####\n",
    "        if self.train_vae:\n",
    "            # train the vae model on post_observations because these are all new\n",
    "            self.model_vae.fit(post_observations, epochs=self.vae_train_epochs, verbose=verbose)\n",
    "\n",
    "\n",
    "\n",
    "    def cem_policy_optimisation(self, z_t_minus_one):\n",
    "\n",
    "        # need to change these two if the policy dimension changes\n",
    "        mean_best_policies = tf.zeros(self.planning_horizon)\n",
    "        std_best_policies = tf.ones(self.planning_horizon)\n",
    "\n",
    "        for i in range(self.n_cem_policy_iterations):\n",
    "            policy_distr = tfp.distributions.MultivariateNormalDiag(loc=mean_best_policies, scale_diag=std_best_policies)\n",
    "            policies = policy_distr.sample([self.n_policies])\n",
    "            policies = tf.clip_by_value(policies, clip_value_min=-1, clip_value_max=1)\n",
    "\n",
    "            # project trajectory into the future using transition model and calculate FEEF for each policy\n",
    "            policy_results = self.forward_policies(policies.numpy(), z_t_minus_one)\n",
    "            FEEFs = self.evaluate_policy(*policy_results)\n",
    "\n",
    "            FEEFs = tf.convert_to_tensor(FEEFs)\n",
    "\n",
    "            # sum over the timesteps to get the FEEF for each policy\n",
    "            FEEFs_sum = tf.reduce_sum(FEEFs, axis=0)\n",
    "\n",
    "            # multiply by one to find largest value which is euqivalent to smallest FEEF with top_k\n",
    "            neg_FEEF_sum = -1*FEEFs_sum\n",
    "\n",
    "            result = tf.math.top_k(neg_FEEF_sum, self.n_policy_candidates, sorted=False)\n",
    "            min_FEEF_indices = result.indices\n",
    "\n",
    "            # update the policy distributions\n",
    "            mean_best_policies = tf.reduce_mean(tf.gather(policies, min_FEEF_indices), axis=0)\n",
    "            std_best_policies = tf.math.reduce_std(tf.gather(policies, min_FEEF_indices), axis=0)\n",
    "\n",
    "\n",
    "        # TODO not sure why we need all of this is with the x means? I think it's for training but maybe not\n",
    "\n",
    "        # One last forward pass to gather the stats of the policy mean\n",
    "        #FEEFs, next_x_means, next_x_stds = self._forward_policies(mean_best_policies.unsqueeze(1))\n",
    "        # return mean_best_policies, std_best_policies, FEEFs.detach().squeeze(1), next_x_means.detach().squeeze(1), next_x_stds.detach().squeeze(1)\n",
    "\n",
    "        print(z_t_minus_one)\n",
    "        print(mean_best_policies)\n",
    "        return mean_best_policies, std_best_policies\n",
    "\n",
    "\n",
    "    def forward_policies(self, policies, z_t_minus_one):\n",
    "        \"\"\"\n",
    "        Forward propogate a policy and compute the FEEF of each policy\n",
    "        :param z_t_minus_one:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # stack up the new observation to have shape [self.n_policies, len(z_t_minus_one)]\n",
    "        prev_latent_mean = np.stack([z_t_minus_one]*self.n_policies)\n",
    "\n",
    "        policy_posteriors = []\n",
    "        policy_sds = []\n",
    "        likelihoods = []\n",
    "        z_means = []\n",
    "        z_sds = []\n",
    "\n",
    "        # get the starting hidden state that coressponds to the memory stored by the previous sequences. Should have shape (1, self.tran.num_hidden_units) for the observed sequence\n",
    "        # extend the current hidden state to the number of policies present\n",
    "        if self.hidden_state is None:\n",
    "            cur_hidden_state = np.zeros((self.n_policies, self.tran.hidden_units))\n",
    "        else:\n",
    "            cur_hidden_state = np.vstack([self.hidden_state]*self.n_policies)\n",
    "\n",
    "        # print(cur_hidden_state)\n",
    "\n",
    "        # find the predicted latent states from the transition model\n",
    "        for t in range(self.planning_horizon):\n",
    "\n",
    "            ob_plus_action = np.concatenate([prev_latent_mean, policies[:, t].reshape(self.n_policies, 1)], axis=1)\n",
    "            tran_input = ob_plus_action.reshape((self.n_policies, 1, ob_plus_action.shape[1]))  # reshape to pass to GRU\n",
    "\n",
    "            next_latent_mean, next_latent_sd, next_hidden_state, _ = self.tran((tran_input, cur_hidden_state))  # shape = [num policies, latent dim\n",
    "\n",
    "            # update the hidden state for use with the next policies\n",
    "            cur_hidden_state = next_hidden_state\n",
    "\n",
    "            policy_posteriors.append(next_latent_mean)\n",
    "            policy_sds.append(next_latent_sd)\n",
    "\n",
    "            next_likelihoods = self.model_vae.decoder(next_latent_mean)\n",
    "            likelihoods.append(next_likelihoods)\n",
    "\n",
    "            next_posterior_means, next_posteriors_sds, next_posteriors_z = self.model_vae.encoder(next_likelihoods)\n",
    "            z_means.append(next_posterior_means)\n",
    "            z_sds.append(next_posteriors_sds)\n",
    "\n",
    "            prev_latent_mean = next_latent_mean\n",
    "\n",
    "        return policy_posteriors, policy_sds, likelihoods, z_means, z_sds\n",
    "\n",
    "\n",
    "    def evaluate_policy(self, policy_posteriors, policy_sd, predicted_likelihood, predicted_posterior, predicted_posterior_sd):\n",
    "\n",
    "        return self.FEEF(policy_posteriors, policy_sd, predicted_likelihood, predicted_posterior, predicted_posterior_sd)\n",
    "\n",
    "\n",
    "    def FEEF(self, policy_posteriors_list, policy_sd_list, predicted_likelihood_list, predicted_posterior_list, predicted_posterior_sd_list):\n",
    "        \"\"\"\n",
    "        Compute the FEEF for policy selection\n",
    "        :param policy_posteriors:\n",
    "        :param predicted_likelihood:\n",
    "        :param predicted_posterior:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        FEEFs = []\n",
    "\n",
    "        for t in range(self.planning_horizon):\n",
    "\n",
    "            # extract the values for each time step\n",
    "            predicted_likelihood = predicted_likelihood_list[t]\n",
    "            policy_posteriors = policy_posteriors_list[t]\n",
    "            policy_sd = policy_sd_list[t]\n",
    "            predicted_posterior = predicted_posterior_list[t]\n",
    "            predicted_posterior_sd = predicted_posterior_sd_list[t]\n",
    "\n",
    "            # !!!! evaluate the EXTRINSIC KL divergence !!!!\n",
    "\n",
    "            # convert to normal distributions\n",
    "            # TODO Why is the stddev 1s here? I think because we assume it is on the true state of the world.\n",
    "            likelihood_dist = tfp.distributions.MultivariateNormalDiag(loc=predicted_likelihood, scale_diag=np.ones_like(predicted_likelihood))\n",
    "\n",
    "            if self.prior_model is None:\n",
    "\n",
    "                # TODO how exactly is the prior defined? After you apply transformations what is the prior\n",
    "                # create the prior distribution\n",
    "                prior_preferences_mean = tf.convert_to_tensor(np.stack([self.given_prior_mean]*self.n_policies), dtype=\"float32\")\n",
    "                prior_preferences_stddev = tf.convert_to_tensor(np.stack([self.given_prior_stddev]*self.n_policies), dtype=\"float32\")\n",
    "\n",
    "                prior_dist = tfp.distributions.MultivariateNormalDiag(loc=prior_preferences_mean, scale_diag=prior_preferences_stddev)\n",
    "\n",
    "            # TODO Fix the learned prior model\n",
    "            else:\n",
    "                prior_dist = self.prior_model()\n",
    "\n",
    "            kl_extrinsic = tfp.distributions.kl_divergence(likelihood_dist, prior_dist)\n",
    "\n",
    "            # !!!! evaluate the KL INTRINSIC part !!!!\n",
    "            policy_posteriors_dist = tfp.distributions.MultivariateNormalDiag(loc=policy_posteriors, scale_diag=policy_sd)\n",
    "            predicted_posterior_dist = tfp.distributions.MultivariateNormalDiag(loc=predicted_posterior, scale_diag=predicted_posterior_sd)\n",
    "\n",
    "            kl_intrinsic = tfp.distributions.kl_divergence(predicted_posterior_dist, policy_posteriors_dist)\n",
    "\n",
    "            FEEF = kl_extrinsic - kl_intrinsic\n",
    "\n",
    "            FEEFs.append(FEEF)\n",
    "\n",
    "        return FEEFs\n",
    "\n",
    "\n",
    "    def EFE(self, policy_posteriors, predicted_likelihood, predicted_posterior):\n",
    "        \"\"\"\n",
    "        Compute the EFE for policy selection\n",
    "        :param policy_posteriors:\n",
    "        :param predicted_likelihood:\n",
    "        :param predicted_posterior:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing with a pretrained transition model\n",
    "\n",
    "This works well! So the problem can't lie with the transition model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# enc = create_encoder(2, 2, [20])\n",
    "# dec = create_decoder(2, 2, [20])\n",
    "# vae = VAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "enc = identity_encoder\n",
    "dec = identity_decoder\n",
    "idvae = IdentityVAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "tran = TransitionGRU(2, 1, 12, 60, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.6, 0.07]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "observation_noise_stddev = [0, 0]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0, 0])  # no noise on prior\n",
    "\n",
    "print(scaled_prior_mean)\n",
    "\n",
    "daifa = DAIFAgentRecurrent(None, idvae, tran, scaled_prior_mean, prior_stddev, train_vae=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [],
   "source": [
    "num_seqs = 200\n",
    "seq_length = 500\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "next_obs_stddev = []\n",
    "actions = []\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, seq_length, epsilon=0.2)\n",
    "\n",
    "    o = transform_observations(o, observation_max, observation_min, [0, 0])\n",
    "\n",
    "    # train = np.concatenate([o[:-1], a], axis=1)\n",
    "    train = o[:-1]\n",
    "    test = o[1:]\n",
    "\n",
    "    actions.append(a)\n",
    "    ob_seqs.append(train)\n",
    "    next_obs.append(test)\n",
    "\n",
    "    ob_seqs_stddev = np.ones_like(train)\n",
    "    next_stddev = np.ones_like(test)\n",
    "\n",
    "    next_obs_stddev.append(next_stddev)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 1ms/step - kl_loss: 0.1993\n",
      "16/16 [==============================] - 0s 1ms/step - kl_loss: 0.0497\n",
      "16/16 [==============================] - 0s 1ms/step - kl_loss: 0.0132\n",
      "16/16 [==============================] - 0s 1ms/step - kl_loss: 0.0103\n",
      "16/16 [==============================] - 0s 1ms/step - kl_loss: 0.0097\n",
      "6/6 [==============================] - 0s 1ms/step - kl_loss: 0.0108\n",
      "16/16 [==============================] - 0s 967us/step - kl_loss: 0.0029\n",
      "16/16 [==============================] - 0s 940us/step - kl_loss: 0.0020\n",
      "15/15 [==============================] - 0s 882us/step - kl_loss: 0.0047\n",
      "16/16 [==============================] - 0s 853us/step - kl_loss: 0.0054\n",
      "16/16 [==============================] - 0s 885us/step - kl_loss: 0.0074\n",
      "16/16 [==============================] - 0s 943us/step - kl_loss: 0.0113\n",
      "8/8 [==============================] - 0s 920us/step - kl_loss: 0.0256\n",
      "16/16 [==============================] - 0s 891us/step - kl_loss: 0.0049\n",
      "16/16 [==============================] - 0s 923us/step - kl_loss: 0.0037\n",
      "16/16 [==============================] - 0s 905us/step - kl_loss: 0.0038\n",
      "16/16 [==============================] - 0s 860us/step - kl_loss: 0.0033\n",
      "14/14 [==============================] - 0s 896us/step - kl_loss: 0.0033\n",
      "16/16 [==============================] - 0s 928us/step - kl_loss: 0.0012\n",
      "7/7 [==============================] - 0s 964us/step - kl_loss: 0.0033\n",
      "16/16 [==============================] - 0s 853us/step - kl_loss: 6.2965e-04\n",
      "16/16 [==============================] - 0s 895us/step - kl_loss: 3.8473e-04\n",
      "16/16 [==============================] - 0s 886us/step - kl_loss: 9.0204e-04\n",
      "16/16 [==============================] - 0s 866us/step - kl_loss: 3.5106e-04\n",
      "7/7 [==============================] - 0s 948us/step - kl_loss: 0.0014\n",
      "16/16 [==============================] - 0s 921us/step - kl_loss: 0.0011\n",
      "16/16 [==============================] - 0s 897us/step - kl_loss: 2.8698e-04\n",
      "16/16 [==============================] - 0s 918us/step - kl_loss: 3.7622e-04\n",
      "12/12 [==============================] - 0s 979us/step - kl_loss: 7.3435e-04\n",
      "16/16 [==============================] - 0s 872us/step - kl_loss: 6.9894e-04\n",
      "16/16 [==============================] - 0s 845us/step - kl_loss: 3.9676e-04\n",
      "16/16 [==============================] - 0s 873us/step - kl_loss: 9.3522e-04\n",
      "16/16 [==============================] - 0s 898us/step - kl_loss: 5.7943e-04\n",
      "16/16 [==============================] - 0s 861us/step - kl_loss: 3.5893e-04\n",
      "16/16 [==============================] - 0s 927us/step - kl_loss: 4.9170e-04\n",
      "16/16 [==============================] - 0s 875us/step - kl_loss: 2.7267e-04\n",
      "16/16 [==============================] - 0s 838us/step - kl_loss: 1.5856e-04\n",
      "6/6 [==============================] - 0s 1ms/step - kl_loss: 9.0418e-04\n",
      "16/16 [==============================] - 0s 886us/step - kl_loss: 5.7081e-04\n",
      "12/12 [==============================] - 0s 907us/step - kl_loss: 4.9615e-04\n",
      "16/16 [==============================] - 0s 878us/step - kl_loss: 6.9546e-04\n",
      "16/16 [==============================] - 0s 857us/step - kl_loss: 2.8895e-04\n",
      "13/13 [==============================] - 0s 899us/step - kl_loss: 7.5522e-04\n",
      "16/16 [==============================] - 0s 857us/step - kl_loss: 6.0688e-04\n",
      "11/11 [==============================] - 0s 921us/step - kl_loss: 5.8398e-04\n",
      "9/9 [==============================] - 0s 976us/step - kl_loss: 0.0012\n",
      "16/16 [==============================] - 0s 898us/step - kl_loss: 6.1929e-04\n",
      "16/16 [==============================] - 0s 836us/step - kl_loss: 2.2836e-04\n",
      "10/10 [==============================] - 0s 916us/step - kl_loss: 5.1460e-04\n",
      "16/16 [==============================] - 0s 867us/step - kl_loss: 4.9099e-04\n",
      "16/16 [==============================] - 0s 858us/step - kl_loss: 3.6082e-04\n",
      "16/16 [==============================] - 0s 889us/step - kl_loss: 3.1299e-04\n",
      "16/16 [==============================] - 0s 902us/step - kl_loss: 8.5156e-04\n",
      "16/16 [==============================] - 0s 921us/step - kl_loss: 0.0018\n",
      "16/16 [==============================] - 0s 852us/step - kl_loss: 0.0030\n",
      "10/10 [==============================] - 0s 915us/step - kl_loss: 0.0085\n",
      "16/16 [==============================] - 0s 897us/step - kl_loss: 0.0071\n",
      "16/16 [==============================] - 0s 917us/step - kl_loss: 0.0035\n",
      "16/16 [==============================] - 0s 873us/step - kl_loss: 0.0035\n",
      "16/16 [==============================] - 0s 890us/step - kl_loss: 0.0026\n",
      "16/16 [==============================] - 0s 882us/step - kl_loss: 0.0020\n",
      "7/7 [==============================] - 0s 966us/step - kl_loss: 0.0028\n",
      "16/16 [==============================] - 0s 896us/step - kl_loss: 0.0013\n",
      "12/12 [==============================] - 0s 911us/step - kl_loss: 0.0014\n",
      "14/14 [==============================] - 0s 918us/step - kl_loss: 0.0015\n",
      "16/16 [==============================] - 0s 880us/step - kl_loss: 8.1093e-04\n",
      "16/16 [==============================] - 0s 859us/step - kl_loss: 5.0124e-04\n",
      "16/16 [==============================] - 0s 862us/step - kl_loss: 2.6348e-04\n",
      "8/8 [==============================] - 0s 976us/step - kl_loss: 5.0341e-04\n",
      "10/10 [==============================] - 0s 871us/step - kl_loss: 4.9221e-04\n",
      "16/16 [==============================] - 0s 873us/step - kl_loss: 2.3029e-04\n",
      "16/16 [==============================] - 0s 906us/step - kl_loss: 6.5155e-05\n",
      "10/10 [==============================] - 0s 918us/step - kl_loss: 5.9321e-04\n",
      "16/16 [==============================] - 0s 912us/step - kl_loss: 3.2684e-04\n",
      "16/16 [==============================] - 0s 874us/step - kl_loss: 1.7592e-04\n",
      "16/16 [==============================] - 0s 863us/step - kl_loss: 1.6582e-04\n",
      "16/16 [==============================] - 0s 864us/step - kl_loss: 1.8564e-04\n",
      "16/16 [==============================] - 0s 925us/step - kl_loss: 1.4003e-04\n",
      "16/16 [==============================] - 0s 915us/step - kl_loss: 1.7503e-04\n",
      "12/12 [==============================] - 0s 975us/step - kl_loss: 2.7620e-04\n",
      "16/16 [==============================] - 0s 935us/step - kl_loss: 2.7183e-04\n",
      "11/11 [==============================] - 0s 942us/step - kl_loss: 4.2113e-04\n",
      "16/16 [==============================] - 0s 867us/step - kl_loss: 4.4761e-04\n",
      "12/12 [==============================] - 0s 916us/step - kl_loss: 2.7003e-04\n",
      "13/13 [==============================] - 0s 886us/step - kl_loss: 5.0503e-04\n",
      "12/12 [==============================] - 0s 891us/step - kl_loss: 4.9012e-04\n",
      "16/16 [==============================] - 0s 888us/step - kl_loss: 2.4893e-04\n",
      "16/16 [==============================] - 0s 1ms/step - kl_loss: 1.1987e-04\n",
      "16/16 [==============================] - 0s 875us/step - kl_loss: 2.8243e-04\n",
      "16/16 [==============================] - 0s 902us/step - kl_loss: 1.1809e-04\n",
      "16/16 [==============================] - 0s 875us/step - kl_loss: 7.0822e-05\n",
      "16/16 [==============================] - 0s 875us/step - kl_loss: 6.8286e-05\n",
      "16/16 [==============================] - 0s 900us/step - kl_loss: 2.7148e-04\n",
      "15/15 [==============================] - 0s 960us/step - kl_loss: 1.1328e-04\n",
      "16/16 [==============================] - 0s 859us/step - kl_loss: 1.6294e-04\n",
      "16/16 [==============================] - 0s 899us/step - kl_loss: 9.3267e-05\n",
      "13/13 [==============================] - 0s 930us/step - kl_loss: 2.7863e-04\n",
      "16/16 [==============================] - 0s 902us/step - kl_loss: 3.4847e-04\n",
      "16/16 [==============================] - 0s 909us/step - kl_loss: 6.9290e-05\n",
      "16/16 [==============================] - 0s 902us/step - kl_loss: 2.5452e-04\n",
      "16/16 [==============================] - 0s 904us/step - kl_loss: 2.0722e-04\n",
      "16/16 [==============================] - 0s 903us/step - kl_loss: 1.6057e-04\n",
      "16/16 [==============================] - 0s 996us/step - kl_loss: 1.6325e-04\n",
      "10/10 [==============================] - 0s 981us/step - kl_loss: 2.9550e-04\n",
      "16/16 [==============================] - 0s 905us/step - kl_loss: 2.2208e-04\n",
      "16/16 [==============================] - 0s 880us/step - kl_loss: 1.4792e-04\n",
      "14/14 [==============================] - 0s 876us/step - kl_loss: 2.6079e-04\n",
      "16/16 [==============================] - 0s 906us/step - kl_loss: 2.2629e-04\n",
      "16/16 [==============================] - 0s 927us/step - kl_loss: 1.7176e-04\n",
      "16/16 [==============================] - 0s 863us/step - kl_loss: 7.7746e-05\n",
      "16/16 [==============================] - 0s 907us/step - kl_loss: 4.9998e-05\n",
      "16/16 [==============================] - 0s 906us/step - kl_loss: 9.7333e-05\n",
      "16/16 [==============================] - 0s 875us/step - kl_loss: 9.3879e-06\n",
      "16/16 [==============================] - 0s 871us/step - kl_loss: 3.5369e-05\n",
      "16/16 [==============================] - 0s 881us/step - kl_loss: 6.1430e-05\n",
      "16/16 [==============================] - 0s 913us/step - kl_loss: 3.4472e-05\n",
      "16/16 [==============================] - 0s 881us/step - kl_loss: 4.7960e-05\n",
      "11/11 [==============================] - 0s 988us/step - kl_loss: 1.9969e-04\n",
      "16/16 [==============================] - 0s 886us/step - kl_loss: 1.3500e-04\n",
      "9/9 [==============================] - 0s 959us/step - kl_loss: 1.3400e-04\n",
      "15/15 [==============================] - 0s 927us/step - kl_loss: 1.8833e-04\n",
      "16/16 [==============================] - 0s 889us/step - kl_loss: 1.6533e-04\n",
      "16/16 [==============================] - 0s 855us/step - kl_loss: 4.5978e-05\n",
      "16/16 [==============================] - 0s 881us/step - kl_loss: 6.0070e-05\n",
      "16/16 [==============================] - 0s 878us/step - kl_loss: 1.2162e-04\n",
      "16/16 [==============================] - 0s 942us/step - kl_loss: 9.9278e-05\n",
      "16/16 [==============================] - 0s 919us/step - kl_loss: 6.8983e-05\n",
      "16/16 [==============================] - 0s 935us/step - kl_loss: 3.9110e-05\n",
      "16/16 [==============================] - 0s 885us/step - kl_loss: 3.2605e-05\n",
      "16/16 [==============================] - 0s 908us/step - kl_loss: 5.6698e-05\n",
      "16/16 [==============================] - 0s 912us/step - kl_loss: 4.7928e-05\n",
      "16/16 [==============================] - 0s 857us/step - kl_loss: 1.7173e-04\n",
      "10/10 [==============================] - 0s 866us/step - kl_loss: 1.5600e-04\n",
      "16/16 [==============================] - 0s 848us/step - kl_loss: 1.7683e-04\n",
      "10/10 [==============================] - 0s 940us/step - kl_loss: 1.8164e-04\n",
      "10/10 [==============================] - 0s 920us/step - kl_loss: 2.5693e-04\n",
      "16/16 [==============================] - 0s 887us/step - kl_loss: 1.4039e-04\n",
      "16/16 [==============================] - 0s 869us/step - kl_loss: 3.1678e-04\n",
      "16/16 [==============================] - 0s 877us/step - kl_loss: 2.0544e-04\n",
      "16/16 [==============================] - 0s 910us/step - kl_loss: 1.3164e-04\n",
      "16/16 [==============================] - 0s 920us/step - kl_loss: 3.7877e-05\n",
      "16/16 [==============================] - 0s 881us/step - kl_loss: 1.7913e-05\n",
      "16/16 [==============================] - 0s 896us/step - kl_loss: 8.9225e-06\n",
      "16/16 [==============================] - 0s 894us/step - kl_loss: 2.8919e-05\n",
      "16/16 [==============================] - 0s 862us/step - kl_loss: 8.2512e-05\n",
      "16/16 [==============================] - 0s 852us/step - kl_loss: 6.1667e-05\n",
      "16/16 [==============================] - 0s 885us/step - kl_loss: 6.0950e-05\n",
      "16/16 [==============================] - 0s 906us/step - kl_loss: 4.6845e-05\n",
      "16/16 [==============================] - 0s 872us/step - kl_loss: 1.2996e-04\n",
      "16/16 [==============================] - 0s 934us/step - kl_loss: 8.1739e-05\n",
      "11/11 [==============================] - 0s 936us/step - kl_loss: 1.4202e-04\n",
      "16/16 [==============================] - 0s 919us/step - kl_loss: 1.3208e-04\n",
      "16/16 [==============================] - 0s 857us/step - kl_loss: 2.5416e-05\n",
      "16/16 [==============================] - 0s 879us/step - kl_loss: 2.3686e-04\n",
      "16/16 [==============================] - 0s 893us/step - kl_loss: 8.3754e-05\n",
      "16/16 [==============================] - 0s 910us/step - kl_loss: 5.5621e-05\n",
      "16/16 [==============================] - 0s 908us/step - kl_loss: 4.7069e-05\n",
      "16/16 [==============================] - 0s 863us/step - kl_loss: 3.4773e-05\n",
      "16/16 [==============================] - 0s 862us/step - kl_loss: 6.9179e-05\n",
      "16/16 [==============================] - 0s 892us/step - kl_loss: 5.2090e-05\n",
      "14/14 [==============================] - 0s 910us/step - kl_loss: 2.1028e-04\n",
      "9/9 [==============================] - 0s 919us/step - kl_loss: 3.0514e-04\n",
      "16/16 [==============================] - 0s 907us/step - kl_loss: 1.1390e-04\n",
      "16/16 [==============================] - 0s 879us/step - kl_loss: 2.2734e-05\n",
      "16/16 [==============================] - 0s 883us/step - kl_loss: 2.9648e-05\n",
      "16/16 [==============================] - 0s 841us/step - kl_loss: 4.2551e-04\n",
      "16/16 [==============================] - 0s 858us/step - kl_loss: 8.8995e-05\n",
      "16/16 [==============================] - 0s 898us/step - kl_loss: 2.1523e-04\n",
      "16/16 [==============================] - 0s 878us/step - kl_loss: 2.3479e-04\n",
      "16/16 [==============================] - 0s 884us/step - kl_loss: 3.5033e-05\n",
      "16/16 [==============================] - 0s 893us/step - kl_loss: 2.2248e-05\n",
      "16/16 [==============================] - 0s 862us/step - kl_loss: 2.9066e-05\n",
      "16/16 [==============================] - 0s 865us/step - kl_loss: 2.1744e-05\n",
      "11/11 [==============================] - 0s 894us/step - kl_loss: 6.2629e-05\n",
      "16/16 [==============================] - 0s 853us/step - kl_loss: 2.1039e-04\n",
      "16/16 [==============================] - 0s 911us/step - kl_loss: 7.2563e-05\n",
      "16/16 [==============================] - 0s 911us/step - kl_loss: 7.8947e-05\n",
      "16/16 [==============================] - 0s 885us/step - kl_loss: 1.6788e-04\n",
      "16/16 [==============================] - 0s 873us/step - kl_loss: 3.6060e-04\n",
      "16/16 [==============================] - 0s 871us/step - kl_loss: 7.9603e-05\n",
      "16/16 [==============================] - 0s 888us/step - kl_loss: 3.5523e-05\n",
      "16/16 [==============================] - 0s 905us/step - kl_loss: 1.2547e-04\n",
      "16/16 [==============================] - 0s 884us/step - kl_loss: 2.6244e-04\n",
      "8/8 [==============================] - 0s 905us/step - kl_loss: 1.9605e-04\n",
      "16/16 [==============================] - 0s 880us/step - kl_loss: 7.6105e-05\n",
      "16/16 [==============================] - 0s 904us/step - kl_loss: 1.9218e-04\n",
      "16/16 [==============================] - 0s 873us/step - kl_loss: 1.0097e-04\n",
      "16/16 [==============================] - 0s 898us/step - kl_loss: 1.8222e-04\n",
      "16/16 [==============================] - 0s 913us/step - kl_loss: 5.0225e-05\n",
      "16/16 [==============================] - 0s 873us/step - kl_loss: 1.4844e-04\n",
      "12/12 [==============================] - 0s 916us/step - kl_loss: 7.4900e-05\n",
      "16/16 [==============================] - 0s 885us/step - kl_loss: 8.2255e-05\n",
      "7/7 [==============================] - 0s 998us/step - kl_loss: 1.0713e-04\n",
      "16/16 [==============================] - 0s 877us/step - kl_loss: 8.7325e-05\n",
      "16/16 [==============================] - 0s 884us/step - kl_loss: 2.1384e-05\n",
      "16/16 [==============================] - 0s 890us/step - kl_loss: 6.9913e-05\n",
      "16/16 [==============================] - 0s 861us/step - kl_loss: 4.8478e-05\n",
      "16/16 [==============================] - 0s 858us/step - kl_loss: 5.1530e-05\n",
      "16/16 [==============================] - 0s 928us/step - kl_loss: 9.6592e-06\n",
      "13/13 [==============================] - 0s 938us/step - kl_loss: 9.6443e-05\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_seqs):\n",
    "\n",
    "    pre = ob_seqs[i]\n",
    "    next = next_obs[i]\n",
    "    acts = actions[i]\n",
    "\n",
    "    next_sd = next_obs_stddev[i]\n",
    "\n",
    "    daifa.train(pre, next, acts, None, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [
    {
     "data": {
      "text/plain": "(20, 5, 3)"
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_seqs = 20\n",
    "seq_length = 150\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, seq_length, epsilon=0.1)\n",
    "\n",
    "    o = transform_observations(o, observation_max, observation_min, [0, 0])\n",
    "\n",
    "    train = np.concatenate([o[:-1], a], axis=1)\n",
    "    test = o[-1]\n",
    "\n",
    "    ob_seqs.append(train)\n",
    "    next_obs.append(test)\n",
    "\n",
    "ob_seqs = np.array(ob_seqs)[:, -5:, :]\n",
    "next_obs = np.array(next_obs)\n",
    "ob_seqs.shape\n",
    "\n",
    "ob_seqs_stddev = np.ones_like(ob_seqs)\n",
    "next_obs_stddev = np.ones_like(next_obs)\n",
    "\n",
    "ob_seqs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Tensor: shape=(20, 2), dtype=float32, numpy=\n array([[0.42757505, 0.6529479 ],\n        [0.38936174, 0.5224733 ],\n        [0.5177275 , 0.5719767 ],\n        [0.32569912, 0.5357033 ],\n        [0.5789795 , 0.37268484],\n        [0.50462687, 0.16914466],\n        [0.10576638, 0.2804633 ],\n        [0.50895584, 0.26160803],\n        [0.84278893, 0.7405859 ],\n        [0.41768757, 0.8168086 ],\n        [0.6252694 , 0.524398  ],\n        [0.29302755, 0.6640839 ],\n        [0.7982165 , 0.4708082 ],\n        [0.0011582 , 0.43203047],\n        [0.15381938, 0.3239351 ],\n        [0.51816386, 0.7722647 ],\n        [0.4246617 , 0.18837008],\n        [0.62402654, 0.48184252],\n        [0.6900874 , 0.6458197 ],\n        [0.48874134, 0.24390756]], dtype=float32)>,\n <tf.Tensor: shape=(20, 2), dtype=float32, numpy=\n array([[1.0015444 , 1.0040803 ],\n        [1.0029435 , 1.0013554 ],\n        [1.00249   , 1.0037054 ],\n        [1.0025867 , 1.0013175 ],\n        [1.0037783 , 1.0024655 ],\n        [1.0045325 , 0.9992334 ],\n        [1.0020174 , 1.0017799 ],\n        [1.0041207 , 1.0012053 ],\n        [1.0033425 , 1.0089743 ],\n        [1.0012552 , 1.0062354 ],\n        [1.0033436 , 1.0037761 ],\n        [1.0008956 , 1.0037417 ],\n        [1.0051221 , 1.0040122 ],\n        [1.0008185 , 1.0032822 ],\n        [1.0018778 , 1.0018895 ],\n        [0.99936193, 1.0098908 ],\n        [1.0041473 , 1.001115  ],\n        [1.0043585 , 1.0022985 ],\n        [1.0025626 , 1.0072029 ],\n        [1.0040324 , 1.0017579 ]], dtype=float32)>,\n <tf.Tensor: shape=(20, 60), dtype=float32, numpy=\n array([[ 0.15026245,  0.02147635,  0.08431074, ..., -0.10982125,\n          0.05334226,  0.06565161],\n        [ 0.1892961 ,  0.0171166 ,  0.14129707, ..., -0.02967911,\n          0.19479504,  0.10307508],\n        [ 0.1276658 ,  0.0259374 ,  0.09705178, ..., -0.09186851,\n          0.05516341,  0.06683648],\n        ...,\n        [ 0.12049596,  0.0347067 ,  0.12938446, ..., -0.06724519,\n          0.1028895 ,  0.08167858],\n        [ 0.067205  ,  0.0587694 ,  0.05941856, ..., -0.19308257,\n         -0.05885605,  0.03636646],\n        [-0.04927346,  0.04336642,  0.01616201, ..., -0.09991126,\n         -0.13079813,  0.00147478]], dtype=float32)>,\n <tf.Tensor: shape=(20, 5, 60), dtype=float32, numpy=\n array([[[ 0.04525499, -0.01716381,  0.02350051, ..., -0.04238965,\n           0.01428884,  0.0045097 ],\n         [ 0.09317333, -0.00512476,  0.05376579, ..., -0.07720339,\n           0.02760326,  0.0271852 ],\n         [ 0.12649374,  0.00985319,  0.0731228 , ..., -0.09722769,\n           0.03932348,  0.04809814],\n         [ 0.14352977,  0.01830245,  0.08136631, ..., -0.10614912,\n           0.04794318,  0.06033898],\n         [ 0.15026245,  0.02147635,  0.08431074, ..., -0.10982125,\n           0.05334226,  0.06565161]],\n \n        [[ 0.06360728, -0.0279705 ,  0.04693291, ...,  0.01876127,\n           0.07270339,  0.02625261],\n         [ 0.12016988, -0.01528889,  0.09293082, ...,  0.00722509,\n           0.12378819,  0.05685403],\n         [ 0.15799734,  0.00201168,  0.12204836, ..., -0.00917845,\n           0.15883154,  0.08118919],\n         [ 0.17884886,  0.0125097 ,  0.13581392, ..., -0.02153258,\n           0.1813325 ,  0.09584883],\n         [ 0.1892961 ,  0.0171166 ,  0.14129707, ..., -0.02967911,\n           0.19479504,  0.10307508]],\n \n        [[ 0.01899024, -0.00537003,  0.01712187, ..., -0.05791149,\n          -0.00749379, -0.00342179],\n         [ 0.05159665,  0.01008601,  0.04413131, ..., -0.09687613,\n          -0.01088502,  0.01538653],\n         [ 0.09476812,  0.01297409,  0.07409859, ..., -0.08821176,\n           0.01896192,  0.04428795],\n         [ 0.11822307,  0.02161739,  0.09018441, ..., -0.08948812,\n           0.0409235 ,  0.05975568],\n         [ 0.1276658 ,  0.0259374 ,  0.09705178, ..., -0.09186851,\n           0.05516341,  0.06683648]],\n \n        ...,\n \n        [[-0.01287574,  0.00913438,  0.01037965, ..., -0.07211688,\n          -0.03120288, -0.01136945],\n         [ 0.04945046, -0.00161371,  0.06758605, ..., -0.04407822,\n           0.02909646,  0.0303868 ],\n         [ 0.09147461,  0.0191132 ,  0.10595157, ..., -0.05436005,\n           0.06481314,  0.0583218 ],\n         [ 0.11274984,  0.03069214,  0.12332863, ..., -0.0628503 ,\n           0.08860222,  0.07462525],\n         [ 0.12049596,  0.0347067 ,  0.12938446, ..., -0.06724519,\n           0.1028895 ,  0.08167858]],\n \n        [[ 0.01436141, -0.00646611,  0.01604711, ..., -0.07796118,\n          -0.01446355, -0.00974533],\n         [ 0.05152211,  0.0144128 ,  0.04881622, ..., -0.12986496,\n          -0.0225791 ,  0.01168774],\n         [ 0.08065747,  0.03350948,  0.06986689, ..., -0.15249343,\n          -0.02346765,  0.03437518],\n         [ 0.09257582,  0.04136415,  0.07716379, ..., -0.15684438,\n          -0.02214691,  0.04622274],\n         [ 0.067205  ,  0.0587694 ,  0.05941856, ..., -0.19308257,\n          -0.05885605,  0.03636646]],\n \n        [[-0.04124852,  0.02623192, -0.00106705, ..., -0.07540748,\n          -0.05910962, -0.01571499],\n         [-0.0516727 ,  0.0423548 ,  0.00782672, ..., -0.10877656,\n          -0.10001399, -0.01105171],\n         [-0.05289169,  0.04889357,  0.01271122, ..., -0.11655216,\n          -0.12273175, -0.00386084],\n         [-0.04969812,  0.04598803,  0.01593486, ..., -0.10666266,\n          -0.12809363,  0.0011813 ],\n         [-0.04927346,  0.04336642,  0.01616201, ..., -0.09991126,\n          -0.13079813,  0.00147478]]], dtype=float32)>]"
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daifa.tran((ob_seqs, None))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.41424149, 0.64817536],\n       [0.37549612, 0.51434882],\n       [0.50395287, 0.56238058],\n       [0.31282919, 0.53150581],\n       [0.56830029, 0.36537232],\n       [0.49751557, 0.15729226],\n       [0.10200014, 0.28023718],\n       [0.49930485, 0.25297206],\n       [0.83264549, 0.76498072],\n       [0.40183171, 0.8195579 ],\n       [0.61205382, 0.51735449],\n       [0.28334383, 0.66585968],\n       [0.78955368, 0.48945753],\n       [0.        , 0.5       ],\n       [0.15014838, 0.32678897],\n       [0.5064109 , 0.78005801],\n       [0.41774712, 0.18253206],\n       [0.61022634, 0.47224011],\n       [0.67659513, 0.6480953 ],\n       [0.48181082, 0.23722683]])"
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_obs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "That looks fantastic!!! With enough data the transition model is training very well"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 60), dtype=float32, numpy=\narray([[ 0.1668222 ,  0.05080901,  0.20015422,  0.38899958, -0.08546768,\n        -0.04040675,  0.03512116,  0.00171472,  0.03852477,  0.20108685,\n        -0.03330585,  0.01087453, -0.03944991, -0.23539615,  0.19884759,\n         0.15129937,  0.08765514,  0.15757117, -0.16009761, -0.02254741,\n        -0.17335685, -0.09706004,  0.05607434,  0.03711884, -0.0560054 ,\n        -0.27313083,  0.02705026,  0.14458522, -0.25310335, -0.08086976,\n        -0.10635097, -0.28293777,  0.00502296,  0.2793439 ,  0.07475004,\n        -0.09199525, -0.23762226,  0.05454395, -0.07554322, -0.06423084,\n         0.11491245,  0.03344171, -0.03258195,  0.04890673,  0.07888647,\n         0.11464167,  0.31568897,  0.01460155, -0.23916677,  0.24096602,\n         0.1589966 ,  0.0215495 , -0.38883814,  0.2073881 ,  0.17495394,\n         0.30218056, -0.14856315, -0.09490789,  0.20044254,  0.12068783]],\n      dtype=float32)>"
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daifa.hidden_state"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4 0.5]\n",
      "tf.Tensor(\n",
      "[ 0.7089493   0.76423895  0.8047202   0.8124183   0.73879427  0.76978123\n",
      "  0.61311316  0.5821078   0.4306626   0.40520254  0.17977683  0.27913105\n",
      " -0.00298302  0.03768509  0.0850338 ], shape=(15,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(15,), dtype=float32, numpy=\narray([ 0.7089493 ,  0.76423895,  0.8047202 ,  0.8124183 ,  0.73879427,\n        0.76978123,  0.61311316,  0.5821078 ,  0.4306626 ,  0.40520254,\n        0.17977683,  0.27913105, -0.00298302,  0.03768509,  0.0850338 ],\n      dtype=float32)>"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_t_minus_1 = np.array([0.4, 0.5])\n",
    "daifa.hidden_state = None\n",
    "p, s = daifa.cem_policy_optimisation(z_t_minus_1)\n",
    "p"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.17485519, 0.28052184]], dtype=float32)>,\n <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.998175 , 0.9848511]], dtype=float32)>,\n <tf.Tensor: shape=(1, 60), dtype=float32, numpy=\n array([[ 0.06734794, -0.03086371,  0.04919352,  0.06776053,  0.05020184,\n         -0.02855486,  0.05532712,  0.00621268,  0.03898622,  0.06404883,\n         -0.06092996,  0.02080428, -0.03182369, -0.09051668,  0.02938318,\n          0.02920253,  0.09898859,  0.04242412, -0.0937261 , -0.07689307,\n         -0.04255384, -0.01035933,  0.0217123 ,  0.0560016 , -0.06113841,\n         -0.08259731, -0.04008626,  0.02852438, -0.09232952, -0.09844272,\n         -0.09578703, -0.0808928 ,  0.07631816,  0.10538951,  0.03266784,\n         -0.06981869, -0.13518177, -0.00443301, -0.0766279 ,  0.03137437,\n          0.10195947,  0.03933517,  0.01060682, -0.02867689,  0.05144734,\n          0.02094595,  0.07122529,  0.09150924, -0.11927285,  0.11849919,\n          0.06474774, -0.00642365, -0.15364884,  0.10189001,  0.09677684,\n          0.10298578,  0.00337658,  0.01931385,  0.07793737,  0.02707184]],\n       dtype=float32)>,\n <tf.Tensor: shape=(1, 1, 60), dtype=float32, numpy=\n array([[[ 0.06734794, -0.03086371,  0.04919352,  0.06776053,\n           0.05020184, -0.02855486,  0.05532712,  0.00621268,\n           0.03898622,  0.06404883, -0.06092996,  0.02080428,\n          -0.03182369, -0.09051668,  0.02938318,  0.02920253,\n           0.09898859,  0.04242412, -0.0937261 , -0.07689307,\n          -0.04255384, -0.01035933,  0.0217123 ,  0.0560016 ,\n          -0.06113841, -0.08259731, -0.04008626,  0.02852438,\n          -0.09232952, -0.09844272, -0.09578703, -0.0808928 ,\n           0.07631816,  0.10538951,  0.03266784, -0.06981869,\n          -0.13518177, -0.00443301, -0.0766279 ,  0.03137437,\n           0.10195947,  0.03933517,  0.01060682, -0.02867689,\n           0.05144734,  0.02094595,  0.07122529,  0.09150924,\n          -0.11927285,  0.11849919,  0.06474774, -0.00642365,\n          -0.15364884,  0.10189001,  0.09677684,  0.10298578,\n           0.00337658,  0.01931385,  0.07793737,  0.02707184]]],\n       dtype=float32)>]"
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daifa.tran((np.array([[[0.4, 0.5, 1]]]), None))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "[0.3531864 0.5      ]\n",
      "tf.Tensor(\n",
      "[0.75776505 0.808785   0.823482   0.7384236  0.66807634 0.75550365\n",
      " 0.65706307 0.57430935 0.44249344 0.50059706 0.30967107 0.3025037\n",
      " 0.23872639 0.13167822 0.03006317], shape=(15,), dtype=float32)\n",
      "[0.41072467 0.60575192]\n",
      "tf.Tensor(\n",
      "[0.80091256 0.831186   0.80336916 0.743643   0.67225486 0.7388898\n",
      " 0.6710419  0.49252346 0.45496187 0.39570916 0.33172902 0.4691094\n",
      " 0.18269321 0.02243686 0.13316137], shape=(15,), dtype=float32)\n",
      "[0.52321638 0.6161014 ]\n",
      "tf.Tensor(\n",
      "[0.7582315  0.7428887  0.78753793 0.70738727 0.6904973  0.6947737\n",
      " 0.7184091  0.63121426 0.51972836 0.44251725 0.4724567  0.35061508\n",
      " 0.20868196 0.29411447 0.1608929 ], shape=(15,), dtype=float32)\n",
      "[0.59332169 0.53282979]\n",
      "tf.Tensor(\n",
      "[ 0.8261601   0.7788568   0.7498009   0.68705684  0.71283436  0.7625619\n",
      "  0.6251273   0.59106356  0.47288027  0.37912145  0.37760547  0.27614397\n",
      "  0.17472365  0.0352636  -0.06415275], shape=(15,), dtype=float32)\n",
      "[0.57653528 0.43853916]\n",
      "tf.Tensor(\n",
      "[ 0.84993833  0.838954    0.836631    0.8009051   0.6381009   0.67451525\n",
      "  0.66360396  0.7313162   0.44090325  0.61107373  0.4429256   0.2499801\n",
      "  0.18311256  0.00455586 -0.03917548], shape=(15,), dtype=float32)\n",
      "[0.48622649 0.38311274]\n",
      "tf.Tensor(\n",
      "[0.8081694  0.80967754 0.7922341  0.7968606  0.7375868  0.6537518\n",
      " 0.64383316 0.62586427 0.55786794 0.3814907  0.40052238 0.48054183\n",
      " 0.37376764 0.13650063 0.09636682], shape=(15,), dtype=float32)\n",
      "[0.38618095 0.41815763]\n",
      "tf.Tensor(\n",
      "[0.808529   0.80657184 0.7916462  0.70533156 0.7616304  0.6811054\n",
      " 0.6398279  0.49607593 0.48863018 0.42573503 0.4255617  0.5032834\n",
      " 0.25781015 0.1669854  0.03199732], shape=(15,), dtype=float32)\n",
      "[0.36487361 0.53167849]\n",
      "tf.Tensor(\n",
      "[ 0.80258495  0.86818594  0.71748924  0.8466585   0.7656668   0.6802341\n",
      "  0.7175385   0.55456597  0.56965184  0.48494464  0.4133271   0.35727996\n",
      "  0.29771766  0.2542887  -0.04310569], shape=(15,), dtype=float32)\n",
      "[0.44369857 0.61764689]\n",
      "tf.Tensor(\n",
      "[0.8110079  0.6923667  0.79028475 0.6758299  0.71477115 0.7232198\n",
      " 0.6768123  0.6062628  0.5514061  0.47747606 0.4313433  0.3517048\n",
      " 0.39273486 0.17666398 0.08394014], shape=(15,), dtype=float32)\n",
      "[0.54803135 0.58811021]\n",
      "tf.Tensor(\n",
      "[0.77069455 0.7971718  0.76023203 0.76838154 0.70611453 0.7311224\n",
      " 0.6250644  0.6438176  0.47762975 0.5243256  0.41966495 0.36352235\n",
      " 0.40499055 0.01003213 0.061273  ], shape=(15,), dtype=float32)\n",
      "[0.58816123 0.5017748 ]\n",
      "tf.Tensor(\n",
      "[ 0.82042825  0.80002797  0.74095577  0.71816117  0.73239034  0.7092903\n",
      "  0.72302485  0.62576604  0.5700318   0.4367064   0.43498516  0.47891188\n",
      "  0.16538338  0.18202068 -0.19701585], shape=(15,), dtype=float32)\n",
      "[0.54586323 0.41759907]\n",
      "tf.Tensor(\n",
      "[0.7925538  0.797785   0.7362157  0.7193825  0.72075266 0.6847715\n",
      " 0.63142014 0.52450913 0.6858361  0.4741538  0.46578348 0.35045347\n",
      " 0.4875199  0.10972673 0.30347246], shape=(15,), dtype=float32)\n",
      "[0.44605739 0.38614578]\n",
      "tf.Tensor(\n",
      "[0.7413631  0.7655986  0.7876091  0.7940088  0.70736146 0.6543615\n",
      " 0.6855993  0.6544356  0.58999455 0.48650116 0.347798   0.12228234\n",
      " 0.24543785 0.20780389 0.03425851], shape=(15,), dtype=float32)\n",
      "[0.36494746 0.45144458]\n",
      "tf.Tensor(\n",
      "[0.8217085  0.73286784 0.7572981  0.7622988  0.7463897  0.71150637\n",
      " 0.5872628  0.6521302  0.51973563 0.41864827 0.4010417  0.27743676\n",
      " 0.38145977 0.16709988 0.10859277], shape=(15,), dtype=float32)\n",
      "[0.3799972  0.56624843]\n",
      "tf.Tensor(\n",
      "[0.7157361  0.8330341  0.7970764  0.7716476  0.79019064 0.6825232\n",
      " 0.58022153 0.49948868 0.45807794 0.5443946  0.4094528  0.3813852\n",
      " 0.3188499  0.09375567 0.2158043 ], shape=(15,), dtype=float32)\n",
      "[0.47352085 0.61658074]\n",
      "tf.Tensor(\n",
      "[0.7780647  0.80061483 0.722193   0.74317825 0.7437629  0.68641585\n",
      " 0.5962243  0.50690097 0.65318114 0.52816546 0.38895717 0.27855322\n",
      " 0.25044137 0.2727542  0.06080603], shape=(15,), dtype=float32)\n",
      "[0.56438515 0.56986869]\n",
      "tf.Tensor(\n",
      "[0.7811205  0.7339901  0.81370497 0.72263205 0.73430645 0.629454\n",
      " 0.6017497  0.6197657  0.56409466 0.43045133 0.26490685 0.2498877\n",
      " 0.31837606 0.00660494 0.18230386], shape=(15,), dtype=float32)\n",
      "[0.58373286 0.47584327]\n",
      "tf.Tensor(\n",
      "[ 0.786635    0.7676723   0.78109056  0.7734856   0.7349278   0.6434932\n",
      "  0.64729017  0.6477715   0.46817616  0.5103125   0.3484181   0.32719758\n",
      "  0.19347914  0.08783682 -0.12831853], shape=(15,), dtype=float32)\n",
      "[0.51849457 0.39698744]\n",
      "tf.Tensor(\n",
      "[0.7013822  0.82110566 0.8151903  0.83248204 0.69641477 0.7037499\n",
      " 0.65221685 0.62713647 0.6174364  0.46683326 0.47702065 0.45662794\n",
      " 0.22590521 0.12989476 0.18857364], shape=(15,), dtype=float32)\n",
      "[0.41009074 0.39329548]\n",
      "tf.Tensor(\n",
      "[0.78286713 0.75951535 0.79978824 0.7267528  0.71680486 0.65614986\n",
      " 0.6204901  0.54773957 0.50284386 0.5718347  0.25679275 0.19043566\n",
      " 0.2571739  0.09063831 0.13465643], shape=(15,), dtype=float32)\n",
      "[0.35496967 0.49114117]\n",
      "tf.Tensor(\n",
      "[ 0.7816021   0.81464404  0.8433688   0.76073045  0.763372    0.6750622\n",
      "  0.5641183   0.69435006  0.5063368   0.4080222   0.47917065  0.31884998\n",
      "  0.17305967 -0.06161011 -0.04073815], shape=(15,), dtype=float32)\n",
      "[0.40579482 0.60065321]\n",
      "tf.Tensor(\n",
      "[0.79529333 0.750566   0.79003304 0.76391315 0.73424697 0.6420629\n",
      " 0.6682913  0.6523948  0.5369906  0.5469905  0.33981997 0.26553097\n",
      " 0.0638757  0.28567824 0.23673962], shape=(15,), dtype=float32)\n",
      "[0.51507599 0.61200315]\n",
      "tf.Tensor(\n",
      "[ 0.79337245  0.7404581   0.7697803   0.73482007  0.70173734  0.73203075\n",
      "  0.5884999   0.60060364  0.46503568  0.4337764   0.4391953   0.34379748\n",
      "  0.26070306  0.07910137 -0.0782097 ], shape=(15,), dtype=float32)\n",
      "[0.58594846 0.53615845]\n",
      "tf.Tensor(\n",
      "[0.77882797 0.69763243 0.7354432  0.78261834 0.7548013  0.7395214\n",
      " 0.6853571  0.57952696 0.5142892  0.46434534 0.52490604 0.3411709\n",
      " 0.2709834  0.09081004 0.05274038], shape=(15,), dtype=float32)\n",
      "[0.57014214 0.43662953]\n",
      "tf.Tensor(\n",
      "[ 0.8492138   0.7675102   0.8595176   0.78523564  0.7543218   0.66763735\n",
      "  0.5548783   0.62393606  0.48151332  0.5518069   0.38802665  0.3985188\n",
      "  0.3526202   0.23939711 -0.12900242], shape=(15,), dtype=float32)\n",
      "[0.47905944 0.38159515]\n",
      "tf.Tensor(\n",
      "[ 0.82852745  0.81620026  0.76462984  0.6585787   0.680708    0.5028422\n",
      "  0.67517024  0.60897154  0.4863976   0.62219536  0.49263546  0.44589314\n",
      "  0.28722784  0.23585846 -0.02223484], shape=(15,), dtype=float32)\n",
      "[0.38228903 0.42519666]\n",
      "tf.Tensor(\n",
      "[0.79549915 0.73700064 0.78116643 0.7397113  0.7940053  0.78030664\n",
      " 0.5730892  0.49749538 0.5726207  0.3887233  0.46988285 0.3230513\n",
      " 0.03857424 0.06511506 0.09033238], shape=(15,), dtype=float32)\n",
      "[0.36676927 0.53437901]\n",
      "tf.Tensor(\n",
      "[0.8047022  0.75837153 0.8462696  0.7162242  0.72801363 0.65123004\n",
      " 0.59589547 0.54535824 0.6131784  0.4514287  0.6247042  0.36965016\n",
      " 0.20724636 0.18744104 0.0636511 ], shape=(15,), dtype=float32)\n",
      "[0.44490315 0.61066828]\n",
      "tf.Tensor(\n",
      "[0.81024164 0.7460855  0.7998578  0.74819976 0.7318434  0.7199478\n",
      " 0.6176514  0.6539627  0.45442376 0.54600036 0.46350846 0.27041775\n",
      " 0.35329205 0.08493165 0.01173883], shape=(15,), dtype=float32)\n",
      "[0.54393757 0.58586972]\n",
      "tf.Tensor(\n",
      "[0.83877844 0.7512684  0.8179611  0.7089987  0.62314284 0.6872689\n",
      " 0.666742   0.58867216 0.43242267 0.48708692 0.5365295  0.36782113\n",
      " 0.2323856  0.22591136 0.1930209 ], shape=(15,), dtype=float32)\n",
      "[0.58560245 0.50302988]\n",
      "tf.Tensor(\n",
      "[ 0.81615007  0.8337144   0.7280479   0.83652335  0.6593734   0.6673092\n",
      "  0.644081    0.6065941   0.49902397  0.597173    0.33554184  0.29067463\n",
      "  0.29533008  0.15974145 -0.04347519], shape=(15,), dtype=float32)\n",
      "[0.54541119 0.42172624]\n",
      "tf.Tensor(\n",
      "[0.77859366 0.7399454  0.80361915 0.8222891  0.6997945  0.7333289\n",
      " 0.5931555  0.5250654  0.38968724 0.4366026  0.41840667 0.2858042\n",
      " 0.20093226 0.11056146 0.28115508], shape=(15,), dtype=float32)\n",
      "[0.44752685 0.38479307]\n",
      "tf.Tensor(\n",
      "[ 0.82429093  0.7936777   0.8563681   0.7860239   0.7406905   0.5799222\n",
      "  0.7315543   0.5343847   0.460609    0.4562714   0.35923907  0.36962327\n",
      "  0.18014123  0.23509723 -0.02257505], shape=(15,), dtype=float32)\n",
      "[0.36856751 0.45480162]\n",
      "tf.Tensor(\n",
      "[0.8142052  0.7555646  0.8146456  0.76780176 0.7035508  0.6438452\n",
      " 0.6299063  0.6259845  0.56285286 0.4900472  0.4291155  0.2972585\n",
      " 0.23083456 0.0416389  0.11854338], shape=(15,), dtype=float32)\n",
      "[0.38437616 0.56566065]\n",
      "tf.Tensor(\n",
      "[0.8717742  0.79311955 0.8349144  0.7581415  0.6517145  0.639386\n",
      " 0.60070837 0.52159375 0.42648387 0.45765376 0.37017617 0.3854718\n",
      " 0.27083525 0.08882858 0.03711194], shape=(15,), dtype=float32)\n",
      "[0.48105746 0.61698049]\n",
      "tf.Tensor(\n",
      "[0.7816412  0.8154942  0.7475302  0.7307145  0.67497694 0.65167934\n",
      " 0.6135576  0.52580523 0.50448567 0.5064087  0.28986984 0.33856618\n",
      " 0.2111372  0.04163319 0.06080171], shape=(15,), dtype=float32)\n",
      "[0.56957929 0.56592761]\n",
      "tf.Tensor(\n",
      "[0.7415218  0.8276692  0.76559246 0.7420308  0.6718621  0.6524063\n",
      " 0.74649006 0.6595096  0.57205176 0.42472783 0.46960062 0.40188935\n",
      " 0.3381443  0.31225252 0.12252428], shape=(15,), dtype=float32)\n",
      "[0.58403423 0.47394873]\n",
      "tf.Tensor(\n",
      "[ 0.7820771   0.76585364  0.77992487  0.7481109   0.71760786  0.7291078\n",
      "  0.73734087  0.65609974  0.58259207  0.44035995  0.39198986  0.0941532\n",
      "  0.22869183 -0.15184657  0.09070029], shape=(15,), dtype=float32)\n",
      "[0.51688021 0.39510235]\n",
      "tf.Tensor(\n",
      "[0.7352284  0.75400406 0.78572464 0.801884   0.6663553  0.7583888\n",
      " 0.67039853 0.5376294  0.50376385 0.5414519  0.5258707  0.35912326\n",
      " 0.2996345  0.05289698 0.06059019], shape=(15,), dtype=float32)\n",
      "[0.40798668 0.39102628]\n",
      "tf.Tensor(\n",
      "[0.7611072  0.8020517  0.78023297 0.6550679  0.66480124 0.76778185\n",
      " 0.6363506  0.5958002  0.47454938 0.5027793  0.5354361  0.33032587\n",
      " 0.32072702 0.1383539  0.08724254], shape=(15,), dtype=float32)\n",
      "[0.3520312  0.49354863]\n",
      "tf.Tensor(\n",
      "[0.79392415 0.7739514  0.8184119  0.79044056 0.6628201  0.73477334\n",
      " 0.6351135  0.6286006  0.4333898  0.42271107 0.5196934  0.10632459\n",
      " 0.33844072 0.25389937 0.09108002], shape=(15,), dtype=float32)\n",
      "[0.40609846 0.60283605]\n",
      "tf.Tensor(\n",
      "[ 0.7884622   0.82729053  0.8360866   0.7258866   0.64380354  0.7157528\n",
      "  0.5779476   0.5710402   0.47314978  0.5921881   0.3813641   0.29816145\n",
      "  0.16894156  0.27616373 -0.02353296], shape=(15,), dtype=float32)\n",
      "[0.51798088 0.61750049]\n",
      "tf.Tensor(\n",
      "[ 0.81359965  0.763978    0.76793635  0.7462814   0.70802116  0.68962127\n",
      "  0.58806014  0.5863664   0.46981502  0.5895484   0.37318972  0.36630228\n",
      "  0.25067335  0.17080323 -0.03141759], shape=(15,), dtype=float32)\n",
      "[0.5938309  0.54126586]\n",
      "tf.Tensor(\n",
      "[0.8113294  0.768809   0.6856807  0.73540765 0.72331357 0.6783503\n",
      " 0.5949049  0.583399   0.61106104 0.5376641  0.33809215 0.40843654\n",
      " 0.18948479 0.06254447 0.08455604], shape=(15,), dtype=float32)\n",
      "[0.58345062 0.44372764]\n",
      "tf.Tensor(\n",
      "[0.8009942  0.8070976  0.7275021  0.69663674 0.71600336 0.70018804\n",
      " 0.65069294 0.66603565 0.7022384  0.45402578 0.34891218 0.22229828\n",
      " 0.2553366  0.20484611 0.02414317], shape=(15,), dtype=float32)\n",
      "[0.49264736 0.37778779]\n",
      "tf.Tensor(\n",
      "[0.74953175 0.75108176 0.7682707  0.7941111  0.6321828  0.7890561\n",
      " 0.59978455 0.5697439  0.5587085  0.5677614  0.34142888 0.45922023\n",
      " 0.34311283 0.18927541 0.04024025], shape=(15,), dtype=float32)\n",
      "[0.38186869 0.40307761]\n",
      "tf.Tensor(\n",
      "[0.8401727  0.83660525 0.7682112  0.7321585  0.7469177  0.6507884\n",
      " 0.6442639  0.64668775 0.45425525 0.34885836 0.329645   0.31632945\n",
      " 0.17799746 0.10585867 0.17687285], shape=(15,), dtype=float32)\n",
      "[0.35298689 0.53085447]\n",
      "tf.Tensor(\n",
      "[0.78200173 0.7954946  0.79973924 0.76843774 0.76992786 0.64292175\n",
      " 0.6476148  0.5449644  0.6215908  0.56584924 0.37136087 0.37221712\n",
      " 0.19877341 0.05788508 0.09599178], shape=(15,), dtype=float32)\n",
      "[0.43535255 0.62311142]\n",
      "tf.Tensor(\n",
      "[0.7988832  0.81995803 0.79670495 0.75617784 0.7537437  0.72877586\n",
      " 0.6120326  0.6481022  0.528509   0.44550523 0.54102105 0.4045983\n",
      " 0.20502405 0.10994437 0.01944509], shape=(15,), dtype=float32)\n",
      "[0.54961391 0.6057297 ]\n",
      "tf.Tensor(\n",
      "[0.82574815 0.8087345  0.79786146 0.726313   0.6651899  0.7448676\n",
      " 0.6447881  0.57326835 0.49473333 0.34929955 0.18304539 0.3073979\n",
      " 0.30910343 0.2195527  0.08602198], shape=(15,), dtype=float32)\n",
      "[0.60715892 0.51897679]\n",
      "tf.Tensor(\n",
      "[0.73939127 0.7683055  0.77412814 0.7428036  0.71010387 0.734558\n",
      " 0.6276515  0.5459412  0.57485867 0.42185855 0.32804263 0.21587849\n",
      " 0.03043543 0.26203704 0.07618994], shape=(15,), dtype=float32)\n",
      "[0.571388   0.41616956]\n",
      "tf.Tensor(\n",
      "[0.8084016  0.79118896 0.7125908  0.78489465 0.7554889  0.70314\n",
      " 0.6542661  0.6204031  0.5129748  0.53307694 0.3740126  0.1729145\n",
      " 0.2167828  0.13401434 0.3829881 ], shape=(15,), dtype=float32)\n",
      "[0.46168311 0.36681081]\n",
      "tf.Tensor(\n",
      "[ 0.80106664  0.8936466   0.76621354  0.7754078   0.77766734  0.63762605\n",
      "  0.644117    0.4937583   0.3810801   0.40484437  0.45562983  0.39988062\n",
      "  0.14110254  0.12532564 -0.0749072 ], shape=(15,), dtype=float32)\n",
      "[0.36223823 0.43672092]\n",
      "tf.Tensor(\n",
      "[ 0.8590739   0.85995823  0.7432653   0.7503428   0.80756474  0.72860914\n",
      "  0.69533503  0.65018004  0.58915186  0.49469632  0.26144204  0.31654248\n",
      "  0.1668773   0.16982254 -0.07862785], shape=(15,), dtype=float32)\n",
      "[0.37103283 0.57032034]\n",
      "tf.Tensor(\n",
      "[0.7883463  0.7421475  0.7198873  0.8076494  0.73724467 0.7076293\n",
      " 0.55192846 0.49001226 0.5639493  0.52365774 0.33413577 0.2639018\n",
      " 0.14376952 0.13097861 0.12782432], shape=(15,), dtype=float32)\n",
      "[0.47393083 0.62502963]\n",
      "tf.Tensor(\n",
      "[ 0.78464913  0.7832258   0.81469816  0.7778928   0.73397785  0.6671145\n",
      "  0.56024915  0.63776195  0.52743816  0.43552956  0.38730374  0.34354916\n",
      "  0.14792752 -0.00164434  0.15573315], shape=(15,), dtype=float32)\n",
      "[0.57156853 0.57477212]\n",
      "tf.Tensor(\n",
      "[0.8371124  0.72853917 0.8691501  0.73401505 0.6498376  0.73067075\n",
      " 0.63454086 0.55254984 0.5146528  0.4891952  0.43070522 0.43262103\n",
      " 0.1375717  0.04265443 0.3134485 ], shape=(15,), dtype=float32)\n",
      "[0.59580991 0.47936026]\n",
      "tf.Tensor(\n",
      "[ 0.81873614  0.83532137  0.7040841   0.7788191   0.6197398   0.61335325\n",
      "  0.68482035  0.5888923   0.61703384  0.4427971   0.6005854   0.20061466\n",
      "  0.14735143  0.22884987 -0.0335655 ], shape=(15,), dtype=float32)\n",
      "[0.5329938  0.39897234]\n",
      "tf.Tensor(\n",
      "[0.8065402  0.7822272  0.76538205 0.7681339  0.7753727  0.7742152\n",
      " 0.69478977 0.57195425 0.4704853  0.49332318 0.31115493 0.395126\n",
      " 0.28096202 0.04866501 0.1842206 ], shape=(15,), dtype=float32)\n",
      "[0.42374525 0.38484408]\n",
      "tf.Tensor(\n",
      "[0.85375875 0.85130006 0.82338494 0.7543496  0.5935664  0.68263274\n",
      " 0.6397417  0.6747055  0.4713774  0.47407013 0.29585087 0.24762736\n",
      " 0.16460706 0.19996603 0.0240241 ], shape=(15,), dtype=float32)\n",
      "[0.35941744 0.48232772]\n",
      "tf.Tensor(\n",
      "[0.8330857  0.7875589  0.7354576  0.7439057  0.73607373 0.72214407\n",
      " 0.57638764 0.573217   0.5422481  0.41029024 0.3359802  0.30563188\n",
      " 0.10840655 0.21389659 0.00672198], shape=(15,), dtype=float32)\n",
      "[0.40275122 0.59225201]\n",
      "tf.Tensor(\n",
      "[ 0.82999897  0.86564636  0.7875039   0.81777596  0.70565     0.67825115\n",
      "  0.61548394  0.5552539   0.42982295  0.41920453  0.4481033   0.38862363\n",
      "  0.21809898  0.06253474 -0.07581279], shape=(15,), dtype=float32)\n",
      "[0.51037026 0.6184226 ]\n",
      "tf.Tensor(\n",
      "[0.7676647  0.82916576 0.7767916  0.7539434  0.705458   0.64423805\n",
      " 0.69134396 0.44446015 0.62188345 0.49696687 0.4288368  0.4260155\n",
      " 0.28188017 0.08480137 0.05216508], shape=(15,), dtype=float32)\n",
      "[0.58867452 0.54802307]\n",
      "tf.Tensor(\n",
      "[0.8200514  0.8098292  0.80813813 0.74955344 0.6526869  0.66327983\n",
      " 0.609704   0.53753686 0.49178484 0.45022994 0.4564877  0.33983544\n",
      " 0.3784235  0.15109646 0.04174715], shape=(15,), dtype=float32)\n",
      "[0.58638319 0.45443259]\n",
      "tf.Tensor(\n",
      "[0.7696876  0.7509072  0.7973766  0.7715203  0.7091568  0.6614527\n",
      " 0.5852787  0.6455517  0.45499912 0.40769756 0.4184576  0.47384334\n",
      " 0.33827722 0.06488781 0.05048884], shape=(15,), dtype=float32)\n",
      "[0.50134118 0.37832446]\n",
      "tf.Tensor(\n",
      "[0.8192935  0.7438691  0.8174823  0.7081893  0.73018426 0.7355522\n",
      " 0.59525925 0.5514984  0.5196334  0.38062623 0.40469217 0.34332815\n",
      " 0.40626797 0.17307793 0.15640299], shape=(15,), dtype=float32)\n",
      "[0.38968613 0.39832184]\n",
      "tf.Tensor(\n",
      "[ 0.8166617   0.8328098   0.79810065  0.78592587  0.77027655  0.6313598\n",
      "  0.5805887   0.6444551   0.6290719   0.4495581   0.3667833   0.28382215\n",
      "  0.2628423  -0.02390542 -0.15235856], shape=(15,), dtype=float32)\n",
      "[0.35192616 0.51947195]\n",
      "tf.Tensor(\n",
      "[0.78434974 0.81409925 0.8017937  0.74562925 0.6691752  0.718595\n",
      " 0.60850894 0.50091076 0.5456703  0.45592985 0.43720937 0.29297298\n",
      " 0.25382063 0.32232195 0.18150227], shape=(15,), dtype=float32)\n",
      "[0.42643755 0.61913247]\n",
      "tf.Tensor(\n",
      "[0.7865445  0.8380168  0.7752155  0.7637406  0.7297546  0.70171916\n",
      " 0.6920485  0.54565537 0.52947325 0.47661933 0.4009594  0.3770377\n",
      " 0.32883    0.16308029 0.02899723], shape=(15,), dtype=float32)\n",
      "[0.54147191 0.61092481]\n",
      "tf.Tensor(\n",
      "[0.78888315 0.7469997  0.67738193 0.7490696  0.66438204 0.69212526\n",
      " 0.6257292  0.5625566  0.64628035 0.53416157 0.4505727  0.4250792\n",
      " 0.22938962 0.04641598 0.08701646], shape=(15,), dtype=float32)\n",
      "[0.60302623 0.52109476]\n",
      "tf.Tensor(\n",
      "[0.78477997 0.81664246 0.84776825 0.7173021  0.6917322  0.72397983\n",
      " 0.64939183 0.47706875 0.5227951  0.51427835 0.32041466 0.2011926\n",
      " 0.26265493 0.08005637 0.13914573], shape=(15,), dtype=float32)\n",
      "[0.57279901 0.42512558]\n",
      "tf.Tensor(\n",
      "[0.8355642  0.81322175 0.8219691  0.64820415 0.6749398  0.6151745\n",
      " 0.6576263  0.528807   0.5957073  0.31524938 0.5663655  0.27555418\n",
      " 0.14108284 0.23462236 0.08474787], shape=(15,), dtype=float32)\n",
      "[0.47154124 0.37436967]\n",
      "tf.Tensor(\n",
      "[ 0.77912587  0.8206091   0.8392971   0.6829742   0.81002873  0.71247864\n",
      "  0.6173976   0.53924984  0.5642729   0.44932613  0.42185163  0.31431144\n",
      "  0.1367163   0.162648   -0.05937104], shape=(15,), dtype=float32)\n",
      "[0.37085166 0.42617494]\n",
      "tf.Tensor(\n",
      "[ 0.7898823   0.7594188   0.79121584  0.78815037  0.7210286   0.71293074\n",
      "  0.6105649   0.70436573  0.4780255   0.39781225  0.34089234  0.3126574\n",
      "  0.20237492 -0.04093971  0.1548445 ], shape=(15,), dtype=float32)\n",
      "[0.36229389 0.54699585]\n",
      "tf.Tensor(\n",
      "[ 0.82355934  0.7344039   0.8172188   0.73402274  0.74502105  0.6534147\n",
      "  0.6435986   0.7128599   0.49431676  0.48380378  0.39066416  0.20980707\n",
      "  0.12757571  0.13026321 -0.0428597 ], shape=(15,), dtype=float32)\n",
      "[0.45297857 0.62130913]\n",
      "tf.Tensor(\n",
      "[ 0.7381621   0.71149874  0.7293028   0.7196442   0.6499199   0.7436134\n",
      "  0.6323719   0.70429844  0.6065198   0.37744427  0.3373286   0.3274003\n",
      "  0.21847181 -0.0329199   0.06734627], shape=(15,), dtype=float32)\n",
      "[0.55327263 0.58079277]\n",
      "tf.Tensor(\n",
      "[0.7875618  0.77709216 0.83968383 0.7608554  0.6851276  0.7055456\n",
      " 0.7077723  0.7634509  0.49213797 0.47112393 0.40849224 0.30878276\n",
      " 0.23586862 0.19032483 0.104571  ], shape=(15,), dtype=float32)\n",
      "[0.58605266 0.49302219]\n",
      "tf.Tensor(\n",
      "[ 0.77135384  0.77240855  0.76240754  0.7110033   0.7368906   0.73387945\n",
      "  0.7226573   0.69948393  0.53461146  0.4671657   0.29715195  0.20918204\n",
      "  0.28141868  0.21912421 -0.05751437], shape=(15,), dtype=float32)\n",
      "[0.53415447 0.40774971]\n",
      "tf.Tensor(\n",
      "[0.8164045  0.7889183  0.7453783  0.7584136  0.790255   0.69659835\n",
      " 0.55485296 0.5503677  0.4235517  0.59859073 0.27493244 0.30828068\n",
      " 0.2731018  0.03790416 0.07867999], shape=(15,), dtype=float32)\n",
      "[0.43198381 0.39000767]\n",
      "tf.Tensor(\n",
      "[ 0.84704113  0.84706455  0.757801    0.8020106   0.7303452   0.7478122\n",
      "  0.66020226  0.51668745  0.36881408  0.40496936  0.41804153  0.26775324\n",
      "  0.29054877  0.09941671 -0.02390235], shape=(15,), dtype=float32)\n",
      "[0.36699534 0.47671569]\n",
      "tf.Tensor(\n",
      "[0.777419   0.8151371  0.75728863 0.82728755 0.7308517  0.66778195\n",
      " 0.64413494 0.6297771  0.5729615  0.43044972 0.48582512 0.2614562\n",
      " 0.19151399 0.0993737  0.01213963], shape=(15,), dtype=float32)\n",
      "[0.40010066 0.58109861]\n",
      "tf.Tensor(\n",
      "[0.8289774  0.84249175 0.7708501  0.7566673  0.75550324 0.6980426\n",
      " 0.6896482  0.68317795 0.41909352 0.3745316  0.4521397  0.201769\n",
      " 0.19879925 0.13832897 0.14238796], shape=(15,), dtype=float32)\n",
      "[0.49982994 0.61265017]\n",
      "tf.Tensor(\n",
      "[0.78668094 0.8483236  0.76588315 0.74072427 0.69789535 0.76625866\n",
      " 0.5793121  0.65345925 0.49243197 0.5656529  0.30996072 0.2837328\n",
      " 0.3334923  0.18241735 0.21956131], shape=(15,), dtype=float32)\n",
      "[0.57826431 0.55251938]\n",
      "tf.Tensor(\n",
      "[0.7769138  0.7900274  0.787963   0.7225514  0.7607372  0.6719565\n",
      " 0.6733853  0.5608764  0.48230317 0.5253998  0.28176615 0.37010866\n",
      " 0.1746049  0.23498641 0.1128964 ], shape=(15,), dtype=float32)\n",
      "No Success\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "daifa.train_tran = False\n",
    "daifa.train_vae = False\n",
    "\n",
    "daifa.hidden_state = None\n",
    "\n",
    "agent, succeeded, time_to_success = train_agent(env, daifa, observation_max, observation_min, observation_noise_stddev,\n",
    "                                                num_episodes=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}