{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Run The Agent on Mountain Car"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from vae_recurrent import VAE, create_decoder, create_encoder\n",
    "from transition_gru import TransitionGRU\n",
    "from recurrent_agent import DAIFAgentRecurrent\n",
    "from prior_model import PriorModelBellman\n",
    "from habitual_action_network import HabitualAction, compute_discounted_cumulative_reward\n",
    "from ddpg import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from util import random_observation_sequence, transform_observations, test_policy, habit_policy\n",
    "from train_agent import train_single_agent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# from identity_vae import IdentityVAE, identity_encoder, identity_decoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What does the agent do?\n",
    "- The agent plans using a policy then executes that policy for 12 simulation timesteps, the first two actions of the policy are executed for 6 steps each\n",
    "\n",
    "What data does it accumulate?\n",
    "- It accumulates 12 observation actions pairs\n",
    "\n",
    "How is it trained?\n",
    "- VAE is trained to reproduce observations using the latent states\n",
    "- Transition is trained by taking previous hidden state and previous latent state and trying to predict the next latent state"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Online learning For all tasks, we initialize all the agents with random weights and learn online only. Training an agent for 150 epochs takes about 3 minutes on a single CPU core (Intel I7-4870HQ). In contrast, previous approaches using active inference [Ueltzh√∂ffer, 2018, Tschantz et al., 2019, 2020] and policy gradient methods (e.g., [Liu et al., 2017]) use (offline) policy replay and typically need hours of GPU-accelerated compute while achieving similar convergence. To our knowledge, this is the first model-based RL method to learn online using neural network representations. This is afforded by the high sample efficiency of the FEEF, which directs exploration towards states that are uncertain for both the encoder and transition models.\n",
    "\n",
    "\n",
    "Why this is true?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Hide GPU from visible devices\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test with no prior model FEEF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "pln_hrzn = 5\n",
    "latent_dim = 2\n",
    "obs_dim = 2\n",
    "\n",
    "# make the VAE\n",
    "enc = create_encoder(2, latent_dim, [20])\n",
    "dec = create_decoder(latent_dim, 2, [20])\n",
    "vae = VAE(enc, dec, latent_dim,  [0]*latent_dim, [0.3]*latent_dim, train_epochs=2, show_training=True)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "# make the TRANSITION\n",
    "tran = TransitionFeedForward(latent_dim, 1, [2*pln_hrzn*latent_dim, 2*pln_hrzn*latent_dim], 2, train_epochs=2, show_training=True)\n",
    "tran.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "# make the HABIT ACTION NET\n",
    "habit_net = HabitualAction(latent_dim, 1, [16, 16], train_epochs=2, show_training=False)\n",
    "habit_net.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "# # # make the HABIT ACTION NET\n",
    "# actor_model = get_actor(2, 1)\n",
    "# critic_model = get_critic(2, 1)\n",
    "# target_actor = get_actor(2, 1)\n",
    "# target_critic = get_critic(2, 1)\n",
    "#\n",
    "# # Making the weights equal initially\n",
    "# target_actor.set_weights(actor_model.get_weights())\n",
    "# target_critic.set_weights(critic_model.get_weights())\n",
    "# critic_optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "# actor_optimizer = tf.keras.optimizers.Adam(0.00005)\n",
    "# habit_net = BasicDDPG(actor_model, critic_model, target_actor, target_critic, tau=0.005, critic_optimizer=critic_optimizer, actor_optimizer=actor_optimizer)\n",
    "\n",
    "\n",
    "# make the PRIOR NET\n",
    "prior_model = PriorModelBellman(latent_dim, output_dim=1, scaling_factor=0.01, show_training=False, use_tanh_on_output=False)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.45, 0]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "# observation_noise_stddev = [0, 0]\n",
    "observation_noise_stddev = [0.05, 0.05]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0,0])  # no noise on prior"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "daifa = DAIFAgent(prior_model,\n",
    "                           vae,\n",
    "                           tran,\n",
    "                           habit_net,\n",
    "                           planning_horizon=pln_hrzn,\n",
    "                           use_kl_extrinsic=False,  # maybe this works\n",
    "                           use_kl_intrinsic=True,\n",
    "                           use_FEEF=False,\n",
    "                           train_habit_net=True,\n",
    "                           train_prior_model=True,\n",
    "                           train_tran=True,\n",
    "                           train_after_exploring=True,\n",
    "                           train_with_replay=True,\n",
    "                           use_fast_thinking=True,\n",
    "                           habit_model_type=\"PG\",\n",
    "                           uncertainty_tolerance=0.1)\n",
    "\n",
    "\n",
    "daifa.train_prior = True\n",
    "daifa.prior_model.show_training = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "[-0.5413134  0.       ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 3), dtype=tf.float32, name='input_44'), name='input_44', description=\"created by layer 'input_44'\"), but it was called on an input with incompatible shape (2, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 3), dtype=tf.float32, name='input_44'), name='input_44', description=\"created by layer 'input_44'\"), but it was called on an input with incompatible shape (2, 3).\n",
      "1/1 [==============================] - 0s 147ms/step - kl_loss: 0.5025\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4624\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 56.9667 - reconstruction_loss: 49.9946 - kl_loss: 6.9721\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 20.4030 - reconstruction_loss: 13.4980 - kl_loss: 6.9050\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4934\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4537\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 46.5224 - reconstruction_loss: 40.2358 - kl_loss: 6.2866\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 42.1835 - reconstruction_loss: 35.9642 - kl_loss: 6.2193\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5122\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4728\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 175.1169 - reconstruction_loss: 169.3397 - kl_loss: 5.7772\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 143.3511 - reconstruction_loss: 137.6366 - kl_loss: 5.7145\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4079\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3734\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 178.9733 - reconstruction_loss: 173.6438 - kl_loss: 5.3295\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 141.8714 - reconstruction_loss: 136.6205 - kl_loss: 5.2509\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2482\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2245\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 111.1261 - reconstruction_loss: 105.6396 - kl_loss: 5.4865\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 118.8568 - reconstruction_loss: 113.4359 - kl_loss: 5.4209\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1580\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1412\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 101.7364 - reconstruction_loss: 95.8077 - kl_loss: 5.9288\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 208.0260 - reconstruction_loss: 202.1574 - kl_loss: 5.8686\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1372\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1237\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 52.3639 - reconstruction_loss: 46.1144 - kl_loss: 6.2495\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 123.2990 - reconstruction_loss: 117.0954 - kl_loss: 6.2036\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2043\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1865\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 100.1892 - reconstruction_loss: 93.8405 - kl_loss: 6.3487\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 113.4775 - reconstruction_loss: 107.1705 - kl_loss: 6.3070\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1810\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1646\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 92.3147 - reconstruction_loss: 86.8887 - kl_loss: 5.4259\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 96.3037 - reconstruction_loss: 90.9244 - kl_loss: 5.3793\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2182\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2003\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 72.5262 - reconstruction_loss: 67.5045 - kl_loss: 5.0217\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 103.4223 - reconstruction_loss: 98.4471 - kl_loss: 4.9751\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1876\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1722\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 110.6481 - reconstruction_loss: 106.1107 - kl_loss: 4.5375\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 135.1355 - reconstruction_loss: 130.6477 - kl_loss: 4.4878\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0765\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0682\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 191.6256 - reconstruction_loss: 186.8250 - kl_loss: 4.8006\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 75.7637 - reconstruction_loss: 71.0160 - kl_loss: 4.7478\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0595\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0520\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 129.5390 - reconstruction_loss: 124.2182 - kl_loss: 5.3208\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 52.4782 - reconstruction_loss: 47.2087 - kl_loss: 5.2695\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0435\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0402\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 116.6253 - reconstruction_loss: 111.1288 - kl_loss: 5.4965\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 71.7140 - reconstruction_loss: 66.2617 - kl_loss: 5.4524\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0674\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0621\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.3421 - reconstruction_loss: 7.8729 - kl_loss: 6.4692\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 76.1763 - reconstruction_loss: 69.7354 - kl_loss: 6.4410\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1140\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1055\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 31.0648 - reconstruction_loss: 25.9428 - kl_loss: 5.1220\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 83.6700 - reconstruction_loss: 78.5773 - kl_loss: 5.0927\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2197\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2078\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 112.1809 - reconstruction_loss: 108.2077 - kl_loss: 3.9731\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 163.5232 - reconstruction_loss: 159.5815 - kl_loss: 3.9416\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2915\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2726\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 203.9352 - reconstruction_loss: 200.5544 - kl_loss: 3.3808\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 198.5027 - reconstruction_loss: 195.1628 - kl_loss: 3.3399\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2171\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1997\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 195.5439 - reconstruction_loss: 192.2320 - kl_loss: 3.3119\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 201.9960 - reconstruction_loss: 198.7272 - kl_loss: 3.2689\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0921\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0813\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 156.9334 - reconstruction_loss: 153.3699 - kl_loss: 3.5635\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 122.5585 - reconstruction_loss: 119.0342 - kl_loss: 3.5243\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0087\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0076\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 122.3631 - reconstruction_loss: 118.0605 - kl_loss: 4.3026\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 84.6001 - reconstruction_loss: 80.3325 - kl_loss: 4.2676\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0279\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0297\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.1214 - reconstruction_loss: 12.7125 - kl_loss: 5.4089\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 201.3578 - reconstruction_loss: 195.9720 - kl_loss: 5.3859\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0453\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0453\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.1972 - reconstruction_loss: 3.4514 - kl_loss: 5.7458\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 34.5331 - reconstruction_loss: 28.8071 - kl_loss: 5.7260\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0620\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0580\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 55.7165 - reconstruction_loss: 51.3334 - kl_loss: 4.3831\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 65.2640 - reconstruction_loss: 60.9029 - kl_loss: 4.3611\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0891\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0832\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 144.2306 - reconstruction_loss: 141.0576 - kl_loss: 3.1730\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 146.2658 - reconstruction_loss: 143.1196 - kl_loss: 3.1462\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1205\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1120\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 219.3431 - reconstruction_loss: 216.3914 - kl_loss: 2.9517\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 163.9903 - reconstruction_loss: 161.0718 - kl_loss: 2.9185\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0644\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0579\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 148.6626 - reconstruction_loss: 145.8143 - kl_loss: 2.8483\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161.3475 - reconstruction_loss: 158.5310 - kl_loss: 2.8165\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0107\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0093\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 107.0012 - reconstruction_loss: 103.7895 - kl_loss: 3.2117\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 165.1582 - reconstruction_loss: 161.9742 - kl_loss: 3.1840\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0168\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0188\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 166.5872 - reconstruction_loss: 162.2189 - kl_loss: 4.3683\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 83.5811 - reconstruction_loss: 79.2471 - kl_loss: 4.3340\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0503\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0516\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 44.1517 - reconstruction_loss: 38.8795 - kl_loss: 5.2722\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 22.7664 - reconstruction_loss: 17.5198 - kl_loss: 5.2466\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0544\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0538\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 27.0295 - reconstruction_loss: 21.6193 - kl_loss: 5.4101\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.0601 - reconstruction_loss: 3.6662 - kl_loss: 5.3940\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0426\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0414\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 83.5549 - reconstruction_loss: 79.5454 - kl_loss: 4.0095\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 102.3442 - reconstruction_loss: 98.3535 - kl_loss: 3.9907\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1289\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1255\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 66.1479 - reconstruction_loss: 62.8979 - kl_loss: 3.2501\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 69.4989 - reconstruction_loss: 66.2692 - kl_loss: 3.2298\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0042\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0040\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 61.3872 - reconstruction_loss: 57.8443 - kl_loss: 3.5429\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 63.5865 - reconstruction_loss: 60.0620 - kl_loss: 3.5246\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0532\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0528\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.8660 - reconstruction_loss: 8.0592 - kl_loss: 4.8068\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 28.7057 - reconstruction_loss: 23.9152 - kl_loss: 4.7905\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0517\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0501\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6774 - reconstruction_loss: 4.6544 - kl_loss: 5.0230\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.2124 - reconstruction_loss: 6.2038 - kl_loss: 5.0087\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0171\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0160\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 30.2056 - reconstruction_loss: 26.2436 - kl_loss: 3.9620\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 35.5934 - reconstruction_loss: 31.6448 - kl_loss: 3.9486\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0555\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0552\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 75.9465 - reconstruction_loss: 72.9173 - kl_loss: 3.0292\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 91.4940 - reconstruction_loss: 88.4791 - kl_loss: 3.0149\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0775\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0753\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 111.7118 - reconstruction_loss: 109.2787 - kl_loss: 2.4331\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 119.3801 - reconstruction_loss: 116.9621 - kl_loss: 2.4180\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0861\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0825\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 146.1568 - reconstruction_loss: 143.7459 - kl_loss: 2.4109\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 137.4114 - reconstruction_loss: 135.0166 - kl_loss: 2.3948\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0033\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0028\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 94.9608 - reconstruction_loss: 92.0647 - kl_loss: 2.8961\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 81.8069 - reconstruction_loss: 78.9277 - kl_loss: 2.8792\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0374\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0390\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 135.4967 - reconstruction_loss: 131.6014 - kl_loss: 3.8954\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 60.1608 - reconstruction_loss: 56.2882 - kl_loss: 3.8726\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0562\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0558\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9604 - reconstruction_loss: 2.9767 - kl_loss: 4.9837\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 49.0250 - reconstruction_loss: 44.0586 - kl_loss: 4.9663\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0262\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0254\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.9541 - reconstruction_loss: 10.2491 - kl_loss: 4.7051\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.1165 - reconstruction_loss: 7.4271 - kl_loss: 4.6894\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0313\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0304\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 24.1338 - reconstruction_loss: 19.8958 - kl_loss: 4.2380\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.5860 - reconstruction_loss: 7.3651 - kl_loss: 4.2210\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0089\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0085\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 31.9536 - reconstruction_loss: 28.4348 - kl_loss: 3.5188\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 23.4272 - reconstruction_loss: 19.9241 - kl_loss: 3.5031\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0304\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0286\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 47.7759 - reconstruction_loss: 44.6511 - kl_loss: 3.1248\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 63.1915 - reconstruction_loss: 60.0820 - kl_loss: 3.1095\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0072\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0067\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 23.0930 - reconstruction_loss: 19.4218 - kl_loss: 3.6711\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 40.3690 - reconstruction_loss: 36.7124 - kl_loss: 3.6565\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0358\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0348\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9924 - reconstruction_loss: 3.6039 - kl_loss: 4.3884\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.0270 - reconstruction_loss: 5.6529 - kl_loss: 4.3742\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0360\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0338\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.7623 - reconstruction_loss: 9.9145 - kl_loss: 4.8478\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.7264 - reconstruction_loss: 12.8903 - kl_loss: 4.8362\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0067\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0064\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 21.0107 - reconstruction_loss: 16.8177 - kl_loss: 4.1931\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.6146 - reconstruction_loss: 15.4327 - kl_loss: 4.1819\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0225\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0230\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 46.0229 - reconstruction_loss: 43.0189 - kl_loss: 3.0040\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 28.3390 - reconstruction_loss: 25.3456 - kl_loss: 2.9934\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1105\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 944us/step - kl_loss: 0.1069\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 59.4128 - reconstruction_loss: 56.9283 - kl_loss: 2.4846\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 76.6589 - reconstruction_loss: 74.1839 - kl_loss: 2.4750\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0064\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0062\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 49.6189 - reconstruction_loss: 46.8678 - kl_loss: 2.7512\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 51.1875 - reconstruction_loss: 48.4483 - kl_loss: 2.7393\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0130\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0130\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 84.1114 - reconstruction_loss: 80.3877 - kl_loss: 3.7237\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 39.2574 - reconstruction_loss: 35.5518 - kl_loss: 3.7056\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0595\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0590\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.3634 - reconstruction_loss: 5.4747 - kl_loss: 4.8886\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.0156 - reconstruction_loss: 11.1412 - kl_loss: 4.8744\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0335\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0327\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.9693 - reconstruction_loss: 14.8600 - kl_loss: 5.1092\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.4967 - reconstruction_loss: 8.3966 - kl_loss: 5.1001\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0088\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0084\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 28.4584 - reconstruction_loss: 24.0897 - kl_loss: 4.3687\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.0666 - reconstruction_loss: 11.7099 - kl_loss: 4.3567\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0686\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0672\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 62.1016 - reconstruction_loss: 59.0331 - kl_loss: 3.0685\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 26.4732 - reconstruction_loss: 23.4157 - kl_loss: 3.0576\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0064\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0065\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 26.8184 - reconstruction_loss: 24.0099 - kl_loss: 2.8085\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 33.3240 - reconstruction_loss: 30.5259 - kl_loss: 2.7981\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0039\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0037\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 27.6644 - reconstruction_loss: 24.3856 - kl_loss: 3.2788\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.0669 - reconstruction_loss: 9.7998 - kl_loss: 3.2671\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0079\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0080\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 40.3549 - reconstruction_loss: 36.6702 - kl_loss: 3.6847\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.9853 - reconstruction_loss: 12.3134 - kl_loss: 3.6719\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0694\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0674\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 25.8391 - reconstruction_loss: 20.9784 - kl_loss: 4.8607\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 72.8568 - reconstruction_loss: 68.0078 - kl_loss: 4.8490\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1078\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1060\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 66.1680 - reconstruction_loss: 59.0561 - kl_loss: 7.1119\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 103.5312 - reconstruction_loss: 96.4324 - kl_loss: 7.0988\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0362\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0350\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 45.1926 - reconstruction_loss: 39.0420 - kl_loss: 6.1506\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 45.6051 - reconstruction_loss: 39.4641 - kl_loss: 6.1410\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1759\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1758\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 87.0098 - reconstruction_loss: 84.0832 - kl_loss: 2.9265\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 145.1672 - reconstruction_loss: 142.2315 - kl_loss: 2.9357\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1918\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1821\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 130.6887 - reconstruction_loss: 128.9263 - kl_loss: 1.7623\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 115.6474 - reconstruction_loss: 113.8913 - kl_loss: 1.7561\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0807\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0717\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 91.4829 - reconstruction_loss: 89.5046 - kl_loss: 1.9784\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 83.3098 - reconstruction_loss: 81.3389 - kl_loss: 1.9709\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0082\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0065\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 130.4951 - reconstruction_loss: 127.9317 - kl_loss: 2.5634\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 51.9736 - reconstruction_loss: 49.4248 - kl_loss: 2.5488\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0236\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0271\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 27.7566 - reconstruction_loss: 24.0213 - kl_loss: 3.7354\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 35.9879 - reconstruction_loss: 32.2677 - kl_loss: 3.7202\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0383\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0403\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.5743 - reconstruction_loss: 4.2983 - kl_loss: 4.2760\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.1445 - reconstruction_loss: 13.8792 - kl_loss: 4.2653\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0155\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0152\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 25.4105 - reconstruction_loss: 21.9149 - kl_loss: 3.4956\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 32.5383 - reconstruction_loss: 29.0484 - kl_loss: 3.4899\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1051\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1028\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 53.4673 - reconstruction_loss: 51.2172 - kl_loss: 2.2501\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 60.1540 - reconstruction_loss: 57.9099 - kl_loss: 2.2441\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1263\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1183\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 47.2574 - reconstruction_loss: 45.0990 - kl_loss: 2.1584\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 44.7636 - reconstruction_loss: 42.6124 - kl_loss: 2.1512\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0640\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0640\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 47.8099 - reconstruction_loss: 44.4623 - kl_loss: 3.3476\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 94.2909 - reconstruction_loss: 90.9511 - kl_loss: 3.3398\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1476\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1465\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 77.1845 - reconstruction_loss: 71.4021 - kl_loss: 5.7824\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 69.4027 - reconstruction_loss: 63.6355 - kl_loss: 5.7672\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0804\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0767\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 38.5412 - reconstruction_loss: 32.2301 - kl_loss: 6.3111\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 50.5044 - reconstruction_loss: 44.1987 - kl_loss: 6.3057\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0742\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0755\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 155.0493 - reconstruction_loss: 151.4250 - kl_loss: 3.6243\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 63.4564 - reconstruction_loss: 59.8348 - kl_loss: 3.6215\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2035\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2005\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 171.7400 - reconstruction_loss: 170.1243 - kl_loss: 1.6157\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 150.6095 - reconstruction_loss: 149.0002 - kl_loss: 1.6093\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0635\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0584\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 82.7382 - reconstruction_loss: 81.0065 - kl_loss: 1.7317\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 86.6398 - reconstruction_loss: 84.9156 - kl_loss: 1.7242\n",
      "training on full data\n",
      "4 167\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 3), dtype=tf.float32, name='input_44'), name='input_44', description=\"created by layer 'input_44'\"), but it was called on an input with incompatible shape (167, 3).\n",
      "1/1 [==============================] - 0s 84ms/step - kl_loss: 0.0475\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0454\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 47.9314 - reconstruction_loss: 44.8794 - kl_loss: 3.0519\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 44.7618 - reconstruction_loss: 41.7454 - kl_loss: 3.0165\n",
      "No Success\n",
      "Episode 2\n",
      "[-0.5735706  0.       ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0330\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0400\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9375 - reconstruction_loss: 2.1244 - kl_loss: 3.8131\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.0568 - reconstruction_loss: 7.2959 - kl_loss: 3.7609\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0633\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0692\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.7357 - reconstruction_loss: 10.9070 - kl_loss: 3.8287\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 21.2253 - reconstruction_loss: 17.4408 - kl_loss: 3.7845\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0318\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0333\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.5521 - reconstruction_loss: 14.8867 - kl_loss: 3.6654\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8277 - reconstruction_loss: 1.1900 - kl_loss: 3.6377\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0161\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0147\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 25.0323 - reconstruction_loss: 22.5426 - kl_loss: 2.4896\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 28.7640 - reconstruction_loss: 26.2964 - kl_loss: 2.4676\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0034\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0032\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 26.0107 - reconstruction_loss: 24.1571 - kl_loss: 1.8536\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 26.3456 - reconstruction_loss: 24.5104 - kl_loss: 1.8352\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0068\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0069\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.8861 - reconstruction_loss: 16.9007 - kl_loss: 1.9854\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 25.6328 - reconstruction_loss: 23.6630 - kl_loss: 1.9698\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0206\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0206\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 30.7185 - reconstruction_loss: 28.3734 - kl_loss: 2.3452\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 26.0730 - reconstruction_loss: 23.7417 - kl_loss: 2.3313\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0675\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0677\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.8101 - reconstruction_loss: 12.7137 - kl_loss: 3.0964\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.7907 - reconstruction_loss: 8.7085 - kl_loss: 3.0822\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0573\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0541\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.5783 - reconstruction_loss: 15.0167 - kl_loss: 3.5616\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.0492 - reconstruction_loss: 10.4995 - kl_loss: 3.5497\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0097\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0092\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9586 - reconstruction_loss: 3.0937 - kl_loss: 2.8649\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.8915 - reconstruction_loss: 9.0362 - kl_loss: 2.8552\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0034\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 994us/step - kl_loss: 0.0035\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.4351 - reconstruction_loss: 12.2176 - kl_loss: 2.2175\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9689 - reconstruction_loss: 7.7601 - kl_loss: 2.2088\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0081\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0077\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5424 - reconstruction_loss: 5.2570 - kl_loss: 2.2854\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.8993 - reconstruction_loss: 5.6217 - kl_loss: 2.2776\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0208\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0192\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.1334 - reconstruction_loss: 3.2789 - kl_loss: 2.8545\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7029 - reconstruction_loss: 2.8555 - kl_loss: 2.8474\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0234\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0211\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.4494 - reconstruction_loss: 6.2653 - kl_loss: 3.1841\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7755 - reconstruction_loss: 3.5980 - kl_loss: 3.1776\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0233\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0250\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.5395 - reconstruction_loss: 16.8244 - kl_loss: 2.7151\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.1788 - reconstruction_loss: 13.4691 - kl_loss: 2.7096\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0704\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0681\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 28.8325 - reconstruction_loss: 27.0265 - kl_loss: 1.8059\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 23.8937 - reconstruction_loss: 22.0922 - kl_loss: 1.8015\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1106\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1012\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 41.2038 - reconstruction_loss: 39.7998 - kl_loss: 1.4039\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 37.8484 - reconstruction_loss: 36.4476 - kl_loss: 1.4007\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0333\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0290\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 22.8538 - reconstruction_loss: 21.1841 - kl_loss: 1.6696\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 37.6783 - reconstruction_loss: 36.0114 - kl_loss: 1.6669\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0086\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0094\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 34.9844 - reconstruction_loss: 32.9703 - kl_loss: 2.0141\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.7498 - reconstruction_loss: 16.7380 - kl_loss: 2.0118\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0142\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0159\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.5601 - reconstruction_loss: 4.9206 - kl_loss: 2.6394\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 946us/step - loss: 7.3219 - reconstruction_loss: 4.6857 - kl_loss: 2.6362\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0479\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0478\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 24.9319 - reconstruction_loss: 20.9311 - kl_loss: 4.0007\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 44.1959 - reconstruction_loss: 40.1991 - kl_loss: 3.9968\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0710\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0716\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 29.1424 - reconstruction_loss: 25.1023 - kl_loss: 4.0401\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.9314 - reconstruction_loss: 13.8981 - kl_loss: 4.0333\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0163\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0160\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 50.6451 - reconstruction_loss: 47.5452 - kl_loss: 3.0999\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 24.0675 - reconstruction_loss: 20.9721 - kl_loss: 3.0954\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1544\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1491\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 71.3285 - reconstruction_loss: 69.9106 - kl_loss: 1.4178\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 76.6386 - reconstruction_loss: 75.2228 - kl_loss: 1.4158\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4651\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4517\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 93.2153 - reconstruction_loss: 91.9206 - kl_loss: 1.2947\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 84.6924 - reconstruction_loss: 83.4009 - kl_loss: 1.2916\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0369\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0385\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 72.8444 - reconstruction_loss: 70.9920 - kl_loss: 1.8524\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 69.8013 - reconstruction_loss: 67.9512 - kl_loss: 1.8501\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1195\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1218\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 75.6526 - reconstruction_loss: 72.5225 - kl_loss: 3.1301\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 61.4314 - reconstruction_loss: 58.3049 - kl_loss: 3.1265\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2532\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2519\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 60.7584 - reconstruction_loss: 55.9004 - kl_loss: 4.8580\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 60.5376 - reconstruction_loss: 55.6843 - kl_loss: 4.8533\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0871\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0841\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 63.4692 - reconstruction_loss: 58.2790 - kl_loss: 5.1901\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 61.4550 - reconstruction_loss: 56.2660 - kl_loss: 5.1890\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1520\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1541\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 108.9893 - reconstruction_loss: 106.8228 - kl_loss: 2.1666\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 83.2346 - reconstruction_loss: 81.0667 - kl_loss: 2.1679\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0546\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0535\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 69.1326 - reconstruction_loss: 67.9615 - kl_loss: 1.1712\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 77.4946 - reconstruction_loss: 76.3240 - kl_loss: 1.1706\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0898\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0865\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 62.3184 - reconstruction_loss: 60.7961 - kl_loss: 1.5223\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 59.9809 - reconstruction_loss: 58.4600 - kl_loss: 1.5209\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0579\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0584\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 51.7273 - reconstruction_loss: 49.4447 - kl_loss: 2.2825\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 63.6091 - reconstruction_loss: 61.3281 - kl_loss: 2.2810\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1375\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1355\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 33.9541 - reconstruction_loss: 30.3752 - kl_loss: 3.5789\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 32.6208 - reconstruction_loss: 29.0449 - kl_loss: 3.5759\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1305\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1229\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 37.9735 - reconstruction_loss: 33.2837 - kl_loss: 4.6898\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 39.1469 - reconstruction_loss: 34.4579 - kl_loss: 4.6891\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0578\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0562\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 51.6360 - reconstruction_loss: 48.5869 - kl_loss: 3.0490\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 45.0218 - reconstruction_loss: 41.9725 - kl_loss: 3.0493\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0389\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0415\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 55.3457 - reconstruction_loss: 53.7277 - kl_loss: 1.6179\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 37.2823 - reconstruction_loss: 35.6658 - kl_loss: 1.6165\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1026\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1013\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 52.1741 - reconstruction_loss: 50.8782 - kl_loss: 1.2960\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 52.9187 - reconstruction_loss: 51.6245 - kl_loss: 1.2942\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0643\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0627\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 60.7523 - reconstruction_loss: 58.9463 - kl_loss: 1.8060\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 64.2570 - reconstruction_loss: 62.4516 - kl_loss: 1.8054\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2806\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2805\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 237.6440 - reconstruction_loss: 233.7440 - kl_loss: 3.8999\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 131.9668 - reconstruction_loss: 128.0814 - kl_loss: 3.8854\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3459\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 980us/step - kl_loss: 0.3377\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 184.7851 - reconstruction_loss: 177.4933 - kl_loss: 7.2917\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 180.5494 - reconstruction_loss: 173.2870 - kl_loss: 7.2624\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2141\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2029\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 116.2685 - reconstruction_loss: 107.5910 - kl_loss: 8.6774\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 118.8679 - reconstruction_loss: 110.1946 - kl_loss: 8.6733\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2201\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2176\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 122.4636 - reconstruction_loss: 116.5524 - kl_loss: 5.9112\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 142.1591 - reconstruction_loss: 136.2305 - kl_loss: 5.9286\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2264\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2267\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 127.9467 - reconstruction_loss: 126.3836 - kl_loss: 1.5631\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 125.9934 - reconstruction_loss: 124.4265 - kl_loss: 1.5669\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1652\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1660\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 84.0484 - reconstruction_loss: 82.4953 - kl_loss: 1.5532\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 101.0733 - reconstruction_loss: 99.5201 - kl_loss: 1.5532\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0854\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0854\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 105.4770 - reconstruction_loss: 102.6923 - kl_loss: 2.7847\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 98.1276 - reconstruction_loss: 95.3467 - kl_loss: 2.7809\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3584\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3569\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 162.1472 - reconstruction_loss: 156.6666 - kl_loss: 5.4806\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 206.6371 - reconstruction_loss: 201.1726 - kl_loss: 5.4645\n",
      "training on full data\n",
      "7 103\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 3), dtype=tf.float32, name='input_44'), name='input_44', description=\"created by layer 'input_44'\"), but it was called on an input with incompatible shape (None, 3).\n",
      "1/1 [==============================] - 0s 130ms/step - kl_loss: 0.0911\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0876\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 56.0290 - reconstruction_loss: 53.1320 - kl_loss: 2.8969\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 53.4662 - reconstruction_loss: 50.5863 - kl_loss: 2.8799\n",
      "WARNING:tensorflow:5 out of the last 293 calls to <function Model.make_train_function.<locals>.train_function at 0x28d495af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Success in episode 2 at time step 617 with reward 91.77550913235075\n",
      "Episode 3\n",
      "[-0.4419238  0.       ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0229\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0318\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8255 - reconstruction_loss: 3.5910 - kl_loss: 3.2345\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.4337 - reconstruction_loss: 11.2291 - kl_loss: 3.2046\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0192\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0221\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 23.3795 - reconstruction_loss: 20.8643 - kl_loss: 2.5152\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.1541 - reconstruction_loss: 16.6557 - kl_loss: 2.4984\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0381\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0351\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 45.5193 - reconstruction_loss: 43.9054 - kl_loss: 1.6140\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 38.1552 - reconstruction_loss: 36.5508 - kl_loss: 1.6044\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0740\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0679\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 57.6834 - reconstruction_loss: 56.5819 - kl_loss: 1.1015\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 62.3468 - reconstruction_loss: 61.2500 - kl_loss: 1.0968\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1141\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1100\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 69.1627 - reconstruction_loss: 67.9245 - kl_loss: 1.2382\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 71.4711 - reconstruction_loss: 70.2337 - kl_loss: 1.2374\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0431\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0469\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 49.3918 - reconstruction_loss: 47.6348 - kl_loss: 1.7569\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 41.8128 - reconstruction_loss: 40.0576 - kl_loss: 1.7552\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1992\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2033\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 40.7096 - reconstruction_loss: 38.4264 - kl_loss: 2.2832\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 22.6593 - reconstruction_loss: 20.3837 - kl_loss: 2.2756\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1309\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1290\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 27.5249 - reconstruction_loss: 24.1044 - kl_loss: 3.4206\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 20.9474 - reconstruction_loss: 17.5364 - kl_loss: 3.4109\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0840\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0778\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 39.5111 - reconstruction_loss: 36.1859 - kl_loss: 3.3253\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 29.5745 - reconstruction_loss: 26.2543 - kl_loss: 3.3203\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0380\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0353\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 68.2363 - reconstruction_loss: 66.3233 - kl_loss: 1.9130\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 65.8806 - reconstruction_loss: 63.9690 - kl_loss: 1.9116\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0809\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0827\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 88.7725 - reconstruction_loss: 87.6087 - kl_loss: 1.1639\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 74.9993 - reconstruction_loss: 73.8372 - kl_loss: 1.1621\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0651\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0636\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 83.0559 - reconstruction_loss: 81.7193 - kl_loss: 1.3366\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 82.7938 - reconstruction_loss: 81.4598 - kl_loss: 1.3340\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0308\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0292\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 46.0613 - reconstruction_loss: 44.5571 - kl_loss: 1.5042\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 39.3354 - reconstruction_loss: 37.8321 - kl_loss: 1.5034\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1082\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1049\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 21.9244 - reconstruction_loss: 19.8794 - kl_loss: 2.0450\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 24.4260 - reconstruction_loss: 22.3830 - kl_loss: 2.0430\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1244\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1187\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.7241 - reconstruction_loss: 10.7575 - kl_loss: 2.9666\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.5864 - reconstruction_loss: 16.6229 - kl_loss: 2.9635\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0259\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0234\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 22.5368 - reconstruction_loss: 19.0757 - kl_loss: 3.4611\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 29.3089 - reconstruction_loss: 25.8504 - kl_loss: 3.4585\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0303\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0324\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 40.0905 - reconstruction_loss: 38.0733 - kl_loss: 2.0171\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 36.2688 - reconstruction_loss: 34.2533 - kl_loss: 2.0155\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0377\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0391\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 64.8921 - reconstruction_loss: 63.8134 - kl_loss: 1.0787\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 72.3662 - reconstruction_loss: 71.2896 - kl_loss: 1.0766\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0884\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 991us/step - kl_loss: 0.0869\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 90.1699 - reconstruction_loss: 89.1945 - kl_loss: 0.9754\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 94.7556 - reconstruction_loss: 93.7837 - kl_loss: 0.9718\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0634\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0591\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 71.9198 - reconstruction_loss: 70.7233 - kl_loss: 1.1965\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 72.0402 - reconstruction_loss: 70.8478 - kl_loss: 1.1924\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0131\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0131\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 57.0773 - reconstruction_loss: 55.6694 - kl_loss: 1.4078\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 55.4609 - reconstruction_loss: 54.0559 - kl_loss: 1.4049\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0501\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0509\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 33.6689 - reconstruction_loss: 31.9211 - kl_loss: 1.7478\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 23.9852 - reconstruction_loss: 22.2389 - kl_loss: 1.7463\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0769\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0763\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.0073 - reconstruction_loss: 14.6224 - kl_loss: 2.3848\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.9029 - reconstruction_loss: 8.5204 - kl_loss: 2.3825\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0371\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0357\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.3792 - reconstruction_loss: 6.5721 - kl_loss: 2.8071\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.0979 - reconstruction_loss: 10.2933 - kl_loss: 2.8047\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0230\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0224\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 21.7323 - reconstruction_loss: 19.4425 - kl_loss: 2.2898\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 22.3114 - reconstruction_loss: 20.0240 - kl_loss: 2.2874\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0843\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0845\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.0988 - reconstruction_loss: 16.4436 - kl_loss: 1.6551\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.6499 - reconstruction_loss: 12.9969 - kl_loss: 1.6529\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0136\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0134\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.8394 - reconstruction_loss: 10.4753 - kl_loss: 1.3641\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.0254 - reconstruction_loss: 13.6635 - kl_loss: 1.3619\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0068\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0065\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.1290 - reconstruction_loss: 11.6091 - kl_loss: 1.5199\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.8199 - reconstruction_loss: 6.3018 - kl_loss: 1.5181\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0149\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0142\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5168 - reconstruction_loss: 5.7859 - kl_loss: 1.7309\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.5460 - reconstruction_loss: 6.8169 - kl_loss: 1.7290\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0819\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0786\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.2519 - reconstruction_loss: 10.5330 - kl_loss: 2.7189\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.9649 - reconstruction_loss: 15.2483 - kl_loss: 2.7166\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0136\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0127\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9590 - reconstruction_loss: 5.3611 - kl_loss: 2.5979\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.2007 - reconstruction_loss: 10.6056 - kl_loss: 2.5951\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0330\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0346\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 35.4804 - reconstruction_loss: 33.5988 - kl_loss: 1.8816\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 31.3861 - reconstruction_loss: 29.5073 - kl_loss: 1.8788\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0403\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0397\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 45.3085 - reconstruction_loss: 44.2233 - kl_loss: 1.0852\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 42.5444 - reconstruction_loss: 41.4620 - kl_loss: 1.0823\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2363\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2294\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 37.9667 - reconstruction_loss: 36.8302 - kl_loss: 1.1365\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 35.5276 - reconstruction_loss: 34.3937 - kl_loss: 1.1340\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0510\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0487\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 43.3435 - reconstruction_loss: 41.5391 - kl_loss: 1.8044\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 55.6800 - reconstruction_loss: 53.8775 - kl_loss: 1.8025\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1341\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1346\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 65.6105 - reconstruction_loss: 62.8821 - kl_loss: 2.7284\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 62.4575 - reconstruction_loss: 59.7317 - kl_loss: 2.7258\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0989\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0964\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 50.1596 - reconstruction_loss: 45.6858 - kl_loss: 4.4738\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 59.7589 - reconstruction_loss: 55.2880 - kl_loss: 4.4709\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0424\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0430\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 42.3866 - reconstruction_loss: 38.7692 - kl_loss: 3.6174\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 58.6712 - reconstruction_loss: 55.0538 - kl_loss: 3.6174\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2520\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2455\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 110.3790 - reconstruction_loss: 108.8918 - kl_loss: 1.4872\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 123.6713 - reconstruction_loss: 122.1794 - kl_loss: 1.4919\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0653\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0588\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 74.1587 - reconstruction_loss: 73.0378 - kl_loss: 1.1209\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 80.3942 - reconstruction_loss: 79.2759 - kl_loss: 1.1182\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0200\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0183\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 50.1062 - reconstruction_loss: 48.8596 - kl_loss: 1.2467\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 52.5593 - reconstruction_loss: 51.3135 - kl_loss: 1.2459\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0333\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0357\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 20.9002 - reconstruction_loss: 19.2273 - kl_loss: 1.6729\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 28.3870 - reconstruction_loss: 26.7149 - kl_loss: 1.6722\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0813\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0828\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 28.2661 - reconstruction_loss: 25.9537 - kl_loss: 2.3124\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 26.0900 - reconstruction_loss: 23.7788 - kl_loss: 2.3112\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0876\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0857\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.8884 - reconstruction_loss: 14.9251 - kl_loss: 2.9633\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 26.6300 - reconstruction_loss: 23.6674 - kl_loss: 2.9626\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0289\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0281\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 39.5186 - reconstruction_loss: 37.1516 - kl_loss: 2.3670\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 25.7318 - reconstruction_loss: 23.3652 - kl_loss: 2.3666\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0391\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0396\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 44.8335 - reconstruction_loss: 43.4020 - kl_loss: 1.4315\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 57.0960 - reconstruction_loss: 55.6640 - kl_loss: 1.4321\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0618\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0594\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 68.5062 - reconstruction_loss: 67.6026 - kl_loss: 0.9036\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 65.3474 - reconstruction_loss: 64.4443 - kl_loss: 0.9030\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0403\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0370\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 70.8496 - reconstruction_loss: 69.8166 - kl_loss: 1.0330\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 70.7658 - reconstruction_loss: 69.7323 - kl_loss: 1.0336\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1235\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1186\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 54.9079 - reconstruction_loss: 53.4335 - kl_loss: 1.4744\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 53.0222 - reconstruction_loss: 51.5462 - kl_loss: 1.4761\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1230\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1261\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 71.2425 - reconstruction_loss: 69.0624 - kl_loss: 2.1802\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 74.0545 - reconstruction_loss: 71.8717 - kl_loss: 2.1828\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1090\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1095\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 58.6938 - reconstruction_loss: 55.4037 - kl_loss: 3.2901\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 57.2991 - reconstruction_loss: 54.0108 - kl_loss: 3.2882\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1540\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1500\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 60.6570 - reconstruction_loss: 55.9245 - kl_loss: 4.7325\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 71.1738 - reconstruction_loss: 66.4456 - kl_loss: 4.7282\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0539\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0542\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 57.1157 - reconstruction_loss: 52.8478 - kl_loss: 4.2679\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 36.4848 - reconstruction_loss: 32.2179 - kl_loss: 4.2669\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1345\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1348\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 138.9055 - reconstruction_loss: 137.4132 - kl_loss: 1.4924\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 132.4712 - reconstruction_loss: 130.9786 - kl_loss: 1.4926\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1845\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1780\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 64.6584 - reconstruction_loss: 63.3581 - kl_loss: 1.3003\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 71.4452 - reconstruction_loss: 70.1467 - kl_loss: 1.2985\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0737\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0743\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 62.4542 - reconstruction_loss: 60.4953 - kl_loss: 1.9589\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 54.2311 - reconstruction_loss: 52.2694 - kl_loss: 1.9617\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1843\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1824\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 83.3153 - reconstruction_loss: 80.5120 - kl_loss: 2.8033\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 90.8989 - reconstruction_loss: 88.0960 - kl_loss: 2.8029\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1494\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1435\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 88.9527 - reconstruction_loss: 83.9918 - kl_loss: 4.9609\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 95.3882 - reconstruction_loss: 90.4312 - kl_loss: 4.9570\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0678\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0652\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 97.8583 - reconstruction_loss: 92.9531 - kl_loss: 4.9053\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 72.7507 - reconstruction_loss: 67.8463 - kl_loss: 4.9044\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0979\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0983\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 94.1844 - reconstruction_loss: 92.1228 - kl_loss: 2.0616\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 82.5958 - reconstruction_loss: 80.5326 - kl_loss: 2.0632\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0854\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0862\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 94.3161 - reconstruction_loss: 93.3801 - kl_loss: 0.9360\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 92.2396 - reconstruction_loss: 91.3050 - kl_loss: 0.9346\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0501\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0480\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 57.4967 - reconstruction_loss: 56.2799 - kl_loss: 1.2169\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 52.2796 - reconstruction_loss: 51.0630 - kl_loss: 1.2166\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0119\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0109\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 30.6528 - reconstruction_loss: 29.3519 - kl_loss: 1.3009\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 24.3070 - reconstruction_loss: 23.0055 - kl_loss: 1.3014\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0791\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0807\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 35.3175 - reconstruction_loss: 33.3435 - kl_loss: 1.9740\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 29.1087 - reconstruction_loss: 27.1346 - kl_loss: 1.9740\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0731\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0710\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 40.4909 - reconstruction_loss: 37.6010 - kl_loss: 2.8898\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 26.2497 - reconstruction_loss: 23.3629 - kl_loss: 2.8868\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0044\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0047\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 27.7898 - reconstruction_loss: 24.8478 - kl_loss: 2.9420\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.2724 - reconstruction_loss: 15.3326 - kl_loss: 2.9397\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0384\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0384\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 29.4439 - reconstruction_loss: 27.9905 - kl_loss: 1.4534\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 37.7194 - reconstruction_loss: 36.2675 - kl_loss: 1.4519\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0520\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0498\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 66.9502 - reconstruction_loss: 65.9979 - kl_loss: 0.9523\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 69.2668 - reconstruction_loss: 68.3157 - kl_loss: 0.9511\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0427\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0388\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 76.3292 - reconstruction_loss: 75.4186 - kl_loss: 0.9106\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 62.5263 - reconstruction_loss: 61.6156 - kl_loss: 0.9107\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1440\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1379\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 68.9095 - reconstruction_loss: 67.6011 - kl_loss: 1.3084\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 75.4730 - reconstruction_loss: 74.1627 - kl_loss: 1.3104\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0756\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0769\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 74.0559 - reconstruction_loss: 71.7194 - kl_loss: 2.3366\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 78.6892 - reconstruction_loss: 76.3478 - kl_loss: 2.3414\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2158\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2171\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 141.4414 - reconstruction_loss: 137.8885 - kl_loss: 3.5528\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 113.6821 - reconstruction_loss: 110.1320 - kl_loss: 3.5502\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1442\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1404\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 106.2613 - reconstruction_loss: 100.7330 - kl_loss: 5.5283\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 110.4256 - reconstruction_loss: 104.9011 - kl_loss: 5.5245\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2325\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2284\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 79.5701 - reconstruction_loss: 74.1148 - kl_loss: 5.4553\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 33.8404 - reconstruction_loss: 28.3961 - kl_loss: 5.4443\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0522\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0516\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 59.0472 - reconstruction_loss: 57.0455 - kl_loss: 2.0017\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 56.9120 - reconstruction_loss: 54.9112 - kl_loss: 2.0008\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0430\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0437\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 59.3917 - reconstruction_loss: 58.4666 - kl_loss: 0.9251\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 61.4096 - reconstruction_loss: 60.4852 - kl_loss: 0.9244\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0322\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0298\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 57.4444 - reconstruction_loss: 56.3911 - kl_loss: 1.0533\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 58.4890 - reconstruction_loss: 57.4349 - kl_loss: 1.0541\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0050\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0046\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 46.2277 - reconstruction_loss: 44.8610 - kl_loss: 1.3668\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 45.1123 - reconstruction_loss: 43.7419 - kl_loss: 1.3704\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0266\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0274\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 33.5572 - reconstruction_loss: 32.1106 - kl_loss: 1.4466\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 26.3257 - reconstruction_loss: 24.8756 - kl_loss: 1.4501\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0746\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0741\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 51.0754 - reconstruction_loss: 49.0045 - kl_loss: 2.0709\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 37.0170 - reconstruction_loss: 34.9460 - kl_loss: 2.0710\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0873\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0843\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 29.4628 - reconstruction_loss: 26.3372 - kl_loss: 3.1257\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 37.9325 - reconstruction_loss: 34.8105 - kl_loss: 3.1220\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0089\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0081\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 51.3637 - reconstruction_loss: 47.8993 - kl_loss: 3.4643\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 46.0534 - reconstruction_loss: 42.5931 - kl_loss: 3.4603\n",
      "training on full data\n",
      "1 167\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0503\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0491\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 47.1884 - reconstruction_loss: 45.0794 - kl_loss: 2.1091\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 48.9063 - reconstruction_loss: 46.7993 - kl_loss: 2.1069\n",
      "No Success\n",
      "Episode 4\n",
      "[-0.50853616  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0173\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 962us/step - kl_loss: 0.0147\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.5062 - reconstruction_loss: 15.2725 - kl_loss: 2.2337\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3595 - reconstruction_loss: 4.1494 - kl_loss: 2.2101\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0037\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0043\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.5053 - reconstruction_loss: 12.3697 - kl_loss: 2.1357\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 23.6338 - reconstruction_loss: 21.5100 - kl_loss: 2.1239\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0351\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0384\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 23.9348 - reconstruction_loss: 22.3472 - kl_loss: 1.5877\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 24.3245 - reconstruction_loss: 22.7450 - kl_loss: 1.5795\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0468\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0481\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 26.3616 - reconstruction_loss: 25.3597 - kl_loss: 1.0020\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 24.9642 - reconstruction_loss: 23.9664 - kl_loss: 0.9978\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0638\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0634\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.2652 - reconstruction_loss: 12.1819 - kl_loss: 1.0833\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.9553 - reconstruction_loss: 9.8736 - kl_loss: 1.0818\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0293\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0288\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.1148 - reconstruction_loss: 16.8395 - kl_loss: 1.2753\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.4862 - reconstruction_loss: 11.2102 - kl_loss: 1.2761\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0148\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0147\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 20.4794 - reconstruction_loss: 18.7883 - kl_loss: 1.6911\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 47.6649 - reconstruction_loss: 45.9762 - kl_loss: 1.6886\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0877\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0869\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 23.2158 - reconstruction_loss: 21.2732 - kl_loss: 1.9426\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 25.3458 - reconstruction_loss: 23.4113 - kl_loss: 1.9345\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0106\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0103\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 23.6844 - reconstruction_loss: 21.1660 - kl_loss: 2.5184\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 25.6746 - reconstruction_loss: 23.1643 - kl_loss: 2.5102\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0200\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0191\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 24.7955 - reconstruction_loss: 22.4976 - kl_loss: 2.2978\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 31.2123 - reconstruction_loss: 28.9195 - kl_loss: 2.2929\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0978\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0955\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 36.7719 - reconstruction_loss: 35.4783 - kl_loss: 1.2936\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 29.4827 - reconstruction_loss: 28.1924 - kl_loss: 1.2902\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0374\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0356\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 24.7958 - reconstruction_loss: 23.6937 - kl_loss: 1.1021\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.0582 - reconstruction_loss: 16.9572 - kl_loss: 1.1010\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0132\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0124\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 24.3447 - reconstruction_loss: 22.7120 - kl_loss: 1.6327\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 22.0105 - reconstruction_loss: 20.3774 - kl_loss: 1.6332\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0301\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0306\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.7965 - reconstruction_loss: 17.0462 - kl_loss: 1.7503\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 20.9708 - reconstruction_loss: 19.2228 - kl_loss: 1.7480\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0317\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0318\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 21.6267 - reconstruction_loss: 19.2737 - kl_loss: 2.3530\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 31.3014 - reconstruction_loss: 28.9515 - kl_loss: 2.3499\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0118\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0113\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.9619 - reconstruction_loss: 14.7060 - kl_loss: 2.2559\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.2239 - reconstruction_loss: 16.9711 - kl_loss: 2.2528\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0291\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0293\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 38.2755 - reconstruction_loss: 35.8299 - kl_loss: 2.4456\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.0290 - reconstruction_loss: 10.5857 - kl_loss: 2.4433\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0501\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0477\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 22.7663 - reconstruction_loss: 21.6193 - kl_loss: 1.1470\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 22.8347 - reconstruction_loss: 21.6894 - kl_loss: 1.1453\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0812\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0787\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 30.1503 - reconstruction_loss: 29.1962 - kl_loss: 0.9540\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 31.3087 - reconstruction_loss: 30.3562 - kl_loss: 0.9525\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0493\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0473\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 32.3456 - reconstruction_loss: 30.7654 - kl_loss: 1.5802\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 31.1410 - reconstruction_loss: 29.5607 - kl_loss: 1.5803\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0177\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0192\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 27.7434 - reconstruction_loss: 25.9929 - kl_loss: 1.7505\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 32.0457 - reconstruction_loss: 30.2944 - kl_loss: 1.7512\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0416\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0420\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 30.8987 - reconstruction_loss: 28.7772 - kl_loss: 2.1214\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 31.0881 - reconstruction_loss: 28.9684 - kl_loss: 2.1197\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0162\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0161\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 24.1854 - reconstruction_loss: 21.8733 - kl_loss: 2.3120\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 20.6035 - reconstruction_loss: 18.2936 - kl_loss: 2.3098\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0529\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0521\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.1353 - reconstruction_loss: 12.6440 - kl_loss: 1.4913\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.1833 - reconstruction_loss: 8.6943 - kl_loss: 1.4890\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0128\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0122\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0649 - reconstruction_loss: 3.8249 - kl_loss: 1.2400\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.3783 - reconstruction_loss: 9.1405 - kl_loss: 1.2379\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0124\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0114\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.9383 - reconstruction_loss: 12.4662 - kl_loss: 1.4721\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.0610 - reconstruction_loss: 10.5908 - kl_loss: 1.4702\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0128\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0123\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.8172 - reconstruction_loss: 7.1516 - kl_loss: 1.6656\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.5701 - reconstruction_loss: 9.9071 - kl_loss: 1.6630\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0030\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0035\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.5810 - reconstruction_loss: 7.8292 - kl_loss: 1.7518\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.1888 - reconstruction_loss: 10.4404 - kl_loss: 1.7484\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0080\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0074\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.3781 - reconstruction_loss: 11.9414 - kl_loss: 1.4367\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.7714 - reconstruction_loss: 11.3366 - kl_loss: 1.4348\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0126\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0118\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.0064 - reconstruction_loss: 12.4197 - kl_loss: 1.5867\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.5023 - reconstruction_loss: 9.9181 - kl_loss: 1.5842\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0103\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0096\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.9344 - reconstruction_loss: 9.9821 - kl_loss: 1.9523\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.9187 - reconstruction_loss: 12.9695 - kl_loss: 1.9492\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0127\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0134\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.6401 - reconstruction_loss: 6.0992 - kl_loss: 1.5409\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3951 - reconstruction_loss: 4.8570 - kl_loss: 1.5381\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0203\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0203\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.2731 - reconstruction_loss: 9.9830 - kl_loss: 1.2900\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.6911 - reconstruction_loss: 7.4041 - kl_loss: 1.2871\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0150\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0146\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1138 - reconstruction_loss: 3.0583 - kl_loss: 1.0555\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4355 - reconstruction_loss: 4.3827 - kl_loss: 1.0528\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0075\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0075\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.7157 - reconstruction_loss: 7.3783 - kl_loss: 1.3374\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 951us/step - loss: 9.1919 - reconstruction_loss: 7.8572 - kl_loss: 1.3347\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0051\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0051\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.7629 - reconstruction_loss: 6.2859 - kl_loss: 1.4770\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.5453 - reconstruction_loss: 5.0711 - kl_loss: 1.4742\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0126\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0123\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1269 - reconstruction_loss: 1.4629 - kl_loss: 1.6640\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.3569 - reconstruction_loss: 10.6957 - kl_loss: 1.6612\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0206\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0190\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.7290 - reconstruction_loss: 9.3020 - kl_loss: 1.4270\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.4259 - reconstruction_loss: 5.0025 - kl_loss: 1.4234\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0652\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 973us/step - kl_loss: 0.0609\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.0695 - reconstruction_loss: 8.0968 - kl_loss: 0.9728\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.9753 - reconstruction_loss: 8.0058 - kl_loss: 0.9695\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0020\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0014\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.3281 - reconstruction_loss: 10.1083 - kl_loss: 1.2198\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.3921 - reconstruction_loss: 16.1745 - kl_loss: 1.2176\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0103\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0103\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.3502 - reconstruction_loss: 15.9939 - kl_loss: 1.3562\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.9913 - reconstruction_loss: 11.6368 - kl_loss: 1.3545\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0192\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0196\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.7404 - reconstruction_loss: 12.8724 - kl_loss: 1.8680\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.7961 - reconstruction_loss: 14.9318 - kl_loss: 1.8643\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0190\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0195\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.1717 - reconstruction_loss: 8.6158 - kl_loss: 1.5560\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.6333 - reconstruction_loss: 7.0817 - kl_loss: 1.5515\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0060\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0062\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9978 - reconstruction_loss: 1.5037 - kl_loss: 1.4941\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9738 - reconstruction_loss: 4.4834 - kl_loss: 1.4904\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0280\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0276\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1832 - reconstruction_loss: 3.6108 - kl_loss: 1.5724\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.2860 - reconstruction_loss: 6.7174 - kl_loss: 1.5686\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0276\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0270\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.3631 - reconstruction_loss: 6.4220 - kl_loss: 0.9411\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.0932 - reconstruction_loss: 7.1551 - kl_loss: 0.9382\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0277\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0258\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.5754 - reconstruction_loss: 13.6764 - kl_loss: 0.8990\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.8450 - reconstruction_loss: 12.9483 - kl_loss: 0.8967\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0196\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0185\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.3434 - reconstruction_loss: 10.3022 - kl_loss: 1.0412\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.7107 - reconstruction_loss: 5.6702 - kl_loss: 1.0405\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1018\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1023\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 24.5369 - reconstruction_loss: 22.8483 - kl_loss: 1.6885\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 40.8081 - reconstruction_loss: 39.1199 - kl_loss: 1.6882\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1126\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1118\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48.5157 - reconstruction_loss: 46.1653 - kl_loss: 2.3505\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 50.1652 - reconstruction_loss: 47.8174 - kl_loss: 2.3478\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0567\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0554\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 62.6427 - reconstruction_loss: 59.0283 - kl_loss: 3.6143\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 41.0867 - reconstruction_loss: 37.4756 - kl_loss: 3.6112\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0171\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0165\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 39.6123 - reconstruction_loss: 36.5970 - kl_loss: 3.0152\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 45.1665 - reconstruction_loss: 42.1520 - kl_loss: 3.0146\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2222\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2156\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 66.8055 - reconstruction_loss: 65.5895 - kl_loss: 1.2160\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 75.2755 - reconstruction_loss: 74.0577 - kl_loss: 1.2178\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0971\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0945\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 58.2212 - reconstruction_loss: 56.9547 - kl_loss: 1.2665\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 57.5658 - reconstruction_loss: 56.3046 - kl_loss: 1.2613\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0201\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0172\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 41.9465 - reconstruction_loss: 40.3258 - kl_loss: 1.6208\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 38.2800 - reconstruction_loss: 36.6594 - kl_loss: 1.6206\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0306\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0336\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 20.5302 - reconstruction_loss: 19.0394 - kl_loss: 1.4907\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 20.0133 - reconstruction_loss: 18.5210 - kl_loss: 1.4923\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0757\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0761\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 35.5684 - reconstruction_loss: 33.7010 - kl_loss: 1.8675\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 31.3844 - reconstruction_loss: 29.5176 - kl_loss: 1.8667\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0698\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0678\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 52.5392 - reconstruction_loss: 49.5844 - kl_loss: 2.9549\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 32.7125 - reconstruction_loss: 29.7586 - kl_loss: 2.9540\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0851\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 916us/step - kl_loss: 0.0843\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 38.5004 - reconstruction_loss: 36.1675 - kl_loss: 2.3329\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 31.3154 - reconstruction_loss: 28.9807 - kl_loss: 2.3348\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0439\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0406\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 62.8813 - reconstruction_loss: 62.0579 - kl_loss: 0.8234\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 57.4813 - reconstruction_loss: 56.6589 - kl_loss: 0.8224\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0346\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0341\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 65.6859 - reconstruction_loss: 64.7142 - kl_loss: 0.9718\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 66.7343 - reconstruction_loss: 65.7657 - kl_loss: 0.9687\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0096\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0087\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 47.8820 - reconstruction_loss: 46.5083 - kl_loss: 1.3737\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 43.1386 - reconstruction_loss: 41.7656 - kl_loss: 1.3730\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0743\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0725\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 27.8122 - reconstruction_loss: 26.0702 - kl_loss: 1.7420\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 35.9640 - reconstruction_loss: 34.2211 - kl_loss: 1.7430\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1505\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1500\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 77.8804 - reconstruction_loss: 75.3970 - kl_loss: 2.4834\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 77.4988 - reconstruction_loss: 75.0113 - kl_loss: 2.4876\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0848\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0803\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 70.6712 - reconstruction_loss: 67.4122 - kl_loss: 3.2590\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 86.0472 - reconstruction_loss: 82.7896 - kl_loss: 3.2576\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0432\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0387\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 57.3778 - reconstruction_loss: 53.2465 - kl_loss: 4.1313\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 78.5907 - reconstruction_loss: 74.4586 - kl_loss: 4.1321\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3532\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3466\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 88.3552 - reconstruction_loss: 86.1944 - kl_loss: 2.1609\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 91.0584 - reconstruction_loss: 88.8966 - kl_loss: 2.1618\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0614\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0556\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 55.2246 - reconstruction_loss: 53.7421 - kl_loss: 1.4825\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 53.2730 - reconstruction_loss: 51.7950 - kl_loss: 1.4780\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0344\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0286\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 41.0660 - reconstruction_loss: 38.8432 - kl_loss: 2.2228\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 60.3665 - reconstruction_loss: 58.1418 - kl_loss: 2.2247\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1329\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1354\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48.9736 - reconstruction_loss: 47.0135 - kl_loss: 1.9601\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 51.0534 - reconstruction_loss: 49.0919 - kl_loss: 1.9614\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1375\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1367\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 85.5994 - reconstruction_loss: 82.2183 - kl_loss: 3.3812\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 87.3821 - reconstruction_loss: 84.0026 - kl_loss: 3.3795\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1956\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1896\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 97.8517 - reconstruction_loss: 92.9328 - kl_loss: 4.9189\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 53.6423 - reconstruction_loss: 48.7200 - kl_loss: 4.9222\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0406\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0393\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 35.5720 - reconstruction_loss: 33.1737 - kl_loss: 2.3983\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 40.3730 - reconstruction_loss: 37.9695 - kl_loss: 2.4036\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4020\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3917\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 71.7626 - reconstruction_loss: 70.8120 - kl_loss: 0.9506\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 68.2866 - reconstruction_loss: 67.3337 - kl_loss: 0.9529\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0655\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0641\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 52.9729 - reconstruction_loss: 51.0608 - kl_loss: 1.9121\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 59.9469 - reconstruction_loss: 58.0377 - kl_loss: 1.9093\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1124\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1094\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 48.5701 - reconstruction_loss: 46.2445 - kl_loss: 2.3256\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 60.0110 - reconstruction_loss: 57.6795 - kl_loss: 2.3316\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2795\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2756\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 148.5396 - reconstruction_loss: 145.2322 - kl_loss: 3.3074\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 160.0733 - reconstruction_loss: 156.7620 - kl_loss: 3.3113\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2327\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2285\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 230.0775 - reconstruction_loss: 224.2403 - kl_loss: 5.8373\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 237.3256 - reconstruction_loss: 231.5019 - kl_loss: 5.8237\n",
      "training on full data\n",
      "1 159\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0610\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0528\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 36.2001 - reconstruction_loss: 34.3811 - kl_loss: 1.8190\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 36.2299 - reconstruction_loss: 34.4208 - kl_loss: 1.8091\n",
      "Success in episode 4 at time step 953 with reward 88.64623768906316\n",
      "Episode 5\n",
      "[-0.5509499  0.       ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0577\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0466\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 20.5707 - reconstruction_loss: 19.0696 - kl_loss: 1.5012\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.0668 - reconstruction_loss: 14.5949 - kl_loss: 1.4719\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0154\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0243\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 22.5799 - reconstruction_loss: 20.6320 - kl_loss: 1.9479\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.0470 - reconstruction_loss: 12.1217 - kl_loss: 1.9253\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1119\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1351\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 30.4710 - reconstruction_loss: 28.5803 - kl_loss: 1.8907\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.1765 - reconstruction_loss: 13.2990 - kl_loss: 1.8775\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1621\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1770\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 39.1248 - reconstruction_loss: 38.2147 - kl_loss: 0.9101\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 36.4854 - reconstruction_loss: 35.5826 - kl_loss: 0.9027\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5101\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5098\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 49.7861 - reconstruction_loss: 49.0719 - kl_loss: 0.7142\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 45.3264 - reconstruction_loss: 44.6179 - kl_loss: 0.7085\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5378\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4914\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 40.2571 - reconstruction_loss: 39.4070 - kl_loss: 0.8500\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 42.3379 - reconstruction_loss: 41.4909 - kl_loss: 0.8470\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2818\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2375\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 28.1508 - reconstruction_loss: 26.6228 - kl_loss: 1.5280\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 27.4064 - reconstruction_loss: 25.8761 - kl_loss: 1.5303\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1722\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1466\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.2124 - reconstruction_loss: 17.8531 - kl_loss: 1.3593\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.8837 - reconstruction_loss: 17.5239 - kl_loss: 1.3598\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0166\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0174\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 40.1975 - reconstruction_loss: 38.7125 - kl_loss: 1.4850\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 33.9823 - reconstruction_loss: 32.5021 - kl_loss: 1.4802\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0357\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0372\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 51.1019 - reconstruction_loss: 48.5026 - kl_loss: 2.5993\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 36.0779 - reconstruction_loss: 33.4851 - kl_loss: 2.5929\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0132\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0149\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 43.3814 - reconstruction_loss: 40.9586 - kl_loss: 2.4228\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.1316 - reconstruction_loss: 10.7107 - kl_loss: 2.4209\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0092\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 990us/step - kl_loss: 0.0080\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 59.7116 - reconstruction_loss: 58.6452 - kl_loss: 1.0664\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 52.8656 - reconstruction_loss: 51.7957 - kl_loss: 1.0700\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0936\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0915\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 64.7417 - reconstruction_loss: 63.7563 - kl_loss: 0.9854\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 61.5607 - reconstruction_loss: 60.5726 - kl_loss: 0.9881\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1141\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1066\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 44.2897 - reconstruction_loss: 42.8251 - kl_loss: 1.4647\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 39.7739 - reconstruction_loss: 38.3027 - kl_loss: 1.4712\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0518\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0513\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 28.3682 - reconstruction_loss: 26.1855 - kl_loss: 2.1826\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48.8443 - reconstruction_loss: 46.6555 - kl_loss: 2.1888\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0653\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0664\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 36.4063 - reconstruction_loss: 34.8314 - kl_loss: 1.5749\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48.7434 - reconstruction_loss: 47.1669 - kl_loss: 1.5765\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1083\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1076\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 52.8758 - reconstruction_loss: 50.0687 - kl_loss: 2.8072\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 58.4597 - reconstruction_loss: 55.6547 - kl_loss: 2.8050\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1026\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0996\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 83.1999 - reconstruction_loss: 78.5640 - kl_loss: 4.6359\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 81.5558 - reconstruction_loss: 76.9169 - kl_loss: 4.6390\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4125\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4027\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 93.9806 - reconstruction_loss: 91.9473 - kl_loss: 2.0333\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 56.8247 - reconstruction_loss: 54.7776 - kl_loss: 2.0471\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0765\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0811\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 51.7779 - reconstruction_loss: 50.2531 - kl_loss: 1.5247\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 60.7115 - reconstruction_loss: 59.1883 - kl_loss: 1.5232\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0593\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0582\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 45.8643 - reconstruction_loss: 43.7545 - kl_loss: 2.1098\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 45.5768 - reconstruction_loss: 43.4628 - kl_loss: 2.1140\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0482\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0462\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 26.8235 - reconstruction_loss: 25.2194 - kl_loss: 1.6040\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 22.8428 - reconstruction_loss: 21.2329 - kl_loss: 1.6099\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0808\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0769\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 36.4998 - reconstruction_loss: 35.1148 - kl_loss: 1.3850\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.2631 - reconstruction_loss: 14.8762 - kl_loss: 1.3869\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0474\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0434\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 61.5549 - reconstruction_loss: 59.5541 - kl_loss: 2.0008\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 29.0325 - reconstruction_loss: 27.0349 - kl_loss: 1.9976\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0933\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0871\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.2763 - reconstruction_loss: 7.7857 - kl_loss: 2.4905\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.3403 - reconstruction_loss: 8.8513 - kl_loss: 2.4890\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1095\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1049\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 50.4759 - reconstruction_loss: 48.8456 - kl_loss: 1.6303\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 39.7887 - reconstruction_loss: 38.1557 - kl_loss: 1.6330\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0446\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0392\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 55.7338 - reconstruction_loss: 54.9505 - kl_loss: 0.7832\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 73.2274 - reconstruction_loss: 72.4378 - kl_loss: 0.7896\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0406\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0411\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 45.9203 - reconstruction_loss: 44.3834 - kl_loss: 1.5369\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 38.4679 - reconstruction_loss: 36.9261 - kl_loss: 1.5418\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1003\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0966\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 39.0928 - reconstruction_loss: 36.9545 - kl_loss: 2.1384\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 41.7988 - reconstruction_loss: 39.6520 - kl_loss: 2.1468\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0286\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0297\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 47.0734 - reconstruction_loss: 44.9218 - kl_loss: 2.1516\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 37.8841 - reconstruction_loss: 35.7238 - kl_loss: 2.1603\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0314\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0301\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 25.6249 - reconstruction_loss: 24.0094 - kl_loss: 1.6155\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 38.8020 - reconstruction_loss: 37.1875 - kl_loss: 1.6145\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0151\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0148\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.1080 - reconstruction_loss: 14.1429 - kl_loss: 2.9651\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 33.7352 - reconstruction_loss: 30.7719 - kl_loss: 2.9634\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0910\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0838\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 50.4274 - reconstruction_loss: 48.7667 - kl_loss: 1.6607\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 41.7799 - reconstruction_loss: 40.1148 - kl_loss: 1.6650\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1247\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1282\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 68.3222 - reconstruction_loss: 67.1545 - kl_loss: 1.1677\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 54.1746 - reconstruction_loss: 53.0002 - kl_loss: 1.1744\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0088\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0089\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 39.0706 - reconstruction_loss: 37.5295 - kl_loss: 1.5410\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48.1256 - reconstruction_loss: 46.5781 - kl_loss: 1.5474\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0977\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0951\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 22.6655 - reconstruction_loss: 20.4845 - kl_loss: 2.1810\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 25.9138 - reconstruction_loss: 23.7265 - kl_loss: 2.1873\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0560\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0552\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 98.3223 - reconstruction_loss: 94.7623 - kl_loss: 3.5600\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 100.0486 - reconstruction_loss: 96.4794 - kl_loss: 3.5692\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0481\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0472\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 95.1708 - reconstruction_loss: 92.0624 - kl_loss: 3.1084\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 92.5198 - reconstruction_loss: 89.4118 - kl_loss: 3.1080\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2655\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2598\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 38.7534 - reconstruction_loss: 33.0619 - kl_loss: 5.6915\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 94.0198 - reconstruction_loss: 88.3220 - kl_loss: 5.6978\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0995\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0944\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 46.5258 - reconstruction_loss: 42.4172 - kl_loss: 4.1086\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 72.9534 - reconstruction_loss: 68.8355 - kl_loss: 4.1179\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6206\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6161\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 43.0731 - reconstruction_loss: 41.3047 - kl_loss: 1.7684\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 67.1739 - reconstruction_loss: 65.3982 - kl_loss: 1.7758\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0921\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0867\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 42.2465 - reconstruction_loss: 40.0635 - kl_loss: 2.1830\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 40.5036 - reconstruction_loss: 38.3201 - kl_loss: 2.1835\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0550\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0522\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 63.8438 - reconstruction_loss: 59.6172 - kl_loss: 4.2266\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 69.4683 - reconstruction_loss: 65.2305 - kl_loss: 4.2378\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0920\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0904\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 143.2996 - reconstruction_loss: 140.0627 - kl_loss: 3.2370\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 151.8693 - reconstruction_loss: 148.6262 - kl_loss: 3.2430\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0150\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0150\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 143.3882 - reconstruction_loss: 137.9406 - kl_loss: 5.4477\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 163.6952 - reconstruction_loss: 158.2511 - kl_loss: 5.4441\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2457\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2417\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 161.1325 - reconstruction_loss: 153.1327 - kl_loss: 7.9998\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 109.2464 - reconstruction_loss: 101.2450 - kl_loss: 8.0014\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1587\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1346\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 88.5411 - reconstruction_loss: 85.3149 - kl_loss: 3.2262\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 80.6702 - reconstruction_loss: 77.4269 - kl_loss: 3.2433\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0729\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0713\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 57.0454 - reconstruction_loss: 55.3320 - kl_loss: 1.7134\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 46.3766 - reconstruction_loss: 44.6578 - kl_loss: 1.7188\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0394\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0388\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 31.7498 - reconstruction_loss: 29.0888 - kl_loss: 2.6610\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 31.8331 - reconstruction_loss: 29.1598 - kl_loss: 2.6733\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0345\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0340\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 68.7498 - reconstruction_loss: 65.5863 - kl_loss: 3.1635\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 75.7521 - reconstruction_loss: 72.5734 - kl_loss: 3.1787\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0331\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0334\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 73.8741 - reconstruction_loss: 71.1366 - kl_loss: 2.7375\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 85.8394 - reconstruction_loss: 83.1038 - kl_loss: 2.7357\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1241\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1253\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 64.4183 - reconstruction_loss: 59.7653 - kl_loss: 4.6530\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 60.7000 - reconstruction_loss: 56.0454 - kl_loss: 4.6546\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7685\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7357\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 83.3591 - reconstruction_loss: 79.5751 - kl_loss: 3.7840\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 77.6994 - reconstruction_loss: 73.8948 - kl_loss: 3.8046\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3013\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3077\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 115.7294 - reconstruction_loss: 113.5318 - kl_loss: 2.1976\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 110.8663 - reconstruction_loss: 108.6538 - kl_loss: 2.2125\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1714\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1584\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 44.0046 - reconstruction_loss: 41.4162 - kl_loss: 2.5884\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 51.5775 - reconstruction_loss: 48.9906 - kl_loss: 2.5869\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0634\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0622\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 106.0397 - reconstruction_loss: 100.1335 - kl_loss: 5.9062\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 90.5792 - reconstruction_loss: 84.6553 - kl_loss: 5.9239\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0938\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0942\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 178.5742 - reconstruction_loss: 174.8429 - kl_loss: 3.7313\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 158.6257 - reconstruction_loss: 154.8887 - kl_loss: 3.7370\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0166\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0163\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 221.8638 - reconstruction_loss: 215.4465 - kl_loss: 6.4173\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 191.3129 - reconstruction_loss: 184.8970 - kl_loss: 6.4158\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5376\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5200\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 123.6619 - reconstruction_loss: 115.1316 - kl_loss: 8.5303\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 74.7283 - reconstruction_loss: 66.1780 - kl_loss: 8.5503\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0751\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0453\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 135.1621 - reconstruction_loss: 129.6221 - kl_loss: 5.5401\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 163.3250 - reconstruction_loss: 157.7203 - kl_loss: 5.6047\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0313\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0313\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 44.2299 - reconstruction_loss: 41.8653 - kl_loss: 2.3646\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 45.1250 - reconstruction_loss: 42.7633 - kl_loss: 2.3617\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0344\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0319\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 56.5721 - reconstruction_loss: 52.1348 - kl_loss: 4.4373\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 49.9806 - reconstruction_loss: 45.5335 - kl_loss: 4.4471\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0388\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0394\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 93.4351 - reconstruction_loss: 91.0190 - kl_loss: 2.4160\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 89.7559 - reconstruction_loss: 87.3363 - kl_loss: 2.4196\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0493\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0489\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 84.4106 - reconstruction_loss: 80.2248 - kl_loss: 4.1858\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 66.9049 - reconstruction_loss: 62.7202 - kl_loss: 4.1848\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2300\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2119\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 26.3588 - reconstruction_loss: 20.0427 - kl_loss: 6.3161\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 40.9352 - reconstruction_loss: 34.5858 - kl_loss: 6.3494\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7576\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7598\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 62.2036 - reconstruction_loss: 59.5833 - kl_loss: 2.6203\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 57.0784 - reconstruction_loss: 54.4362 - kl_loss: 2.6423\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1140\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1124\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 42.1026 - reconstruction_loss: 39.0512 - kl_loss: 3.0514\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 40.8609 - reconstruction_loss: 37.8098 - kl_loss: 3.0511\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0917\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0778\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 128.9624 - reconstruction_loss: 122.7368 - kl_loss: 6.2256\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 158.9573 - reconstruction_loss: 152.7022 - kl_loss: 6.2551\n",
      "training on full data\n",
      "0 139\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1718\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1615\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 59.9178 - reconstruction_loss: 56.6571 - kl_loss: 3.2607\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 61.1574 - reconstruction_loss: 57.8501 - kl_loss: 3.3073\n",
      "Success in episode 5 at time step 829 with reward 89.78251319153874\n",
      "Episode 6\n",
      "[-0.5420245  0.       ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0340\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0464\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 21.9108 - reconstruction_loss: 20.7851 - kl_loss: 1.1257\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.5484 - reconstruction_loss: 16.4477 - kl_loss: 1.1007\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1648\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1639\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.6740 - reconstruction_loss: 13.0444 - kl_loss: 1.6296\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3194 - reconstruction_loss: 4.7018 - kl_loss: 1.6176\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1451\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1393\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5001 - reconstruction_loss: 2.5698 - kl_loss: 0.9302\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0595 - reconstruction_loss: 4.1394 - kl_loss: 0.9201\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1023\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1125\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.3549 - reconstruction_loss: 10.4986 - kl_loss: 0.8563\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3238 - reconstruction_loss: 4.4792 - kl_loss: 0.8446\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0560\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0588\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.5191 - reconstruction_loss: 16.6626 - kl_loss: 0.8565\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6699 - reconstruction_loss: 8.8230 - kl_loss: 0.8469\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2041\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2059\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.6235 - reconstruction_loss: 17.6615 - kl_loss: 0.9621\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 24.4944 - reconstruction_loss: 23.5360 - kl_loss: 0.9584\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2739\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2740\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.7508 - reconstruction_loss: 13.7121 - kl_loss: 1.0387\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 34.4300 - reconstruction_loss: 33.4008 - kl_loss: 1.0292\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0956\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 21.9716 - reconstruction_loss: 19.8720 - kl_loss: 2.0996\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.4405 - reconstruction_loss: 10.3433 - kl_loss: 2.0973\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0603\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0625\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 38.2314 - reconstruction_loss: 35.7426 - kl_loss: 2.4887\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 32.3494 - reconstruction_loss: 29.8468 - kl_loss: 2.5026\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0609\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0610\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 68.2840 - reconstruction_loss: 66.4314 - kl_loss: 1.8526\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 46.9280 - reconstruction_loss: 45.0570 - kl_loss: 1.8710\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2851\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2638\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 40.7222 - reconstruction_loss: 38.9093 - kl_loss: 1.8129\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 42.3825 - reconstruction_loss: 40.5546 - kl_loss: 1.8279\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8579\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7758\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 38.9808 - reconstruction_loss: 35.6526 - kl_loss: 3.3281\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 41.5620 - reconstruction_loss: 38.2276 - kl_loss: 3.3344\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3474\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2918\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 58.3163 - reconstruction_loss: 49.4194 - kl_loss: 8.8969\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 78.4346 - reconstruction_loss: 69.5319 - kl_loss: 8.9028\n",
      "training on full data\n",
      "1 30\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1339\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1193\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 32.5791 - reconstruction_loss: 30.2157 - kl_loss: 2.3634\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 43.0939 - reconstruction_loss: 40.7201 - kl_loss: 2.3738\n",
      "Success in episode 6 at time step 178 with reward 98.13503785498334\n",
      "Episode 7\n",
      "[-0.46649384  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0460\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0378\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 22.9875 - reconstruction_loss: 22.1773 - kl_loss: 0.8103\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 37.2486 - reconstruction_loss: 36.4461 - kl_loss: 0.8025\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0743\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0695\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 27.2262 - reconstruction_loss: 26.0834 - kl_loss: 1.1428\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 41.1943 - reconstruction_loss: 40.0610 - kl_loss: 1.1333\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0268\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0289\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.0896 - reconstruction_loss: 10.0053 - kl_loss: 4.0843\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 31.1501 - reconstruction_loss: 27.0634 - kl_loss: 4.0867\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5080\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4938\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4135 - reconstruction_loss: 16.2609 - kl_loss: 3.1526\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 27.4579 - reconstruction_loss: 24.2925 - kl_loss: 3.1654\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0764\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0764\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 50.2800 - reconstruction_loss: 47.8184 - kl_loss: 2.4616\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 46.2656 - reconstruction_loss: 43.7821 - kl_loss: 2.4835\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1569\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1374\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 37.0714 - reconstruction_loss: 34.6690 - kl_loss: 2.4023\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 53.6321 - reconstruction_loss: 51.2134 - kl_loss: 2.4187\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1464\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1507\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 33.6734 - reconstruction_loss: 28.4782 - kl_loss: 5.1952\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 28.6388 - reconstruction_loss: 23.4398 - kl_loss: 5.1990\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1811\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1782\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 84.8717 - reconstruction_loss: 76.3580 - kl_loss: 8.5137\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 76.2347 - reconstruction_loss: 67.7056 - kl_loss: 8.5291\n",
      "training on full data\n",
      "0 18\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1344\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1257\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 48.7955 - reconstruction_loss: 45.1091 - kl_loss: 3.6864\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 44.5274 - reconstruction_loss: 40.8202 - kl_loss: 3.7072\n",
      "Success in episode 7 at time step 108 with reward 98.55157466884157\n",
      "Episode 8\n",
      "[-0.5185112  0.       ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0449\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0406\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.0591 - reconstruction_loss: 10.3303 - kl_loss: 0.7288\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.9003 - reconstruction_loss: 13.1715 - kl_loss: 0.7288\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0945\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0866\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 27.6869 - reconstruction_loss: 26.8331 - kl_loss: 0.8538\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 46.4835 - reconstruction_loss: 45.6332 - kl_loss: 0.8503\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0685\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0614\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 42.6402 - reconstruction_loss: 41.7366 - kl_loss: 0.9036\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 51.0175 - reconstruction_loss: 50.1188 - kl_loss: 0.8987\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0805\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0715\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 25.6926 - reconstruction_loss: 24.2970 - kl_loss: 1.3957\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 33.6431 - reconstruction_loss: 32.2532 - kl_loss: 1.3900\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1009\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0957\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 59.7652 - reconstruction_loss: 58.2410 - kl_loss: 1.5242\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 22.2774 - reconstruction_loss: 20.7600 - kl_loss: 1.5174\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1305\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1234\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 36.9721 - reconstruction_loss: 34.9003 - kl_loss: 2.0718\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 47.7723 - reconstruction_loss: 45.7070 - kl_loss: 2.0653\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1356\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1269\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 27.5541 - reconstruction_loss: 25.3862 - kl_loss: 2.1679\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.1408 - reconstruction_loss: 5.9741 - kl_loss: 2.1667\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2565\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2593\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3751 - reconstruction_loss: 4.9445 - kl_loss: 1.4306\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.1057 - reconstruction_loss: 10.6782 - kl_loss: 1.4275\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0863\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0896\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.4024 - reconstruction_loss: 5.8333 - kl_loss: 1.5691\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.5528 - reconstruction_loss: 16.9917 - kl_loss: 1.5612\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0314\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0300\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 55.3155 - reconstruction_loss: 52.5001 - kl_loss: 2.8154\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 37.0526 - reconstruction_loss: 34.2297 - kl_loss: 2.8228\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0485\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0474\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 91.2828 - reconstruction_loss: 87.9174 - kl_loss: 3.3654\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 109.3327 - reconstruction_loss: 105.9596 - kl_loss: 3.3730\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2165\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2131\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 152.7529 - reconstruction_loss: 146.3653 - kl_loss: 6.3877\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 155.8467 - reconstruction_loss: 149.4684 - kl_loss: 6.3783\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1127\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1055\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 178.9583 - reconstruction_loss: 169.0788 - kl_loss: 9.8795\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 193.4438 - reconstruction_loss: 183.5653 - kl_loss: 9.8785\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1699\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1580\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 83.6693 - reconstruction_loss: 70.2802 - kl_loss: 13.3891\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 70.3262 - reconstruction_loss: 56.9779 - kl_loss: 13.3483\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.6223\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.2172\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 50.3395 - reconstruction_loss: 44.6028 - kl_loss: 5.7367\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 57.2678 - reconstruction_loss: 51.5233 - kl_loss: 5.7445\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2932\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2849\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 34.3698 - reconstruction_loss: 30.4613 - kl_loss: 3.9085\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 33.0510 - reconstruction_loss: 29.1447 - kl_loss: 3.9063\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0910\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0833\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 44.8986 - reconstruction_loss: 36.9789 - kl_loss: 7.9197\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 40.0478 - reconstruction_loss: 32.1204 - kl_loss: 7.9275\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1951\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1831\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 170.8132 - reconstruction_loss: 164.0285 - kl_loss: 6.7847\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 194.4317 - reconstruction_loss: 187.6281 - kl_loss: 6.8037\n",
      "training on full data\n",
      "1 39\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2124\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2015\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 71.5582 - reconstruction_loss: 67.6582 - kl_loss: 3.9000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 56.6960 - reconstruction_loss: 52.7992 - kl_loss: 3.8968\n",
      "Success in episode 8 at time step 233 with reward 97.6877466829377\n",
      "Episode 9\n",
      "[-0.54978925  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1416\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1344\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.0078 - reconstruction_loss: 13.0133 - kl_loss: 0.9946\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2638 - reconstruction_loss: 3.2840 - kl_loss: 0.9798\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0261\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0218\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.7246 - reconstruction_loss: 17.2115 - kl_loss: 0.5132\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.5342 - reconstruction_loss: 17.0314 - kl_loss: 0.5028\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0691\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0692\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 29.7774 - reconstruction_loss: 29.0184 - kl_loss: 0.7590\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.7312 - reconstruction_loss: 12.9794 - kl_loss: 0.7519\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1513\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1484\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 64.4162 - reconstruction_loss: 62.6090 - kl_loss: 1.8072\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 46.0409 - reconstruction_loss: 44.2402 - kl_loss: 1.8006\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3838\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3870\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 47.6785 - reconstruction_loss: 43.4960 - kl_loss: 4.1825\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 27.7798 - reconstruction_loss: 23.5918 - kl_loss: 4.1880\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5940\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5758\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 41.3464 - reconstruction_loss: 37.2735 - kl_loss: 4.0728\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 43.6966 - reconstruction_loss: 39.6039 - kl_loss: 4.0927\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1689\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1489\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 20.1697 - reconstruction_loss: 18.6835 - kl_loss: 1.4862\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 27.6708 - reconstruction_loss: 26.1797 - kl_loss: 1.4911\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1028\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1071\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.5069 - reconstruction_loss: 6.9114 - kl_loss: 1.5955\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.2990 - reconstruction_loss: 12.7119 - kl_loss: 1.5871\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0469\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0429\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.6919 - reconstruction_loss: 13.3026 - kl_loss: 4.3892\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 27.7760 - reconstruction_loss: 23.3886 - kl_loss: 4.3874\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1608\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1575\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 127.4635 - reconstruction_loss: 121.2681 - kl_loss: 6.1955\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 155.9817 - reconstruction_loss: 149.7726 - kl_loss: 6.2092\n",
      "training on full data\n",
      "0 22\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2395\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2320\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 40.3915 - reconstruction_loss: 37.6774 - kl_loss: 2.7141\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 32.2076 - reconstruction_loss: 29.4912 - kl_loss: 2.7164\n",
      "Success in episode 9 at time step 130 with reward 98.514967393433\n",
      "Episode 10\n",
      "[-0.4733431  0.       ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2414\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2347\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2908 - reconstruction_loss: 5.7946 - kl_loss: 0.4962\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.0653 - reconstruction_loss: 14.5760 - kl_loss: 0.4893\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1005\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0894\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.1278 - reconstruction_loss: 13.5264 - kl_loss: 1.6013\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.9531 - reconstruction_loss: 11.3612 - kl_loss: 1.5919\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0671\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0590\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6822 - reconstruction_loss: 3.9932 - kl_loss: 1.6889\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.2695 - reconstruction_loss: 11.5863 - kl_loss: 1.6833\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4858\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4289\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 26.4743 - reconstruction_loss: 25.2238 - kl_loss: 1.2504\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 28.4601 - reconstruction_loss: 27.2043 - kl_loss: 1.2558\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2203\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2222\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.0807 - reconstruction_loss: 17.5011 - kl_loss: 1.5795\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 31.4337 - reconstruction_loss: 29.8448 - kl_loss: 1.5889\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2245\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2217\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.8812 - reconstruction_loss: 8.0143 - kl_loss: 2.8669\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.8558 - reconstruction_loss: 7.9816 - kl_loss: 2.8742\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0364\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0369\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 37.1532 - reconstruction_loss: 31.7220 - kl_loss: 5.4312\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 38.9274 - reconstruction_loss: 33.4848 - kl_loss: 5.4425\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1799\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1808\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 159.5278 - reconstruction_loss: 153.5380 - kl_loss: 5.9898\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 107.7725 - reconstruction_loss: 101.7680 - kl_loss: 6.0045\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3654\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3609\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 149.1907 - reconstruction_loss: 141.3076 - kl_loss: 7.8832\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 122.1733 - reconstruction_loss: 114.2846 - kl_loss: 7.8887\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0884\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0838\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 94.2964 - reconstruction_loss: 82.4758 - kl_loss: 11.8206\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 100.3664 - reconstruction_loss: 88.5244 - kl_loss: 11.8420\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4819\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4334\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 118.7901 - reconstruction_loss: 102.8638 - kl_loss: 15.9263\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 74.1613 - reconstruction_loss: 58.1963 - kl_loss: 15.9650\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.2291\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.8039\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 72.6770 - reconstruction_loss: 62.9220 - kl_loss: 9.7549\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 68.7384 - reconstruction_loss: 58.9062 - kl_loss: 9.8322\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5402\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4650\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 39.3562 - reconstruction_loss: 35.1813 - kl_loss: 4.1749\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48.7920 - reconstruction_loss: 44.6104 - kl_loss: 4.1816\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1946\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1620\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 58.8966 - reconstruction_loss: 47.6076 - kl_loss: 11.2890\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 39.6535 - reconstruction_loss: 28.3672 - kl_loss: 11.2863\n",
      "training on full data\n",
      "0 31\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4134\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4052\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 76.2307 - reconstruction_loss: 69.9660 - kl_loss: 6.2647\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 69.1902 - reconstruction_loss: 62.8943 - kl_loss: 6.2959\n",
      "Success in episode 10 at time step 182 with reward 97.71903373659019\n",
      "Episode 11\n",
      "[-0.40307632  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2347\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2394\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.1679 - reconstruction_loss: 18.2840 - kl_loss: 0.8839\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.4361 - reconstruction_loss: 14.5562 - kl_loss: 0.8799\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1098\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1082\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 29.2788 - reconstruction_loss: 28.2594 - kl_loss: 1.0193\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9890 - reconstruction_loss: 8.9669 - kl_loss: 1.0221\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0392\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0439\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7468 - reconstruction_loss: 3.4268 - kl_loss: 0.3200\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0472 - reconstruction_loss: 1.7252 - kl_loss: 0.3220\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1946\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1971\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.2289 - reconstruction_loss: 7.5075 - kl_loss: 0.7213\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.4559 - reconstruction_loss: 9.7414 - kl_loss: 0.7145\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0992\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0987\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 40.2161 - reconstruction_loss: 39.0933 - kl_loss: 1.1228\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 33.7398 - reconstruction_loss: 32.6224 - kl_loss: 1.1173\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1719\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1688\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 88.2902 - reconstruction_loss: 86.4343 - kl_loss: 1.8559\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 78.5320 - reconstruction_loss: 76.6791 - kl_loss: 1.8529\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5037\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4895\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 58.6365 - reconstruction_loss: 54.1527 - kl_loss: 4.4838\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.7649 - reconstruction_loss: 15.2681 - kl_loss: 4.4968\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8999\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7876\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 34.8618 - reconstruction_loss: 26.7217 - kl_loss: 8.1401\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.0942 - reconstruction_loss: 4.9319 - kl_loss: 8.1624\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1654\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1428\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.6405 - reconstruction_loss: 16.2821 - kl_loss: 2.3583\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 30.6336 - reconstruction_loss: 28.2625 - kl_loss: 2.3711\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4264\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4207\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.3426 - reconstruction_loss: 5.1540 - kl_loss: 2.1886\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.3739 - reconstruction_loss: 16.1829 - kl_loss: 2.1910\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2040\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1862\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 35.2420 - reconstruction_loss: 28.3948 - kl_loss: 6.8472\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 28.2046 - reconstruction_loss: 21.3459 - kl_loss: 6.8587\n",
      "training on full data\n",
      "0 25\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2242\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2129\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 35.9392 - reconstruction_loss: 32.9102 - kl_loss: 3.0289\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 36.3593 - reconstruction_loss: 33.3251 - kl_loss: 3.0343\n",
      "Success in episode 11 at time step 149 with reward 98.27745247096134\n",
      "Episode 12\n",
      "[-0.498884  0.      ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3450\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3293\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.2246 - reconstruction_loss: 12.9113 - kl_loss: 0.3133\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.2650 - reconstruction_loss: 9.9582 - kl_loss: 0.3068\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2723\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 38.8838 - reconstruction_loss: 38.1127 - kl_loss: 0.7711\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 31.9521 - reconstruction_loss: 31.1869 - kl_loss: 0.7651\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1053\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0957\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.4189 - reconstruction_loss: 5.2683 - kl_loss: 2.1507\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 29.4226 - reconstruction_loss: 27.2757 - kl_loss: 2.1469\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1367\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1291\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.4752 - reconstruction_loss: 8.3745 - kl_loss: 4.1007\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.3040 - reconstruction_loss: 11.1960 - kl_loss: 4.1079\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7497\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7218\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.9611 - reconstruction_loss: 19.4624 - kl_loss: 0.4987\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.6533 - reconstruction_loss: 13.1566 - kl_loss: 0.4967\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2978\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3080\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0202 - reconstruction_loss: 2.1287 - kl_loss: 1.8915\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.4432 - reconstruction_loss: 14.5540 - kl_loss: 1.8892\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1226\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1205\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 77.9643 - reconstruction_loss: 75.1206 - kl_loss: 2.8437\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 34.1712 - reconstruction_loss: 31.3215 - kl_loss: 2.8497\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4143\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4024\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 71.9170 - reconstruction_loss: 67.7340 - kl_loss: 4.1830\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 87.5008 - reconstruction_loss: 83.3136 - kl_loss: 4.1872\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1847\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1894\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 60.1821 - reconstruction_loss: 53.2959 - kl_loss: 6.8862\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 37.1904 - reconstruction_loss: 30.3014 - kl_loss: 6.8891\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6818\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6307\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 35.4007 - reconstruction_loss: 26.0053 - kl_loss: 9.3954\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 24.6954 - reconstruction_loss: 15.2797 - kl_loss: 9.4157\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6712\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6323\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 26.0644 - reconstruction_loss: 21.5051 - kl_loss: 4.5593\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 20.6801 - reconstruction_loss: 16.1074 - kl_loss: 4.5727\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1742\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1761\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.9356 - reconstruction_loss: 17.4369 - kl_loss: 2.4987\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 30.6156 - reconstruction_loss: 28.1170 - kl_loss: 2.4986\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0562\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0562\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 38.4787 - reconstruction_loss: 31.3586 - kl_loss: 7.1201\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 32.8986 - reconstruction_loss: 25.7772 - kl_loss: 7.1214\n",
      "training on full data\n",
      "1 30\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2423\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2372\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 39.7871 - reconstruction_loss: 35.9361 - kl_loss: 3.8510\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 29.0750 - reconstruction_loss: 25.2188 - kl_loss: 3.8561\n",
      "Success in episode 12 at time step 178 with reward 97.80685155428539\n",
      "Episode 13\n",
      "[-0.54549855  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3913\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3506\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7961 - reconstruction_loss: 1.2741 - kl_loss: 0.5220\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.3841 - reconstruction_loss: 11.8712 - kl_loss: 0.5129\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1467\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1391\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.5196 - reconstruction_loss: 7.7700 - kl_loss: 0.7496\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.8603 - reconstruction_loss: 9.1101 - kl_loss: 0.7502\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1191\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1031\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.0236 - reconstruction_loss: 15.2458 - kl_loss: 1.7778\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 34.4834 - reconstruction_loss: 32.7079 - kl_loss: 1.7755\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2700\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2704\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.1315 - reconstruction_loss: 8.2281 - kl_loss: 6.9034\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 33.5426 - reconstruction_loss: 26.6521 - kl_loss: 6.8905\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.3012\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.9650\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 46.1734 - reconstruction_loss: 39.3081 - kl_loss: 6.8654\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 31.8782 - reconstruction_loss: 24.9949 - kl_loss: 6.8833\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4546\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3772\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 67.4701 - reconstruction_loss: 62.4018 - kl_loss: 5.0682\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 58.7528 - reconstruction_loss: 53.6412 - kl_loss: 5.1116\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2339\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1425\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 57.8802 - reconstruction_loss: 51.0714 - kl_loss: 6.8088\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48.1736 - reconstruction_loss: 41.3538 - kl_loss: 6.8198\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2623\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2723\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 34.1858 - reconstruction_loss: 20.2809 - kl_loss: 13.9049\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 42.9424 - reconstruction_loss: 29.0606 - kl_loss: 13.8817\n",
      "training on full data\n",
      "5 23\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4745\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4699\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 30.7111 - reconstruction_loss: 26.1324 - kl_loss: 4.5787\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 29.8003 - reconstruction_loss: 25.2023 - kl_loss: 4.5979\n",
      "Success in episode 13 at time step 136 with reward 98.38036666958465\n",
      "Episode 14\n",
      "[-0.48594463  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2376\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2297\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.6784 - reconstruction_loss: 7.9940 - kl_loss: 0.6844\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.4997 - reconstruction_loss: 7.8109 - kl_loss: 0.6889\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3634\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3587\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.1603 - reconstruction_loss: 16.2967 - kl_loss: 2.8636\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 36.6916 - reconstruction_loss: 33.7998 - kl_loss: 2.8918\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8836\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7904\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 23.2467 - reconstruction_loss: 18.9396 - kl_loss: 4.3070\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.9944 - reconstruction_loss: 11.6137 - kl_loss: 4.3807\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5261\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5484\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 24.9601 - reconstruction_loss: 20.1780 - kl_loss: 4.7820\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 31.2232 - reconstruction_loss: 26.3651 - kl_loss: 4.8582\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3496\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3159\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 21.1733 - reconstruction_loss: 17.4234 - kl_loss: 3.7499\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 22.7754 - reconstruction_loss: 18.9927 - kl_loss: 3.7827\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0256\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0295\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 32.5134 - reconstruction_loss: 22.8128 - kl_loss: 9.7005\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 27.2435 - reconstruction_loss: 17.5410 - kl_loss: 9.7025\n",
      "training on full data\n",
      "0 15\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3129\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3017\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 37.9766 - reconstruction_loss: 32.6636 - kl_loss: 5.3131\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 29.8487 - reconstruction_loss: 24.5037 - kl_loss: 5.3451\n",
      "Success in episode 14 at time step 85 with reward 98.7710619417552\n",
      "Episode 15\n",
      "[-0.5118073  0.       ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1829\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1826\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.4875 - reconstruction_loss: 10.2359 - kl_loss: 0.2517\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2555 - reconstruction_loss: 4.9995 - kl_loss: 0.2560\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8010\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7811\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8218 - reconstruction_loss: 3.8427 - kl_loss: 0.9791\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4100 - reconstruction_loss: 4.4221 - kl_loss: 0.9879\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0723\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0741\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.4820 - reconstruction_loss: 15.2861 - kl_loss: 0.1959\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.9422 - reconstruction_loss: 11.7485 - kl_loss: 0.1937\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2410\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2368\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 30.7252 - reconstruction_loss: 30.0957 - kl_loss: 0.6295\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9845 - reconstruction_loss: 4.3587 - kl_loss: 0.6257\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1599\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1601\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 24.1039 - reconstruction_loss: 18.7130 - kl_loss: 5.3909\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.9250 - reconstruction_loss: 12.5249 - kl_loss: 5.4000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3611\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1458\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.4267 - reconstruction_loss: 3.0740 - kl_loss: 10.3526\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 29.8287 - reconstruction_loss: 19.4582 - kl_loss: 10.3706\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5968\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6862\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 37.3139 - reconstruction_loss: 28.3506 - kl_loss: 8.9632\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 39.3427 - reconstruction_loss: 30.3695 - kl_loss: 8.9732\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4905\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4335\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 34.2554 - reconstruction_loss: 27.6173 - kl_loss: 6.6381\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 30.5647 - reconstruction_loss: 23.8779 - kl_loss: 6.6868\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5792\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5507\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 23.0352 - reconstruction_loss: 12.0368 - kl_loss: 10.9984\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 29.1548 - reconstruction_loss: 18.1434 - kl_loss: 11.0114\n",
      "training on full data\n",
      "1 22\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3342\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3223\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 32.4942 - reconstruction_loss: 26.9532 - kl_loss: 5.5410\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 21.0003 - reconstruction_loss: 15.4547 - kl_loss: 5.5456\n",
      "Success in episode 15 at time step 128 with reward 98.3712071609682\n",
      "Episode 16\n",
      "[-0.4126071  0.       ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1361\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1312\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.9216 - reconstruction_loss: 7.9529 - kl_loss: 0.9688\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.1031 - reconstruction_loss: 17.1580 - kl_loss: 0.9451\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0822\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0707\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3093 - reconstruction_loss: 4.0610 - kl_loss: 3.2483\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0632 - reconstruction_loss: 1.8495 - kl_loss: 3.2137\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2021\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1956\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.1437 - reconstruction_loss: 10.3403 - kl_loss: 3.8035\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.1921 - reconstruction_loss: 7.3961 - kl_loss: 3.7959\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2693\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 999us/step - kl_loss: 0.2654\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.8168 - reconstruction_loss: 6.2743 - kl_loss: 4.5424\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.4650 - reconstruction_loss: 7.8897 - kl_loss: 4.5753\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1874\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1807\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 39.5083 - reconstruction_loss: 30.0752 - kl_loss: 9.4331\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 24.5756 - reconstruction_loss: 15.1155 - kl_loss: 9.4601\n",
      "training on full data\n",
      "2 15\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2541\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2509\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 29.7794 - reconstruction_loss: 25.1999 - kl_loss: 4.5795\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 25.2546 - reconstruction_loss: 20.6629 - kl_loss: 4.5916\n",
      "Success in episode 16 at time step 86 with reward 98.85041336329371\n",
      "Episode 17\n",
      "[-0.5455121  0.       ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4831\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4752\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0961 - reconstruction_loss: 4.8948 - kl_loss: 0.2013\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 31.6562 - reconstruction_loss: 31.4532 - kl_loss: 0.2029\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2475\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2387\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.7433 - reconstruction_loss: 9.5862 - kl_loss: 0.1571\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 26.3485 - reconstruction_loss: 26.1914 - kl_loss: 0.1571\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2113\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2010\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.8329 - reconstruction_loss: 14.2171 - kl_loss: 0.6158\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.9438 - reconstruction_loss: 16.3305 - kl_loss: 0.6133\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1727\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1653\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 41.6980 - reconstruction_loss: 39.8412 - kl_loss: 1.8568\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.0710 - reconstruction_loss: 11.2153 - kl_loss: 1.8558\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0451\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0454\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.6247 - reconstruction_loss: 13.6222 - kl_loss: 4.0025\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.3253 - reconstruction_loss: 13.3255 - kl_loss: 3.9998\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1577\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1472\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.7577 - reconstruction_loss: 4.7498 - kl_loss: 5.0080\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.1983 - reconstruction_loss: 9.1928 - kl_loss: 5.0055\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2543\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2518\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.0275 - reconstruction_loss: 11.2280 - kl_loss: 3.7995\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.7497 - reconstruction_loss: 5.9441 - kl_loss: 3.8056\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0840\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0812\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 34.7690 - reconstruction_loss: 28.3532 - kl_loss: 6.4158\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.5747 - reconstruction_loss: 13.1562 - kl_loss: 6.4185\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8005\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7917\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 98.2688 - reconstruction_loss: 91.9434 - kl_loss: 6.3253\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 41.8979 - reconstruction_loss: 35.5582 - kl_loss: 6.3397\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8587\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8233\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 26.6835 - reconstruction_loss: 18.5418 - kl_loss: 8.1417\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 96.0629 - reconstruction_loss: 87.9043 - kl_loss: 8.1586\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6657\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5874\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 108.6966 - reconstruction_loss: 97.0774 - kl_loss: 11.6193\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 59.6917 - reconstruction_loss: 48.0478 - kl_loss: 11.6438\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 12.5014\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 10.9822\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 32.5737 - reconstruction_loss: 14.7383 - kl_loss: 17.8354\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 36.4411 - reconstruction_loss: 18.6121 - kl_loss: 17.8290\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5392\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3968\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 27.7297 - reconstruction_loss: 19.6310 - kl_loss: 8.0988\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 31.3557 - reconstruction_loss: 23.2270 - kl_loss: 8.1287\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1695\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1967\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 37.2466 - reconstruction_loss: 23.7708 - kl_loss: 13.4758\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 36.2920 - reconstruction_loss: 22.8131 - kl_loss: 13.4789\n",
      "training on full data\n",
      "3 34\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8679\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8522\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 43.4293 - reconstruction_loss: 36.3409 - kl_loss: 7.0884\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 57.3192 - reconstruction_loss: 50.2300 - kl_loss: 7.0892\n",
      "Success in episode 17 at time step 201 with reward 97.8277563698586\n",
      "Episode 18\n",
      "[-0.55081254  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5865\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5683\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6049 - reconstruction_loss: 5.5013 - kl_loss: 0.1036\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.8279 - reconstruction_loss: 8.7239 - kl_loss: 0.1040\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2268\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2008\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.1092 - reconstruction_loss: 15.8844 - kl_loss: 0.2247\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.2582 - reconstruction_loss: 11.0286 - kl_loss: 0.2296\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0008\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9957\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.3599 - reconstruction_loss: 7.5926 - kl_loss: 0.7673\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 24.1201 - reconstruction_loss: 23.3443 - kl_loss: 0.7758\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5694\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5278\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.6416 - reconstruction_loss: 9.3955 - kl_loss: 2.2461\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.2138 - reconstruction_loss: 5.9472 - kl_loss: 2.2666\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6816\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6715\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.5110 - reconstruction_loss: 6.5785 - kl_loss: 1.9325\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 20.8571 - reconstruction_loss: 18.9097 - kl_loss: 1.9474\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3840\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3701\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.8914 - reconstruction_loss: 7.1117 - kl_loss: 1.7796\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9312 - reconstruction_loss: 3.1644 - kl_loss: 1.7668\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4121\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3993\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 23.0898 - reconstruction_loss: 21.6791 - kl_loss: 1.4107\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.1089 - reconstruction_loss: 13.7024 - kl_loss: 1.4065\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1848\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1756\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 27.5605 - reconstruction_loss: 23.6086 - kl_loss: 3.9519\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.6488 - reconstruction_loss: 6.6874 - kl_loss: 3.9614\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.4050\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.1363\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.5054 - reconstruction_loss: 9.6759 - kl_loss: 5.8294\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.5694 - reconstruction_loss: 7.7208 - kl_loss: 5.8486\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.3454\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.3661\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.3820 - reconstruction_loss: 12.3322 - kl_loss: 5.0498\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.9437 - reconstruction_loss: 11.8685 - kl_loss: 5.0752\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2491\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2391\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.6504 - reconstruction_loss: 4.0687 - kl_loss: 6.5817\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.6200 - reconstruction_loss: 6.0434 - kl_loss: 6.5767\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4710\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4440\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.6716 - reconstruction_loss: 5.1691 - kl_loss: 5.5025\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 23.3574 - reconstruction_loss: 17.8626 - kl_loss: 5.4947\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6202\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6113\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 49.2117 - reconstruction_loss: 43.6026 - kl_loss: 5.6091\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 60.1984 - reconstruction_loss: 54.5927 - kl_loss: 5.6057\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3503\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3285\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 57.8960 - reconstruction_loss: 49.6992 - kl_loss: 8.1968\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 42.7005 - reconstruction_loss: 34.5083 - kl_loss: 8.1922\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.4308\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.0790\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.9016 - reconstruction_loss: 2.4248 - kl_loss: 15.4768\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 20.1868 - reconstruction_loss: 4.7244 - kl_loss: 15.4624\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5859\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4545\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 23.3413 - reconstruction_loss: 15.5467 - kl_loss: 7.7946\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 26.4804 - reconstruction_loss: 18.6603 - kl_loss: 7.8201\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7343\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6454\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 34.5698 - reconstruction_loss: 22.2362 - kl_loss: 12.3336\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 28.5393 - reconstruction_loss: 16.1788 - kl_loss: 12.3606\n",
      "training on full data\n",
      "4 41\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7423\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7336\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 22.1676 - reconstruction_loss: 16.2813 - kl_loss: 5.8864\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 22.2785 - reconstruction_loss: 16.3766 - kl_loss: 5.9020\n",
      "Success in episode 18 at time step 244 with reward 98.05983727511908\n",
      "Episode 19\n",
      "[-0.47230262  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4786\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4825\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.9476 - reconstruction_loss: 13.8642 - kl_loss: 0.0833\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9025 - reconstruction_loss: 6.8178 - kl_loss: 0.0847\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2265\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2174\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.4153 - reconstruction_loss: 7.0453 - kl_loss: 0.3701\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.3410 - reconstruction_loss: 9.9676 - kl_loss: 0.3734\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9807\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9254\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 27.5082 - reconstruction_loss: 25.1743 - kl_loss: 2.3339\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8042 - reconstruction_loss: 3.4694 - kl_loss: 2.3348\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4544\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3414\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.6795 - reconstruction_loss: 8.8263 - kl_loss: 3.8532\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0079 - reconstruction_loss: 1.1475 - kl_loss: 3.8604\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8182\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7012\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.3140 - reconstruction_loss: 6.6535 - kl_loss: 3.6604\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5295 - reconstruction_loss: 1.8666 - kl_loss: 3.6629\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4925\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4689\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.4525 - reconstruction_loss: 4.6881 - kl_loss: 5.7644\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.8331 - reconstruction_loss: 2.0618 - kl_loss: 5.7712\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2880\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2836\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.0480 - reconstruction_loss: 9.9433 - kl_loss: 5.1048\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 60.0368 - reconstruction_loss: 54.9320 - kl_loss: 5.1047\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7870\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7835\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48.6913 - reconstruction_loss: 42.7319 - kl_loss: 5.9594\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 24.7706 - reconstruction_loss: 18.7958 - kl_loss: 5.9747\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4635\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4514\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 53.6240 - reconstruction_loss: 45.0413 - kl_loss: 8.5827\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 81.6542 - reconstruction_loss: 73.0427 - kl_loss: 8.6115\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7197\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6227\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 39.1090 - reconstruction_loss: 18.7627 - kl_loss: 20.3463\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 60.5301 - reconstruction_loss: 40.1480 - kl_loss: 20.3821\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 9.8691\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 8.2971\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 26.1332 - reconstruction_loss: 8.0342 - kl_loss: 18.0990\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 30.2430 - reconstruction_loss: 12.0962 - kl_loss: 18.1468\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3376\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0391\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.3529 - reconstruction_loss: 6.5528 - kl_loss: 8.8001\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 24.2898 - reconstruction_loss: 15.4657 - kl_loss: 8.8241\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3824\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4247\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 28.0226 - reconstruction_loss: 10.3675 - kl_loss: 17.6551\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 31.6022 - reconstruction_loss: 13.9601 - kl_loss: 17.6421\n",
      "training on full data\n",
      "2 30\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8880\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8958\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 25.3367 - reconstruction_loss: 17.7679 - kl_loss: 7.5688\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 29.0380 - reconstruction_loss: 21.4599 - kl_loss: 7.5781\n",
      "Success in episode 19 at time step 178 with reward 98.02699776434896\n",
      "Episode 20\n",
      "[-0.45798334  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4159\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4237\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6305 - reconstruction_loss: 5.1282 - kl_loss: 0.5023\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.7185 - reconstruction_loss: 4.2116 - kl_loss: 0.5069\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4254\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4206\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2833 - reconstruction_loss: 4.0992 - kl_loss: 0.1841\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.3367 - reconstruction_loss: 8.1508 - kl_loss: 0.1859\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3530\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3451\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 20.0875 - reconstruction_loss: 19.4012 - kl_loss: 0.6862\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.8903 - reconstruction_loss: 8.2020 - kl_loss: 0.6883\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4656\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4484\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5888 - reconstruction_loss: 3.1584 - kl_loss: 0.4303\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3092 - reconstruction_loss: 0.8764 - kl_loss: 0.4328\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4689\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4471\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.6876 - reconstruction_loss: 6.2490 - kl_loss: 0.4386\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0830 - reconstruction_loss: 3.6424 - kl_loss: 0.4407\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5064\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4800\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.7175 - reconstruction_loss: 18.1693 - kl_loss: 0.5482\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9810 - reconstruction_loss: 3.4306 - kl_loss: 0.5504\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2930\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2747\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.5938 - reconstruction_loss: 5.8140 - kl_loss: 0.7798\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.5107 - reconstruction_loss: 6.7278 - kl_loss: 0.7829\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5560\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5332\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.2899 - reconstruction_loss: 9.1232 - kl_loss: 0.1666\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8643 - reconstruction_loss: 5.6958 - kl_loss: 0.1685\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4258\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4020\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6500 - reconstruction_loss: 4.8995 - kl_loss: 0.7505\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.2409 - reconstruction_loss: 7.4884 - kl_loss: 0.7526\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3128\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3261\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.0856 - reconstruction_loss: 8.8903 - kl_loss: 1.1953\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2562 - reconstruction_loss: 4.0601 - kl_loss: 1.1961\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8524\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8370\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.6418 - reconstruction_loss: 7.0001 - kl_loss: 0.6417\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6939 - reconstruction_loss: 4.0496 - kl_loss: 0.6443\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2228\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2026\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6527 - reconstruction_loss: 8.8843 - kl_loss: 0.7684\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.9846 - reconstruction_loss: 10.2136 - kl_loss: 0.7710\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6264\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5977\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.2742 - reconstruction_loss: 7.2864 - kl_loss: 0.9877\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3230 - reconstruction_loss: 5.3326 - kl_loss: 0.9904\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2945\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2828\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6932 - reconstruction_loss: 5.4694 - kl_loss: 0.2238\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.9924 - reconstruction_loss: 10.7690 - kl_loss: 0.2234\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8770\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8150\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5795 - reconstruction_loss: 2.6820 - kl_loss: 0.8975\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.7273 - reconstruction_loss: 7.8289 - kl_loss: 0.8984\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9440\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8732\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.8461 - reconstruction_loss: 11.0168 - kl_loss: 3.8292\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.5085 - reconstruction_loss: 5.6786 - kl_loss: 3.8299\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1924\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0832\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.8901 - reconstruction_loss: 5.0607 - kl_loss: 5.8294\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4348 - reconstruction_loss: 2.6023 - kl_loss: 5.8325\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5645\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5669\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5161 - reconstruction_loss: 1.8966 - kl_loss: 3.6195\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.8680 - reconstruction_loss: 4.2504 - kl_loss: 3.6176\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7729\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7638\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.0529 - reconstruction_loss: 1.2300 - kl_loss: 6.8228\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.0181 - reconstruction_loss: 9.2006 - kl_loss: 6.8174\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4722\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4561\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 39.6999 - reconstruction_loss: 33.1569 - kl_loss: 6.5430\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 52.4542 - reconstruction_loss: 45.9099 - kl_loss: 6.5443\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9441\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.8337\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 182.6093 - reconstruction_loss: 171.8710 - kl_loss: 10.7383\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 52.0236 - reconstruction_loss: 41.2544 - kl_loss: 10.7691\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0029\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8666\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 22.1223 - reconstruction_loss: 6.6617 - kl_loss: 15.4606\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 45.8874 - reconstruction_loss: 30.3999 - kl_loss: 15.4875\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 11.6903\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 10.1448\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 34.1940 - reconstruction_loss: 12.3951 - kl_loss: 21.7989\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 24.7713 - reconstruction_loss: 2.9416 - kl_loss: 21.8297\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.6841\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.7361\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 21.8027 - reconstruction_loss: 10.9864 - kl_loss: 10.8163\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 20.2912 - reconstruction_loss: 9.4443 - kl_loss: 10.8470\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1543\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9308\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 20.9593 - reconstruction_loss: 7.3171 - kl_loss: 13.6422\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 30.9622 - reconstruction_loss: 17.3198 - kl_loss: 13.6425\n",
      "training on full data\n",
      "10 63\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8855\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8283\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.2530 - reconstruction_loss: 9.0100 - kl_loss: 4.2430\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.0761 - reconstruction_loss: 7.8244 - kl_loss: 4.2517\n",
      "Success in episode 20 at time step 374 with reward 97.5232138973655\n",
      "Episode 21\n",
      "[-0.5273047  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4867\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4495\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.4810 - reconstruction_loss: 6.3586 - kl_loss: 0.1225\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.8162 - reconstruction_loss: 14.6905 - kl_loss: 0.1257\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1330\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1262\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1313 - reconstruction_loss: 6.6318 - kl_loss: 0.4995\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.1333 - reconstruction_loss: 8.6340 - kl_loss: 0.4992\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2957\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2758\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.8953 - reconstruction_loss: 11.7659 - kl_loss: 1.1294\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6615 - reconstruction_loss: 4.5265 - kl_loss: 1.1350\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3223\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3338\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0305 - reconstruction_loss: 4.1247 - kl_loss: 0.9058\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.6729 - reconstruction_loss: 9.7570 - kl_loss: 0.9159\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0591\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0679\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4486 - reconstruction_loss: 3.9608 - kl_loss: 0.4878\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8944 - reconstruction_loss: 3.4015 - kl_loss: 0.4929\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9704\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9715\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4619 - reconstruction_loss: 2.8244 - kl_loss: 1.6375\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7341 - reconstruction_loss: 2.0879 - kl_loss: 1.6462\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2389\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2432\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.1968 - reconstruction_loss: 8.9747 - kl_loss: 0.2221\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1608 - reconstruction_loss: 2.9375 - kl_loss: 0.2233\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5395\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5206\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.7506 - reconstruction_loss: 8.1450 - kl_loss: 3.6056\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.3497 - reconstruction_loss: 13.7448 - kl_loss: 3.6049\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8564\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8302\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.1369 - reconstruction_loss: 5.9025 - kl_loss: 3.2344\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.9685 - reconstruction_loss: 4.7366 - kl_loss: 3.2319\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3872\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3594\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8398 - reconstruction_loss: 2.7535 - kl_loss: 1.0863\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8858 - reconstruction_loss: 2.7996 - kl_loss: 1.0863\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6231\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5362\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.3849 - reconstruction_loss: 6.4847 - kl_loss: 1.9002\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8291 - reconstruction_loss: 1.9247 - kl_loss: 1.9044\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6043\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5102\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.6654 - reconstruction_loss: 0.9411 - kl_loss: 5.7243\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.9566 - reconstruction_loss: 2.2337 - kl_loss: 5.7229\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.6162\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.2602\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.2622 - reconstruction_loss: 5.6342 - kl_loss: 6.6280\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.7574 - reconstruction_loss: 5.1330 - kl_loss: 6.6244\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.4247\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.3944\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.6151 - reconstruction_loss: 1.1037 - kl_loss: 6.5114\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.7222 - reconstruction_loss: 4.2059 - kl_loss: 6.5163\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.5421\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 964us/step - kl_loss: 2.0988\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.5731 - reconstruction_loss: 6.6490 - kl_loss: 9.9241\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.6282 - reconstruction_loss: 5.7036 - kl_loss: 9.9246\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3706\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3543\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.3290 - reconstruction_loss: 14.5702 - kl_loss: 3.7589\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 22.6411 - reconstruction_loss: 18.8808 - kl_loss: 3.7603\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6940\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6265\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.2798 - reconstruction_loss: 8.1299 - kl_loss: 9.1499\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 34.0821 - reconstruction_loss: 24.9269 - kl_loss: 9.1552\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 8.4005\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.9095\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 25.8603 - reconstruction_loss: 6.9074 - kl_loss: 18.9529\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 21.2041 - reconstruction_loss: 2.2750 - kl_loss: 18.9291\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6009\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6536\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 21.1694 - reconstruction_loss: 8.6271 - kl_loss: 12.5423\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 981us/step - loss: 21.1153 - reconstruction_loss: 8.5771 - kl_loss: 12.5383\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.2779\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.8050\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.4323 - reconstruction_loss: 5.9879 - kl_loss: 11.4444\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 24.5920 - reconstruction_loss: 13.1359 - kl_loss: 11.4561\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0395\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9664\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.7537 - reconstruction_loss: 3.9031 - kl_loss: 8.8505\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.0284 - reconstruction_loss: 4.1482 - kl_loss: 8.8802\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2897\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2992\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.7291 - reconstruction_loss: 8.5790 - kl_loss: 9.1501\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.6112 - reconstruction_loss: 7.4581 - kl_loss: 9.1532\n",
      "training on full data\n",
      "13 59\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9771\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9520\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.4777 - reconstruction_loss: 8.8538 - kl_loss: 4.6239\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.9113 - reconstruction_loss: 8.2796 - kl_loss: 4.6316\n",
      "Success in episode 21 at time step 349 with reward 96.74711120834148\n",
      "Episode 22\n",
      "[-0.562744  0.      ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6141\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6002\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3966 - reconstruction_loss: 0.5421 - kl_loss: 0.8544\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4585 - reconstruction_loss: 2.6003 - kl_loss: 0.8582\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1466\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1333\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0564 - reconstruction_loss: 3.7536 - kl_loss: 1.3028\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.4182 - reconstruction_loss: 7.1114 - kl_loss: 1.3069\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4536\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4329\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2465 - reconstruction_loss: 1.8709 - kl_loss: 3.3756\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.7751 - reconstruction_loss: 1.4013 - kl_loss: 3.3739\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.2212\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.2229\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6856 - reconstruction_loss: 6.7359 - kl_loss: 2.9497\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6918 - reconstruction_loss: 0.7375 - kl_loss: 2.9543\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6158\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6021\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.8244 - reconstruction_loss: 6.9603 - kl_loss: 1.8641\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4946 - reconstruction_loss: 2.6227 - kl_loss: 1.8719\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3765\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3700\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.7373 - reconstruction_loss: 9.5665 - kl_loss: 1.1708\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4065 - reconstruction_loss: 4.2317 - kl_loss: 1.1748\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1229\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1210\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.0838 - reconstruction_loss: 10.0354 - kl_loss: 2.0484\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8784 - reconstruction_loss: 2.8235 - kl_loss: 2.0549\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.7437\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.5259\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.5457 - reconstruction_loss: 2.7051 - kl_loss: 8.8406\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.2095 - reconstruction_loss: 5.3674 - kl_loss: 8.8421\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 11.7839\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 10.5257\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.7114 - reconstruction_loss: 2.3344 - kl_loss: 15.3770\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.5403 - reconstruction_loss: 1.1956 - kl_loss: 15.3447\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1205\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.8370\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 21.1799 - reconstruction_loss: 7.8639 - kl_loss: 13.3160\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.8598 - reconstruction_loss: 4.5429 - kl_loss: 13.3169\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7491\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7710\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 22.4104 - reconstruction_loss: 6.8903 - kl_loss: 15.5201\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 30.3048 - reconstruction_loss: 14.7934 - kl_loss: 15.5114\n",
      "training on full data\n",
      "8 33\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2429\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1981\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.2478 - reconstruction_loss: 6.7077 - kl_loss: 5.5401\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.8762 - reconstruction_loss: 8.3382 - kl_loss: 5.5380\n",
      "Success in episode 22 at time step 194 with reward 98.45517963271007\n",
      "Episode 23\n",
      "[-0.5678395  0.       ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.6035\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.5709\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8617 - reconstruction_loss: 0.9993 - kl_loss: 0.8623\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.4283 - reconstruction_loss: 8.5609 - kl_loss: 0.8674\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1495\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0287\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7379 - reconstruction_loss: 4.0646 - kl_loss: 1.6733\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1628 - reconstruction_loss: 1.4829 - kl_loss: 1.6799\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.5488\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.0986\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3102 - reconstruction_loss: 2.5762 - kl_loss: 1.7339\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9323 - reconstruction_loss: 2.1955 - kl_loss: 1.7367\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.0756\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.9358\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3805 - reconstruction_loss: 1.6813 - kl_loss: 0.6992\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1936 - reconstruction_loss: 0.4929 - kl_loss: 0.7007\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6493\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6289\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5249 - reconstruction_loss: 4.6411 - kl_loss: 0.8839\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3321 - reconstruction_loss: 1.4435 - kl_loss: 0.8886\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3852\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4420\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1546 - reconstruction_loss: 1.9622 - kl_loss: 1.1924\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2352 - reconstruction_loss: 6.0393 - kl_loss: 1.1959\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5980\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5756\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3163 - reconstruction_loss: 3.3489 - kl_loss: 0.9674\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.1129 - reconstruction_loss: 9.1487 - kl_loss: 0.9643\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4984\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4846\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.3583 - reconstruction_loss: 9.6180 - kl_loss: 1.7403\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.2920 - reconstruction_loss: 12.5521 - kl_loss: 1.7399\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4653\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4797\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.0577 - reconstruction_loss: 7.2672 - kl_loss: 3.7905\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.6853 - reconstruction_loss: 6.8892 - kl_loss: 3.7961\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.8735\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7169\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 27.0119 - reconstruction_loss: 16.5184 - kl_loss: 10.4935\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.7101 - reconstruction_loss: 1.2216 - kl_loss: 10.4885\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 14.5985\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 12.6909\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 29.0379 - reconstruction_loss: 8.5191 - kl_loss: 20.5188\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 24.0896 - reconstruction_loss: 3.6464 - kl_loss: 20.4433\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 20.4325\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 15.5484\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.1027 - reconstruction_loss: 6.6411 - kl_loss: 12.4616\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.8191 - reconstruction_loss: 4.3359 - kl_loss: 12.4832\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6183\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8710\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 24.3678 - reconstruction_loss: 7.9283 - kl_loss: 16.4394\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 28.1838 - reconstruction_loss: 11.7525 - kl_loss: 16.4312\n",
      "training on full data\n",
      "4 33\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6971\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6314\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.2939 - reconstruction_loss: 8.5379 - kl_loss: 5.7561\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.7263 - reconstruction_loss: 6.9769 - kl_loss: 5.7494\n",
      "Success in episode 23 at time step 194 with reward 97.81487203520521\n",
      "Episode 24\n",
      "[-0.5533298  0.       ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.0990\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.8647\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3061 - reconstruction_loss: 5.1219 - kl_loss: 1.1842\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4126 - reconstruction_loss: 2.2317 - kl_loss: 1.1810\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3941\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3906\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8845 - reconstruction_loss: 0.1591 - kl_loss: 1.7254\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.1757 - reconstruction_loss: 8.4499 - kl_loss: 1.7258\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8205\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8168\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.1790 - reconstruction_loss: 8.0126 - kl_loss: 2.1663\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7702 - reconstruction_loss: 3.5987 - kl_loss: 2.1715\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4197\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4194\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6900 - reconstruction_loss: 2.9823 - kl_loss: 0.7077\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1968 - reconstruction_loss: 2.4837 - kl_loss: 0.7131\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3949\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3975\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.1559 - reconstruction_loss: 5.7223 - kl_loss: 0.4337\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.1126 - reconstruction_loss: 5.6786 - kl_loss: 0.4341\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5501\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5367\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7159 - reconstruction_loss: 1.4705 - kl_loss: 1.2453\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8426 - reconstruction_loss: 2.5974 - kl_loss: 1.2452\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7147\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6603\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.7581 - reconstruction_loss: 3.6782 - kl_loss: 4.0799\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8248 - reconstruction_loss: 0.7377 - kl_loss: 4.0871\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.8247\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.5979\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.6869 - reconstruction_loss: 4.0335 - kl_loss: 3.6534\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9723 - reconstruction_loss: 2.3147 - kl_loss: 3.6576\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2246\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.2149\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8008 - reconstruction_loss: 2.6141 - kl_loss: 3.1867\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.3704 - reconstruction_loss: 7.1830 - kl_loss: 3.1873\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3623\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3605\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9465 - reconstruction_loss: 3.8990 - kl_loss: 1.0475\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8877 - reconstruction_loss: 1.8384 - kl_loss: 1.0493\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3674\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4041\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.0566 - reconstruction_loss: 1.7753 - kl_loss: 4.2813\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.3158 - reconstruction_loss: 15.0390 - kl_loss: 4.2768\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.2068\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.1621\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.1632 - reconstruction_loss: 6.6603 - kl_loss: 9.5029\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.8941 - reconstruction_loss: 5.3754 - kl_loss: 9.5187\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 20.5402\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 19.2818\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.6218 - reconstruction_loss: 2.2241 - kl_loss: 14.3977\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.4365 - reconstruction_loss: 2.0097 - kl_loss: 14.4268\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 24.8433\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 22.3479\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.9918 - reconstruction_loss: 5.6873 - kl_loss: 13.3045\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.8077 - reconstruction_loss: 4.4919 - kl_loss: 13.3158\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1631\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.5850\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 25.3809 - reconstruction_loss: 10.1941 - kl_loss: 15.1867\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 28.5856 - reconstruction_loss: 13.4163 - kl_loss: 15.1693\n",
      "training on full data\n",
      "8 41\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.5206\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.3411\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.4132 - reconstruction_loss: 5.4536 - kl_loss: 4.9596\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.4575 - reconstruction_loss: 4.4946 - kl_loss: 4.9629\n",
      "Success in episode 24 at time step 241 with reward 98.51800679042175\n",
      "Episode 25\n",
      "[-0.5099817  0.       ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3138\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2865\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5516 - reconstruction_loss: 3.7920 - kl_loss: 0.7596\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9967 - reconstruction_loss: 4.2311 - kl_loss: 0.7656\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1853\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1799\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0576 - reconstruction_loss: 2.3767 - kl_loss: 0.6809\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7859 - reconstruction_loss: 1.1011 - kl_loss: 0.6848\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5641\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5519\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.4538 - reconstruction_loss: 6.2064 - kl_loss: 1.2474\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 20.5293 - reconstruction_loss: 19.2720 - kl_loss: 1.2573\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8810\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9191\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5692 - reconstruction_loss: 2.3350 - kl_loss: 3.2341\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2122 - reconstruction_loss: 1.9638 - kl_loss: 3.2485\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5322\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5211\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9664 - reconstruction_loss: 0.9873 - kl_loss: 1.9791\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4847 - reconstruction_loss: 1.5085 - kl_loss: 1.9762\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4257\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4133\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 30.0190 - reconstruction_loss: 26.8657 - kl_loss: 3.1532\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.0555 - reconstruction_loss: 8.8913 - kl_loss: 3.1642\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5951\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6247\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.7286 - reconstruction_loss: 4.5783 - kl_loss: 10.1503\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.6542 - reconstruction_loss: 4.4792 - kl_loss: 10.1750\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 13.4498\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 12.3487\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.1918 - reconstruction_loss: 2.1537 - kl_loss: 14.0381\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.9520 - reconstruction_loss: 3.9326 - kl_loss: 14.0194\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 9.8804\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 7.9493\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.5799 - reconstruction_loss: 2.4548 - kl_loss: 12.1251\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.3349 - reconstruction_loss: 4.2141 - kl_loss: 12.1208\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.7976\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.3804\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 20.1712 - reconstruction_loss: 5.8470 - kl_loss: 14.3242\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7621 - reconstruction_loss: 5.4393 - kl_loss: 14.3228\n",
      "training on full data\n",
      "8 31\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0716\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9649\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.7832 - reconstruction_loss: 5.4390 - kl_loss: 5.3442\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.8754 - reconstruction_loss: 5.5405 - kl_loss: 5.3349\n",
      "Success in episode 25 at time step 183 with reward 98.46873343163482\n",
      "Episode 26\n",
      "[-0.40921298  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2729\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2765\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.0030 - reconstruction_loss: 7.1110 - kl_loss: 0.8919\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8620 - reconstruction_loss: 2.9693 - kl_loss: 0.8927\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1090\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1517\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3951 - reconstruction_loss: 1.7134 - kl_loss: 2.6816\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.0846 - reconstruction_loss: 4.4167 - kl_loss: 2.6680\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8811\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9077\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9363 - reconstruction_loss: 1.6339 - kl_loss: 1.3024\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7597 - reconstruction_loss: 0.4506 - kl_loss: 1.3092\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4305\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4174\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6165 - reconstruction_loss: 3.4823 - kl_loss: 2.1342\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.6449 - reconstruction_loss: 6.4965 - kl_loss: 2.1484\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5584\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5491\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.7840 - reconstruction_loss: 9.6066 - kl_loss: 7.1775\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.7565 - reconstruction_loss: 4.5745 - kl_loss: 7.1820\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 7.3775\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 7.0040\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.0734 - reconstruction_loss: 3.4874 - kl_loss: 11.5860\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.4464 - reconstruction_loss: 3.8900 - kl_loss: 11.5564\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 10.8267\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 9.3385\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.9533 - reconstruction_loss: 3.2600 - kl_loss: 12.6933\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.5783 - reconstruction_loss: 4.9057 - kl_loss: 12.6727\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 12.5820\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 10.3999\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5770 - reconstruction_loss: 0.9636 - kl_loss: 6.6134\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.7988 - reconstruction_loss: 2.1900 - kl_loss: 6.6088\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0836\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9362\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2047 - reconstruction_loss: 0.0937 - kl_loss: 5.1110\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.5588 - reconstruction_loss: 5.4515 - kl_loss: 5.1073\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2536\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2569\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6738 - reconstruction_loss: 0.5413 - kl_loss: 5.1325\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 29.7839 - reconstruction_loss: 24.6493 - kl_loss: 5.1346\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.7087\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.5377\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.1065 - reconstruction_loss: 2.9841 - kl_loss: 12.1224\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 29.9521 - reconstruction_loss: 17.8354 - kl_loss: 12.1167\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 23.1553\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 20.1710\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.8243 - reconstruction_loss: 1.7414 - kl_loss: 17.0830\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 30.1148 - reconstruction_loss: 13.0451 - kl_loss: 17.0698\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.9645\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.2303\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.4168 - reconstruction_loss: 2.9888 - kl_loss: 11.4281\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.3072 - reconstruction_loss: 3.8552 - kl_loss: 11.4520\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.0208\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9846\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.0024 - reconstruction_loss: 3.9061 - kl_loss: 15.0963\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.1032 - reconstruction_loss: 4.0137 - kl_loss: 15.0895\n",
      "fast thinking\n",
      "training on full data\n",
      "10 41\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.6596\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.2677\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.2962 - reconstruction_loss: 4.9948 - kl_loss: 7.3014\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.0287 - reconstruction_loss: 6.7227 - kl_loss: 7.3060\n",
      "Success in episode 26 at time step 241 with reward 97.78053992549276\n",
      "Episode 27\n",
      "[-0.530696  0.      ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0494\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1810\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7676 - reconstruction_loss: 0.3406 - kl_loss: 1.4270\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2877 - reconstruction_loss: 1.8478 - kl_loss: 1.4399\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3497\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3775\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4514 - reconstruction_loss: 1.8548 - kl_loss: 0.5966\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7737 - reconstruction_loss: 3.1715 - kl_loss: 0.6022\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7104\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.8292\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8311 - reconstruction_loss: 3.6048 - kl_loss: 1.2263\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.8458 - reconstruction_loss: 7.6110 - kl_loss: 1.2348\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.6375\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.6736\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4219 - reconstruction_loss: 0.6456 - kl_loss: 1.7763\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.5407 - reconstruction_loss: 5.7507 - kl_loss: 1.7899\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1834\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2890\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.1033 - reconstruction_loss: 4.0646 - kl_loss: 2.0387\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1411 - reconstruction_loss: 1.0893 - kl_loss: 2.0518\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6858\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6861\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1866 - reconstruction_loss: 1.5912 - kl_loss: 0.5954\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7832 - reconstruction_loss: 6.1880 - kl_loss: 0.5951\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5427\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5615\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6164 - reconstruction_loss: 1.7977 - kl_loss: 0.8187\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.5371 - reconstruction_loss: 12.7137 - kl_loss: 0.8234\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7451\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7546\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.9870 - reconstruction_loss: 7.6326 - kl_loss: 2.3544\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5756 - reconstruction_loss: 3.2172 - kl_loss: 2.3584\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.5059\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.4647\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.4160 - reconstruction_loss: 5.1195 - kl_loss: 5.2965\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.7221 - reconstruction_loss: 5.4049 - kl_loss: 5.3171\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3536\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3208\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.9934 - reconstruction_loss: 2.2562 - kl_loss: 6.7372\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.8174 - reconstruction_loss: 1.0708 - kl_loss: 6.7466\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.4278\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.2489\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0037 - reconstruction_loss: 0.5639 - kl_loss: 5.4398\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3675 - reconstruction_loss: 0.9263 - kl_loss: 5.4411\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0260\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9882\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.4845 - reconstruction_loss: 3.2747 - kl_loss: 5.2098\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.6295 - reconstruction_loss: 12.4173 - kl_loss: 5.2122\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0961\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0522\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 22.5850 - reconstruction_loss: 16.1793 - kl_loss: 6.4057\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 25.3401 - reconstruction_loss: 18.9226 - kl_loss: 6.4175\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8755\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.7307\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.1608 - reconstruction_loss: 6.4520 - kl_loss: 7.7089\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.2646 - reconstruction_loss: 11.5476 - kl_loss: 7.7170\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9717\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7117\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 26.8102 - reconstruction_loss: 13.1536 - kl_loss: 13.6566\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 36.3741 - reconstruction_loss: 22.7742 - kl_loss: 13.5999\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 102.1129\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 87.9965\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 21.3140 - reconstruction_loss: 1.9477 - kl_loss: 19.3663\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 23.3861 - reconstruction_loss: 4.0621 - kl_loss: 19.3241\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 41.9118\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 37.2935\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.9283 - reconstruction_loss: 2.5187 - kl_loss: 14.4096\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.1426 - reconstruction_loss: 1.7353 - kl_loss: 14.4073\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4401\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4242\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.7051 - reconstruction_loss: 2.4680 - kl_loss: 14.2372\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.7272 - reconstruction_loss: 4.4883 - kl_loss: 14.2389\n",
      "training on full data\n",
      "18 57\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.3186\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.2338\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.2624 - reconstruction_loss: 4.4448 - kl_loss: 4.8175\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.4760 - reconstruction_loss: 4.6675 - kl_loss: 4.8085\n",
      "Success in episode 27 at time step 342 with reward 98.43830540023936\n",
      "Episode 28\n",
      "[-0.47989994  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4595\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4554\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6991 - reconstruction_loss: 2.7709 - kl_loss: 0.9282\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1658 - reconstruction_loss: 3.2403 - kl_loss: 0.9256\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9009\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9741\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6278 - reconstruction_loss: 1.4206 - kl_loss: 1.2073\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6418 - reconstruction_loss: 3.4397 - kl_loss: 1.2021\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1449\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1288\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2038 - reconstruction_loss: 4.5365 - kl_loss: 1.6672\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.0706 - reconstruction_loss: 7.4131 - kl_loss: 1.6575\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6774\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6988\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6693 - reconstruction_loss: 4.4127 - kl_loss: 1.2565\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0267 - reconstruction_loss: 1.7718 - kl_loss: 1.2549\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5096\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4964\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6626 - reconstruction_loss: 2.4156 - kl_loss: 1.2470\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4126 - reconstruction_loss: 2.1689 - kl_loss: 1.2438\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3924\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3836\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.5677 - reconstruction_loss: 3.5807 - kl_loss: 0.9870\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.5444 - reconstruction_loss: 7.5576 - kl_loss: 0.9868\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0637\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0385\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3222 - reconstruction_loss: 3.2746 - kl_loss: 1.0475\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1148 - reconstruction_loss: 1.0676 - kl_loss: 1.0472\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.2004\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1577\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9838 - reconstruction_loss: 4.8963 - kl_loss: 1.0876\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.3227 - reconstruction_loss: 7.2355 - kl_loss: 1.0872\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9173\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.8833\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5464 - reconstruction_loss: 1.4343 - kl_loss: 1.1121\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.3919 - reconstruction_loss: 14.2812 - kl_loss: 1.1108\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3443\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3373\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4107 - reconstruction_loss: 0.6256 - kl_loss: 0.7851\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9420 - reconstruction_loss: 2.1553 - kl_loss: 0.7867\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5562\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5349\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7685 - reconstruction_loss: 4.9089 - kl_loss: 1.8596\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.6383 - reconstruction_loss: 5.7721 - kl_loss: 1.8662\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6654\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6530\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3764 - reconstruction_loss: 3.9873 - kl_loss: 1.3891\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4058 - reconstruction_loss: 1.0114 - kl_loss: 1.3944\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0548\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0339\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.7092 - reconstruction_loss: 3.3918 - kl_loss: 1.3173\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2731 - reconstruction_loss: 2.9542 - kl_loss: 1.3189\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5710\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5536\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.3602 - reconstruction_loss: 11.9141 - kl_loss: 1.4461\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4755 - reconstruction_loss: 3.0222 - kl_loss: 1.4533\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5419\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5371\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9833 - reconstruction_loss: 8.1563 - kl_loss: 1.8271\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.7113 - reconstruction_loss: 7.8725 - kl_loss: 1.8388\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3462\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3542\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7615 - reconstruction_loss: 1.6741 - kl_loss: 1.0874\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.6041 - reconstruction_loss: 6.5085 - kl_loss: 1.0956\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4720\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4385\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4068 - reconstruction_loss: 0.6241 - kl_loss: 2.7827\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4366 - reconstruction_loss: 3.6374 - kl_loss: 2.7992\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8544\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8679\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.7644 - reconstruction_loss: 2.9701 - kl_loss: 1.7943\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2806 - reconstruction_loss: 4.4755 - kl_loss: 1.8052\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6433\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6415\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.2646 - reconstruction_loss: 9.0170 - kl_loss: 1.2476\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8796 - reconstruction_loss: 1.6280 - kl_loss: 1.2516\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4230\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4102\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.6707 - reconstruction_loss: 6.3167 - kl_loss: 2.3541\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 21.1905 - reconstruction_loss: 18.8306 - kl_loss: 2.3599\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3555\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3373\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9393 - reconstruction_loss: 0.2438 - kl_loss: 3.6955\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3733 - reconstruction_loss: 1.6728 - kl_loss: 3.7006\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 11.0763\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 10.8440\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9006 - reconstruction_loss: 2.7751 - kl_loss: 4.1255\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2341 - reconstruction_loss: 2.1039 - kl_loss: 4.1302\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 10.0336\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 9.6468\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.3671 - reconstruction_loss: 0.0663 - kl_loss: 7.3008\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.2706 - reconstruction_loss: 0.9763 - kl_loss: 7.2944\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 17.7661\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 16.1667\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.4221 - reconstruction_loss: 1.2124 - kl_loss: 7.2097\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.9252 - reconstruction_loss: 2.7120 - kl_loss: 7.2132\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8005\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8651\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.0171 - reconstruction_loss: 6.5847 - kl_loss: 7.4324\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.0038 - reconstruction_loss: 3.5679 - kl_loss: 7.4359\n",
      "training on full data\n",
      "19 72\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4278\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3628\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1374 - reconstruction_loss: 2.9391 - kl_loss: 2.1983\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6956 - reconstruction_loss: 3.4939 - kl_loss: 2.2017\n",
      "Success in episode 28 at time step 430 with reward 97.39933824772994\n",
      "Episode 29\n",
      "[-0.50104016  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6806\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7031\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3944 - reconstruction_loss: 2.2206 - kl_loss: 1.1738\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8490 - reconstruction_loss: 4.6727 - kl_loss: 1.1763\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5684\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5094\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.8832 - reconstruction_loss: 9.2032 - kl_loss: 1.6800\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2728 - reconstruction_loss: 2.5949 - kl_loss: 1.6780\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7469\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6484\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9339 - reconstruction_loss: 2.0721 - kl_loss: 2.8618\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3757 - reconstruction_loss: 3.5075 - kl_loss: 2.8683\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4518\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4848\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3374 - reconstruction_loss: 1.3895 - kl_loss: 1.9480\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.5001 - reconstruction_loss: 2.5410 - kl_loss: 1.9591\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7128\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6867\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.8665 - reconstruction_loss: 10.5620 - kl_loss: 3.3045\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.2456 - reconstruction_loss: 7.9490 - kl_loss: 3.2966\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 10.8988\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 10.2444\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.6395 - reconstruction_loss: 1.2679 - kl_loss: 7.3716\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.1624 - reconstruction_loss: 0.7865 - kl_loss: 7.3759\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 11.3600\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 10.2894\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.4693 - reconstruction_loss: 1.4860 - kl_loss: 8.9833\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6825 - reconstruction_loss: 0.6986 - kl_loss: 8.9839\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 11.5013\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 11.9274\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.3689 - reconstruction_loss: 2.8691 - kl_loss: 12.4998\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.7014 - reconstruction_loss: 2.1855 - kl_loss: 12.5160\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4534\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3887\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.5274 - reconstruction_loss: 4.2251 - kl_loss: 12.3023\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.7150 - reconstruction_loss: 5.4003 - kl_loss: 12.3148\n",
      "training on full data\n",
      "14 35\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2425\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1173\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.6168 - reconstruction_loss: 2.9764 - kl_loss: 4.6404\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8829 - reconstruction_loss: 2.2411 - kl_loss: 4.6418\n",
      "Success in episode 29 at time step 206 with reward 98.69771996461029\n",
      "Episode 30\n",
      "[-0.5961324  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8517\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8331\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3857 - reconstruction_loss: 0.3331 - kl_loss: 1.0526\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7136 - reconstruction_loss: 0.6613 - kl_loss: 1.0523\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7994\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7734\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5518 - reconstruction_loss: 1.4417 - kl_loss: 1.1102\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8959 - reconstruction_loss: 0.7861 - kl_loss: 1.1098\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0913\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1006\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8904 - reconstruction_loss: 1.9189 - kl_loss: 0.9715\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8073 - reconstruction_loss: 4.8351 - kl_loss: 0.9722\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9448\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8363\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9207 - reconstruction_loss: 2.5362 - kl_loss: 2.3845\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9653 - reconstruction_loss: 1.5816 - kl_loss: 2.3838\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4714\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.4597\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.6854 - reconstruction_loss: 5.2599 - kl_loss: 1.4256\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2421 - reconstruction_loss: 1.8128 - kl_loss: 1.4293\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3122\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2925\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.7478 - reconstruction_loss: 7.3100 - kl_loss: 6.4378\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.0606 - reconstruction_loss: 4.6183 - kl_loss: 6.4423\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3999\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3865\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.4683 - reconstruction_loss: 4.2393 - kl_loss: 4.2290\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8446 - reconstruction_loss: 1.6174 - kl_loss: 4.2272\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.8000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.8517\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9197 - reconstruction_loss: 0.5750 - kl_loss: 5.3447\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2655 - reconstruction_loss: 0.9283 - kl_loss: 5.3372\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7913\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7745\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9530 - reconstruction_loss: 0.1170 - kl_loss: 5.8361\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.2585 - reconstruction_loss: 2.4336 - kl_loss: 5.8248\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0267\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0352\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 27.3090 - reconstruction_loss: 20.4459 - kl_loss: 6.8631\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.0790 - reconstruction_loss: 11.2055 - kl_loss: 6.8735\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7972\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7800\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 23.9430 - reconstruction_loss: 14.5611 - kl_loss: 9.3820\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 21.0882 - reconstruction_loss: 11.6898 - kl_loss: 9.3985\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 21.8583\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 20.3020\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.6595 - reconstruction_loss: 2.0702 - kl_loss: 17.5893\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.8135 - reconstruction_loss: 1.2250 - kl_loss: 17.5885\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 26.4361\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 26.1031\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.7198 - reconstruction_loss: 1.7875 - kl_loss: 17.9323\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.7316 - reconstruction_loss: 1.8260 - kl_loss: 17.9056\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 8.9068\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.3464\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.3606 - reconstruction_loss: 4.8835 - kl_loss: 14.4771\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.7780 - reconstruction_loss: 4.2984 - kl_loss: 14.4796\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2688\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3280\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 21.7670 - reconstruction_loss: 6.9558 - kl_loss: 14.8113\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 27.2334 - reconstruction_loss: 12.4270 - kl_loss: 14.8064\n",
      "training on full data\n",
      "19 51\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.5020\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4394\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.7166 - reconstruction_loss: 5.9859 - kl_loss: 5.7307\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.2886 - reconstruction_loss: 4.5489 - kl_loss: 5.7396\n",
      "Success in episode 30 at time step 303 with reward 97.89535904249053\n",
      "Episode 31\n",
      "[-0.4004035  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0242\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0198\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7619 - reconstruction_loss: 3.3802 - kl_loss: 1.3817\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7471 - reconstruction_loss: 0.3587 - kl_loss: 1.3884\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.2747\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.2028\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.3595 - reconstruction_loss: 9.1895 - kl_loss: 1.1699\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9095 - reconstruction_loss: 1.7313 - kl_loss: 1.1781\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0093\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0339\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.8331 - reconstruction_loss: 4.2415 - kl_loss: 1.5915\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9608 - reconstruction_loss: 1.3591 - kl_loss: 1.6018\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.5240\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.4711\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8265 - reconstruction_loss: 1.0336 - kl_loss: 1.7929\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5895 - reconstruction_loss: 0.7881 - kl_loss: 1.8014\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6055\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6168\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3362 - reconstruction_loss: 0.8912 - kl_loss: 1.4450\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8966 - reconstruction_loss: 1.4472 - kl_loss: 1.4494\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3073\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2631\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6841 - reconstruction_loss: 5.5124 - kl_loss: 1.1716\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6819 - reconstruction_loss: 2.5045 - kl_loss: 1.1775\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9745\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9848\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7200 - reconstruction_loss: 1.7720 - kl_loss: 1.9480\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4673 - reconstruction_loss: 3.5129 - kl_loss: 1.9544\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1064\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.0947\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3418 - reconstruction_loss: 1.6703 - kl_loss: 3.6715\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0768 - reconstruction_loss: 0.3981 - kl_loss: 3.6787\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9241\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9202\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3157 - reconstruction_loss: 0.5040 - kl_loss: 1.8117\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2171 - reconstruction_loss: 1.4044 - kl_loss: 1.8127\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9066\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8940\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.7026 - reconstruction_loss: 8.1032 - kl_loss: 1.5994\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7733 - reconstruction_loss: 2.1706 - kl_loss: 1.6027\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7858\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7807\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3314 - reconstruction_loss: 2.5357 - kl_loss: 3.7956\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.0921 - reconstruction_loss: 4.2960 - kl_loss: 3.7961\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3051\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3047\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.9600 - reconstruction_loss: 2.6721 - kl_loss: 5.2879\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5650 - reconstruction_loss: 0.2743 - kl_loss: 5.2907\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.6785\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.2162\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.4142 - reconstruction_loss: 1.8395 - kl_loss: 9.5747\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.3013 - reconstruction_loss: 0.7287 - kl_loss: 9.5726\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "22 51\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1844\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1210\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0705 - reconstruction_loss: 1.9123 - kl_loss: 3.1582\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9941 - reconstruction_loss: 1.8514 - kl_loss: 3.1428\n",
      "Success in episode 31 at time step 305 with reward 98.83202530844008\n",
      "Episode 32\n",
      "[-0.45761952  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0580\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0564\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0151 - reconstruction_loss: 1.1833 - kl_loss: 1.8317\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0666 - reconstruction_loss: 1.2433 - kl_loss: 1.8233\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8408\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.8813\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5400 - reconstruction_loss: 1.2663 - kl_loss: 1.2737\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6379 - reconstruction_loss: 1.3675 - kl_loss: 1.2704\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1332\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1391\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4552 - reconstruction_loss: 1.0498 - kl_loss: 1.4055\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5439 - reconstruction_loss: 1.1413 - kl_loss: 1.4026\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6721\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6885\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9645 - reconstruction_loss: 1.8469 - kl_loss: 2.1176\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4074 - reconstruction_loss: 0.2938 - kl_loss: 2.1136\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0176\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9949\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2527 - reconstruction_loss: 0.4234 - kl_loss: 1.8293\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.0575 - reconstruction_loss: 4.2294 - kl_loss: 1.8281\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3178\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3125\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9615 - reconstruction_loss: 4.5440 - kl_loss: 1.4175\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.7839 - reconstruction_loss: 5.3659 - kl_loss: 1.4180\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5098\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 993us/step - kl_loss: 1.5118\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9687 - reconstruction_loss: 0.6288 - kl_loss: 3.3399\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9883 - reconstruction_loss: 2.6519 - kl_loss: 3.3364\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2906\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2923\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8195 - reconstruction_loss: 1.3412 - kl_loss: 1.4783\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3611 - reconstruction_loss: 2.8819 - kl_loss: 1.4792\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1351\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0749\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2835 - reconstruction_loss: 2.2718 - kl_loss: 4.0117\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9881 - reconstruction_loss: 0.9767 - kl_loss: 4.0114\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8484\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8397\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2633 - reconstruction_loss: 1.0653 - kl_loss: 3.1980\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6233 - reconstruction_loss: 0.4249 - kl_loss: 3.1984\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6692\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6429\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.1821 - reconstruction_loss: 4.0052 - kl_loss: 7.1770\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.7608 - reconstruction_loss: 8.5798 - kl_loss: 7.1810\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 16.0232\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 14.9062\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.2426 - reconstruction_loss: 3.5862 - kl_loss: 11.6564\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.8726 - reconstruction_loss: 3.2312 - kl_loss: 11.6414\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 9.6738\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 8.0997\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9480 - reconstruction_loss: 0.6693 - kl_loss: 9.2787\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9933 - reconstruction_loss: 0.7301 - kl_loss: 9.2632\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2746\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3808\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.2927 - reconstruction_loss: 0.9666 - kl_loss: 9.3261\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.7857 - reconstruction_loss: 2.4597 - kl_loss: 9.3260\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "38 69\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3269\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2815\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7769 - reconstruction_loss: 2.4153 - kl_loss: 3.3616\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.7040 - reconstruction_loss: 3.3403 - kl_loss: 3.3637\n",
      "Success in episode 32 at time step 409 with reward 98.13860670003206\n",
      "Episode 33\n",
      "[-0.4975703  0.       ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8533\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8428\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4604 - reconstruction_loss: 1.5863 - kl_loss: 1.8740\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.4621 - reconstruction_loss: 4.5831 - kl_loss: 1.8790\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8690\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8532\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2468 - reconstruction_loss: 2.2751 - kl_loss: 0.9717\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.5326 - reconstruction_loss: 3.5580 - kl_loss: 0.9746\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5606\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5739\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3572 - reconstruction_loss: 2.2288 - kl_loss: 3.1285\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3386 - reconstruction_loss: 1.2029 - kl_loss: 3.1358\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8435\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9237\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6194 - reconstruction_loss: 0.2729 - kl_loss: 5.3464\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3881 - reconstruction_loss: 1.0397 - kl_loss: 5.3484\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.7662\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.8448\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.9047 - reconstruction_loss: 0.3379 - kl_loss: 7.5668\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.4435 - reconstruction_loss: 0.8799 - kl_loss: 7.5637\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "11 23\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1225\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0509\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5234 - reconstruction_loss: 2.5486 - kl_loss: 3.9748\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0933 - reconstruction_loss: 2.1172 - kl_loss: 3.9761\n",
      "Success in episode 33 at time step 137 with reward 99.23580344621857\n",
      "Episode 34\n",
      "[-0.5603939  0.       ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3973\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3312\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7825 - reconstruction_loss: 2.4727 - kl_loss: 1.3099\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3342 - reconstruction_loss: 1.0241 - kl_loss: 1.3100\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5509\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4552\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9232 - reconstruction_loss: 0.9433 - kl_loss: 1.9799\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6641 - reconstruction_loss: 1.6867 - kl_loss: 1.9774\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5490\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5720\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6057 - reconstruction_loss: 1.1022 - kl_loss: 1.5036\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5400 - reconstruction_loss: 2.0317 - kl_loss: 1.5083\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9112\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9272\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.3403 - reconstruction_loss: 9.0978 - kl_loss: 6.2425\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.1837 - reconstruction_loss: 5.9489 - kl_loss: 6.2348\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 29.5453\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 28.0463\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.9587 - reconstruction_loss: 1.0819 - kl_loss: 11.8768\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.2069 - reconstruction_loss: 0.3429 - kl_loss: 11.8640\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0905\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1655\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.6371 - reconstruction_loss: 2.4269 - kl_loss: 11.2103\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.3268 - reconstruction_loss: 3.0980 - kl_loss: 11.2288\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6296\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5903\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.2019 - reconstruction_loss: 6.4723 - kl_loss: 12.7296\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.8048 - reconstruction_loss: 1.0760 - kl_loss: 12.7288\n",
      "training on full data\n",
      "11 27\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8847\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.7829\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.9207 - reconstruction_loss: 4.0970 - kl_loss: 5.8237\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.8025 - reconstruction_loss: 2.9781 - kl_loss: 5.8244\n",
      "Success in episode 34 at time step 158 with reward 98.99453947102106\n",
      "Episode 35\n",
      "[-0.42623156  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1933\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1879\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9161 - reconstruction_loss: 2.1948 - kl_loss: 1.7213\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4724 - reconstruction_loss: 2.7456 - kl_loss: 1.7267\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.6633\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.6608\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9132 - reconstruction_loss: 2.0424 - kl_loss: 2.8707\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6904 - reconstruction_loss: 1.8217 - kl_loss: 2.8687\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.2049\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.1461\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9957 - reconstruction_loss: 1.2005 - kl_loss: 1.7953\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5697 - reconstruction_loss: 0.7758 - kl_loss: 1.7939\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4483\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4302\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2917 - reconstruction_loss: 1.2174 - kl_loss: 1.0743\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7149 - reconstruction_loss: 1.6391 - kl_loss: 1.0758\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6581\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6690\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9716 - reconstruction_loss: 1.2206 - kl_loss: 1.7510\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0697 - reconstruction_loss: 4.3188 - kl_loss: 1.7509\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6515\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6410\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7546 - reconstruction_loss: 0.4468 - kl_loss: 2.3078\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2432 - reconstruction_loss: 1.9351 - kl_loss: 2.3081\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6952\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7025\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.6813 - reconstruction_loss: 5.0912 - kl_loss: 3.5901\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.7488 - reconstruction_loss: 13.1572 - kl_loss: 3.5916\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8760\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8579\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.7457 - reconstruction_loss: 4.8802 - kl_loss: 6.8656\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.7295 - reconstruction_loss: 2.8721 - kl_loss: 6.8574\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.5333\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.2342\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.9045 - reconstruction_loss: 0.6423 - kl_loss: 12.2621\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.3191 - reconstruction_loss: 0.0699 - kl_loss: 12.2491\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.0300\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.6300\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.3810 - reconstruction_loss: 4.4187 - kl_loss: 12.9623\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.4810 - reconstruction_loss: 3.5066 - kl_loss: 12.9744\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "16 38\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0662\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0355\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.8164 - reconstruction_loss: 2.6700 - kl_loss: 5.1464\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.2155 - reconstruction_loss: 3.0709 - kl_loss: 5.1446\n",
      "Success in episode 35 at time step 226 with reward 98.37925475763907\n",
      "Episode 36\n",
      "[-0.59143704  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2375\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2383\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.0293 - reconstruction_loss: 8.0016 - kl_loss: 1.0277\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8914 - reconstruction_loss: 0.8630 - kl_loss: 1.0284\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9586\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 907us/step - kl_loss: 0.8532\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0824 - reconstruction_loss: 1.4577 - kl_loss: 2.6246\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3762 - reconstruction_loss: 2.7524 - kl_loss: 2.6238\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.0896\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.7252\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5833 - reconstruction_loss: 0.4458 - kl_loss: 3.1376\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1206 - reconstruction_loss: 0.9822 - kl_loss: 3.1384\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0928\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0874\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6421 - reconstruction_loss: 0.3510 - kl_loss: 3.2912\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0754 - reconstruction_loss: 0.7812 - kl_loss: 3.2942\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8054\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8412\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.1214 - reconstruction_loss: 7.1265 - kl_loss: 2.9950\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.9121 - reconstruction_loss: 4.9188 - kl_loss: 2.9933\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4767\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4783\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.7364 - reconstruction_loss: 4.9951 - kl_loss: 8.7413\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.2029 - reconstruction_loss: 7.4669 - kl_loss: 8.7360\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 15.2884\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 14.9433\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.5552 - reconstruction_loss: 0.9795 - kl_loss: 12.5757\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.4950 - reconstruction_loss: 0.9478 - kl_loss: 12.5473\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 13.3241\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 12.3014\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.7382 - reconstruction_loss: 1.6980 - kl_loss: 15.0402\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.5016 - reconstruction_loss: 1.4740 - kl_loss: 15.0276\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9856\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9545\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 22.1796 - reconstruction_loss: 7.7663 - kl_loss: 14.4134\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.7645 - reconstruction_loss: 4.3305 - kl_loss: 14.4340\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5944\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5680\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.0698 - reconstruction_loss: 8.6172 - kl_loss: 9.4526\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.2637 - reconstruction_loss: 4.8194 - kl_loss: 9.4444\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5528\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4890\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 21.9105 - reconstruction_loss: 10.6901 - kl_loss: 11.2204\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.0402 - reconstruction_loss: 7.8272 - kl_loss: 11.2130\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5597\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5424\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.0064 - reconstruction_loss: 6.6388 - kl_loss: 12.3676\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 30.0083 - reconstruction_loss: 17.6599 - kl_loss: 12.3484\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.7269\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.4526\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 35.9232 - reconstruction_loss: 20.1964 - kl_loss: 15.7267\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 20.2728 - reconstruction_loss: 4.5550 - kl_loss: 15.7179\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 91.5759\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 82.3784\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.1242 - reconstruction_loss: 0.8658 - kl_loss: 14.2585\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.7828 - reconstruction_loss: 1.5262 - kl_loss: 14.2566\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 32.0310\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 29.7635\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.8828 - reconstruction_loss: 1.8933 - kl_loss: 11.9896\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.2886 - reconstruction_loss: 1.2852 - kl_loss: 12.0034\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2610\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3922\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.2169 - reconstruction_loss: 0.6913 - kl_loss: 13.5256\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.9029 - reconstruction_loss: 1.3876 - kl_loss: 13.5153\n",
      "training on full data\n",
      "11 46\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.8069\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.6599\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.0087 - reconstruction_loss: 3.9048 - kl_loss: 8.1039\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.7145 - reconstruction_loss: 4.6152 - kl_loss: 8.0993\n",
      "Success in episode 36 at time step 273 with reward 97.56533208716735\n",
      "Episode 37\n",
      "[-0.41283062  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2323\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1017\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5538 - reconstruction_loss: 1.8150 - kl_loss: 1.7388\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3803 - reconstruction_loss: 0.6171 - kl_loss: 1.7632\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.4672\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.5302\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2373 - reconstruction_loss: 0.7494 - kl_loss: 2.4879\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9932 - reconstruction_loss: 1.4853 - kl_loss: 2.5079\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0736\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9652\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3292 - reconstruction_loss: 3.6044 - kl_loss: 2.7248\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0042 - reconstruction_loss: 1.2680 - kl_loss: 2.7362\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.8986\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.8172\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3534 - reconstruction_loss: 1.6628 - kl_loss: 1.6907\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9804 - reconstruction_loss: 2.2954 - kl_loss: 1.6850\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8625\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8382\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0504 - reconstruction_loss: 2.9619 - kl_loss: 1.0885\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8899 - reconstruction_loss: 2.7961 - kl_loss: 1.0938\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9532\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8970\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6490 - reconstruction_loss: 2.1538 - kl_loss: 2.4952\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7741 - reconstruction_loss: 3.2659 - kl_loss: 2.5083\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.8312\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.7566\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8738 - reconstruction_loss: 3.0734 - kl_loss: 3.8004\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0132 - reconstruction_loss: 2.1953 - kl_loss: 3.8179\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9111\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9180\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2217 - reconstruction_loss: 1.9944 - kl_loss: 2.2273\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9132 - reconstruction_loss: 0.6900 - kl_loss: 2.2231\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1709\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1491\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.5537 - reconstruction_loss: 7.3440 - kl_loss: 4.2097\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5101 - reconstruction_loss: 3.2925 - kl_loss: 4.2176\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.5960\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.5723\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9831 - reconstruction_loss: 0.5947 - kl_loss: 5.3884\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0625 - reconstruction_loss: 0.6768 - kl_loss: 5.3857\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.7721\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.7566\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8244 - reconstruction_loss: 0.2376 - kl_loss: 4.5868\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.7478 - reconstruction_loss: 0.1630 - kl_loss: 4.5848\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6035\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5852\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.2074 - reconstruction_loss: 5.8331 - kl_loss: 2.3743\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3730 - reconstruction_loss: 1.9983 - kl_loss: 2.3746\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3191\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3083\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9468 - reconstruction_loss: 0.8090 - kl_loss: 7.1379\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.3616 - reconstruction_loss: 6.2339 - kl_loss: 7.1276\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3445\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2176\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.0215 - reconstruction_loss: 1.2840 - kl_loss: 7.7374\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.5016 - reconstruction_loss: 1.7741 - kl_loss: 7.7276\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.9558\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.7266\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.2445 - reconstruction_loss: 1.1989 - kl_loss: 8.0455\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.2122 - reconstruction_loss: 0.1646 - kl_loss: 8.0476\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2472\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1512\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.1972 - reconstruction_loss: 3.3133 - kl_loss: 7.8839\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.8971 - reconstruction_loss: 3.0109 - kl_loss: 7.8862\n",
      "fast thinking\n",
      "training on full data\n",
      "16 50\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9190\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.8677\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5035 - reconstruction_loss: 2.5998 - kl_loss: 3.9037\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3985 - reconstruction_loss: 1.5010 - kl_loss: 3.8975\n",
      "Success in episode 37 at time step 299 with reward 99.02621924486611\n",
      "Episode 38\n",
      "[-0.49372643  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6666\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6419\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3982 - reconstruction_loss: 3.0818 - kl_loss: 1.3164\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1776 - reconstruction_loss: 1.8601 - kl_loss: 1.3175\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5876\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5523\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5321 - reconstruction_loss: 2.2453 - kl_loss: 1.2868\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3868 - reconstruction_loss: 2.0992 - kl_loss: 1.2877\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7896\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.8035\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0159 - reconstruction_loss: 1.2725 - kl_loss: 1.7434\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4937 - reconstruction_loss: 0.7518 - kl_loss: 1.7419\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0902\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0878\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9726 - reconstruction_loss: 1.0265 - kl_loss: 1.9461\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0173 - reconstruction_loss: 2.0698 - kl_loss: 1.9475\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.4844\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.4474\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6920 - reconstruction_loss: 1.4861 - kl_loss: 1.2059\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5893 - reconstruction_loss: 1.3819 - kl_loss: 1.2074\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7059\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6921\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0606 - reconstruction_loss: 2.2926 - kl_loss: 1.7680\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1658 - reconstruction_loss: 2.3969 - kl_loss: 1.7689\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5991\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5908\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4414 - reconstruction_loss: 2.9977 - kl_loss: 1.4437\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5531 - reconstruction_loss: 2.1076 - kl_loss: 1.4455\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4254\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4182\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4815 - reconstruction_loss: 1.2033 - kl_loss: 2.2781\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1104 - reconstruction_loss: 2.8275 - kl_loss: 2.2829\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.3511\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.3434\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8300 - reconstruction_loss: 0.5849 - kl_loss: 1.2451\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2457 - reconstruction_loss: 1.9990 - kl_loss: 1.2467\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6324\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6274\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8666 - reconstruction_loss: 4.3777 - kl_loss: 1.4888\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7058 - reconstruction_loss: 2.2161 - kl_loss: 1.4897\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1269\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1133\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5548 - reconstruction_loss: 1.1035 - kl_loss: 1.4513\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6755 - reconstruction_loss: 3.2243 - kl_loss: 1.4513\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.0184\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.0013\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.6649 - reconstruction_loss: 6.1373 - kl_loss: 1.5276\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4599 - reconstruction_loss: 0.9335 - kl_loss: 1.5265\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5630\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5628\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7442 - reconstruction_loss: 0.3850 - kl_loss: 2.3592\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3432 - reconstruction_loss: 0.9889 - kl_loss: 2.3542\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.7079\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.6644\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9729 - reconstruction_loss: 1.7360 - kl_loss: 3.2369\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1671 - reconstruction_loss: 0.9342 - kl_loss: 3.2329\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1654\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1251\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9456 - reconstruction_loss: 0.3764 - kl_loss: 2.5692\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1096 - reconstruction_loss: 0.5423 - kl_loss: 2.5673\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9495\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9472\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6151 - reconstruction_loss: 0.5786 - kl_loss: 2.0364\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8559 - reconstruction_loss: 0.8181 - kl_loss: 2.0378\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3386\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3369\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.6611 - reconstruction_loss: 5.0108 - kl_loss: 1.6503\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3025 - reconstruction_loss: 1.6506 - kl_loss: 1.6519\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.4101\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.2256\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3549 - reconstruction_loss: 0.9145 - kl_loss: 4.4403\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7179 - reconstruction_loss: 0.2853 - kl_loss: 4.4326\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1037\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0339\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3413 - reconstruction_loss: 0.1743 - kl_loss: 6.1670\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2362 - reconstruction_loss: 0.0793 - kl_loss: 6.1568\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5285\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5250\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7903 - reconstruction_loss: 0.6762 - kl_loss: 5.1141\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.1544 - reconstruction_loss: 3.0374 - kl_loss: 5.1170\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5454\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5474\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.7835 - reconstruction_loss: 3.0562 - kl_loss: 7.7273\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.2217 - reconstruction_loss: 6.5002 - kl_loss: 7.7215\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 7.0474\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.6400\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.1523 - reconstruction_loss: 8.5012 - kl_loss: 10.6511\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.7679 - reconstruction_loss: 7.1338 - kl_loss: 10.6341\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 72.3547\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 69.2977\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.8751 - reconstruction_loss: 0.9668 - kl_loss: 15.9084\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.1461 - reconstruction_loss: 0.2562 - kl_loss: 15.8899\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.0656\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.0754\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.4483 - reconstruction_loss: 1.0821 - kl_loss: 11.3662\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.3599 - reconstruction_loss: 1.9787 - kl_loss: 11.3811\n",
      "fast thinking\n",
      "training on full data\n",
      "28 79\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.2106\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1316\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2324 - reconstruction_loss: 1.6201 - kl_loss: 3.6124\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6508 - reconstruction_loss: 2.0504 - kl_loss: 3.6004\n",
      "Success in episode 38 at time step 474 with reward 97.71641795120024\n",
      "Episode 39\n",
      "[-0.5331746  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9811\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9110\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7626 - reconstruction_loss: 1.0209 - kl_loss: 1.7417\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9330 - reconstruction_loss: 3.2020 - kl_loss: 1.7310\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5546\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6250\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2366 - reconstruction_loss: 0.5292 - kl_loss: 1.7074\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8628 - reconstruction_loss: 2.1617 - kl_loss: 1.7011\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0687\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0830\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2186 - reconstruction_loss: 1.2386 - kl_loss: 1.9800\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1106 - reconstruction_loss: 1.1335 - kl_loss: 1.9771\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9359\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9934\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3463 - reconstruction_loss: 1.3409 - kl_loss: 2.0054\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2712 - reconstruction_loss: 2.2672 - kl_loss: 2.0040\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1820\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1631\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7141 - reconstruction_loss: 0.7494 - kl_loss: 1.9648\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0576 - reconstruction_loss: 4.0933 - kl_loss: 1.9642\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6440\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6030\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1878 - reconstruction_loss: 3.9111 - kl_loss: 1.2766\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1513 - reconstruction_loss: 1.8752 - kl_loss: 1.2761\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3297\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2997\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0895 - reconstruction_loss: 3.2058 - kl_loss: 2.8837\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.6091 - reconstruction_loss: 3.7254 - kl_loss: 2.8837\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9945\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9100\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2381 - reconstruction_loss: 1.1657 - kl_loss: 4.0724\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2265 - reconstruction_loss: 2.1523 - kl_loss: 4.0741\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4019\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3652\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2350 - reconstruction_loss: 3.2306 - kl_loss: 2.0044\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9718 - reconstruction_loss: 1.9678 - kl_loss: 2.0041\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6362\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6112\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5669 - reconstruction_loss: 0.5415 - kl_loss: 5.0254\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.8820 - reconstruction_loss: 4.8492 - kl_loss: 5.0328\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.3524\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.8430\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.3559 - reconstruction_loss: 0.6466 - kl_loss: 8.7094\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.7612 - reconstruction_loss: 1.0475 - kl_loss: 8.7137\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.9363\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.2112\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.9105 - reconstruction_loss: 1.7856 - kl_loss: 9.1250\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.5290 - reconstruction_loss: 1.4203 - kl_loss: 9.1087\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5415\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5087\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.9980 - reconstruction_loss: 3.8062 - kl_loss: 11.1918\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.6271 - reconstruction_loss: 2.4605 - kl_loss: 11.1667\n",
      "training on full data\n",
      "21 49\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2205\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1760\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.8443 - reconstruction_loss: 2.1491 - kl_loss: 3.6952\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6812 - reconstruction_loss: 1.9834 - kl_loss: 3.6978\n",
      "Success in episode 39 at time step 291 with reward 98.18158262351143\n",
      "Episode 40\n",
      "[-0.5831788  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5825\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5283\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3650 - reconstruction_loss: 2.9909 - kl_loss: 1.3741\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0956 - reconstruction_loss: 2.7086 - kl_loss: 1.3870\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0489\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0674\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4653 - reconstruction_loss: 2.0394 - kl_loss: 3.4260\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1429 - reconstruction_loss: 3.6874 - kl_loss: 3.4554\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.7519\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.7390\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4623 - reconstruction_loss: 1.3901 - kl_loss: 5.0722\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8201 - reconstruction_loss: 0.7290 - kl_loss: 5.0910\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.4024\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.3154\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.8659 - reconstruction_loss: 0.6967 - kl_loss: 7.1693\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.5121 - reconstruction_loss: 1.3545 - kl_loss: 7.1576\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6239\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5436\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.0393 - reconstruction_loss: 3.0668 - kl_loss: 7.9725\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.1422 - reconstruction_loss: 3.1852 - kl_loss: 7.9570\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "6 19\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3114\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2727\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8814 - reconstruction_loss: 1.9903 - kl_loss: 4.8911\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.3981 - reconstruction_loss: 3.5061 - kl_loss: 4.8920\n",
      "Success in episode 40 at time step 109 with reward 98.9891785349066\n",
      "Episode 41\n",
      "[-0.44615754  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.5847\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.5722\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2917 - reconstruction_loss: 0.5318 - kl_loss: 1.7598\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 986us/step - loss: 3.7314 - reconstruction_loss: 1.9733 - kl_loss: 1.7581\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9971\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9967\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3644 - reconstruction_loss: 1.7305 - kl_loss: 1.6339\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3012 - reconstruction_loss: 2.6593 - kl_loss: 1.6418\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0239\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.0433\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.5680 - reconstruction_loss: 4.0823 - kl_loss: 3.4857\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5602 - reconstruction_loss: 2.0798 - kl_loss: 3.4804\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3920\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3592\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.0157 - reconstruction_loss: 1.9108 - kl_loss: 8.1050\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.1044 - reconstruction_loss: 2.0269 - kl_loss: 8.0775\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 7.4585\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.9334\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.2001 - reconstruction_loss: 2.2157 - kl_loss: 11.9844\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.2674 - reconstruction_loss: 2.3135 - kl_loss: 11.9539\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.3961\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.6161\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.7206 - reconstruction_loss: 2.5936 - kl_loss: 11.1270\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.3393 - reconstruction_loss: 2.1810 - kl_loss: 11.1583\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1549\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1644\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.0991 - reconstruction_loss: 1.9084 - kl_loss: 14.1906\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.5021 - reconstruction_loss: 3.2992 - kl_loss: 14.2028\n",
      "fast thinking\n",
      "training on full data\n",
      "8 23\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.2858\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.1554\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.6678 - reconstruction_loss: 2.5514 - kl_loss: 6.1164\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.6379 - reconstruction_loss: 2.5243 - kl_loss: 6.1136\n",
      "Success in episode 41 at time step 134 with reward 98.87651816815897\n",
      "Episode 42\n",
      "[-0.5896139  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.2229\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 958us/step - kl_loss: 3.0187\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5955 - reconstruction_loss: 1.1770 - kl_loss: 1.4185\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 955us/step - loss: 4.7479 - reconstruction_loss: 3.3300 - kl_loss: 1.4179\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.6865\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.7462\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.7444 - reconstruction_loss: 2.6373 - kl_loss: 4.1071\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5085 - reconstruction_loss: 1.4217 - kl_loss: 4.0867\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0609\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1504\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.0055 - reconstruction_loss: 1.7835 - kl_loss: 6.2220\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3079 - reconstruction_loss: 0.0949 - kl_loss: 6.2130\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 12.2554\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 12.1642\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.9989 - reconstruction_loss: 0.6855 - kl_loss: 7.3134\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.4614 - reconstruction_loss: 1.1397 - kl_loss: 7.3217\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9761\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9982\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.1900 - reconstruction_loss: 3.7776 - kl_loss: 10.4124\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.4689 - reconstruction_loss: 2.0567 - kl_loss: 10.4122\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8011\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7999\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.6479 - reconstruction_loss: 8.7696 - kl_loss: 8.8782\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.0498 - reconstruction_loss: 9.1771 - kl_loss: 8.8728\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.4791\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.4102\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 28.8619 - reconstruction_loss: 19.4966 - kl_loss: 9.3653\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.3322 - reconstruction_loss: 5.9301 - kl_loss: 9.4021\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8796\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.6786\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 37.0460 - reconstruction_loss: 24.9761 - kl_loss: 12.0699\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.7762 - reconstruction_loss: 4.6715 - kl_loss: 12.1046\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0561\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.8717\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 25.5791 - reconstruction_loss: 11.8663 - kl_loss: 13.7128\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.0530 - reconstruction_loss: 3.2967 - kl_loss: 13.7564\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 81.2952\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 76.2461\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.1147 - reconstruction_loss: 1.2246 - kl_loss: 15.8901\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.9156 - reconstruction_loss: 1.0080 - kl_loss: 15.9076\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 15.9721\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 15.8742\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.2414 - reconstruction_loss: 1.9637 - kl_loss: 13.2776\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.1979 - reconstruction_loss: 0.9168 - kl_loss: 13.2810\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7384\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7626\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.3766 - reconstruction_loss: 2.6497 - kl_loss: 13.7269\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.0855 - reconstruction_loss: 1.3785 - kl_loss: 13.7071\n",
      "training on full data\n",
      "6 33\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.1807\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.9899\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.7606 - reconstruction_loss: 4.1017 - kl_loss: 8.6588\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.6785 - reconstruction_loss: 4.0232 - kl_loss: 8.6553\n",
      "Success in episode 42 at time step 193 with reward 98.18903269284621\n",
      "Episode 43\n",
      "[-0.47749117  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.8321\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.9103\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7199 - reconstruction_loss: 0.1067 - kl_loss: 1.6132\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.4125 - reconstruction_loss: 5.7946 - kl_loss: 1.6180\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.7177\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.7265\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3817 - reconstruction_loss: 1.9322 - kl_loss: 2.4496\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4485 - reconstruction_loss: 2.9871 - kl_loss: 2.4614\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.9056\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.9271\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7628 - reconstruction_loss: 0.4897 - kl_loss: 2.2731\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4418 - reconstruction_loss: 0.1588 - kl_loss: 2.2830\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.2062\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.2285\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1164 - reconstruction_loss: 2.0078 - kl_loss: 2.1087\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6467 - reconstruction_loss: 1.5308 - kl_loss: 2.1159\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7824\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7783\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1697 - reconstruction_loss: 0.7875 - kl_loss: 1.3822\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5968 - reconstruction_loss: 1.2122 - kl_loss: 1.3846\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3629\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3628\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1514 - reconstruction_loss: 2.4954 - kl_loss: 1.6561\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2345 - reconstruction_loss: 3.5746 - kl_loss: 1.6599\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.5476\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.5414\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8704 - reconstruction_loss: 0.6419 - kl_loss: 2.2284\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1437 - reconstruction_loss: 0.9078 - kl_loss: 2.2359\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5994\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5927\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4412 - reconstruction_loss: 0.7597 - kl_loss: 2.6814\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5810 - reconstruction_loss: 0.8961 - kl_loss: 2.6848\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 9.8364\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 9.7022\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6161 - reconstruction_loss: 1.2696 - kl_loss: 3.3465\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9331 - reconstruction_loss: 0.5892 - kl_loss: 3.3438\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1746\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1465\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8133 - reconstruction_loss: 3.6366 - kl_loss: 2.1766\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3075 - reconstruction_loss: 1.1319 - kl_loss: 2.1755\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.5247\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.3554\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.0680 - reconstruction_loss: 1.1462 - kl_loss: 4.9218\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.8553 - reconstruction_loss: 4.9273 - kl_loss: 4.9280\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 11.8047\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 11.4038\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.8238 - reconstruction_loss: 4.1538 - kl_loss: 7.6700\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.6342 - reconstruction_loss: 0.9705 - kl_loss: 7.6636\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 17.7402\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 16.6148\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5897 - reconstruction_loss: 0.7425 - kl_loss: 9.8472\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.1355 - reconstruction_loss: 0.3260 - kl_loss: 9.8095\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 11.8972\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 11.0960\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.0658 - reconstruction_loss: 2.1264 - kl_loss: 12.9395\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.0440 - reconstruction_loss: 1.1206 - kl_loss: 12.9235\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3315\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2769\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.7422 - reconstruction_loss: 0.4788 - kl_loss: 11.2634\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.8788 - reconstruction_loss: 8.6319 - kl_loss: 11.2469\n",
      "training on full data\n",
      "8 40\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.4266\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.3473\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7993 - reconstruction_loss: 2.2528 - kl_loss: 4.5465\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9447 - reconstruction_loss: 1.4069 - kl_loss: 4.5378\n",
      "Success in episode 43 at time step 237 with reward 99.01534223405972\n",
      "Episode 44\n",
      "[-0.57860523  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8002\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7848\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7885 - reconstruction_loss: 3.3164 - kl_loss: 1.4720\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8935 - reconstruction_loss: 2.4151 - kl_loss: 1.4784\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3664\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4426\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9636 - reconstruction_loss: 0.7109 - kl_loss: 3.2528\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0632 - reconstruction_loss: 0.8125 - kl_loss: 3.2507\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.0518\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 954us/step - kl_loss: 4.1732\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4175 - reconstruction_loss: 0.4905 - kl_loss: 1.9270\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1815 - reconstruction_loss: 0.2598 - kl_loss: 1.9216\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.3968\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.3603\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4467 - reconstruction_loss: 1.0542 - kl_loss: 2.3925\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9614 - reconstruction_loss: 0.5705 - kl_loss: 2.3909\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.5824\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.5985\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7639 - reconstruction_loss: 0.6433 - kl_loss: 4.1206\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2214 - reconstruction_loss: 0.1133 - kl_loss: 4.1081\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.0156\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.9133\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3486 - reconstruction_loss: 1.0550 - kl_loss: 3.2936\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7495 - reconstruction_loss: 0.4614 - kl_loss: 3.2881\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0676\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0903\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9962 - reconstruction_loss: 0.2072 - kl_loss: 2.7890\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8287 - reconstruction_loss: 1.0385 - kl_loss: 2.7902\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4726\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4624\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.1761 - reconstruction_loss: 12.0459 - kl_loss: 3.1302\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.4319 - reconstruction_loss: 3.2910 - kl_loss: 3.1409\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2179\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2126\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8526 - reconstruction_loss: 1.7506 - kl_loss: 5.1020\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.1469 - reconstruction_loss: 1.0344 - kl_loss: 5.1125\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 9.4784\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 8.9785\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.0045 - reconstruction_loss: 0.6950 - kl_loss: 9.3095\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.6488 - reconstruction_loss: 2.3540 - kl_loss: 9.2948\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 21.1138\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 20.1304\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.2454 - reconstruction_loss: 0.7422 - kl_loss: 11.5031\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.1269 - reconstruction_loss: 0.6510 - kl_loss: 11.4759\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3613\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4713\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.6384 - reconstruction_loss: 3.2355 - kl_loss: 12.4029\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.3528 - reconstruction_loss: 1.9556 - kl_loss: 12.3973\n",
      "training on full data\n",
      "22 49\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8014\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.7186\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9544 - reconstruction_loss: 1.7072 - kl_loss: 4.2472\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3500 - reconstruction_loss: 2.0983 - kl_loss: 4.2517\n",
      "Success in episode 44 at time step 293 with reward 98.4109490096363\n",
      "Episode 45\n",
      "[-0.41398627  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3091\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3123\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5146 - reconstruction_loss: 1.5786 - kl_loss: 1.9360\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.7151 - reconstruction_loss: 2.7867 - kl_loss: 1.9285\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1425\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 893us/step - kl_loss: 2.0993\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3226 - reconstruction_loss: 1.4683 - kl_loss: 2.8543\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7950 - reconstruction_loss: 0.9222 - kl_loss: 2.8728\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3696\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3513\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3957 - reconstruction_loss: 2.4456 - kl_loss: 2.9502\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8756 - reconstruction_loss: 1.9439 - kl_loss: 2.9317\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6670\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6609\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.1151 - reconstruction_loss: 2.2416 - kl_loss: 3.8735\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6705 - reconstruction_loss: 1.8143 - kl_loss: 3.8562\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.5336\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.4473\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.0552 - reconstruction_loss: 0.5631 - kl_loss: 7.4921\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.0672 - reconstruction_loss: 0.5775 - kl_loss: 7.4897\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.3900\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.3174\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7645 - reconstruction_loss: 0.8337 - kl_loss: 5.9307\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1659 - reconstruction_loss: 0.2107 - kl_loss: 5.9552\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1849\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 897us/step - kl_loss: 0.1877\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3147 - reconstruction_loss: 1.5179 - kl_loss: 4.7968\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5896 - reconstruction_loss: 1.8023 - kl_loss: 4.7873\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7995\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.8171\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.0073 - reconstruction_loss: 5.2685 - kl_loss: 6.7388\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.0234 - reconstruction_loss: 10.3047 - kl_loss: 6.7187\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5878\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5803\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.7217 - reconstruction_loss: 5.5262 - kl_loss: 10.1955\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.0521 - reconstruction_loss: 2.8668 - kl_loss: 10.1853\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9720\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9153\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.5668 - reconstruction_loss: 5.4125 - kl_loss: 11.1543\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.8350 - reconstruction_loss: 8.6913 - kl_loss: 11.1437\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 10.5844\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 9.6169\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.0869 - reconstruction_loss: 2.9312 - kl_loss: 12.1557\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.4455 - reconstruction_loss: 1.2652 - kl_loss: 12.1803\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9676\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7094\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.6472 - reconstruction_loss: 1.2991 - kl_loss: 11.3482\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.6822 - reconstruction_loss: 1.3427 - kl_loss: 11.3394\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.0175\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9966\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.7250 - reconstruction_loss: 1.0797 - kl_loss: 11.6454\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.4969 - reconstruction_loss: 0.8473 - kl_loss: 11.6496\n",
      "fast thinking\n",
      "training on full data\n",
      "8 36\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4895\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4567\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.7407 - reconstruction_loss: 2.2225 - kl_loss: 6.5181\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.0886 - reconstruction_loss: 2.5800 - kl_loss: 6.5086\n",
      "Success in episode 45 at time step 214 with reward 98.04987936232477\n",
      "Episode 46\n",
      "[-0.45800745  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.4031\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.4449\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4487 - reconstruction_loss: 1.1447 - kl_loss: 2.3039\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5218 - reconstruction_loss: 3.2222 - kl_loss: 2.2996\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.9480\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.9541\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6940 - reconstruction_loss: 2.8842 - kl_loss: 1.8098\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4251 - reconstruction_loss: 1.6240 - kl_loss: 1.8011\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1389\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1301\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4973 - reconstruction_loss: 1.3218 - kl_loss: 2.1755\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6776 - reconstruction_loss: 1.5119 - kl_loss: 2.1657\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.5098\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.4978\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3179 - reconstruction_loss: 1.7566 - kl_loss: 1.5614\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3482 - reconstruction_loss: 1.7894 - kl_loss: 1.5589\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1416\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1101\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8237 - reconstruction_loss: 1.0690 - kl_loss: 1.7547\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5723 - reconstruction_loss: 1.8213 - kl_loss: 1.7510\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5885\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5711\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8075 - reconstruction_loss: 0.9638 - kl_loss: 1.8437\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0182 - reconstruction_loss: 2.1778 - kl_loss: 1.8404\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.4632\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.4648\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0410 - reconstruction_loss: 0.9700 - kl_loss: 2.0711\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9828 - reconstruction_loss: 0.9150 - kl_loss: 2.0678\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5955\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5943\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2115 - reconstruction_loss: 0.4140 - kl_loss: 1.7975\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2575 - reconstruction_loss: 3.4610 - kl_loss: 1.7965\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6532\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6508\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9516 - reconstruction_loss: 1.4262 - kl_loss: 1.5254\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2138 - reconstruction_loss: 1.6864 - kl_loss: 1.5274\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1599\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1568\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3886 - reconstruction_loss: 2.8065 - kl_loss: 1.5820\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5850 - reconstruction_loss: 1.9998 - kl_loss: 1.5852\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5577\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5239\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4222 - reconstruction_loss: 0.4598 - kl_loss: 1.9625\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3360 - reconstruction_loss: 1.3671 - kl_loss: 1.9689\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4959\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5037\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7974 - reconstruction_loss: 1.3622 - kl_loss: 2.4352\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9206 - reconstruction_loss: 1.4806 - kl_loss: 2.4400\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4182\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.4103\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6670 - reconstruction_loss: 2.1232 - kl_loss: 1.5438\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0184 - reconstruction_loss: 2.4752 - kl_loss: 1.5432\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2901\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.2813\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4749 - reconstruction_loss: 0.8548 - kl_loss: 1.6201\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3651 - reconstruction_loss: 3.7432 - kl_loss: 1.6218\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5034\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4838\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3051 - reconstruction_loss: 3.9903 - kl_loss: 2.3148\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4587 - reconstruction_loss: 2.1422 - kl_loss: 2.3165\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6854\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6829\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9590 - reconstruction_loss: 0.0624 - kl_loss: 1.8966\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2386 - reconstruction_loss: 0.3373 - kl_loss: 1.9013\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2871\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2600\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7887 - reconstruction_loss: 0.6217 - kl_loss: 2.1669\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6048 - reconstruction_loss: 1.4373 - kl_loss: 2.1675\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7806\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7835\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2651 - reconstruction_loss: 0.5138 - kl_loss: 1.7514\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8414 - reconstruction_loss: 0.0902 - kl_loss: 1.7512\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4105\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4070\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2182 - reconstruction_loss: 2.3614 - kl_loss: 1.8567\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.8507 - reconstruction_loss: 5.9970 - kl_loss: 1.8537\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6185\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6052\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.7433 - reconstruction_loss: 3.6215 - kl_loss: 3.1218\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.7721 - reconstruction_loss: 1.6392 - kl_loss: 3.1329\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1120\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.0750\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4980 - reconstruction_loss: 0.8347 - kl_loss: 2.6633\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3289 - reconstruction_loss: 0.6640 - kl_loss: 2.6649\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4798\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.4521\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.1444 - reconstruction_loss: 6.9110 - kl_loss: 3.2335\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.5368 - reconstruction_loss: 3.3039 - kl_loss: 3.2329\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.5977\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.5742\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6976 - reconstruction_loss: 1.7809 - kl_loss: 3.9166\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 957us/step - loss: 9.1065 - reconstruction_loss: 5.1849 - kl_loss: 3.9216\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.6501\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.5097\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.8387 - reconstruction_loss: 0.9669 - kl_loss: 6.8718\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.6685 - reconstruction_loss: 0.7839 - kl_loss: 6.8846\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2877\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2780\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3228 - reconstruction_loss: 1.3470 - kl_loss: 3.9757\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2778 - reconstruction_loss: 0.2981 - kl_loss: 3.9797\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2685\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2681\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.2933 - reconstruction_loss: 4.6457 - kl_loss: 7.6476\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.3744 - reconstruction_loss: 1.7400 - kl_loss: 7.6344\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1644\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1125\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6884 - reconstruction_loss: 1.7215 - kl_loss: 7.9669\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.2413 - reconstruction_loss: 4.2939 - kl_loss: 7.9474\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 7.1587\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.4676\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.9527 - reconstruction_loss: 0.3182 - kl_loss: 9.6345\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.8358 - reconstruction_loss: 0.2048 - kl_loss: 9.6310\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2070\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2504\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6248 - reconstruction_loss: 0.7528 - kl_loss: 8.8720\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6687 - reconstruction_loss: 0.7856 - kl_loss: 8.8830\n",
      "training on full data\n",
      "56 117\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6474\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6108\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8241 - reconstruction_loss: 1.6949 - kl_loss: 3.1292\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9088 - reconstruction_loss: 1.7905 - kl_loss: 3.1183\n",
      "Success in episode 46 at time step 702 with reward 98.53021136360852\n",
      "Episode 47\n",
      "[-0.54164433  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3680\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2670\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1692 - reconstruction_loss: 2.1390 - kl_loss: 2.0302\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4580 - reconstruction_loss: 0.4230 - kl_loss: 2.0349\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.5530\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.1989\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3866 - reconstruction_loss: 0.3877 - kl_loss: 1.9988\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1082 - reconstruction_loss: 2.1185 - kl_loss: 1.9897\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1805\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3186\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6563 - reconstruction_loss: 1.6876 - kl_loss: 1.9687\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6079 - reconstruction_loss: 1.6158 - kl_loss: 1.9921\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8463\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7724\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2113 - reconstruction_loss: 2.1404 - kl_loss: 3.0709\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.5252 - reconstruction_loss: 1.4479 - kl_loss: 3.0773\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6598\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5820\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1246 - reconstruction_loss: 1.4103 - kl_loss: 2.7143\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3723 - reconstruction_loss: 0.6680 - kl_loss: 2.7043\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7387\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7826\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4782 - reconstruction_loss: 1.5808 - kl_loss: 2.8974\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.7454 - reconstruction_loss: 1.8404 - kl_loss: 2.9050\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5151\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5310\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.4212 - reconstruction_loss: 3.1203 - kl_loss: 3.3009\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1241 - reconstruction_loss: 1.8207 - kl_loss: 3.3035\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1992\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1464\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8621 - reconstruction_loss: 1.4945 - kl_loss: 2.3677\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9279 - reconstruction_loss: 0.5616 - kl_loss: 2.3663\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6011\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5775\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3442 - reconstruction_loss: 1.0575 - kl_loss: 2.2867\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6036 - reconstruction_loss: 2.3170 - kl_loss: 2.2866\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7036\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6949\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2558 - reconstruction_loss: 1.1304 - kl_loss: 2.1254\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1208 - reconstruction_loss: 0.9935 - kl_loss: 2.1273\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9404\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9457\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.5189 - reconstruction_loss: 10.7587 - kl_loss: 4.7602\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.5396 - reconstruction_loss: 2.7923 - kl_loss: 4.7472\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5194\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5043\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.7891 - reconstruction_loss: 2.7913 - kl_loss: 4.9978\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.4451 - reconstruction_loss: 1.4514 - kl_loss: 4.9938\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.5239\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.2564\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.3779 - reconstruction_loss: 3.3549 - kl_loss: 5.0230\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2567 - reconstruction_loss: 1.2209 - kl_loss: 5.0358\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 10.3229\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 8.2321\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6314 - reconstruction_loss: 0.9097 - kl_loss: 8.7217\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.8258 - reconstruction_loss: 1.0787 - kl_loss: 8.7471\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1095\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.9429\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.9982 - reconstruction_loss: 1.7782 - kl_loss: 11.2200\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.5971 - reconstruction_loss: 3.3552 - kl_loss: 11.2419\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0564\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0431\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.9920 - reconstruction_loss: 0.6016 - kl_loss: 11.3904\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.1616 - reconstruction_loss: 5.7914 - kl_loss: 11.3703\n",
      "training on full data\n",
      "19 53\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4880\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4675\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5532 - reconstruction_loss: 1.6896 - kl_loss: 3.8636\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1911 - reconstruction_loss: 2.3246 - kl_loss: 3.8665\n",
      "Success in episode 47 at time step 315 with reward 98.11618782457782\n",
      "Episode 48\n",
      "[-0.57478493  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1342\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9867\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8847 - reconstruction_loss: 5.1053 - kl_loss: 1.7794\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4392 - reconstruction_loss: 0.6457 - kl_loss: 1.7934\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0200\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0685\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2166 - reconstruction_loss: 1.4519 - kl_loss: 1.7647\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6416 - reconstruction_loss: 1.8709 - kl_loss: 1.7706\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.0878\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.9633\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3543 - reconstruction_loss: 0.4240 - kl_loss: 2.9303\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1408 - reconstruction_loss: 1.2191 - kl_loss: 2.9217\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8492\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.5759\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9750 - reconstruction_loss: 1.5192 - kl_loss: 4.4558\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8109 - reconstruction_loss: 0.3464 - kl_loss: 4.4645\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.3682\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.6913\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.8175 - reconstruction_loss: 1.5956 - kl_loss: 8.2219\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.5102 - reconstruction_loss: 2.2663 - kl_loss: 8.2439\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 10.8216\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 10.7939\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.0717 - reconstruction_loss: 1.5853 - kl_loss: 12.4864\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.6426 - reconstruction_loss: 2.1290 - kl_loss: 12.5136\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.6901\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.6542\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.5549 - reconstruction_loss: 1.0638 - kl_loss: 11.4911\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.7483 - reconstruction_loss: 1.2489 - kl_loss: 11.4994\n",
      "fast thinking\n",
      "training on full data\n",
      "7 23\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1635\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.0500\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.9534 - reconstruction_loss: 3.0869 - kl_loss: 5.8665\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9379 - reconstruction_loss: 2.0740 - kl_loss: 5.8638\n",
      "Success in episode 48 at time step 134 with reward 98.93052986696689\n",
      "Episode 49\n",
      "[-0.5085477  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3981\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3780\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5807 - reconstruction_loss: 0.8414 - kl_loss: 1.7393\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0037 - reconstruction_loss: 1.2683 - kl_loss: 1.7354\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9008\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9359\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3248 - reconstruction_loss: 1.2092 - kl_loss: 2.1156\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.3976 - reconstruction_loss: 5.2809 - kl_loss: 2.1167\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2210\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1862\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5517 - reconstruction_loss: 1.1591 - kl_loss: 5.3927\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3691 - reconstruction_loss: 0.9985 - kl_loss: 5.3707\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "18 26\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4558\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4370\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7480 - reconstruction_loss: 2.3196 - kl_loss: 4.4283\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8376 - reconstruction_loss: 2.4185 - kl_loss: 4.4190\n",
      "Success in episode 49 at time step 155 with reward 99.30792422996043\n",
      "Episode 50\n",
      "[-0.41163832  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7668\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7084\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9359 - reconstruction_loss: 1.8538 - kl_loss: 2.0821\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7233 - reconstruction_loss: 0.6327 - kl_loss: 2.0906\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.8630\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.3103\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2022 - reconstruction_loss: 1.3236 - kl_loss: 2.8786\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4395 - reconstruction_loss: 0.5763 - kl_loss: 2.8632\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.2748\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.1121\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1716 - reconstruction_loss: 0.1595 - kl_loss: 3.0120\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6093 - reconstruction_loss: 0.6155 - kl_loss: 2.9938\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1887\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.8680\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8229 - reconstruction_loss: 0.7628 - kl_loss: 4.0601\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.5400 - reconstruction_loss: 0.5059 - kl_loss: 4.0340\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.6157\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.6738\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0833 - reconstruction_loss: 0.9457 - kl_loss: 3.1375\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9553 - reconstruction_loss: 0.8280 - kl_loss: 3.1274\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.7541\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.7374\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4620 - reconstruction_loss: 0.4777 - kl_loss: 2.9843\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1255 - reconstruction_loss: 1.1390 - kl_loss: 2.9866\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6092\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6005\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.6435 - reconstruction_loss: 4.8374 - kl_loss: 5.8061\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2187 - reconstruction_loss: 1.4011 - kl_loss: 5.8176\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4320\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.3411\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.2404 - reconstruction_loss: 4.4980 - kl_loss: 8.7424\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.1041 - reconstruction_loss: 0.3473 - kl_loss: 8.7568\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 49.0250\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 47.1675\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.1401 - reconstruction_loss: 0.8732 - kl_loss: 12.2669\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.4868 - reconstruction_loss: 0.2501 - kl_loss: 12.2367\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 37.6504\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 30.3003\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.0549 - reconstruction_loss: 2.4138 - kl_loss: 10.6411\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.9945 - reconstruction_loss: 1.3688 - kl_loss: 10.6257\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2673\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9482\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.2962 - reconstruction_loss: 2.2611 - kl_loss: 11.0351\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.4614 - reconstruction_loss: 4.4375 - kl_loss: 11.0239\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7002\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7139\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.8691 - reconstruction_loss: 2.2187 - kl_loss: 10.6504\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 16.2940 - reconstruction_loss: 5.6695 - kl_loss: 10.6245\n",
      "training on full data\n",
      "4 30\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.0452\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.9958\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.6589 - reconstruction_loss: 1.8047 - kl_loss: 5.8542\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.3933 - reconstruction_loss: 2.5430 - kl_loss: 5.8503\n",
      "Success in episode 50 at time step 177 with reward 98.1705876458765\n",
      "Episode 51\n",
      "[-0.5009595  0.       ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8941\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8592\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4402 - reconstruction_loss: 1.3306 - kl_loss: 2.1096\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8381 - reconstruction_loss: 0.7251 - kl_loss: 2.1130\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.0765\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.9776\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4458 - reconstruction_loss: 1.3713 - kl_loss: 3.0745\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9466 - reconstruction_loss: 0.8590 - kl_loss: 3.0876\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5028\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5179\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3979 - reconstruction_loss: 1.5760 - kl_loss: 1.8218\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5270 - reconstruction_loss: 1.7050 - kl_loss: 1.8220\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5369\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5081\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1495 - reconstruction_loss: 0.2167 - kl_loss: 1.9327\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0084 - reconstruction_loss: 2.0757 - kl_loss: 1.9327\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5323\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5386\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9833 - reconstruction_loss: 1.4503 - kl_loss: 2.5330\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1113 - reconstruction_loss: 2.5741 - kl_loss: 2.5373\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3935\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3747\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.3096 - reconstruction_loss: 5.6750 - kl_loss: 2.6346\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8000 - reconstruction_loss: 4.1759 - kl_loss: 2.6241\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6651\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6724\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2866 - reconstruction_loss: 0.2513 - kl_loss: 3.0353\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4473 - reconstruction_loss: 1.4124 - kl_loss: 3.0349\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9587\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9528\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0263 - reconstruction_loss: 1.8399 - kl_loss: 2.1864\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0942 - reconstruction_loss: 0.9043 - kl_loss: 2.1899\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1807\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1735\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0052 - reconstruction_loss: 0.8206 - kl_loss: 2.1845\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0150 - reconstruction_loss: 0.8326 - kl_loss: 2.1823\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9584\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9451\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4270 - reconstruction_loss: 2.1385 - kl_loss: 3.2885\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3186 - reconstruction_loss: 2.0343 - kl_loss: 3.2843\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.9367\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.9256\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4148 - reconstruction_loss: 1.4376 - kl_loss: 1.9772\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8401 - reconstruction_loss: 0.8608 - kl_loss: 1.9794\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9069\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9041\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9886 - reconstruction_loss: 0.2761 - kl_loss: 1.7125\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2676 - reconstruction_loss: 1.5564 - kl_loss: 1.7113\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5245\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5148\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7631 - reconstruction_loss: 1.9661 - kl_loss: 2.7970\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2099 - reconstruction_loss: 3.4167 - kl_loss: 2.7931\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7371\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7132\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9021 - reconstruction_loss: 1.1472 - kl_loss: 1.7549\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9415 - reconstruction_loss: 1.1863 - kl_loss: 1.7552\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.5762\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.4586\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3830 - reconstruction_loss: 2.9525 - kl_loss: 3.4305\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9631 - reconstruction_loss: 1.5378 - kl_loss: 3.4253\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.6179\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.4413\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2073 - reconstruction_loss: 0.7114 - kl_loss: 4.4959\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9283 - reconstruction_loss: 0.4316 - kl_loss: 4.4967\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2705\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2972\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0151 - reconstruction_loss: 0.8078 - kl_loss: 3.2073\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2818 - reconstruction_loss: 0.0707 - kl_loss: 3.2112\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6672\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6432\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5458 - reconstruction_loss: 1.5786 - kl_loss: 3.9672\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.1441 - reconstruction_loss: 2.1806 - kl_loss: 3.9636\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5087\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4543\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.0682 - reconstruction_loss: 4.3168 - kl_loss: 5.7515\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.5807 - reconstruction_loss: 2.8383 - kl_loss: 5.7424\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 12.5149\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 11.6049\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.0400 - reconstruction_loss: 0.6115 - kl_loss: 7.4286\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.5483 - reconstruction_loss: 1.1205 - kl_loss: 7.4278\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.7284\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.6777\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.0443 - reconstruction_loss: 0.4239 - kl_loss: 5.6204\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8170 - reconstruction_loss: 0.2009 - kl_loss: 5.6161\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3625\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3786\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3248 - reconstruction_loss: 0.8867 - kl_loss: 3.4380\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7078 - reconstruction_loss: 2.2698 - kl_loss: 3.4380\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3087\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3345\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.7374 - reconstruction_loss: 1.6453 - kl_loss: 6.0921\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.4953 - reconstruction_loss: 8.4045 - kl_loss: 6.0908\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 10.9967\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 10.9927\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.3315 - reconstruction_loss: 1.0284 - kl_loss: 9.3031\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.4361 - reconstruction_loss: 1.1325 - kl_loss: 9.3036\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 20.8179\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 18.7622\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.5935 - reconstruction_loss: 1.7449 - kl_loss: 9.8486\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.2762 - reconstruction_loss: 0.4288 - kl_loss: 9.8474\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4333\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4441\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.0566 - reconstruction_loss: 1.1226 - kl_loss: 8.9341\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.1130 - reconstruction_loss: 3.1789 - kl_loss: 8.9340\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.5676\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.4200\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.8865 - reconstruction_loss: 3.3056 - kl_loss: 7.5809\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.9813 - reconstruction_loss: 6.4065 - kl_loss: 7.5747\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6469\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6974\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.9902 - reconstruction_loss: 1.3123 - kl_loss: 10.6779\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.0158 - reconstruction_loss: 4.3580 - kl_loss: 10.6578\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 23.1904\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 21.5123\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.0204 - reconstruction_loss: 0.5662 - kl_loss: 13.4543\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.5409 - reconstruction_loss: 2.1080 - kl_loss: 13.4329\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 7.8333\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.9221\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.5082 - reconstruction_loss: 1.4327 - kl_loss: 12.0755\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.5749 - reconstruction_loss: 0.5100 - kl_loss: 12.0649\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2171\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3306\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.9526 - reconstruction_loss: 1.7243 - kl_loss: 13.2283\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.0342 - reconstruction_loss: 1.8087 - kl_loss: 13.2255\n",
      "fast thinking\n",
      "training on full data\n",
      "41 105\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8204\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.6741\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1863 - reconstruction_loss: 1.6449 - kl_loss: 4.5414\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0317 - reconstruction_loss: 1.4938 - kl_loss: 4.5380\n",
      "Success in episode 51 at time step 630 with reward 96.35581436095096\n",
      "Episode 52\n",
      "[-0.5328334  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3907\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6239\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9745 - reconstruction_loss: 0.1079 - kl_loss: 1.8666\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3130 - reconstruction_loss: 2.4286 - kl_loss: 1.8844\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8341\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.1786\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9031 - reconstruction_loss: 0.5862 - kl_loss: 2.3169\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6556 - reconstruction_loss: 1.3220 - kl_loss: 2.3336\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2908\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.3958\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3881 - reconstruction_loss: 0.4363 - kl_loss: 1.9518\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2859 - reconstruction_loss: 0.3291 - kl_loss: 1.9569\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.3910\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.6334\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9089 - reconstruction_loss: 2.4446 - kl_loss: 4.4643\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5629 - reconstruction_loss: 1.0706 - kl_loss: 4.4923\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.5199\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.3056\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8599 - reconstruction_loss: 0.3537 - kl_loss: 6.5062\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.3561 - reconstruction_loss: 0.8489 - kl_loss: 6.5072\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 8.4206\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 8.1958\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.1583 - reconstruction_loss: 2.1710 - kl_loss: 7.9873\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.2861 - reconstruction_loss: 2.3201 - kl_loss: 7.9660\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.5399\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.3596\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.8826 - reconstruction_loss: 2.7997 - kl_loss: 8.0829\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.2591 - reconstruction_loss: 1.1749 - kl_loss: 8.0842\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0537\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9767\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5698 - reconstruction_loss: 1.9393 - kl_loss: 5.6305\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.5400 - reconstruction_loss: 8.9081 - kl_loss: 5.6319\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4520\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3567\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.0453 - reconstruction_loss: 1.2875 - kl_loss: 7.7577\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.3917 - reconstruction_loss: 3.6312 - kl_loss: 7.7605\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 12.5676\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 12.3000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.2638 - reconstruction_loss: 1.1100 - kl_loss: 10.1538\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.1051 - reconstruction_loss: 2.9727 - kl_loss: 10.1324\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 67.0256\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 62.6338\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.4340 - reconstruction_loss: 1.3364 - kl_loss: 11.0975\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.4783 - reconstruction_loss: 2.4125 - kl_loss: 11.0658\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1267\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.0301\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.6571 - reconstruction_loss: 2.7789 - kl_loss: 9.8782\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.8194 - reconstruction_loss: 0.9134 - kl_loss: 9.9060\n",
      "training on full data\n",
      "16 43\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.3836\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.9316\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.8538 - reconstruction_loss: 2.3402 - kl_loss: 5.5136\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5162 - reconstruction_loss: 2.0063 - kl_loss: 5.5098\n",
      "Success in episode 52 at time step 253 with reward 98.19266866958372\n",
      "Episode 53\n",
      "[-0.4516396  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.5899\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9300\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1133 - reconstruction_loss: 0.5790 - kl_loss: 2.5343\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0086 - reconstruction_loss: 2.5183 - kl_loss: 2.4903\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.5081\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.7562\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5919 - reconstruction_loss: 0.4548 - kl_loss: 3.1371\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2877 - reconstruction_loss: 1.1634 - kl_loss: 3.1243\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.9540\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.1785\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2963 - reconstruction_loss: 0.1355 - kl_loss: 4.1608\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8494 - reconstruction_loss: 0.6634 - kl_loss: 4.1860\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.8954\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.0467\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2654 - reconstruction_loss: 0.2308 - kl_loss: 5.0346\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6044 - reconstruction_loss: 0.5321 - kl_loss: 5.0723\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6270\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 920us/step - kl_loss: 0.6378\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.5906 - reconstruction_loss: 3.1326 - kl_loss: 4.4580\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2004 - reconstruction_loss: 0.7306 - kl_loss: 4.4699\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2379\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3114\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.1975 - reconstruction_loss: 9.1715 - kl_loss: 7.0261\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.2948 - reconstruction_loss: 3.2592 - kl_loss: 7.0356\n",
      "training on full data\n",
      "3 17\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9719\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9269\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2889 - reconstruction_loss: 2.9665 - kl_loss: 4.3223\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.7812 - reconstruction_loss: 3.4535 - kl_loss: 4.3278\n",
      "Success in episode 53 at time step 97 with reward 99.071008332119\n",
      "Episode 54\n",
      "[-0.52271855  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0430\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9108\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9487 - reconstruction_loss: 3.0384 - kl_loss: 1.9104\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4970 - reconstruction_loss: 1.5781 - kl_loss: 1.9190\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.8420\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.8189\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7731 - reconstruction_loss: 0.5838 - kl_loss: 3.1894\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8694 - reconstruction_loss: 3.6715 - kl_loss: 3.1979\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.4900\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.3123\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8982 - reconstruction_loss: 1.3412 - kl_loss: 3.5570\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4517 - reconstruction_loss: 0.8923 - kl_loss: 3.5594\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.9809\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.7954\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9381 - reconstruction_loss: 0.1681 - kl_loss: 4.7700\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8451 - reconstruction_loss: 1.0910 - kl_loss: 4.7542\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1834\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1415\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3120 - reconstruction_loss: 2.7291 - kl_loss: 3.5829\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.4599 - reconstruction_loss: 3.8653 - kl_loss: 3.5946\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 7.4498\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 7.1276\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.0587 - reconstruction_loss: 3.4095 - kl_loss: 5.6493\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.4736 - reconstruction_loss: 6.8087 - kl_loss: 5.6649\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 12.7699\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 11.4268\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.5153 - reconstruction_loss: 5.4588 - kl_loss: 9.0566\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.9687 - reconstruction_loss: 5.8911 - kl_loss: 9.0776\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 15.1257\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 14.8735\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.3570 - reconstruction_loss: 1.7574 - kl_loss: 11.5996\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.2024 - reconstruction_loss: 0.6010 - kl_loss: 11.6014\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9251\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0538\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.4830 - reconstruction_loss: 0.8295 - kl_loss: 8.6535\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.1694 - reconstruction_loss: 0.5415 - kl_loss: 8.6279\n",
      "training on full data\n",
      "4 25\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.6407\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.3748\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.0450 - reconstruction_loss: 2.0476 - kl_loss: 5.9974\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.5675 - reconstruction_loss: 1.5775 - kl_loss: 5.9900\n",
      "Success in episode 54 at time step 149 with reward 98.6064612979406\n",
      "Episode 55\n",
      "[-0.44220927  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.5702\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.2503\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0267 - reconstruction_loss: 1.4063 - kl_loss: 2.6204\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7071 - reconstruction_loss: 4.0790 - kl_loss: 2.6281\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1115\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7267\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2087 - reconstruction_loss: 1.3909 - kl_loss: 3.8178\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5351 - reconstruction_loss: 0.7182 - kl_loss: 3.8169\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.3067\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.1652\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9186 - reconstruction_loss: 0.4673 - kl_loss: 5.4513\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6167 - reconstruction_loss: 0.1795 - kl_loss: 5.4373\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8710\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9687\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2961 - reconstruction_loss: 0.7715 - kl_loss: 6.5247\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.0468 - reconstruction_loss: 1.5362 - kl_loss: 6.5107\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4684\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4627\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.1525 - reconstruction_loss: 1.8240 - kl_loss: 6.3285\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.0816 - reconstruction_loss: 4.7655 - kl_loss: 6.3160\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6854\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5743\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.0135 - reconstruction_loss: 5.2665 - kl_loss: 9.7470\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 45.0061 - reconstruction_loss: 35.2881 - kl_loss: 9.7180\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4845\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5476\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.8407 - reconstruction_loss: 8.4193 - kl_loss: 11.4214\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.3447 - reconstruction_loss: 2.8924 - kl_loss: 11.4523\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1045\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.0047\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.7816 - reconstruction_loss: 3.9912 - kl_loss: 12.7904\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.7862 - reconstruction_loss: 2.9614 - kl_loss: 12.8248\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 51.7022\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 48.5334\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.5720 - reconstruction_loss: 0.4264 - kl_loss: 11.1456\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.2973 - reconstruction_loss: 1.1511 - kl_loss: 11.1463\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9586\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6205\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.4108 - reconstruction_loss: 0.7548 - kl_loss: 9.6560\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.0566 - reconstruction_loss: 0.4021 - kl_loss: 9.6545\n",
      "fast thinking\n",
      "training on full data\n",
      "5 28\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.0718\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.6037\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.4912 - reconstruction_loss: 2.8387 - kl_loss: 7.6524\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.6093 - reconstruction_loss: 2.9702 - kl_loss: 7.6391\n",
      "Success in episode 55 at time step 167 with reward 98.30035634121083\n",
      "Episode 56\n",
      "[-0.47030616  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0054\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8879\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8849 - reconstruction_loss: 2.5153 - kl_loss: 2.3696\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8511 - reconstruction_loss: 0.4801 - kl_loss: 2.3711\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5197\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5441\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0934 - reconstruction_loss: 0.2901 - kl_loss: 1.8033\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0459 - reconstruction_loss: 0.2418 - kl_loss: 1.8040\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8537\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9171\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2283 - reconstruction_loss: 1.4416 - kl_loss: 1.7868\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6378 - reconstruction_loss: 0.8534 - kl_loss: 1.7844\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.4068\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.5205\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9768 - reconstruction_loss: 1.8551 - kl_loss: 3.1217\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.5047 - reconstruction_loss: 3.3919 - kl_loss: 3.1127\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.4251\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.7293\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7691 - reconstruction_loss: 0.4630 - kl_loss: 4.3061\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.7956 - reconstruction_loss: 0.4910 - kl_loss: 4.3047\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2044\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1673\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7520 - reconstruction_loss: 0.6749 - kl_loss: 5.0772\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7208 - reconstruction_loss: 0.6421 - kl_loss: 5.0786\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 7.7943\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 7.8883\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.0682 - reconstruction_loss: 1.4268 - kl_loss: 4.6414\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1401 - reconstruction_loss: 0.4936 - kl_loss: 4.6465\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.0642\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.0473\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0746 - reconstruction_loss: 0.2424 - kl_loss: 4.8322\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2971 - reconstruction_loss: 0.4590 - kl_loss: 4.8382\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0851\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0746\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.0332 - reconstruction_loss: 3.2062 - kl_loss: 4.8270\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5527 - reconstruction_loss: 0.7209 - kl_loss: 4.8317\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8928\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8842\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.3148 - reconstruction_loss: 7.5208 - kl_loss: 7.7940\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.7198 - reconstruction_loss: 6.9586 - kl_loss: 7.7612\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 14.6612\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 13.7944\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.5239 - reconstruction_loss: 3.0385 - kl_loss: 9.4854\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.3872 - reconstruction_loss: 1.9095 - kl_loss: 9.4777\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.9345\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.0357\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.8841 - reconstruction_loss: 1.2207 - kl_loss: 10.6633\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.8534 - reconstruction_loss: 1.1924 - kl_loss: 10.6609\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 8.1625\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 8.1701\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.6060 - reconstruction_loss: 1.0169 - kl_loss: 10.5890\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.9537 - reconstruction_loss: 1.3676 - kl_loss: 10.5861\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8006\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7700\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.2218 - reconstruction_loss: 2.6393 - kl_loss: 8.5825\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.7541 - reconstruction_loss: 2.1862 - kl_loss: 8.5679\n",
      "training on full data\n",
      "12 42\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.8618\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.6319\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4441 - reconstruction_loss: 1.3559 - kl_loss: 5.0883\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6067 - reconstruction_loss: 1.5239 - kl_loss: 5.0828\n",
      "Success in episode 56 at time step 247 with reward 98.6046302923964\n",
      "Episode 57\n",
      "[-0.50103635  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2804\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3122\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2174 - reconstruction_loss: 1.2644 - kl_loss: 1.9529\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9409 - reconstruction_loss: 0.9810 - kl_loss: 1.9599\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2648\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.3750\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.0610 - reconstruction_loss: 6.7516 - kl_loss: 2.3094\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3318 - reconstruction_loss: 1.0103 - kl_loss: 2.3215\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.8804\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.1325\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2873 - reconstruction_loss: 0.5845 - kl_loss: 2.7028\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8055 - reconstruction_loss: 1.0980 - kl_loss: 2.7076\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3776\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3387\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.1828 - reconstruction_loss: 4.8245 - kl_loss: 3.3583\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1263 - reconstruction_loss: 3.7567 - kl_loss: 3.3696\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 15.6074\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 15.5934\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6662 - reconstruction_loss: 0.3734 - kl_loss: 6.2928\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.7458 - reconstruction_loss: 1.4520 - kl_loss: 6.2938\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6571\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6540\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.7469 - reconstruction_loss: 0.5863 - kl_loss: 7.1606\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6837 - reconstruction_loss: 2.5393 - kl_loss: 7.1443\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "29 42\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.3080\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.2218\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4309 - reconstruction_loss: 1.0174 - kl_loss: 3.4135\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8028 - reconstruction_loss: 1.3925 - kl_loss: 3.4103\n",
      "Success in episode 57 at time step 252 with reward 99.3098407517339\n",
      "Episode 58\n",
      "[-0.5165318  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.8344\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9970\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4583 - reconstruction_loss: 1.5713 - kl_loss: 1.8870\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5042 - reconstruction_loss: 0.6169 - kl_loss: 1.8873\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5010\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4662\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2012 - reconstruction_loss: 1.8312 - kl_loss: 3.3700\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4819 - reconstruction_loss: 2.1234 - kl_loss: 3.3585\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.3052\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.0282\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6643 - reconstruction_loss: 1.0896 - kl_loss: 5.5747\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.4365 - reconstruction_loss: 0.8695 - kl_loss: 5.5669\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8944\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.9155\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4128 - reconstruction_loss: 0.4928 - kl_loss: 4.9199\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4237 - reconstruction_loss: 0.4940 - kl_loss: 4.9297\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.5042\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.5112\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.7773 - reconstruction_loss: 0.3458 - kl_loss: 7.4314\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.5781 - reconstruction_loss: 0.1423 - kl_loss: 7.4358\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "13 25\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9508\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9404\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7974 - reconstruction_loss: 1.7734 - kl_loss: 4.0240\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0813 - reconstruction_loss: 1.0567 - kl_loss: 4.0245\n",
      "Success in episode 58 at time step 147 with reward 99.14361530049865\n",
      "Episode 59\n",
      "[-0.56206995  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0350\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0386\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4891 - reconstruction_loss: 0.6229 - kl_loss: 1.8662\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1409 - reconstruction_loss: 2.2719 - kl_loss: 1.8690\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9924\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9370\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7584 - reconstruction_loss: 3.1195 - kl_loss: 2.6390\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4931 - reconstruction_loss: 0.8469 - kl_loss: 2.6462\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8690\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.8848\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8853 - reconstruction_loss: 0.7553 - kl_loss: 3.1300\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4439 - reconstruction_loss: 1.3189 - kl_loss: 3.1250\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 14.7127\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 14.2313\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.9941 - reconstruction_loss: 0.3235 - kl_loss: 7.6707\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.7432 - reconstruction_loss: 0.0758 - kl_loss: 7.6674\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 15.0172\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 14.5769\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.9297 - reconstruction_loss: 1.7575 - kl_loss: 10.1722\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.6193 - reconstruction_loss: 0.4705 - kl_loss: 10.1488\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.9124\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.7959\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.6142 - reconstruction_loss: 2.2101 - kl_loss: 8.4042\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.0542 - reconstruction_loss: 0.6426 - kl_loss: 8.4117\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6089\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6064\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.2666 - reconstruction_loss: 6.9361 - kl_loss: 10.3305\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.6424 - reconstruction_loss: 1.3027 - kl_loss: 10.3397\n",
      "training on full data\n",
      "14 30\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.2126\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.1805\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2548 - reconstruction_loss: 1.0509 - kl_loss: 5.2039\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5242 - reconstruction_loss: 1.3241 - kl_loss: 5.2001\n",
      "Success in episode 59 at time step 175 with reward 98.88429524457622\n",
      "Episode 60\n",
      "[-0.4116464  0.       ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4755\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4489\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0326 - reconstruction_loss: 1.6742 - kl_loss: 2.3584\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5967 - reconstruction_loss: 3.2422 - kl_loss: 2.3545\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6387\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6223\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1110 - reconstruction_loss: 0.9834 - kl_loss: 3.1276\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8836 - reconstruction_loss: 1.7530 - kl_loss: 3.1305\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7414\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7553\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.7052 - reconstruction_loss: 3.7990 - kl_loss: 3.9062\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6491 - reconstruction_loss: 5.7432 - kl_loss: 3.9059\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6533\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6547\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.7084 - reconstruction_loss: 5.2392 - kl_loss: 7.4692\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.1937 - reconstruction_loss: 2.7513 - kl_loss: 7.4424\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 8.7975\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 8.7310\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.9270 - reconstruction_loss: 0.0563 - kl_loss: 9.8707\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.1915 - reconstruction_loss: 0.3297 - kl_loss: 9.8618\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7047\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6708\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.4226 - reconstruction_loss: 1.5469 - kl_loss: 9.8757\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 991us/step - loss: 11.0770 - reconstruction_loss: 1.1839 - kl_loss: 9.8931\n",
      "fast thinking\n",
      "training on full data\n",
      "10 24\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.3985\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.3190\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3441 - reconstruction_loss: 1.7198 - kl_loss: 5.6243\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9280 - reconstruction_loss: 1.3059 - kl_loss: 5.6221\n",
      "Success in episode 60 at time step 144 with reward 99.09191883510026\n"
     ]
    }
   ],
   "source": [
    "# train the agent on the env\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "daifa, results_one = train_single_agent(env, daifa, observation_max, observation_min, observation_noise_stddev, num_episodes=60, render_env=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "       reward  timesteps  num_actions\n0   99.660569        324           54\n1   99.615112        522           87\n2   99.698807        396           66\n3   99.721974        468           78\n4   99.643577        318           53\n5   99.742296        318           53\n6   99.610623        522           87\n7   99.783046        330           55\n8   99.680440        408           68\n9   99.596904        498           83\n10  99.644096        552           92\n11  99.606594        402           67\n12  99.644003        468           78\n13  99.762650        324           54\n14  99.634849        324           54\n15  99.738322        318           53\n16  99.672698        360           60\n17  99.602932        546           91\n18  99.698488        360           60\n19  99.608213        414           69",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reward</th>\n      <th>timesteps</th>\n      <th>num_actions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>99.660569</td>\n      <td>324</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>99.615112</td>\n      <td>522</td>\n      <td>87</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>99.698807</td>\n      <td>396</td>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>99.721974</td>\n      <td>468</td>\n      <td>78</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>99.643577</td>\n      <td>318</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>99.742296</td>\n      <td>318</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>99.610623</td>\n      <td>522</td>\n      <td>87</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>99.783046</td>\n      <td>330</td>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>99.680440</td>\n      <td>408</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>99.596904</td>\n      <td>498</td>\n      <td>83</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>99.644096</td>\n      <td>552</td>\n      <td>92</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>99.606594</td>\n      <td>402</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>99.644003</td>\n      <td>468</td>\n      <td>78</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>99.762650</td>\n      <td>324</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>99.634849</td>\n      <td>324</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>99.738322</td>\n      <td>318</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>99.672698</td>\n      <td>360</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>99.602932</td>\n      <td>546</td>\n      <td>91</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>99.698488</td>\n      <td>360</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>99.608213</td>\n      <td>414</td>\n      <td>69</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = habit_policy(daifa)\n",
    "res = test_policy(env, p, observation_max, observation_min, observation_noise_stddev, 20, daifa.agent_time_ratio)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "daifa.train_vae = False\n",
    "daifa.model_vae.show_training = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "[-0.53786975  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.7409\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.7811\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.6929\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.6462\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1461\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.0883\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2705\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2633\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5810\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5740\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7434\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7168\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 27.4071\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 26.4306\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "15 32\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.5206\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.3907\n",
      "Success in episode 1 at time step 187 with reward 98.58043318142022\n",
      "Episode 2\n",
      "[-0.4795834  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.7101\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.8072\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.0487\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.0255\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2546\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2837\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2703\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2641\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1935\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2038\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.9167\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.8431\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.9248\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.7908\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6686\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6354\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1408\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1289\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9759\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9307\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 22.7938\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 21.3769\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 36.2450\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 33.1457\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1996\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2284\n",
      "fast thinking\n",
      "training on full data\n",
      "19 48\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.2286\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.0205\n",
      "Success in episode 2 at time step 283 with reward 97.9582090330639\n",
      "Episode 3\n",
      "[-0.4792921  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0138\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1074\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4260\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.4973\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6389\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6384\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1734\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1683\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4490\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4441\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.6307\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.6481\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 13.2943\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 13.3394\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1947\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1349\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2860\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2984\n",
      "training on full data\n",
      "19 39\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.0085\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8208\n",
      "Success in episode 3 at time step 229 with reward 98.65745128265368\n",
      "Episode 4\n",
      "[-0.4361179  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.8171\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.8385\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.2664\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.1752\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5735\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4904\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.8679\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.6379\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 12.9774\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 12.8456\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.0087\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.7621\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3257\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3441\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6725\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6154\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1241\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0708\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 31.2545\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 29.7292\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.8171\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6094\n",
      "training on full data\n",
      "14 39\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.3996\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.1344\n",
      "Success in episode 4 at time step 230 with reward 97.978537305188\n",
      "Episode 5\n",
      "[-0.46921447  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5491\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4335\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2611\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.0883\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4465\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.3760\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.1667\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.2566\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.8457\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.0805\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4490\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.4126\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.3179\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.3519\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.2432\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.1577\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.3031\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1994\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.3686\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.0647\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2705\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0785\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 53.1814\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 49.2662\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0147\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.8308\n",
      "training on full data\n",
      "12 41\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.9009\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.4129\n",
      "Success in episode 5 at time step 241 with reward 98.4727569369086\n",
      "Episode 6\n",
      "[-0.5088146  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0984\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5262\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4709\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6569\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4183\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5456\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1852\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3216\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3396\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3634\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5049\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5559\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5571\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5548\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.4003\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.3623\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5768\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5101\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.4723\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.5225\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.3906\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.3520\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9373\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.8860\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8089\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.7569\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2976\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2521\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 11.9149\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 11.6592\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 22.9214\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 21.7071\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4118\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3795\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6228\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6003\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8505\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8279\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 15.5480\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 14.3560\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.3997\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.1232\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0263\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0682\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5520\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5058\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.3753\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.4364\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.7987\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.7478\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.1515\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.9219\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0705\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.0901\n",
      "fast thinking\n",
      "training on full data\n",
      "21 77\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8381\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.6964\n",
      "Success in episode 6 at time step 461 with reward 96.63395225217587\n",
      "Episode 7\n",
      "[-0.45366466  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0691\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9533\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6364\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9927\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.3862\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.6758\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1737\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.2981\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4129\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.2987\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.7860\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.7207\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.8502\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.8380\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.0171\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.9502\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.1286\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.1618\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.9921\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.9181\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2689\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2310\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8839\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.6389\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1696\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.6867\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 50.2554\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 46.1022\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.8160\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.8448\n",
      "fast thinking\n",
      "training on full data\n",
      "22 55\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.8699\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.8030\n",
      "Success in episode 7 at time step 325 with reward 97.58408800313823\n",
      "Episode 8\n",
      "[-0.5761529  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7563\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8033\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1248\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1524\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6549\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5990\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9761\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9388\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.7564\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 979us/step - kl_loss: 4.9017\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.9035\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.7531\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7873\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7642\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9146\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.8646\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.2248\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.8757\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 68.0962\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 978us/step - kl_loss: 66.1778\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.9424\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.0394\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1766\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1724\n",
      "fast thinking\n",
      "training on full data\n",
      "16 41\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.1058\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.9935\n",
      "Success in episode 8 at time step 245 with reward 98.40488593911319\n",
      "Episode 9\n",
      "[-0.54417884  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.7680\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.6219\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.4389\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.4997\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.7844\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.9185\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.5699\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.5041\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9261\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9061\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2194\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2422\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1551\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.1519\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0986\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.0337\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6878\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6326\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.5094\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.5321\n",
      "training on full data\n",
      "6 28\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.9461\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8870\n",
      "Success in episode 9 at time step 165 with reward 98.44387093636564\n",
      "Episode 10\n",
      "[-0.5477101  0.       ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.2129\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.8917\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9396\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6753\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7741\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7061\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4962\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.3422\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8907\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 981us/step - kl_loss: 2.8200\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0463\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0544\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4794\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5150\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8144\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.6936\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 12.4168\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 12.2517\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 10.6214\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 9.6121\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.0970\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.6978\n",
      "training on full data\n",
      "14 38\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.6682\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.5464\n",
      "Success in episode 10 at time step 228 with reward 98.2881732945751\n",
      "Episode 11\n",
      "[-0.5267792  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3001\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 989us/step - kl_loss: 1.3485\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4363\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.4320\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1891\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 981us/step - kl_loss: 2.0568\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.1653\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.2062\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.0088\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.0558\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1176\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1568\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4976\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.5068\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.2994\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.2583\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2531\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.2270\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3207\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2986\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3023\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 949us/step - kl_loss: 0.2994\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4495\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3603\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.4995\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.4486\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.5135\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.5214\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2576\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2469\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0613\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.0633\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.1617\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.1504\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1930\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1874\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2055\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2025\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.5254\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 997us/step - kl_loss: 2.4638\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 7.5989\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 7.2991\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 11.7923\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 11.6024\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 8.5949\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 7.8099\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3758\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3250\n",
      "fast thinking\n",
      "training on full data\n",
      "39 88\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2313\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1723\n",
      "Success in episode 11 at time step 524 with reward 96.84999773314468\n",
      "Episode 12\n",
      "[-0.4539575  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.5075\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.4825\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.9839\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.8357\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.2458\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.2421\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 9.5823\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 9.2466\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.1118\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.9908\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2695\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1978\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "13 28\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4832\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.3792\n",
      "Success in episode 12 at time step 164 with reward 98.79430359760447\n",
      "Episode 13\n",
      "[-0.41550657  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4493\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5070\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.9860\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.9084\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2171\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2145\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.8664\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.8436\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 10.9937\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 10.9244\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.5664\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.3636\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "22 37\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.3859\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2555\n",
      "Success in episode 13 at time step 220 with reward 98.91632967488836\n",
      "Episode 14\n",
      "[-0.40823853  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2781\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.0723\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7627\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9329\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7001\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7455\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5244\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5589\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1233\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1068\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.4823\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.8500\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.2329\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.1261\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "14 29\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1255\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.9988\n",
      "Success in episode 14 at time step 173 with reward 98.93866953799125\n",
      "Episode 15\n",
      "[-0.559739  0.      ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.7939\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.5677\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4452\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.4964\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0817\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1935\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.0839\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.0649\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.4633\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.5257\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 16.3465\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 15.5232\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.0153\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.7541\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "13 29\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.5125\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.4043\n",
      "Success in episode 15 at time step 171 with reward 98.68295915788583\n",
      "Episode 16\n",
      "[-0.4019772  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.3468\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.3444\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.4529\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.4510\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3788\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4017\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8074\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8071\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 9.9758\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 9.9040\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.8878\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.7043\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "12 27\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.3611\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1889\n",
      "Success in episode 16 at time step 158 with reward 98.84468505962603\n",
      "Episode 17\n",
      "[-0.5627067  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.8213\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.3717\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.9469\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.8830\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8315\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.6365\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.5311\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.6179\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.3964\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.4113\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1803\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2049\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 9.0278\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 8.6565\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.0974\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.1011\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5908\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6589\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4428\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.4677\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.5546\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.4956\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7841\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7394\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2861\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2073\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.0736\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.9979\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 97.9282\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 93.3581\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7394\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7357\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8145\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8095\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.8416\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7369\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9188\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 884us/step - kl_loss: 0.9470\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.9525\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.0500\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 11.6412\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 11.3297\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 7.5502\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 7.0745\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.5673\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.5835\n",
      "training on full data\n",
      "22 71\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.7272\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.5232\n",
      "Success in episode 17 at time step 424 with reward 96.94031815162789\n",
      "Episode 18\n",
      "[-0.52839655  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2378\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2600\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8856\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9119\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6897\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7931\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.2772\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.1947\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7440\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.8498\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5322\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4722\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8211\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.8892\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8695\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8355\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4741\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.4389\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1794\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1729\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 15.8541\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 15.6232\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.4414\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.3318\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1201\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.0588\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0562\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.0019\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.0244\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.8890\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1484\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.7900\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0327\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7060\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 7.6974\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 7.4751\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5213\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 933us/step - kl_loss: 1.5040\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0576\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 986us/step - kl_loss: 0.9915\n",
      "training on full data\n",
      "19 61\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.5744\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.5183\n",
      "Success in episode 18 at time step 361 with reward 97.46769179861163\n",
      "Episode 19\n",
      "[-0.5054948  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1515\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.1514\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.9209\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.8781\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.3198\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.3414\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8351\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8467\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.8708\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9168\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 20.2554\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 19.6947\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.5326\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.0946\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "12 27\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.9227\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.7493\n",
      "Success in episode 19 at time step 157 with reward 99.0385210171369\n",
      "Episode 20\n",
      "[-0.5682347  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7548\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7922\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4476\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3873\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.5565\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.6991\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4289\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5125\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5456\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5797\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2094\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2214\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0673\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0659\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 7.8831\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 7.7225\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2196\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.2403\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.9951\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.9144\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.7244\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.6385\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1643\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.0186\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.6325\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.7007\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6600\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6765\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 7.8175\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 7.5112\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 8.2359\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 8.1120\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1082\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.9987\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0871\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0791\n",
      "training on full data\n",
      "40 78\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.3710\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2406\n",
      "Success in episode 20 at time step 463 with reward 97.32573053515243\n"
     ]
    }
   ],
   "source": [
    "# train the agent on the env\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "daifa, results_two = train_single_agent(env, daifa, observation_max, observation_min, observation_noise_stddev, num_episodes=20, render_env=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "# # make the HABIT ACTION NET\n",
    "# habit_net = HabitualAction(latent_dim, 1, [16, 16], train_epochs=2, show_training=True)\n",
    "# habit_net.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "#\n",
    "# daifa.habit_action_model = habit_net\n",
    "#\n",
    "# actor_model = get_actor(latent_dim, 1)\n",
    "# critic_model = get_critic(latent_dim, 1)\n",
    "#\n",
    "# target_actor = get_actor(latent_dim, 1)\n",
    "# target_critic = get_critic(latent_dim, 1)\n",
    "#\n",
    "# # Making the weights equal initially\n",
    "# target_actor.set_weights(actor_model.get_weights())\n",
    "# target_critic.set_weights(critic_model.get_weights())\n",
    "#\n",
    "# critic_optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "# actor_optimizer = tf.keras.optimizers.Adam(0.00005)\n",
    "#\n",
    "# habit_net = BasicDDPG(actor_model, critic_model, target_actor, target_critic, tau=0.005, critic_optimizer=critic_optimizer, actor_optimizer=actor_optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "       reward  timesteps  num_actions\n0   -0.843838       1002          167\n1   99.721022        324           54\n2   99.462706        624          104\n3   99.340526        756          126\n4   99.634499        396           66\n5   99.553337        480           80\n6   99.580220        474           79\n7   99.692898        324           54\n8   99.566838        480           80\n9   99.696078        324           54\n10  99.539940        486           81\n11  99.616288        408           68\n12  99.498874        552           92\n13  -0.856320       1002          167\n14  99.309365        774          129\n15  99.690317        324           54\n16  99.556488        480           80\n17  99.713784        324           54\n18  99.584498        474           79\n19  99.326137        774          129",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reward</th>\n      <th>timesteps</th>\n      <th>num_actions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.843838</td>\n      <td>1002</td>\n      <td>167</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>99.721022</td>\n      <td>324</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>99.462706</td>\n      <td>624</td>\n      <td>104</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>99.340526</td>\n      <td>756</td>\n      <td>126</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>99.634499</td>\n      <td>396</td>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>99.553337</td>\n      <td>480</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>99.580220</td>\n      <td>474</td>\n      <td>79</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>99.692898</td>\n      <td>324</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>99.566838</td>\n      <td>480</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>99.696078</td>\n      <td>324</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>99.539940</td>\n      <td>486</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>99.616288</td>\n      <td>408</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>99.498874</td>\n      <td>552</td>\n      <td>92</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>-0.856320</td>\n      <td>1002</td>\n      <td>167</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>99.309365</td>\n      <td>774</td>\n      <td>129</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>99.690317</td>\n      <td>324</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>99.556488</td>\n      <td>480</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>99.713784</td>\n      <td>324</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>99.584498</td>\n      <td>474</td>\n      <td>79</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>99.326137</td>\n      <td>774</td>\n      <td>129</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = habit_policy(daifa)\n",
    "res = test_policy(env, p, observation_max, observation_min, observation_noise_stddev, 20, daifa.agent_time_ratio)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "[-0.4969045  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2552\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.1887\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1323\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4350\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3263\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.2794\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.3815\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.3718\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.2949\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.4714\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.8203\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 984us/step - kl_loss: 4.9133\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9340\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9367\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.2374\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.1937\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3679\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3726\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4930\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4924\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7806\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 984us/step - kl_loss: 0.7706\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5163\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5186\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.7278\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.6566\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.0164\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.9925\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6557\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6417\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.8825\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.7628\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4292\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4147\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9828\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9882\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8348\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8056\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.0487\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 999us/step - kl_loss: 4.0081\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.5175\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.4332\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1233\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.1221\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3816\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 906us/step - kl_loss: 0.3419\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.6447\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.6120\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.3659\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.3506\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8691\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8717\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2472\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2087\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8015\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.8051\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1049\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 961us/step - kl_loss: 1.1153\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5850\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5773\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5429\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 930us/step - kl_loss: 1.5450\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.4855\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.4787\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.7422\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.7362\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0550\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0272\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6227\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5687\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.3726\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3804\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.2999\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.2279\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4732\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 959us/step - kl_loss: 1.4210\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8790\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8745\n",
      "training on full data\n",
      "58 139\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.8193\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7894\n",
      "Success in episode 1 at time step 834 with reward 95.90901783104393\n",
      "Episode 2\n",
      "[-0.41607282  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3792\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4165\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2717\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.3443\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1295\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1314\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.9810\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.8875\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6367\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6142\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9875\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 958us/step - kl_loss: 2.0283\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.5414\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 967us/step - kl_loss: 3.4999\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.4598\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.2035\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.0720\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.9628\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4952\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4804\n",
      "training on full data\n",
      "7 29\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.7554\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.7187\n",
      "Success in episode 2 at time step 169 with reward 98.54789302640654\n",
      "Episode 3\n",
      "[-0.56873727  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.9469\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.9225\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1379\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.1216\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0674\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9755\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 7.2513\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 929us/step - kl_loss: 7.2275\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.0248\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.8005\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4340\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4796\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9168\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9338\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.6653\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.6559\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.6462\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.5267\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.7078\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.7579\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "15 38\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.5431\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.5201\n",
      "Success in episode 3 at time step 223 with reward 98.13213265275535\n",
      "Episode 4\n",
      "[-0.5983835  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.9849\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 950us/step - kl_loss: 3.0246\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.9225\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.8714\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.5085\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.4035\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3970\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2943\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1814\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1984\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0433\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.0502\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 9.9320\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 9.8810\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5108\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5085\n",
      "training on full data\n",
      "14 32\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.7297\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.7008\n",
      "Success in episode 4 at time step 190 with reward 98.62810248052034\n",
      "Episode 5\n",
      "[-0.5951957  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.6941\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.6989\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.3017\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.2828\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7492\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7674\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1768\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1719\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.0674\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.0592\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.9235\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.9125\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4003\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3904\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.4620\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.4352\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4444\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.3798\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2212\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2204\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 10.9854\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 10.6574\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6531\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5272\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7551\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7507\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4870\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3867\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3967\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4521\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3487\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2726\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 13.4788\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 13.2615\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "30 67\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4793\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4161\n",
      "Success in episode 5 at time step 400 with reward 97.71784524402008\n",
      "Episode 6\n",
      "[-0.49562514  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3077\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1374\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.0111\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.0112\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5809\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 998us/step - kl_loss: 1.5658\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5214\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6358\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7393\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7687\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.7872\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.7671\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.1145\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.0186\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.3610\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.3673\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "24 43\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2195\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1441\n",
      "Success in episode 6 at time step 255 with reward 98.69828139567976\n",
      "Episode 7\n",
      "[-0.45636952  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.4973\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.1554\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 8.0884\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 8.1583\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.9656\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 983us/step - kl_loss: 4.5627\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 9.3271\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 9.3572\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9013\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9120\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.7787\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.8098\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 13.1551\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 12.9354\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 11.2395\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 10.9172\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0574\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.0625\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "9 28\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.0124\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.8496\n",
      "Success in episode 7 at time step 165 with reward 98.50639778198116\n",
      "Episode 8\n",
      "[-0.5666048  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4055\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.2008\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5344\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5753\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2077\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.2186\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.2081\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.0312\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0959\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1766\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6246\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5885\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.7773\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.8206\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5418\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5285\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.5349\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.4828\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.1682\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.1221\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.8389\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7444\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0420\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9357\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9706\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.8205\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 23.5333\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 22.7355\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 7.2887\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.5859\n",
      "fast thinking\n",
      "training on full data\n",
      "28 61\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.3384\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2389\n",
      "Success in episode 8 at time step 362 with reward 97.42844724472923\n",
      "Episode 9\n",
      "[-0.5978663  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.1539\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.2242\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7622\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 984us/step - kl_loss: 1.8590\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 7.2554\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 7.4039\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1333\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.1012\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4392\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.4779\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.0346\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.9478\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7596\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7265\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3652\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3091\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.0130\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.9571\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7729\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7708\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0073\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9556\n",
      "training on full data\n",
      "9 34\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.8310\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.7447\n",
      "Success in episode 9 at time step 200 with reward 98.00537606851782\n",
      "Episode 10\n",
      "[-0.5053107  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6411\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5309\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5398\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 987us/step - kl_loss: 1.7090\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5539\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5632\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0481\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0507\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.2522\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.1989\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0728\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0968\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5037\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 957us/step - kl_loss: 1.4254\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 17.6387\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 16.4500\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.6757\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.0845\n",
      "fast thinking\n",
      "training on full data\n",
      "16 37\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.7590\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.6422\n",
      "Success in episode 10 at time step 221 with reward 98.45929639068108\n",
      "Episode 11\n",
      "[-0.57154834  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4955\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5613\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3078\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.3398\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0001\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0099\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9136\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9269\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9071\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8578\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5584\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5351\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.5123\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.4734\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9463\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9471\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6901\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6636\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.0960\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1114\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 13.6709\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 13.0878\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9620\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.8408\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9094\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7605\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 36.6957\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 33.2687\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.6139\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.4791\n",
      "training on full data\n",
      "35 68\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.9371\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.8161\n",
      "Success in episode 11 at time step 403 with reward 97.30579387520206\n",
      "Episode 12\n",
      "[-0.44892415  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.9628\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.8363\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9294\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1299\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.0896\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.1484\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2070\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.2299\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.7302\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.7584\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6646\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6728\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 7.8719\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 7.7958\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.5463\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5636\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0665\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.0034\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2037\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 999us/step - kl_loss: 2.1776\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9787\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9199\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8717\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8953\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.3883\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.3895\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3100\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3008\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7939\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7970\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8121\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 995us/step - kl_loss: 0.8079\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9639\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9682\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7201\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7171\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.3761\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.3521\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0042\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0188\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.8980\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 995us/step - kl_loss: 3.8921\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6286\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6227\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7158\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6944\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0923\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0800\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.7350\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.7088\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.3886\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.3553\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4732\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4479\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.7590\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.7624\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8692\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8782\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0042\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9847\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9537\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9161\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6270\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6141\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.9094\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.9261\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.6595\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.6614\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0382\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0310\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9894\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9837\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0224\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.0009\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1972\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1716\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.4887\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4729\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "88 167\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.1210\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9751\n",
      "No Success\n",
      "Episode 13\n",
      "[-0.43487975  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.5253\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.1656\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.0524\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 949us/step - kl_loss: 0.1409\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.4091\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7731\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.6271\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.1467\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.1909\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.3863\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.1442\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1732\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.8505\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.7736\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.0551\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.9016\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.4289\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.8612\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 16.2879\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 15.7859\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.9470\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.8726\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1213\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0285\n",
      "training on full data\n",
      "11 37\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.6750\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.3630\n",
      "Success in episode 13 at time step 218 with reward 98.4405110500101\n",
      "Episode 14\n",
      "[-0.4354928  0.       ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1717\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.5727\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3794\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6062\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.4588\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.4689\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.5586\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.5588\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5915\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6664\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.4456\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 999us/step - kl_loss: 5.5774\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 58.6308\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 970us/step - kl_loss: 57.2607\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 7.5079\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.8302\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "8 26\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.9963\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.4725\n",
      "Success in episode 14 at time step 155 with reward 98.65534901368419\n",
      "Episode 15\n",
      "[-0.41673347  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.2234\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.2743\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5140\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7615\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.1952\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 997us/step - kl_loss: 3.0167\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6229\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 927us/step - kl_loss: 0.6391\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.6410\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.7307\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.4466\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.5771\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 10.1512\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 10.1028\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.7338\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.6596\n",
      "training on full data\n",
      "8 27\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.2888\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.8930\n",
      "Success in episode 15 at time step 162 with reward 98.89995499598238\n",
      "Episode 16\n",
      "[-0.55000305  0.        ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.0271\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.9611\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3483\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.1855\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.7837\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.8589\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5311\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.4194\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7404\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7506\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6526\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.5985\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 12.2478\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 12.1157\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 12.3335\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 12.1028\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3822\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.3082\n",
      "fast thinking\n",
      "training on full data\n",
      "4 24\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1862\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.0088\n",
      "Success in episode 16 at time step 144 with reward 98.73802746954355\n",
      "Episode 17\n",
      "[-0.5511446  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6568\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7658\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9982\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0310\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.9774\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 2.1551\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.7436\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.7533\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.8083\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.6606\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8333\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8237\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "29 43\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7043\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6447\n",
      "Success in episode 17 at time step 254 with reward 98.98039018676968\n",
      "Episode 18\n",
      "[-0.48185095  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.9738\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.8744\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.8973\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.8414\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7554\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.8073\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 16.3960\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 16.2337\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.9890\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.9431\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.5631\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.5400\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.8686\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 4.7931\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 15.2640\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 14.8467\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.9501\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.0890\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.6798\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.6491\n",
      "fast thinking\n",
      "training on full data\n",
      "17 39\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.2627\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1645\n",
      "Success in episode 18 at time step 231 with reward 98.64092241549142\n",
      "Episode 19\n",
      "[-0.5881081  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.3222\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.4122\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7565\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 972us/step - kl_loss: 1.7310\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.2691\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.2237\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.8632\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9062\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.7642\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 6.2915\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 11.0777\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 11.1949\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0796\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.0137\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "33 49\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7257\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.6259\n",
      "Success in episode 19 at time step 292 with reward 98.95308311024269\n",
      "Episode 20\n",
      "[-0.4086439  0.       ]\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.0349\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 0.9793\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.2012\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.3288\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.9924\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 5.0987\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.8057\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 3.6499\n",
      "fast thinking\n",
      "fast thinking\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 1.7632\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 1ms/step - kl_loss: 1.7004\n",
      "training on full data\n",
      "2 14\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.9888\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 2.9767\n",
      "Success in episode 20 at time step 79 with reward 99.11367463835238\n"
     ]
    }
   ],
   "source": [
    "daifa.habit_action_model.show_training = False\n",
    "daifa.train_habit_net = True\n",
    "daifa.train_after_exploring = True\n",
    "daifa.use_kl_intrinsic = True\n",
    "daifa.use_kl_extrinsic = False\n",
    "daifa.use_fast_thinking = True\n",
    "daifa.uncertainty_tolerance = 0.1\n",
    "\n",
    "# daifa.tran.show_training = False\n",
    "# daifa.prior_model.show_training = False\n",
    "\n",
    "# train the agent on the env\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "daifa, results_three = train_single_agent(env, daifa, observation_max, observation_min, observation_noise_stddev, num_episodes=20, render_env=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "       reward  timesteps  num_actions\n0   99.303372        756          126\n1   99.681198        318           53\n2   99.551412        426           71\n3   -0.848039       1002          167\n4   99.714342        324           54\n5   -0.874360       1002          167\n6   99.463053        618          103\n7   99.407967        642          107\n8   99.329797        762          127\n9   99.694477        318           53\n10  99.656749        396           66\n11  99.270491        834          139\n12  99.618997        402           67\n13  99.501223        498           83\n14  99.698423        324           54\n15  99.705888        324           54\n16  99.303138        792          132\n17  99.693799        324           54\n18  99.718167        324           54\n19  99.711570        324           54",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reward</th>\n      <th>timesteps</th>\n      <th>num_actions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>99.303372</td>\n      <td>756</td>\n      <td>126</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>99.681198</td>\n      <td>318</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>99.551412</td>\n      <td>426</td>\n      <td>71</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.848039</td>\n      <td>1002</td>\n      <td>167</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>99.714342</td>\n      <td>324</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-0.874360</td>\n      <td>1002</td>\n      <td>167</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>99.463053</td>\n      <td>618</td>\n      <td>103</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>99.407967</td>\n      <td>642</td>\n      <td>107</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>99.329797</td>\n      <td>762</td>\n      <td>127</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>99.694477</td>\n      <td>318</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>99.656749</td>\n      <td>396</td>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>99.270491</td>\n      <td>834</td>\n      <td>139</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>99.618997</td>\n      <td>402</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>99.501223</td>\n      <td>498</td>\n      <td>83</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>99.698423</td>\n      <td>324</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>99.705888</td>\n      <td>324</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>99.303138</td>\n      <td>792</td>\n      <td>132</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>99.693799</td>\n      <td>324</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>99.718167</td>\n      <td>324</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>99.711570</td>\n      <td>324</td>\n      <td>54</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = habit_policy(daifa)\n",
    "res = test_policy(env, p, observation_max, observation_min, observation_noise_stddev, 20, daifa.agent_time_ratio)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x288465d00>,\n <matplotlib.lines.Line2D at 0x28f96f370>]"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs_pos = np.vstack([np.linspace(-1, 1, 100), np.zeros(100)]).T\n",
    "\n",
    "latent_mean, _ , _ = daifa.model_vae.encoder(obs_pos)\n",
    "\n",
    "utils = daifa.prior_model(latent_mean)\n",
    "# print(utils)\n",
    "\n",
    "plt.plot(obs_pos, utils)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x289938d00>,\n <matplotlib.lines.Line2D at 0x289938100>]"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAhs0lEQVR4nO3deXhU9dnG8e+TBFRQkCVugIKK1lj3yCqC4gJuiKAFARUXDIvVttpq3Wr1dalvq28lgAiIO6KyqVFwAQQBJVgQAdGICxGXiAtqVQSe948zqdOQZQIzObPcn+vK5cw5Z2ZuJ+PtyZnf+R1zd0REJPVlhR1ARETiQ4UuIpImVOgiImlChS4ikiZU6CIiaSInrBdu3ry5t27dOqyXFxFJSUuWLPnC3XMrWxdaobdu3Zri4uKwXl5EJCWZ2YdVrdMhFxGRNKFCFxFJEyp0EZE0oUIXEUkTKnQRkTShQhcRSRMqdBGRNBFToZtZDzNbbWYlZnZ1Jesbm9nTZrbMzFaY2eD4R434rgye/zN8vz5hLyGZ7aanV3DT0yvCjiFSazUWupllA4VATyAP6G9meRU2Gw6sdPfDgG7A382sfpyzBt6fC6+Nhn8eAQvugU0/JeRlJHOtXLeBles2hB1DpNZi2UNvB5S4+xp33whMAnpV2MaBXczMgJ2BL4FNcU1a7pC+MHQBtGoHs66DwnawcjroQh0ikuFiKfQWwNqo+6WRZdFGAgcB64DlwOXuviUuCSuz20Ew8EkY+BTUawCTz4P7T4GP30jYS4qIJLtYCt0qWVZxd/hkYCmwF3A4MNLMGm31RGZDzKzYzIrLyspqGbUS+58Al86D0+6CL96B+46DKZfChnXb/9wiIikmlkIvBVpF3W9JsCcebTAwxQMlwPvAryo+kbuPdfd8d8/Pza10srDay86B/Avht/+CzlfAiilwz1Ew53bY+O/4vIaISAqIpdAXA23NrE3ki85+wIwK23wEdAcws92BA4E18Qxaox0bwYk3wYjF0PYkmHMbjMyHZY/DlsQd/RERSRY1Frq7bwJGADOBVcBkd19hZgVmVhDZ7Gagk5ktB14C/uTuXyQqdLWatIZzHoDBz0HDXJg6BMafAGtfDyWOiEhdiWk+dHcvAooqLBsTdXsdcFJ8o22nfTrBJbPhzUnw0l9h/Inw677BXnzjlmGnExGJu/Q+UzQrCw4/F0YUw7F/hLefgXvyYfatsPH7sNOJiMRVehd6uR12huOvDY6v/+oUmHtHUOxvTtb4dRFJG5lR6OV23Rv6ToDBz8POu8GUS4JDMaVLwk4mIrLdMqvQy+3TMTi+3qsQvvoQxh0PUwtgwydhJxMR2WaZWegQHF8/YiBctiQYv/7WU8Ewx3n/gJ9/DDudiEitZW6hlysfvz5sEbTpCi/dBKPaw9vP6vi6iKQUFXq5ZvtB/0dh0FTI2REmnQsP9YbP3w47mYhITFToFe13PBTMhx53wLo3YHQneO5q+OHrsJOJiFRLhV6Z7HrQoQAuewOOPA9eGwP3HAlLJsKWzWGnExGplAq9Og2bw+l3w6WvQPMD4enLYWw3+GhR2MlERLaiQo/FnofC4CLoMx7+vR4mnAxThsC3n4adTETkP1TosTILrpY0YjF0uRJWTA2m6Z1/N2zaGHY6EREVeq3Vbwjdr4fhr0GbY+HFG2F0R3j3xbCTiUiGU6Fvq6b7Qv/HYMCTwXj1R/rApAHw1QdhJxORDKVC315tT4RhC+GEv8B7s6GwPcy+DX7+IexkIpJhVOjxkLMDHPO7yGyOp8Lc26GwHax6RmebikidUaHHU+MWwWyO5z8D9RrC4wPg4T7wRUnYyUQkA6jQE6FNFyiYBz1uh9LFwZemL96ki2qISEKp0BMlux50GBpcLengs2D+P2BkO1g5XYdhRCQhVOiJtsvucNa9wUU1dtoVJp8HD5+lwzAiEncq9LqyT0cYMhd6/g1Ki2FUBx2GEZG4UqHXpewcaH9pcFGNQ/oGh2EK22s0jIjEhQo9DDvvBr3HwODnYIddgtEwj5wNX64JO5mIpLCYCt3MepjZajMrMbOrK1l/lZktjfy8ZWabzaxp/OOmmX06BTM5nnwrfLQQCjvAnNt1CTwR2SY1FrqZZQOFQE8gD+hvZnnR27j7ne5+uLsfDlwDzHX3LxOQN/1k14OOw385KWnObcHxdc0NIyK1FMseejugxN3XuPtGYBLQq5rt+wOPxSNcRmm0F5x9P5w3HbJygrlhHh8E35SGnUxEUkQshd4CWBt1vzSybCtm1gDoATxVxfohZlZsZsVlZWW1zZoZ9u0GQ1+F46+Hd2cFY9cX3AObfw47mYgkuVgK3SpZVtWQjNOBV6s63OLuY909393zc3NzY82YeXJ2gGOvjEzR2wVmXQf3dtWVkkSkWrEUeinQKup+S2BdFdv2Q4db4qdJa+g/Cfo9Cj9tCK6UNH04fL8+7GQikoRiKfTFQFsza2Nm9QlKe0bFjcysMdAVmB7fiBnOLPiydPhr0PlyWDYJRubDGw/Cli1hpxORJFJjobv7JmAEMBNYBUx29xVmVmBmBVGb9gZmubtOfUyE+g3hxL/CpfMg90CYcRlMPAU+Wxl2MhFJEjGNQ3f3Inc/wN33c/f/iSwb4+5joraZ6O79EhVUInbPgwuKoFchlK2Ge7vACzdqCgER0ZmiKSkrC44YGMzkeGg/ePXu4KSkd2aGnUxEQqRCT2UNm8GZhcEee72d4NFzgrHrG6r6zlpE0pkKPR207gwF8/977Ppr98KWzWEnE5E6pEJPFzn1g7HrwxZCq6PhuT/CuO6wbmnYyUSkjqjQ003TfWHgFOgzHr75GO47DmZeCz99F3YyEUkwFXo6MgvmWx+xGI66ABaODOZdX/1c2MlEJIFU6Olsp13htLvgwlmwYyN4rF/kS9NPwk4mIgmgQs8Ee7cPLn/X/YbgS9PCdrB4nM40FUkzKvRMkVMfuvwBhi6AFkfCs38I5obRmaYiaUOFnmma7QeDpkHvsfDle8GZpi/9VVdJEkkDKvRMZAaH/QaGL4ZDzoF5f4fRneD9V8JOJiLbQYWeyRo2g96jgz123wwPnA7ThsO/dfVAkVSkQhfY7zgYuhA6XwHLHgu+NF3+JHhV1zERkWSkQpdA/QZw4k0wZA40bglPXQSP/ga+XlvjQ0UkOajQ5b/teShc/BKcfCt8MA9GddC8MCIpQoUuW8vKho7DYdgiaNU+mBdmwsnw+aqwk4lINVToUrUm+8DAp4IhjuvfgzFdYPZtsOmnsJOJSCVU6FK98iGOIxbDwWfC3Nvh3mNh7ethJxORClToEpuGzaHPODj3iWDmxvEnQdEfNYujSBJRoUvtHHASDF8E7S6B18fCqI5Q8mLYqUQEFbpsix12gVPuhAufh3o7wsN9YOpQnZAkEjIVumy7vTvApfOgy5WwfHJwQtKKaWGnEslYKnTZPvV2hO7XwyWzodFe8MT58PhA+PazsJOJZJyYCt3MepjZajMrMbOrq9imm5ktNbMVZjY3vjEl6e15KFz8MpxwE7z7QrC3vvRRTR8gUodqLHQzywYKgZ5AHtDfzPIqbLMrMAo4w90PBs6Of1RJetk5cMwVUPAq7HYQTBsaHF//+qOwk4lkhFj20NsBJe6+xt03ApOAXhW2OReY4u4fAbj75/GNKSml+f5wQRH0vBM+WhSMhNEVkkQSLpZCbwFEz9BUGlkW7QCgiZnNMbMlZnZeZU9kZkPMrNjMisvKyrYtsaSGrCxoPwSGLYSWRwdXSHrgtOCMUxFJiFgK3SpZVvHAaA5wFHAqcDJwvZkdsNWD3Me6e7675+fm5tY6rKSgJvvAoKlwxkj49C0Y3RkWFmqyL5EEiKXQS4FWUfdbAusq2eZ5d//e3b8AXgEOi09ESXlmcOSg4ISkfbvCzD/DhB5Q9k7YyUTSSiyFvhhoa2ZtzKw+0A+YUWGb6UAXM8sxswZAe0BT88l/a7QX9J8EZ90H69+FMcfA/Lth86awk4mkhRoL3d03ASOAmQQlPdndV5hZgZkVRLZZBTwPvAm8Doxz97cSF1tSlhkceg4Mfz2YRuDFG2H8ifDZyrCTiaS8nFg2cvcioKjCsjEV7t8J3Bm/aJLWdt4NznkIVkyFoithbFfo+qfgMnjZMX0sRaQCnSkq4TGDX58V7K3/6lR4+WYY1x0+WxF2MpGUpEKX8DVsDmdPhHMehA0fw71dYe6dsPnnsJOJpBQVuiSPvF4w7DXIOwNm36K9dZFaUqFLcmnYDPpOCI6vb1invXWRWlChS3LKOyPYWz/o9Ki9dY2EEamOCl2SV8NmcPb9wbH1bz4OrmX6yv9q3LpIFVTokvzyesHw134ZCTP+RPj87bBTiSQdFbqkhobN4ZwHgtEwX38Y7K3Pv1tzwohEUaFLajm4d3Bsvfws0wk94IuSsFOJJAUVuqSenXODUTB9xsMX78CYzrBwlOZbl4ynQpfUZAaH9A2Ore/bDWZeE8y3/uX7YScTCY0KXVLbLnsEMzj2GgWfLg/mW188XtcylYykQpfUZwZHDAiujtSqHTz7e3ioN3xTGnYykTqlQpf00bhlcHWk0+6Cta8H1zJd+qj21iVjqNAlvZhB/oUw9FXY/dcwbShMGgDf6brlkv5U6JKemraBC56Fk2+FkhehsD2smBZ2KpGEUqFL+srKgo7DoWBecLHqJ86Hpy6GH74KO5lIQqjQJf3lHggXvQDHXRtcIWlUR3j3xbBTicSdCl0yQ3Y96PpHuPgl2HFXeKQPPPM7+Om7sJOJxI0KXTLLXofDkDnQ6TIovj84y/SjRWGnEokLFbpknno7wkm3BF+a+pZgPpgXboRNP4WdTGS7qNAlc7XuDEMXwJGD4NW7YexxwdmmIilKhS6ZbYdd4Ix7oP/j8H0ZjD2OXt89jrmm5ZXUE1Ohm1kPM1ttZiVmdnUl67uZ2TdmtjTyc0P8o4ok0IE9YNgiOLAn5357P39ZfxV8uSbsVCK1UmOhm1k2UAj0BPKA/maWV8mm89z98MjPX+OcUyTxGjaDcx7knsZX0WrThzD6GFgyUVMHSMqIZQ+9HVDi7mvcfSMwCeiV2FgiITFjfoPuXJU7BloeBU9fDo/+Br79LOxkIjWKpdBbAGuj7pdGllXU0cyWmdlzZnZwZU9kZkPMrNjMisvKyrYhrkjdWJ+dC4OmQ4/b4f25MKoDrJwRdiyRasVS6FbJsop/g74B7OPuhwH3ANMqeyJ3H+vu+e6en5ubW6ugInUuKws6DIVLX4FdW8HkQTBtGPy4IexkIpWKpdBLgVZR91sC66I3cPcN7v5d5HYRUM/MmsctpUiYcg+Ei16EY6+CZY8FF9H44NWwU4lsJZZCXwy0NbM2ZlYf6Af819+eZraHmVnkdrvI866Pd1iR0OTUh+OvgwtnQnYOTDwVZl2vk5EkqdRY6O6+CRgBzARWAZPdfYWZFZhZQWSzvsBbZrYM+CfQz11DAyQNtWoHl86Doy6ABf+E+46Hz1aEnUoEgJxYNoocRimqsGxM1O2RwMj4RhNJUjvsDKffDQf0gBkjYGw36H4DdBgeHHcXCYk+fSLbqvxkpP1PhFnXwYNnwNdra36cSIKo0EW2R8Pm0O8ROGMkrPtX8IXpm0+EnUoylApdZHuZBRN8FcyH3X4FUy6GJy/UlZGkzqnQReKlaRu4oCgYDbNyerC3vmZu2Kkkg6jQReIpOycYr37RC1CvQXBcfea18POPYSeTDKBCF0mEFkcGZ5gefTEsHKnhjVInVOgiiVK/AZz6dzj3ichc691gwT2wZUvYySRNqdBFEu2Ak2DYwl+GNz7UC775OOxUkoZU6CJ1oXx44+n/B6XFMLojvDUl7FSSZlToInXFLJgyoGA+NGsLTw6GKZdq9kaJGxW6SF1rtl8wyVfXq2H5ZBjTGT5cGHYqSQMqdJEwZOfAcdcExW5ZMPEUeOlm2Pxz2MkkhanQRcLUql1wCOawc2He/8L4k+CLkrBTSYpSoYuEbYdd4MxCOOdB+Op9uLcLFN+vi1NLranQRZJFXi8YuiDYa3/mCpg0AL7/IuxUkkJU6CLJpNFeMHAqnHwblLwAozvBuy+GnUpShApdJNlkZUHHYXDJbGjQDB7pA0V/hJ9/CDuZJDkVukiy2uPXQam3Hwqv3wtjj4NPl4edSpKYCl0kmdXbEXreDgOfgh++DCb5WjBS88FIpVToIqlg/xNgaPl8MNfCw71hw7qwU0mSUaGLpIqGzX6ZD2bt68EXpiunh51KkogKXSSVlM8Hc+k8aNIaJp8H04fDT9+FnUySQEyFbmY9zGy1mZWY2dXVbHe0mW02s77xiygiW2m+f3BVpC5/gH89EpyMVLok7FQSshoL3cyygUKgJ5AH9DezvCq2uwOYGe+QIlKJ7HrQ/Qa44NlgDpjxJ8LcO2HL5rCTSUhi2UNvB5S4+xp33whMAnpVst1lwFPA53HMJyI1ad05mA/m4N4w+xa4/xT46sOwU0kIYin0FsDaqPulkWX/YWYtgN7AmPhFE5GY7bQr9B0PZ90Hn6+EMcfAm5PDTiV1LJZCt0qWVZw16G7gT+5e7d96ZjbEzIrNrLisrCzGiCISs0PPCfbWd8uDKZfAkxfBD1+HnUrqSCyFXgq0irrfEqg4ADYfmGRmHwB9gVFmdmbFJ3L3se6e7+75ubm525ZYRKrXZJ/guPpx18GKqcHe+gevhp1K6kAshb4YaGtmbcysPtAPmBG9gbu3cffW7t4aeBIY5u7T4h1WRGKUnQNdr4KLZkFWDkw8FV68SRfQSHM1Frq7bwJGEIxeWQVMdvcVZlZgZgWJDigi26FlfnAI5ogBMP8fwUgYXUAjbeXEspG7FwFFFZZV+gWou1+w/bFEJG522Bl6FULbk2DGb4Mx6z1ugyPPD05UkrShM0VFMkX5BTRa5sPTl8PjA+H79WGnkjhSoYtkksYtYNB0OOkWeHdWMB9MyUthp5I4UaGLZJqsLOh0GVzycjB+/eGz4Plr4Ocfw04m20mFLpKp9jgEhsyBdkNg0ahgrvXPVoSdSraDCl0kk9XbCU65EwY8Cd+XBVdFWjhKF9BIUSp0EYG2JwZfmO53PMy8JjgMs+GTsFNJLanQRSSwcy70fwxOuws+WhR8Ybrq6bBTSS2o0EXkF2aQfyEUzINd9w6GNuoCGilDhS4iW2veNriAxjG/Dy6gMeYYWLs47FRSAxW6iFQupz6ccCMMLgoumjHhZJhzO2zeFHYyqYIKXUSqt08nGDofDukLc26D+3vAl2vCTiWVUKGLSM12bAxnjYU+4+GLd2BMF3jjIfCKl0aQMKnQRSR2h/QNhjfudQTMGKH5YJKMCl1EaqdxSzhvBpx4M7wzE0Z3hHdfCDuVoEIXkW2RlQWdfwtDZsNOTeGRvvDsH2Djv8NOltFU6CKy7crng+kwHBaPg3uPhY/fCDtVxlKhi8j2qbcj9LgVzpsOG78Pror0yp0a3hgCFbqIxMe+3WDYguBCGi/fAhNP0fDGOqZCF5H42akJ9J0AZ42Dz9+G0cfAkoka3lhHVOgiEn+Hnh3srbc8Krjc3WP94LvPw06V9lToIpIYjVsGl7s7+VZ4bzaM6girngk7VVpToYtI4mRlQcfhcOlcaLQXPD4Apg2DHzeEnSwtqdBFJPF2Owgufgm6XAnLHoPRneGD+WGnSjsxFbqZ9TCz1WZWYmZXV7K+l5m9aWZLzazYzI6Jf1QRSWk59aH79XDhTMjOgYmnwcxrdXHqOKqx0M0sGygEegJ5QH8zy6uw2UvAYe5+OHAhMC7OOUUkXbRqBwXzIX8wLBwJY7vCuqVhp0oLseyhtwNK3H2Nu28EJgG9ojdw9+/c/zMuqSGgMUoiUrX6DYNL3Q14Cn78BsZ1h7l/08lI2ymWQm8BrI26XxpZ9l/MrLeZvQ08S7CXvhUzGxI5JFNcVla2LXlFJJ20PSGYvTHvTJj9P8FZpmWrw06VsmIpdKtk2VZ74O4+1d1/BZwJ3FzZE7n7WHfPd/f83NzcWgUVkTTVoCn0HQ9nT4SvPgjmg1lYCFu2hJ0s5cRS6KVAq6j7LYF1VW3s7q8A+5lZ8+3MJiKZ5ODeMGxRMIXAzD/DA6fBl++HnSqlxFLoi4G2ZtbGzOoD/YAZ0RuY2f5mZpHbRwL1Ac16LyK1s8vu0H8S9CqET5cHwxsXj9fUATGqsdDdfRMwApgJrAImu/sKMysws4LIZn2At8xsKcGImN9EfUkqIhI7MzhiYHBsvdXR8Ozv4aHe8E1p2MmSXk4sG7l7EVBUYdmYqNt3AHfEN5qIZLRdW8GgaVA8HmbdEEwd0OM2OHxAUPqyFZ0pKiLJywyOvhiGvgp7HArTh8Oj58CGKr/Gy2gqdBFJfk3bwPlPQ4874P15UNgBlj6qY+sVqNBFJDVkZUGHgmBvffeDYdpQePQ32luPokIXkdTSbD+44FnocTu8/0qwt/6vh7W3jgpdRFJRVhZ0GBo5tv7r4Nj6I33h67U1PzaNqdBFJHU12w/OfwZ63gkfLgxGwhRPyNi9dRW6iKS2rCxoPyS45F2LI+CZ38EDp2fkBapV6CKSHpq0hvNmwOn/B58sg1GdYMFI2LI57GR1RoUuIunDDI66IDInTFeYdS2MPwk+Wxl2sjqhQheR9NO4RTAnTJ/x8NX7wQyOs2+DTT+FnSyhVOgikp7M4JC+MHxxMJPj3NuDYv/otbCTJYwKXUTSW8Nm0Oc+OPcJ2Pg9TDgZnr0SftwQdrK4U6GLSGY44KTg2Hr7Alg8Dgrbw9vPhp0qrlToIpI5dtgZet4OF78IOzWBSefC4wPTZvoAFbqIZJ6W+XDpXOh+I7z7AoxsB6/fl/JDHFXoIpKZsutBl9/DsIVBwRddCeNOgE/eDDvZNlOhi0hma7ovDJoaDHH8Zi2M7QbP/xl++jbsZLWmQhcRKR/iOGIxHHU+LBoVHIZZOT2l5oVRoYuIlNupCZx2F1z0AjRoBpPPg0fOTpl5YVToIiIVtToahsyBk2+DjxYFc67Pvg1+/iHsZNVSoYuIVCY7BzoOCw7DHHRacKbpqA7wzsywk1VJhS4iUp1Ge0LfCXDedMjeIbhI9aP94Mv3w062FRW6iEgs9u0GBfPhxL9GLn3XHl6+BTb+O+xk/xFToZtZDzNbbWYlZnZ1JesHmNmbkZ8FZnZY/KOKiIQspz50vhwuK4a8M+CVO2Hk0fDWlKQYDVNjoZtZNlAI9ATygP5mlldhs/eBru5+KHAzMDbeQUVEkkajvaDPOBj8XDAy5snBMPE0+HR5qLFi2UNvB5S4+xp33whMAnpFb+DuC9z9q8jdRUDL+MYUEUlC+3QKphA47S74fGUwPe/Tl8N3ZaHEiaXQWwDRl9IujSyrykXAc5WtMLMhZlZsZsVlZeH8C4uIxFVWNuRfCL99A9oNgX89DPccCQvuqfMLasRS6FbJskoPFpnZcQSF/qfK1rv7WHfPd/f83Nzc2FOKiCS7nZpAzztg6ELYuwPMui744rQOzzaNpdBLgVZR91sCW801aWaHAuOAXu6+Pj7xRERSTO4BMOAJGPAU5OwYnG16f0/4eEnCXzqWQl8MtDWzNmZWH+gHzIjewMz2BqYAg9z9nfjHFBFJMW1PCIY5nnY3rC+B+46HJy+Erz5I2EvWWOjuvgkYAcwEVgGT3X2FmRWYWUFksxuAZsAoM1tqZsUJSywikiqycyB/MFz2BnS5Et4uCoY5LhiZkJfLiWUjdy8CiiosGxN1+2Lg4vhGEwlH3l6Nwo4g6WbHRtD9+uDL09m3QtM2CXkZ85AGw+fn53txsXbkRURqw8yWuHt+Zet06r+ISJpQoYuIpAkVuohImlChi4ikCRW6iEiaUKGLiKQJFbqISJpQoYuIpInQTiwyszLgw218eHPgizjGiZdkzQXJm025ake5aicdc+3j7pVOVxtaoW8PMyuu6kypMCVrLkjebMpVO8pVO5mWS4dcRETShApdRCRNpGqhJ+tFqJM1FyRvNuWqHeWqnYzKlZLH0EVEZGupuocuIiIVqNBFRNJE0ha6mZ1tZivMbIuZVTm8x8x6mNlqMysxs6ujljc1sxfM7N3IP5vEKVeNz2tmB0YuxVf+s8HMrois+4uZfRy17pS6yhXZ7gMzW17xUoEhv1+tzGy2ma2K/M4vj1oX1/erqs9L1Hozs39G1r9pZkfG+tgE5xoQyfOmmS0ws8Oi1lX6O62jXN3M7Juo388NsT42wbmuisr0lpltNrOmkXWJfL8mmNnnZvZWFesT+/ly96T8AQ4CDgTmAPlVbJMNvAfsC9QHlgF5kXV/A66O3L4auCNOuWr1vJGMnxKcDADwF+DKBLxfMeUCPgCab++/VzxzAXsCR0Zu7wK8E/V7jNv7Vd3nJWqbU4DnAAM6AK/F+tgE5+oENInc7lmeq7rfaR3l6gY8sy2PTWSuCtufDryc6Pcr8tzHAkcCb1WxPqGfr6TdQ3f3Ve6+uobN2gEl7r7G3TcCk4BekXW9gAcitx8AzoxTtNo+b3fgPXff1rNiY7W9/76hvV/u/om7vxG5/S3BxchbxOn1o1X3eYnO+6AHFgG7mtmeMT42YbncfYG7fxW5uwhoGafX3q5cCXpsvJ+7P/BYnF67Wu7+CvBlNZsk9POVtIUeoxbA2qj7pfxSBLu7+ycQFAawW5xes7bP24+tP0wjIn9uTYjXoY1a5HJglpktMbMh2/D4ROUCwMxaA0cAr0Utjtf7Vd3npaZtYnlsInNFu4hgL69cVb/TusrV0cyWmdlzZnZwLR+byFyYWQOgB/BU1OJEvV+xSOjnK2e7om0nM3sR2KOSVde6+/RYnqKSZds9DrO6XLV8nvrAGcA1UYtHAzcT5LwZ+DtwYR3m6uzu68xsN+AFM3s7slexzeL4fu1M8B/eFe6+IbJ4m9+vyl6ikmUVPy9VbZOQz1oNr7n1hmbHERT6MVGL4/47rUWuNwgOJ34X+X5jGtA2xscmMle504FX3T16rzlR71csEvr5CrXQ3f2E7XyKUqBV1P2WwLrI7c/MbE93/yTyJ83n8chlZrV53p7AG+7+WdRz/+e2md0HPFOXudx9XeSfn5vZVII/9V4h5PfLzOoRlPkj7j4l6rm3+f2qRHWfl5q2qR/DYxOZCzM7FBgH9HT39eXLq/mdJjxX1P94cfciMxtlZs1jeWwic0XZ6i/kBL5fsUjo5yvVD7ksBtqaWZvI3nA/YEZk3Qzg/Mjt84FY9vhjUZvn3erYXaTUyvUGKv02PBG5zKyhme1Sfhs4Ker1Q3u/zMyA8cAqd/9HhXXxfL+q+7xE5z0vMhqhA/BN5FBRLI9NWC4z2xuYAgxy93eillf3O62LXHtEfn+YWTuCTlkfy2MTmSuSpzHQlajPXILfr1gk9vOViG964/FD8B9vKfAT8BkwM7J8L6AoartTCEZFvEdwqKZ8eTPgJeDdyD+bxilXpc9bSa4GBB/sxhUe/xCwHHgz8gvbs65yEXyDvizysyJZ3i+CwwceeU+WRn5OScT7VdnnBSgACiK3DSiMrF9O1Airqj5rcXqfaso1Dvgq6v0prul3Wke5RkRedxnBl7WdkuH9ity/AJhU4XGJfr8eAz4Bfibor4vq8vOlU/9FRNJEqh9yERGRCBW6iEiaUKGLiKQJFbqISJpQoYuIpAkVuohImlChi4ikif8HQVjFMY+XB7cAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vel_pos = np.vstack([np.zeros(100), np.linspace(-1, 1, 100)]).T\n",
    "\n",
    "latent_mean, _ , _ = daifa.model_vae.encoder(vel_pos)\n",
    "\n",
    "utils = daifa.prior_model(latent_mean)\n",
    "# print(utils)\n",
    "\n",
    "plt.plot(vel_pos, utils)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x288760d00>,\n <matplotlib.lines.Line2D at 0x288760d90>]"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs_pos = np.vstack([np.linspace(-1, 1, 100), np.zeros(100)]).T\n",
    "\n",
    "latent_mean, _ , _ = daifa.model_vae.encoder(obs_pos)\n",
    "\n",
    "# utils = daifa.habit_action_model.actor_model(latent_mean)\n",
    "utils = daifa.select_fast_thinking_policy(latent_mean)\n",
    "# print(utils)\n",
    "\n",
    "plt.plot(obs_pos, utils)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x28b224a90>,\n <matplotlib.lines.Line2D at 0x28b224b80>]"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vel_pos = np.vstack([np.zeros(100), np.linspace(-1, 1, 100)]).T\n",
    "\n",
    "latent_mean, _ , _ = daifa.model_vae.encoder(vel_pos)\n",
    "\n",
    "# utils = daifa.habit_action_model.actor_model(latent_mean)\n",
    "utils = daifa.select_fast_thinking_policy(latent_mean)\n",
    "# print(utils)\n",
    "\n",
    "plt.plot(vel_pos, utils)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "res = test_policy(env, p, observation_max, observation_min, observation_noise_stddev, 5, daifa.agent_time_ratio, show_env=True)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "[-0.5958538  0.       ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "24 39\n",
      "Success in episode 1 at time step 229 with reward 98.42801505676881\n",
      "Episode 2\n",
      "[-0.45815662  0.        ]\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "fast thinking\n",
      "training on full data\n",
      "8 29\n",
      "Success in episode 2 at time step 171 with reward 98.23162916257424\n",
      "Episode 3\n",
      "[-0.572035  0.      ]\n",
      "fast thinking\n"
     ]
    }
   ],
   "source": [
    "# train the agent on the env\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "daifa, results_four = train_single_agent(env, daifa, observation_max, observation_min, observation_noise_stddev, num_episodes=50, render_env=False, flip_dynamics=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p = habit_policy(daifa)\n",
    "res = test_policy(env, p, observation_max, observation_min, observation_noise_stddev, 20, daifa.agent_time_ratio)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train the agent on the env\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "daifa, results_four = train_single_agent(env, daifa, observation_max, observation_min, observation_noise_stddev, num_episodes=50, render_env=False, flip_dynamics=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p = habit_policy(daifa)\n",
    "res = test_policy(env, p, observation_max, observation_min, observation_noise_stddev, 20, daifa.agent_time_ratio)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p = habit_policy(daifa)\n",
    "res = test_policy(env, p, observation_max, observation_min, observation_noise_stddev, 4, daifa.agent_time_ratio, show_env=False)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_results = pd.concat([results_one, results_two, results_three, results_four])\n",
    "full_results.reset_index(drop=True)\n",
    "full_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "T = np.arange(len(full_results))\n",
    "plt.plot(T, full_results.percent_use_fast_thinking)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(T, full_results.success)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(T, full_results.total_reward)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(T, full_results.sim_steps)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}