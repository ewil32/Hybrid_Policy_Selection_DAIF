{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# The Habitual DDPG Network\n",
    "\n",
    "Habitual network\n",
    "\n",
    "Assuming generative model is perfect, then action selected would always be the action that maximises chance of observing prior preferences. Hence habitual network can be trained to output maximally rewarding actions, as these actions are the free energy minimising actions.\n",
    "\n",
    "Also has a nice interpretation as long as the generative models keep training. Eventually the generative model is less sure about old things. Why people eventually revisit old states they were previously certain about.\n",
    "\n",
    "As far as an agent knows, if observations are confirming perfectly to expectations then it has a perfect world model. So why would it change it? Itâ€™s only when an uncertain observation comes in that the agent needs to reconsider whether or not it has the best model of the world.\n",
    "\n",
    "\n",
    "I think this network should be performing policy gradient method but instead of minimising the discounted reward sequence it should minimise the discounted external EFE/FEEF component sequence. That way in the end the end the fast and slow thinking methods should be converging as the world model continues to improve\n",
    "\n",
    "\n",
    "What is this network trying to learn?\n",
    "- This network is trying to learn the state action mapping that maximises the probability of being in the preferred states\n",
    "- It is also trying to learn to output actions that minimise the extrinsic part of the EFE/FEEF\n",
    "\n",
    "\n",
    "What does this network take as input?\n",
    "- Current state\n",
    "- Maybe sequence of previous states and actions\n",
    "\n",
    "What should this network output?\n",
    "- The action that leads to the next state that maximally achieves the prior preferences\n",
    "\n",
    "How should this network learn?\n",
    "- It should learn by outputting\n",
    "\n",
    "\n",
    "Okay so new idea! DDPG seems pretty good so far. How about we have the Q function take latent states as input and use the VAEs good latent features as input. Then we'll have\n",
    "- Q(o, a)\n",
    "- p(s|o) and p(o|s)\n",
    "- p(s'|s, a)\n",
    "- V(o) or U(o)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ethan/miniconda3/envs/tf_daif_car_race/lib/python3.8/site-packages/tensorflow_probability/python/__init__.py:61: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if (distutils.version.LooseVersion(tf.__version__) <\n"
     ]
    }
   ],
   "source": [
    "from util import random_observation_sequence, transform_observations\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "\n",
    "from ddpg import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hide GPU from visible devices\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of State Space ->  2\n",
      "Size of Action Space ->  1\n",
      "Max Value of Action ->  1.0\n",
      "Min Value of Action ->  -1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ethan/python_repos/gym/gym/core.py:330: DeprecationWarning: \u001B[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001B[0m\n",
      "  deprecation(\n",
      "/Users/Ethan/python_repos/gym/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001B[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001B[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "num_states = env.observation_space.shape[0]\n",
    "print(\"Size of State Space ->  {}\".format(num_states))\n",
    "num_actions = env.action_space.shape[0]\n",
    "print(\"Size of Action Space ->  {}\".format(num_actions))\n",
    "\n",
    "upper_bound = env.action_space.high[0]\n",
    "lower_bound = env.action_space.low[0]\n",
    "\n",
    "print(\"Max Value of Action ->  {}\".format(upper_bound))\n",
    "print(\"Min Value of Action ->  {}\".format(lower_bound))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "actor_model = get_actor(2, 1)\n",
    "critic_model = get_critic(2, 1)\n",
    "\n",
    "target_actor = get_actor(2, 1)\n",
    "target_critic = get_critic(2, 1)\n",
    "\n",
    "# Making the weights equal initially\n",
    "target_actor.set_weights(actor_model.get_weights())\n",
    "target_critic.set_weights(critic_model.get_weights())\n",
    "\n",
    "# Learning rate for actor-critic models\n",
    "critic_lr = 0.0001\n",
    "actor_lr = 0.00005\n",
    "\n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 100\n",
    "# Discount factor for future rewards\n",
    "gamma = 0.99\n",
    "# Used to update target networks\n",
    "tau = 0.005\n",
    "\n",
    "# buffer = Buffer(50000, 64, 0.99, 2, 1, critic_optimizer, actor_optimizer)\n",
    "\n",
    "ddpg = BasicDDPG(actor_model, critic_model, target_actor, target_critic, tau, critic_optimizer=critic_optimizer, actor_optimizer=actor_optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-33.04776346421558\n",
      "1.0 0.99998903\n",
      "74.11115526533595\n",
      "1.0 0.9805884\n",
      "-33.21363154655761\n",
      "1.0 0.99988675\n",
      "84.7942343750702\n",
      "1.0 0.9774433\n",
      "-35.26668935817751\n",
      "1.0 0.9674082\n",
      "-33.430041847754104\n",
      "1.0 0.99990267\n",
      "79.92642768907245\n",
      "1.0 0.9904716\n",
      "75.85511048259082\n",
      "1.0 0.97927713\n",
      "73.4471165287704\n",
      "1.0 0.9999975\n",
      "-32.6958885898863\n",
      "1.0 0.99999976\n",
      "-33.23100233740506\n",
      "1.0 0.99997145\n",
      "-29.60730057009701\n",
      "1.0 0.99999976\n",
      "74.55052192384022\n",
      "1.0 0.9999251\n",
      "85.72272065091403\n",
      "1.0 0.9999638\n",
      "77.83197901632163\n",
      "1.0 0.99999964\n",
      "92.95478341957659\n",
      "1.0 0.9999687\n",
      "-32.412052358214915\n",
      "1.0 0.99999756\n",
      "69.74323508267804\n",
      "1.0 0.9999967\n",
      "73.0468521197316\n",
      "1.0 0.999998\n",
      "-31.500069501794567\n",
      "1.0 0.99999386\n",
      "88.67837182234491\n",
      "1.0 0.9999961\n",
      "-30.16829582916364\n",
      "1.0 0.99999976\n",
      "91.92049156465663\n",
      "1.0 0.99998665\n",
      "91.64458096920055\n",
      "1.0 0.99999976\n",
      "-36.31846038803997\n",
      "1.0 0.9999909\n",
      "-29.64909740086122\n",
      "1.0 0.99999976\n",
      "83.31622014330962\n",
      "1.0 0.99999976\n",
      "77.24332674685584\n",
      "1.0 0.99999917\n",
      "90.12593465796877\n",
      "1.0 0.99999976\n",
      "-31.69247455211393\n",
      "1.0 0.9999979\n",
      "75.62464113597366\n",
      "0.99999976 -0.01869033\n",
      "-35.923425657225\n",
      "0.99999976 -0.8801673\n",
      "93.67671354112242\n",
      "0.99999976 -0.93785775\n",
      "79.07692261382591\n",
      "0.99999976 -0.9174915\n",
      "-30.659972642990198\n",
      "1.0 -0.9933293\n",
      "70.74029821047897\n",
      "0.99999976 -0.97939557\n",
      "86.88868479780226\n",
      "1.0 -0.9945631\n",
      "-33.512589633899864\n",
      "0.99999976 -0.9968459\n",
      "-38.28595091116302\n",
      "1.0 -0.9836782\n",
      "-38.52919014932606\n",
      "0.99999976 -0.9930083\n",
      "80.87899870874068\n",
      "0.99999976 -0.9984516\n",
      "89.26151224292272\n",
      "1.0 -0.9973431\n",
      "79.08207529350402\n",
      "1.0 -0.98387414\n",
      "79.88200713159677\n",
      "1.0 -0.99788624\n",
      "93.61857114883996\n",
      "0.99999976 -0.9981679\n",
      "76.20699613363689\n",
      "1.0 -0.99897987\n",
      "-34.9266378946052\n",
      "1.0 -0.99938357\n",
      "82.68907081343356\n",
      "1.0 -0.99767\n",
      "-29.704227348897206\n",
      "1.0 -0.9992965\n",
      "77.58552979815295\n",
      "0.99999976 -0.9992015\n"
     ]
    }
   ],
   "source": [
    "t_max = 1000\n",
    "num_episodes = 50\n",
    "\n",
    "min_reward_cutoff = -1000\n",
    "min_reward_set = -0.5\n",
    "\n",
    "reward_increase = 0\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "for i in range(num_episodes):\n",
    "\n",
    "    all_observations = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "\n",
    "    total_reward = 0\n",
    "\n",
    "    o, a, r = random_observation_sequence(env, t_max, epsilon=0.2)\n",
    "    o = transform_observations(o, observation_max, observation_min, [0, 0])\n",
    "    # o = transform_observations(o, observation_max, observation_min, [0.05, 0.05])\n",
    "    # print(o)\n",
    "\n",
    "    for i in range(len(a)):\n",
    "\n",
    "        prev_state = o[i]\n",
    "        state = o[i+1]\n",
    "        action = a[i]\n",
    "        reward = r[i] + reward_increase\n",
    "\n",
    "        # if reward < 0:\n",
    "        #     print(\"yes\")\n",
    "\n",
    "        total_reward += reward\n",
    "\n",
    "        # ddpg.buffer.record((prev_state, action, reward, state))\n",
    "        # # episodic_reward += reward\n",
    "        #\n",
    "        # ddpg.buffer.learn()\n",
    "\n",
    "        ddpg.record((prev_state, action, reward, state))\n",
    "        # episodic_reward += reward\n",
    "\n",
    "        ddpg.train([], [], [], [])\n",
    "\n",
    "    print(total_reward)\n",
    "\n",
    "    acts = ddpg.actor_model((np.random.random(size=(10, 2))*2 - 1))\n",
    "    print(np.max(acts), np.min(acts))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\narray([[ 838.5698 ],\n       [ 532.83673],\n       [ 775.032  ],\n       [ 807.1837 ],\n       [ 796.0321 ],\n       [ 798.75635],\n       [ 484.0688 ],\n       [2515.2515 ],\n       [ 623.87976],\n       [ 579.2384 ]], dtype=float32)>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddpg.critic_model([(np.random.random(size=(10, 2))*2 - 1), (np.random.random(size=(10, 1))*2 - 1)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\narray([[ 0.66189045],\n       [ 0.99999976],\n       [ 0.99999976],\n       [ 0.99999976],\n       [ 0.99956656],\n       [-0.99893314],\n       [-0.9954624 ],\n       [-0.9723895 ],\n       [-0.98310494],\n       [ 1.        ]], dtype=float32)>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddpg.actor_model((np.random.random(size=(10, 2))*2 - 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x17f9ca760>,\n <matplotlib.lines.Line2D at 0x17f9ca820>]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs_pos = np.vstack([np.linspace(-1, 1, 100), np.zeros(100)]).T\n",
    "actions_pred = ddpg.actor_model(obs_pos)\n",
    "\n",
    "actions_pred\n",
    "\n",
    "\n",
    "plt.plot(obs_pos, actions_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]\n",
      " [0.99999976]], shape=(100, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x17fef9ca0>,\n <matplotlib.lines.Line2D at 0x17fef9dc0>]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vel_pos = np.vstack([np.zeros(100), np.linspace(-1, 1, 100)]).T\n",
    "actions_pred = ddpg.actor_model(vel_pos)\n",
    "print(actions_pred)\n",
    "\n",
    "plt.plot(obs_pos, actions_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Can it solve the environment?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ethan/python_repos/gym/gym/core.py:330: DeprecationWarning: \u001B[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001B[0m\n",
      "  deprecation(\n",
      "/Users/Ethan/python_repos/gym/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001B[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001B[0m\n",
      "  deprecation(\n",
      "/Users/Ethan/python_repos/gym/gym/core.py:57: DeprecationWarning: \u001B[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
      "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001B[0m\n",
      "  deprecation(\n",
      "/Users/Ethan/python_repos/gym/gym/utils/passive_env_checker.py:165: UserWarning: \u001B[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001B[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "success\n",
      "93.44974719718894\n",
      "68\n",
      "success\n",
      "93.44670235530067\n",
      "68\n",
      "success\n",
      "93.44526474662442\n",
      "66\n",
      "success\n",
      "93.64958955736816\n",
      "68\n",
      "success\n",
      "93.44829517462155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 10\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "# obs_stddev = [0.05, 0.05]\n",
    "obs_stddev = [0, 0]\n",
    "\n",
    "\n",
    "t_max = 1000\n",
    "\n",
    "for i in range(num_episodes):\n",
    "\n",
    "    env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "    obs = env.reset()\n",
    "\n",
    "    done = False\n",
    "    rewards = []\n",
    "\n",
    "    t = 0\n",
    "    while not done:\n",
    "\n",
    "        env.render()\n",
    "\n",
    "        obs = obs.reshape(1, obs.shape[0])\n",
    "        obs = transform_observations(obs, observation_max, observation_min, obs_stddev)\n",
    "\n",
    "        # print(obs)\n",
    "\n",
    "        # action = act_net(obs) * 10\n",
    "        # action = np.clip(action.numpy(), -1, 1)\n",
    "\n",
    "        action = ddpg.actor_model(obs)\n",
    "        action = action.numpy()\n",
    "\n",
    "        obs, reward, done, info = env.step(action)\n",
    "\n",
    "        # print(obs)\n",
    "\n",
    "        rewards.append(reward)\n",
    "\n",
    "        t += 1\n",
    "\n",
    "        if t == t_max:\n",
    "            done = True\n",
    "\n",
    "    print(t)\n",
    "    if t < t_max:\n",
    "        print(\"success\")\n",
    "    else:\n",
    "        print(\"Failure\")\n",
    "        print(\"max obs\", obs)\n",
    "\n",
    "    print(np.sum(rewards))\n",
    "    # print(rewards)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'act_net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m both \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(both)\n\u001B[1;32m      4\u001B[0m both\n\u001B[0;32m----> 6\u001B[0m both_acts \u001B[38;5;241m=\u001B[39m \u001B[43mact_net\u001B[49m(both)\n\u001B[1;32m      8\u001B[0m both_acts\n",
      "\u001B[0;31mNameError\u001B[0m: name 'act_net' is not defined"
     ]
    }
   ],
   "source": [
    "n = 50\n",
    "both = [[i/n, j/n] for i in range(-1*n, n) for j in range(-1*n, n)]\n",
    "both = np.array(both)\n",
    "both\n",
    "\n",
    "both_acts = act_net(both)\n",
    "\n",
    "both_acts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = 50\n",
    "coords = [[i/n, j/n] for i in range(-1*n, n) for j in range(-1*n, n)]\n",
    "coords = np.array(coords)\n",
    "coords\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = np.arange(-5, 5.1, 0.5)\n",
    "y = np.arange(-5, 5.1, 0.5)\n",
    "X,Y = np.meshgrid(x,y)\n",
    "\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}