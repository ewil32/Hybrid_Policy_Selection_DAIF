{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Run The Agent on Mountain Car"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from vae_recurrent import VAE, create_decoder, create_encoder\n",
    "from transition_gru import TransitionGRU\n",
    "from recurrent_agent import DAIFAgentRecurrent\n",
    "from prior_model import PriorModelBellman"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from util import random_observation_sequence, transform_observations\n",
    "from train_agent import train_single_agent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from identity_vae import IdentityVAE, identity_encoder, identity_decoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What does the agent do?\n",
    "- The agent plans using a policy then executes that policy for 12 simulation timesteps, the first two actions of the policy are executed for 6 steps each\n",
    "\n",
    "What data does it accumulate?\n",
    "- It accumulates 12 observation actions pairs\n",
    "\n",
    "How is it trained?\n",
    "- VAE is trained to reproduce observations using the latent states\n",
    "- Transition is trained by taking previous hidden state and previous latent state and trying to predict the next latent state"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Online learning For all tasks, we initialize all the agents with random weights and learn online only. Training an agent for 150 epochs takes about 3 minutes on a single CPU core (Intel I7-4870HQ). In contrast, previous approaches using active inference [Ueltzh√∂ffer, 2018, Tschantz et al., 2019, 2020] and policy gradient methods (e.g., [Liu et al., 2017]) use (offline) policy replay and typically need hours of GPU-accelerated compute while achieving similar convergence. To our knowledge, this is the first model-based RL method to learn online using neural network representations. This is afforded by the high sample efficiency of the FEEF, which directs exploration towards states that are uncertain for both the encoder and transition models.\n",
    "\n",
    "\n",
    "Why this is true?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Hide GPU from visible devices\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test with no prior model FEEF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.83333333, 0.        ])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = create_encoder(2, 2, [20])\n",
    "dec = create_decoder(2, 2, [20])\n",
    "vae = VAE(enc, dec, 2,  [0, 0], [0.3, 0.3], llik_scaling=1)\n",
    "\n",
    "tran = TransitionGRU(2, 1, 12, 20, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.45, 0]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "# observation_noise_stddev = [0, 0]\n",
    "observation_noise_stddev = [0.05, 0.05]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0,0])  # no noise on prior\n",
    "\n",
    "daifa = DAIFAgentRecurrent(None,\n",
    "                           vae,\n",
    "                           tran,\n",
    "                           scaled_prior_mean,\n",
    "                           prior_stddev,\n",
    "                           planning_horizon=5,\n",
    "                           use_kl_extrinsic=True,\n",
    "                           use_kl_intrinsic=True,\n",
    "                           use_FEEF=True,\n",
    "                           vae_train_epochs=1,\n",
    "                           tran_train_epochs=1,\n",
    "                           show_vae_training=False)\n",
    "\n",
    "scaled_prior_mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ethan/python_repos/gym/gym/core.py:330: DeprecationWarning: \u001B[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001B[0m\n",
      "  deprecation(\n",
      "/Users/Ethan/python_repos/gym/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001B[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001B[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "[-0.42957658  0.        ]\n",
      "[0.58504761 0.42339256]\n",
      "tf.Tensor([0.0950127  0.96160364 0.9598403  0.9530458  0.83590174], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "17/17 [==============================] - 0s 553us/step - loss: 53.4407 - reconstruction_loss: 41.8815 - kl_loss: 5.8700\n",
      "Epoch 2/2\n",
      "17/17 [==============================] - 0s 515us/step - loss: 36.8502 - reconstruction_loss: 32.8406 - kl_loss: 4.8377\n",
      "Success in episode 1 at time step 534\n",
      "Episode 2\n",
      "[-0.5635607  0.       ]\n",
      "[0.66039371 0.39513287]\n",
      "tf.Tensor([ 0.91372454  0.9814795   0.9678287   0.33687112 -0.8263337 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 772us/step - loss: 60.1748 - reconstruction_loss: 54.9759 - kl_loss: 4.0585\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 868us/step - loss: 55.0610 - reconstruction_loss: 50.3528 - kl_loss: 3.9210\n",
      "Success in episode 2 at time step 161\n",
      "Episode 3\n",
      "[-0.43447006  0.        ]\n",
      "[0.52652141 0.86452982]\n",
      "tf.Tensor([0.80554044 0.948588   0.94971925 0.8987086  0.7198782 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "11/11 [==============================] - 0s 549us/step - loss: 70.6794 - reconstruction_loss: 68.5431 - kl_loss: 3.9102\n",
      "Epoch 2/2\n",
      "11/11 [==============================] - 0s 484us/step - loss: 71.2584 - reconstruction_loss: 66.4467 - kl_loss: 3.7843\n",
      "Success in episode 3 at time step 328\n",
      "Episode 4\n",
      "[-0.5383583  0.       ]\n",
      "[0.71447755 0.38639628]\n",
      "tf.Tensor([0.8532745  0.94231576 0.97507674 0.90273106 0.5781229 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "29/29 [==============================] - 0s 510us/step - loss: 51.2229 - reconstruction_loss: 43.1488 - kl_loss: 3.5903\n",
      "Epoch 2/2\n",
      "29/29 [==============================] - 0s 446us/step - loss: 36.5597 - reconstruction_loss: 31.6073 - kl_loss: 4.0069\n",
      "Success in episode 4 at time step 901\n",
      "Episode 5\n",
      "[-0.5061187  0.       ]\n",
      "Epoch 1/2\n",
      "32/32 [==============================] - 0s 450us/step - loss: 9.3139 - reconstruction_loss: 7.4505 - kl_loss: 0.8269\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 0s 455us/step - loss: 6.1763 - reconstruction_loss: 5.1918 - kl_loss: 0.6583\n",
      "No Success\n",
      "Episode 6\n",
      "[-0.5525747  0.       ]\n",
      "[0.66553807 0.11210008]\n",
      "tf.Tensor([0.96178013 0.9230198  0.9278269  0.87355095 0.5671798 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "22/22 [==============================] - 0s 499us/step - loss: 16.9439 - reconstruction_loss: 11.0815 - kl_loss: 3.7489\n",
      "Epoch 2/2\n",
      "22/22 [==============================] - 0s 470us/step - loss: 12.0595 - reconstruction_loss: 7.6007 - kl_loss: 3.6443\n",
      "Success in episode 6 at time step 708\n",
      "Episode 7\n",
      "[-0.50916415  0.        ]\n",
      "[0.34038956 0.74133048]\n",
      "tf.Tensor([ 0.9926748   0.96806467  0.358387   -0.767311   -0.78652555], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "12/12 [==============================] - 0s 523us/step - loss: 20.0230 - reconstruction_loss: 17.9595 - kl_loss: 1.8176\n",
      "Epoch 2/2\n",
      "12/12 [==============================] - 0s 534us/step - loss: 20.1751 - reconstruction_loss: 16.0293 - kl_loss: 2.0261\n",
      "Success in episode 7 at time step 370\n",
      "Episode 8\n",
      "[-0.57437485  0.        ]\n",
      "[0.22500777 0.9421629 ]\n",
      "tf.Tensor([ 0.9971769   0.9938398   0.98012257  0.3592868  -0.2574732 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 0s 672us/step - loss: 44.7112 - reconstruction_loss: 40.1591 - kl_loss: 4.9704\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 0s 672us/step - loss: 41.2670 - reconstruction_loss: 39.4636 - kl_loss: 5.0068\n",
      "Success in episode 8 at time step 190\n",
      "Episode 9\n",
      "[-0.58765423  0.        ]\n",
      "[0.65087184 0.61583481]\n",
      "tf.Tensor([ 0.99200886  0.10859832 -0.76272905 -0.923898   -0.9448712 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - 0s 709us/step - loss: 36.6839 - reconstruction_loss: 31.6313 - kl_loss: 4.1699\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 0s 782us/step - loss: 35.8499 - reconstruction_loss: 31.8539 - kl_loss: 4.1821\n",
      "Success in episode 9 at time step 114\n",
      "Episode 10\n",
      "[-0.5797845  0.       ]\n",
      "[0.6374089  0.40849724]\n",
      "tf.Tensor([ 0.31574178  0.28881833 -0.54052883 -0.9221482  -0.9637238 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "7/7 [==============================] - 0s 638us/step - loss: 22.1666 - reconstruction_loss: 18.9123 - kl_loss: 3.4786\n",
      "Epoch 2/2\n",
      "7/7 [==============================] - 0s 666us/step - loss: 21.4231 - reconstruction_loss: 17.9413 - kl_loss: 3.4122\n",
      "Success in episode 10 at time step 211\n",
      "Episode 11\n",
      "[-0.53453654  0.        ]\n",
      "[0.74319401 0.24869371]\n",
      "tf.Tensor([ 0.9865267  0.2298184 -0.2903653 -0.9179106 -0.9699744], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "10/10 [==============================] - 0s 606us/step - loss: 13.4930 - reconstruction_loss: 10.9007 - kl_loss: 2.7755\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 0s 538us/step - loss: 12.7698 - reconstruction_loss: 10.4263 - kl_loss: 2.7813\n",
      "Success in episode 11 at time step 306\n",
      "Episode 12\n",
      "[-0.4245447  0.       ]\n",
      "[0.56935362 0.73109109]\n",
      "tf.Tensor([ 0.989495    0.8321691  -0.79087585 -0.87396914 -0.9265584 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "9/9 [==============================] - 0s 691us/step - loss: 8.8860 - reconstruction_loss: 7.1584 - kl_loss: 1.6964\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 0s 671us/step - loss: 9.2639 - reconstruction_loss: 7.0199 - kl_loss: 1.7440\n",
      "Success in episode 12 at time step 294\n",
      "Episode 13\n",
      "[-0.5818703  0.       ]\n",
      "[0.29903077 0.98549167]\n",
      "tf.Tensor([ 0.9958095   0.99396765  0.9704274   0.11999497 -0.26981226], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - 0s 714us/step - loss: 26.2421 - reconstruction_loss: 20.3011 - kl_loss: 5.8638\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 0s 775us/step - loss: 22.2252 - reconstruction_loss: 17.1446 - kl_loss: 6.0545\n",
      "Success in episode 13 at time step 117\n",
      "Episode 14\n",
      "[-0.5272365  0.       ]\n",
      "[0.68543848 0.85899735]\n",
      "tf.Tensor([ 0.99204624  0.93530285 -0.7457399  -0.88338387 -0.816055  ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - 0s 701us/step - loss: 17.4704 - reconstruction_loss: 10.6126 - kl_loss: 7.3275\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 0s 729us/step - loss: 16.1958 - reconstruction_loss: 8.7762 - kl_loss: 7.5318\n",
      "Success in episode 14 at time step 111\n",
      "Episode 15\n",
      "[-0.5376411  0.       ]\n",
      "[0.59549642 0.83191128]\n",
      "tf.Tensor([ 0.9901873   0.9262102  -0.75046897 -0.85178244 -0.76981795], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - 0s 764us/step - loss: 12.6298 - reconstruction_loss: 5.0223 - kl_loss: 7.8917\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 0s 795us/step - loss: 12.2099 - reconstruction_loss: 4.2189 - kl_loss: 7.9071\n",
      "Success in episode 15 at time step 111\n",
      "Episode 16\n",
      "[-0.5259764  0.       ]\n",
      "[0.01655595 0.97783868]\n",
      "tf.Tensor([ 0.9904285   0.96443295 -0.657036   -0.8594879  -0.7345955 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 0s 917us/step - loss: 10.4783 - reconstruction_loss: 3.4250 - kl_loss: 6.6727\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 0s 934us/step - loss: 9.8421 - reconstruction_loss: 3.0130 - kl_loss: 6.6290\n",
      "Success in episode 16 at time step 108\n",
      "Episode 17\n",
      "[-0.46263567  0.        ]\n",
      "[0.46597575 0.86926482]\n",
      "tf.Tensor([ 0.98545676  0.97119206 -0.8486699  -0.7962256  -0.7431621 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 0s 795us/step - loss: 10.1570 - reconstruction_loss: 3.0767 - kl_loss: 7.2118\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 0s 926us/step - loss: 9.5072 - reconstruction_loss: 2.6696 - kl_loss: 7.1438\n",
      "Success in episode 17 at time step 102\n",
      "Episode 18\n",
      "[-0.56129426  0.        ]\n",
      "[0.61192781 0.41984164]\n",
      "tf.Tensor([ 0.99089235  0.99249494 -0.7348106  -0.029804   -0.7943643 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 717us/step - loss: 8.4993 - reconstruction_loss: 3.9964 - kl_loss: 4.2928\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 660us/step - loss: 7.6926 - reconstruction_loss: 2.9494 - kl_loss: 4.3359\n",
      "Success in episode 18 at time step 153\n",
      "Episode 19\n",
      "[-0.4948978  0.       ]\n",
      "[0.30331525 0.78573388]\n",
      "tf.Tensor([ 0.9954558   0.989367   -0.47235602 -0.8561288  -0.67507786], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "12/12 [==============================] - 0s 484us/step - loss: 5.4915 - reconstruction_loss: 2.6638 - kl_loss: 2.8948\n",
      "Epoch 2/2\n",
      "12/12 [==============================] - 0s 510us/step - loss: 5.5756 - reconstruction_loss: 2.3212 - kl_loss: 2.9749\n",
      "Success in episode 19 at time step 370\n",
      "Episode 20\n",
      "[-0.4333108  0.       ]\n",
      "[0.22167367 0.99379549]\n",
      "tf.Tensor([ 0.99094087  0.9728505  -0.7303999  -0.8309687  -0.6818103 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 9.2373 - reconstruction_loss: 2.1868 - kl_loss: 6.9224\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8.5509 - reconstruction_loss: 1.7795 - kl_loss: 6.9217\n",
      "Success in episode 20 at time step 104\n",
      "Episode 21\n",
      "[-0.4534033  0.       ]\n",
      "[0.70790719 0.50826374]\n",
      "tf.Tensor([ 0.99091864 -0.6725039  -0.85639846 -0.7216191  -0.438336  ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 0s 903us/step - loss: 6.9780 - reconstruction_loss: 1.9677 - kl_loss: 5.0085\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 0s 991us/step - loss: 6.2516 - reconstruction_loss: 1.2443 - kl_loss: 5.0301\n",
      "Success in episode 21 at time step 102\n",
      "Episode 22\n",
      "[-0.59913325  0.        ]\n",
      "[0.61750773 0.47225357]\n",
      "tf.Tensor([ 0.09467974 -0.62447596 -0.59837073 -0.37371847 -0.5307564 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "9/9 [==============================] - 0s 589us/step - loss: 7.4150 - reconstruction_loss: 2.1472 - kl_loss: 5.0101\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 0s 570us/step - loss: 6.8794 - reconstruction_loss: 2.0667 - kl_loss: 5.0251\n",
      "Success in episode 22 at time step 283\n",
      "Episode 23\n",
      "[-0.44301707  0.        ]\n",
      "[0.72945774 0.86715257]\n",
      "tf.Tensor([ 0.990499   -0.32825628 -0.6422026  -0.48685476 -0.30392826], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 0s 582us/step - loss: 7.3703 - reconstruction_loss: 1.8630 - kl_loss: 5.4764\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 0s 642us/step - loss: 6.9313 - reconstruction_loss: 1.6429 - kl_loss: 5.4668\n",
      "Success in episode 23 at time step 169\n",
      "Episode 24\n",
      "[-0.5605119  0.       ]\n",
      "[0.85930057 0.26502735]\n",
      "tf.Tensor([-0.7089933  -0.84034175 -0.84305716  0.17617504 -0.34903035], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - 0s 794us/step - loss: 6.7326 - reconstruction_loss: 1.4981 - kl_loss: 5.1195\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 0s 865us/step - loss: 6.6506 - reconstruction_loss: 1.7775 - kl_loss: 5.1059\n",
      "Success in episode 24 at time step 109\n",
      "Episode 25\n",
      "[-0.58486  0.     ]\n",
      "[0.70979324 0.31006735]\n",
      "tf.Tensor([ 0.99423826 -0.7402563   0.7302985   0.5098444  -0.7071162 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "16/16 [==============================] - 0s 480us/step - loss: 5.3547 - reconstruction_loss: 1.6210 - kl_loss: 3.6782\n",
      "Epoch 2/2\n",
      "16/16 [==============================] - 0s 510us/step - loss: 5.2728 - reconstruction_loss: 1.5995 - kl_loss: 3.6459\n",
      "Success in episode 25 at time step 508\n",
      "Episode 26\n",
      "[-0.43151298  0.        ]\n",
      "[0.71821801 0.32888695]\n",
      "tf.Tensor([ 0.99523   -0.7534873 -0.5588699 -0.5341251 -0.8633588], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "20/20 [==============================] - 0s 526us/step - loss: 4.0957 - reconstruction_loss: 1.3581 - kl_loss: 2.7186\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 0s 459us/step - loss: 3.8483 - reconstruction_loss: 1.1599 - kl_loss: 2.7499\n",
      "Success in episode 26 at time step 642\n",
      "Episode 27\n",
      "[-0.5246644  0.       ]\n",
      "Epoch 1/2\n",
      "32/32 [==============================] - 0s 488us/step - loss: 4.3779 - reconstruction_loss: 1.1983 - kl_loss: 3.1477\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 0s 478us/step - loss: 4.2033 - reconstruction_loss: 1.0856 - kl_loss: 3.1190\n",
      "No Success\n",
      "Episode 28\n",
      "[-0.5646309  0.       ]\n",
      "[0.72702396 0.16645543]\n",
      "tf.Tensor([ 0.97981143 -0.95468336 -0.13598335 -0.664326   -0.88875705], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "20/20 [==============================] - 0s 523us/step - loss: 4.7496 - reconstruction_loss: 1.1333 - kl_loss: 3.6576\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 0s 463us/step - loss: 4.8938 - reconstruction_loss: 1.2053 - kl_loss: 3.6225\n",
      "Success in episode 28 at time step 629\n",
      "Episode 29\n",
      "[-0.44652718  0.        ]\n",
      "Epoch 1/2\n",
      "32/32 [==============================] - 0s 443us/step - loss: 3.3048 - reconstruction_loss: 0.9791 - kl_loss: 2.2956\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 0s 476us/step - loss: 3.3046 - reconstruction_loss: 1.0044 - kl_loss: 2.2937\n",
      "No Success\n",
      "Episode 30\n",
      "[-0.58049124  0.        ]\n",
      "[0.7134012 0.2488163]\n",
      "tf.Tensor([ 0.96864    0.9796716 -0.6083425 -0.8412258 -0.8621672], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "10/10 [==============================] - 0s 532us/step - loss: 4.8509 - reconstruction_loss: 1.0860 - kl_loss: 3.6847\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 0s 529us/step - loss: 4.8013 - reconstruction_loss: 1.0753 - kl_loss: 3.6798\n",
      "Success in episode 30 at time step 318\n",
      "Episode 31\n",
      "[-0.46344498  0.        ]\n",
      "Epoch 1/2\n",
      "32/32 [==============================] - 0s 455us/step - loss: 3.2267 - reconstruction_loss: 0.9373 - kl_loss: 2.2847\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 0s 441us/step - loss: 3.2881 - reconstruction_loss: 0.9998 - kl_loss: 2.2740\n",
      "No Success\n",
      "Episode 32\n",
      "[-0.5248158  0.       ]\n",
      "[0.52263903 0.72414695]\n",
      "tf.Tensor([ 0.991323    0.9939178   0.93540543  0.02127596 -0.40618628], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - 0s 854us/step - loss: 6.4587 - reconstruction_loss: 1.2795 - kl_loss: 5.2212\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 0s 745us/step - loss: 6.4012 - reconstruction_loss: 1.0468 - kl_loss: 5.2435\n",
      "Success in episode 32 at time step 127\n",
      "Episode 33\n",
      "[-0.5463143  0.       ]\n",
      "Epoch 1/2\n",
      "32/32 [==============================] - 0s 481us/step - loss: 4.4003 - reconstruction_loss: 1.0373 - kl_loss: 3.3385\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 0s 445us/step - loss: 4.3649 - reconstruction_loss: 1.1246 - kl_loss: 3.2653\n",
      "No Success\n",
      "Episode 34\n",
      "[-0.41959515  0.        ]\n",
      "Epoch 1/2\n",
      "32/32 [==============================] - 0s 430us/step - loss: 3.0906 - reconstruction_loss: 0.9480 - kl_loss: 2.1232\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 0s 444us/step - loss: 3.0880 - reconstruction_loss: 0.9470 - kl_loss: 2.1066\n",
      "No Success\n",
      "Episode 35\n",
      "[-0.40333512  0.        ]\n",
      "[0.20516833 0.91740476]\n",
      "tf.Tensor([0.94651586 0.9440254  0.9081497  0.87007636 0.6558102 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - 0s 791us/step - loss: 7.7320 - reconstruction_loss: 1.2327 - kl_loss: 6.5220\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 0s 820us/step - loss: 7.5942 - reconstruction_loss: 1.2838 - kl_loss: 6.5877\n",
      "Success in episode 35 at time step 117\n",
      "Episode 36\n",
      "[-0.56672615  0.        ]\n",
      "Epoch 1/2\n",
      "32/32 [==============================] - 0s 491us/step - loss: 4.4525 - reconstruction_loss: 1.1362 - kl_loss: 3.2817\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 0s 485us/step - loss: 4.3402 - reconstruction_loss: 1.0610 - kl_loss: 3.2621\n",
      "No Success\n",
      "Episode 37\n",
      "[-0.49027866  0.        ]\n",
      "Epoch 1/2\n",
      "32/32 [==============================] - 0s 513us/step - loss: 3.5051 - reconstruction_loss: 1.0187 - kl_loss: 2.5137\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 0s 472us/step - loss: 3.4774 - reconstruction_loss: 0.9516 - kl_loss: 2.5163\n",
      "No Success\n",
      "Episode 38\n",
      "[-0.5978558  0.       ]\n",
      "[0.75220343 0.1660885 ]\n",
      "tf.Tensor([ 0.9732193   0.96271294  0.9180458  -0.31786066 -0.6709325 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "28/28 [==============================] - 0s 462us/step - loss: 4.9911 - reconstruction_loss: 1.1575 - kl_loss: 3.8248\n",
      "Epoch 2/2\n",
      "28/28 [==============================] - 0s 449us/step - loss: 4.8738 - reconstruction_loss: 1.1019 - kl_loss: 3.7267\n",
      "Success in episode 38 at time step 896\n",
      "Episode 39\n",
      "[-0.45259595  0.        ]\n",
      "Epoch 1/2\n",
      "32/32 [==============================] - 0s 442us/step - loss: 3.3683 - reconstruction_loss: 1.0046 - kl_loss: 2.3669\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 0s 495us/step - loss: 3.3280 - reconstruction_loss: 0.9562 - kl_loss: 2.3471\n",
      "No Success\n",
      "Episode 40\n",
      "[-0.53467596  0.        ]\n",
      "[0.7341652  0.58231435]\n",
      "tf.Tensor([0.96386695 0.96278024 0.9461813  0.7760432  0.46805146], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 0s 900us/step - loss: 7.9177 - reconstruction_loss: 1.2659 - kl_loss: 6.5931\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 0s 919us/step - loss: 7.6612 - reconstruction_loss: 1.0563 - kl_loss: 6.6783\n",
      "Success in episode 40 at time step 75\n"
     ]
    }
   ],
   "source": [
    "# train the agent on the env\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "agent, results = train_single_agent(env, daifa, observation_max, observation_min, observation_noise_stddev, num_episodes=40, action_repeats=6, num_actions_to_execute=2, train_on_full_data=True, show_replay_training=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ethan/python_repos/gym/gym/core.py:330: DeprecationWarning: \u001B[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001B[0m\n",
      "  deprecation(\n",
      "/Users/Ethan/python_repos/gym/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001B[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001B[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "data": {
      "text/plain": "(12690, 2)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_seqs = 20\n",
    "seq_length = 500\n",
    "ob_dim = 2\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "observations = []\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, 1000, epsilon=0.1)\n",
    "\n",
    "    o = transform_observations(o, observation_max, observation_min, observation_noise_stddev)\n",
    "\n",
    "    train = np.concatenate([o[:-1], a], axis=1)\n",
    "    # train = o[:-1]\n",
    "    test = o[-1]\n",
    "\n",
    "    observations.append(o)\n",
    "    ob_seqs.append(train)\n",
    "    next_obs.append(test)\n",
    "\n",
    "observations = np.vstack(observations)\n",
    "\n",
    "\n",
    "observations.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.24595183,  0.0371885 ],\n       [-0.21116235,  0.06468806],\n       [-0.26904556,  0.02188016],\n       ...,\n       [ 0.7791379 ,  0.63562229],\n       [ 0.72304778,  0.68490671],\n       [ 0.81090177,  0.76606673]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(11628, 2), dtype=float32, numpy=\narray([[-0.15425514,  0.05922233],\n       [-0.22476536, -0.00983024],\n       [-0.17882505,  0.04152825],\n       ...,\n       [ 0.70444614,  0.60643506],\n       [ 0.6450296 ,  0.6960083 ],\n       [ 0.8769556 ,  0.75102764]], dtype=float32)>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = agent.model_vae(observations)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test without the replay training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.83333333, 0.        ])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = create_encoder(2, 2, [20])\n",
    "dec = create_decoder(2, 2, [20])\n",
    "vae = VAE(enc, dec, 2,  [0, 0], [0.3, 0.3], llik_scaling=1)\n",
    "\n",
    "tran = TransitionGRU(2, 1, 12, 20, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.45, 0]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "# observation_noise_stddev = [0, 0]\n",
    "observation_noise_stddev = [0.05, 0.05]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0,0])  # no noise on prior\n",
    "\n",
    "daifa = DAIFAgentRecurrent(None,\n",
    "                           vae,\n",
    "                           tran,\n",
    "                           scaled_prior_mean,\n",
    "                           prior_stddev,\n",
    "                           planning_horizon=5,\n",
    "                           use_kl_extrinsic=True,\n",
    "                           use_kl_intrinsic=True,\n",
    "                           use_FEEF=True,\n",
    "                           vae_train_epochs=1,\n",
    "                           tran_train_epochs=1,\n",
    "                           show_vae_training=False)\n",
    "\n",
    "scaled_prior_mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ethan/python_repos/gym/gym/core.py:330: DeprecationWarning: \u001B[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001B[0m\n",
      "  deprecation(\n",
      "/Users/Ethan/python_repos/gym/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001B[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001B[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "[-0.5452394  0.       ]\n",
      "WARNING:tensorflow:From /Users/Ethan/miniconda3/envs/tf_daif_car_race/lib/python3.8/site-packages/tensorflow_probability/python/distributions/distribution.py:345: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`scale_identity_multiplier` is deprecated; please combine it into `scale_diag` directly instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 14:32:26.876947: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80860598 0.09458183]\n",
      "tf.Tensor([ 0.9830013   0.7846042   0.3220308  -0.01687961  0.16555098], shape=(5,), dtype=float32)\n",
      "Success in episode 1 at time step 369\n",
      "Episode 2\n",
      "[-0.57064813  0.        ]\n",
      "[0.47878008 0.40288668]\n",
      "tf.Tensor([ 0.957456    0.79769796  0.22657327 -0.27285808 -0.09558801], shape=(5,), dtype=float32)\n",
      "Success in episode 2 at time step 106\n",
      "Episode 3\n",
      "[-0.4439096  0.       ]\n",
      "[0.55124285 0.51222228]\n",
      "tf.Tensor([ 0.9207449  -0.5341525  -0.88466763 -0.8933735  -0.15289223], shape=(5,), dtype=float32)\n",
      "Success in episode 3 at time step 92\n",
      "Episode 4\n",
      "[-0.55050933  0.        ]\n",
      "No Success\n",
      "Episode 5\n",
      "[-0.53231597  0.        ]\n",
      "[0.7296093  0.15947908]\n",
      "tf.Tensor([ 0.9820634   0.93507713  0.9540813   0.42379785 -0.84602374], shape=(5,), dtype=float32)\n",
      "Success in episode 5 at time step 125\n",
      "Episode 6\n",
      "[-0.4112631  0.       ]\n",
      "No Success\n",
      "Episode 7\n",
      "[-0.53678113  0.        ]\n",
      "No Success\n",
      "Episode 8\n",
      "[-0.42946008  0.        ]\n",
      "[0.74362838 0.34122923]\n",
      "tf.Tensor([0.7967912  0.9772121  0.9674017  0.93885607 0.19883062], shape=(5,), dtype=float32)\n",
      "Success in episode 8 at time step 758\n",
      "Episode 9\n",
      "[-0.5263604  0.       ]\n",
      "[0.84034789 0.53523016]\n",
      "tf.Tensor([ 0.9681933   0.97307837  0.94899935  0.8507929  -0.10709003], shape=(5,), dtype=float32)\n",
      "Success in episode 9 at time step 122\n",
      "Episode 10\n",
      "[-0.5852645  0.       ]\n",
      "[0.69803108 0.45851984]\n",
      "tf.Tensor([ 0.93200725  0.07335937  0.35393855 -0.43221903 -0.99461627], shape=(5,), dtype=float32)\n",
      "Success in episode 10 at time step 438\n",
      "Episode 11\n",
      "[-0.42456153  0.        ]\n",
      "[0.90410014 0.03039351]\n",
      "tf.Tensor([0.955181   0.9668999  0.94788754 0.9243209  0.03093042], shape=(5,), dtype=float32)\n",
      "Success in episode 11 at time step 196\n",
      "Episode 12\n",
      "[-0.5621345  0.       ]\n",
      "[0.60916363 0.64281688]\n",
      "tf.Tensor([0.9673787  0.9515966  0.9198448  0.83164215 0.37397212], shape=(5,), dtype=float32)\n",
      "Success in episode 12 at time step 353\n",
      "Episode 13\n",
      "[-0.44907644  0.        ]\n",
      "[0.6238851  0.56028498]\n",
      "tf.Tensor([0.962473   0.96590596 0.91697454 0.80474585 0.36682007], shape=(5,), dtype=float32)\n",
      "Success in episode 13 at time step 245\n",
      "Episode 14\n",
      "[-0.5084155  0.       ]\n",
      "[0.52400454 0.49420985]\n",
      "tf.Tensor([0.96537584 0.95639193 0.8497883  0.8272771  0.53330594], shape=(5,), dtype=float32)\n",
      "Success in episode 14 at time step 139\n",
      "Episode 15\n",
      "[-0.4963757  0.       ]\n",
      "[0.5967929  0.78715146]\n",
      "tf.Tensor([0.9737183  0.96602696 0.92889744 0.8075658  0.27599594], shape=(5,), dtype=float32)\n",
      "Success in episode 15 at time step 472\n",
      "Episode 16\n",
      "[-0.41137737  0.        ]\n",
      "[0.64697548 0.55997122]\n",
      "tf.Tensor([ 0.7319554   0.5848996   0.45162955 -0.20630382 -0.1557222 ], shape=(5,), dtype=float32)\n",
      "Success in episode 16 at time step 114\n",
      "Episode 17\n",
      "[-0.47954446  0.        ]\n",
      "[0.66216164 0.5763151 ]\n",
      "tf.Tensor([0.9872321 0.9339481 0.8323261 0.7743125 0.7955457], shape=(5,), dtype=float32)\n",
      "Success in episode 17 at time step 126\n",
      "Episode 18\n",
      "[-0.54798496  0.        ]\n",
      "[0.80955268 0.84861332]\n",
      "tf.Tensor([0.9511565  0.91198766 0.914686   0.92453223 0.4987105 ], shape=(5,), dtype=float32)\n",
      "Success in episode 18 at time step 109\n",
      "Episode 19\n",
      "[-0.41204917  0.        ]\n",
      "[0.76391228 0.86990232]\n",
      "tf.Tensor([0.9856899  0.91792905 0.67700845 0.79191905 0.81273013], shape=(5,), dtype=float32)\n",
      "Success in episode 19 at time step 122\n",
      "Episode 20\n",
      "[-0.5644128  0.       ]\n",
      "[0.67947636 0.68230617]\n",
      "tf.Tensor([ 0.9875462   0.9684505   0.82187605  0.0949681  -0.51842016], shape=(5,), dtype=float32)\n",
      "Success in episode 20 at time step 135\n",
      "Episode 21\n",
      "[-0.5304834  0.       ]\n",
      "[0.0453475 0.9325196]\n",
      "tf.Tensor([ 0.99650794  0.9938319   0.9598182   0.10676017 -0.1436152 ], shape=(5,), dtype=float32)\n",
      "Success in episode 21 at time step 120\n",
      "Episode 22\n",
      "[-0.58897793  0.        ]\n",
      "[0.32071005 0.86789848]\n",
      "tf.Tensor([ 0.96506894  0.97593784  0.9567569   0.37466732 -0.29258507], shape=(5,), dtype=float32)\n",
      "Success in episode 22 at time step 105\n",
      "Episode 23\n",
      "[-0.4831836  0.       ]\n",
      "[0.55355523 0.84974087]\n",
      "tf.Tensor([ 0.8452918  -0.92526656 -0.96639925 -0.9039103  -0.2935575 ], shape=(5,), dtype=float32)\n",
      "Success in episode 23 at time step 90\n",
      "Episode 24\n",
      "[-0.4490086  0.       ]\n",
      "[0.15431216 0.96833963]\n",
      "tf.Tensor([ 0.9827694   0.66276896 -0.89383835 -0.9488957  -0.9110807 ], shape=(5,), dtype=float32)\n",
      "Success in episode 24 at time step 94\n",
      "Episode 25\n",
      "[-0.51117045  0.        ]\n",
      "[0.42419586 0.93457236]\n",
      "tf.Tensor([-0.8502137  -0.9579167  -0.9561652  -0.8854989  -0.45486552], shape=(5,), dtype=float32)\n",
      "Success in episode 25 at time step 105\n",
      "Episode 26\n",
      "[-0.47662842  0.        ]\n",
      "[0.23855552 0.93985884]\n",
      "tf.Tensor([ 0.0436843  -0.96799046 -0.9648949  -0.92606574 -0.81029797], shape=(5,), dtype=float32)\n",
      "Success in episode 26 at time step 96\n",
      "Episode 27\n",
      "[-0.5792641  0.       ]\n",
      "[0.39285086 0.89285321]\n",
      "tf.Tensor([-0.8838425  -0.9465538  -0.9562758  -0.8997264  -0.53602725], shape=(5,), dtype=float32)\n",
      "Success in episode 27 at time step 117\n",
      "Episode 28\n",
      "[-0.4025429  0.       ]\n",
      "[0.16296143 0.88732952]\n",
      "tf.Tensor([ 0.96141434 -0.7195983  -0.9567334  -0.9061281  -0.70640635], shape=(5,), dtype=float32)\n",
      "Success in episode 28 at time step 84\n",
      "Episode 29\n",
      "[-0.45679152  0.        ]\n",
      "[0.75470664 0.31699938]\n",
      "tf.Tensor([-0.97266483 -0.9755431  -0.9096328  -0.63750523 -0.53149885], shape=(5,), dtype=float32)\n",
      "Success in episode 29 at time step 89\n",
      "Episode 30\n",
      "[-0.5462031  0.       ]\n",
      "[0.34965257 0.95319361]\n",
      "tf.Tensor([ 0.30918306 -0.9515482  -0.9745215  -0.934501   -0.7999848 ], shape=(5,), dtype=float32)\n",
      "Success in episode 30 at time step 140\n",
      "Episode 31\n",
      "[-0.41845554  0.        ]\n",
      "[0.42680894 0.5955394 ]\n",
      "tf.Tensor([ 0.0122298  -0.97020054 -0.97598225 -0.92446953 -0.71551466], shape=(5,), dtype=float32)\n",
      "Success in episode 31 at time step 273\n",
      "Episode 32\n",
      "[-0.41770574  0.        ]\n",
      "[0.77922881 0.63037632]\n",
      "tf.Tensor([-0.9758603  -0.988826   -0.92702734  0.09244861  0.27263066], shape=(5,), dtype=float32)\n",
      "Success in episode 32 at time step 253\n",
      "Episode 33\n",
      "[-0.463659  0.      ]\n",
      "[0.62340402 0.5435404 ]\n",
      "tf.Tensor([-0.9704191  -0.9395351  -0.89592385 -0.80561024 -0.7685855 ], shape=(5,), dtype=float32)\n",
      "Success in episode 33 at time step 283\n",
      "Episode 34\n",
      "[-0.47814003  0.        ]\n",
      "[0.79361985 0.38159733]\n",
      "tf.Tensor([-0.9939903  -0.8851764   0.33940306 -0.06241485 -0.8044955 ], shape=(5,), dtype=float32)\n",
      "Success in episode 34 at time step 219\n",
      "Episode 35\n",
      "[-0.5698738  0.       ]\n",
      "[0.80840458 0.25253609]\n",
      "tf.Tensor([-0.65526855 -0.10981813  0.9148883  -0.66293246 -0.93880355], shape=(5,), dtype=float32)\n",
      "Success in episode 35 at time step 436\n",
      "Episode 36\n",
      "[-0.4417323  0.       ]\n",
      "No Success\n",
      "Episode 37\n",
      "[-0.5901701  0.       ]\n",
      "[0.73845693 0.1457434 ]\n",
      "tf.Tensor([0.50353736 0.82554203 0.9732157  0.9508254  0.50749767], shape=(5,), dtype=float32)\n",
      "Success in episode 37 at time step 238\n",
      "Episode 38\n",
      "[-0.45247665  0.        ]\n",
      "[0.7372389  0.34390254]\n",
      "tf.Tensor([-0.30627385 -0.20624106  0.9204775   0.93034166 -0.22478874], shape=(5,), dtype=float32)\n",
      "Success in episode 38 at time step 471\n",
      "Episode 39\n",
      "[-0.41200373  0.        ]\n",
      "[0.70348916 0.06563696]\n",
      "tf.Tensor([ 0.9063062   0.90392214  0.8661124  -0.79284    -0.9465599 ], shape=(5,), dtype=float32)\n",
      "Success in episode 39 at time step 576\n",
      "Episode 40\n",
      "[-0.57113284  0.        ]\n",
      "[0.74960369 0.26518259]\n",
      "tf.Tensor([ 0.8939229  -0.29449376  0.42528403 -0.7624439  -0.9759877 ], shape=(5,), dtype=float32)\n",
      "Success in episode 40 at time step 229\n"
     ]
    }
   ],
   "source": [
    "# train the agent on the env\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "agent, results = train_single_agent(env, daifa, observation_max, observation_min, observation_noise_stddev, num_episodes=40, action_repeats=6, num_actions_to_execute=2, train_on_full_data=False, show_replay_training=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'observations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mobservations\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'observations' is not defined"
     ]
    }
   ],
   "source": [
    "observations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'observations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m res \u001B[38;5;241m=\u001B[39m agent\u001B[38;5;241m.\u001B[39mmodel_vae(\u001B[43mobservations\u001B[49m)\n\u001B[1;32m      2\u001B[0m res\n",
      "\u001B[0;31mNameError\u001B[0m: name 'observations' is not defined"
     ]
    }
   ],
   "source": [
    "res = agent.model_vae(observations)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test with the prior model FEEF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "enc = create_encoder(2, 2, [20])\n",
    "dec = create_decoder(2, 2, [20])\n",
    "vae = VAE(enc, dec, 2, [0, 0], [0.3, 0.3], llik_scaling=1, recon_stddev=0.05)\n",
    "\n",
    "pl_hoz = 5\n",
    "latent_dim = 2\n",
    "\n",
    "tran = TransitionGRU(2, 1, 12, 2*latent_dim*pl_hoz, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_model = PriorModelBellman(2)\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "# observation_noise_stddev = [0, 0]\n",
    "observation_noise_stddev = [0.05, 0.05]\n",
    "\n",
    "daifa = DAIFAgentRecurrent(prior_model,\n",
    "                           vae,\n",
    "                           tran,\n",
    "                           None,\n",
    "                           None,\n",
    "                           train_prior_model=True,\n",
    "                           planning_horizon=pl_hoz,\n",
    "                           use_kl_extrinsic=True,\n",
    "                           use_kl_intrinsic=True,\n",
    "                           use_FEEF=True,\n",
    "                           vae_train_epochs=1,\n",
    "                           tran_train_epochs=1,\n",
    "                           show_vae_training=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "[-0.5484944  0.       ]\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 599us/step - loss: 58.4202 - reconstruction_loss: 45.0543 - kl_loss: 6.8987\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 627us/step - loss: 36.1541 - reconstruction_loss: 31.3868 - kl_loss: 5.3182\n",
      "No Success\n",
      "Episode 2\n",
      "[-0.518806  0.      ]\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 514us/step - loss: 23.7571 - reconstruction_loss: 19.5673 - kl_loss: 3.8580\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 470us/step - loss: 22.4032 - reconstruction_loss: 18.4973 - kl_loss: 2.9210\n",
      "No Success\n",
      "Episode 3\n",
      "[-0.48708177  0.        ]\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 488us/step - loss: 44.9584 - reconstruction_loss: 41.6020 - kl_loss: 2.8819\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 453us/step - loss: 37.5611 - reconstruction_loss: 33.4581 - kl_loss: 3.1555\n",
      "No Success\n",
      "Episode 4\n",
      "[-0.59569204  0.        ]\n",
      "[0.43393912 0.60661473]\n",
      "tf.Tensor([ 0.53942364 -0.80796605 -0.9376626  -0.9712407  -0.96946347], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "19/19 [==============================] - 0s 583us/step - loss: 28.1456 - reconstruction_loss: 25.0616 - kl_loss: 2.8645\n",
      "Epoch 2/2\n",
      "19/19 [==============================] - 0s 588us/step - loss: 23.4992 - reconstruction_loss: 20.2202 - kl_loss: 3.0532\n",
      "Success in episode 4 at time step 610\n",
      "Episode 5\n",
      "[-0.52210057  0.        ]\n",
      "[0.43684663 0.46498674]\n",
      "tf.Tensor([ 0.92546123  0.68108666 -0.6756315  -0.9598786  -0.95649064], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "20/20 [==============================] - 0s 475us/step - loss: 24.0181 - reconstruction_loss: 15.6585 - kl_loss: 6.4340\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 0s 469us/step - loss: 17.0986 - reconstruction_loss: 9.3317 - kl_loss: 7.0323\n",
      "Success in episode 5 at time step 639\n",
      "Episode 6\n",
      "[-0.5314198  0.       ]\n",
      "[-0.64987119  0.68371874]\n",
      "tf.Tensor([ 0.90175134  0.9434608  -0.32570428 -0.9429536  -0.9643723 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 753us/step - loss: 8.7762 - reconstruction_loss: 5.5566 - kl_loss: 3.6357\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 686us/step - loss: 8.4378 - reconstruction_loss: 4.6241 - kl_loss: 3.6613\n",
      "Success in episode 6 at time step 179\n",
      "Episode 7\n",
      "[-0.4605715  0.       ]\n",
      "[-0.00353998  0.9392916 ]\n",
      "tf.Tensor([ 0.68352056 -0.5560999  -0.9425656  -0.9672263  -0.95395947], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 13.1592 - reconstruction_loss: 5.6714 - kl_loss: 7.1696\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 0s 792us/step - loss: 12.0877 - reconstruction_loss: 4.8470 - kl_loss: 7.1424\n",
      "Success in episode 7 at time step 105\n",
      "Episode 8\n",
      "[-0.5544191  0.       ]\n",
      "[0.07817301 0.7160106 ]\n",
      "tf.Tensor([ 0.5129768  -0.8201981  -0.95326155 -0.9582234  -0.9605208 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "12/12 [==============================] - 0s 523us/step - loss: 20.3771 - reconstruction_loss: 9.2486 - kl_loss: 11.3828\n",
      "Epoch 2/2\n",
      "12/12 [==============================] - 0s 499us/step - loss: 19.7152 - reconstruction_loss: 8.1764 - kl_loss: 11.3159\n",
      "Success in episode 8 at time step 377\n",
      "Episode 9\n",
      "[-0.45428526  0.        ]\n",
      "[-0.71513816  0.66045801]\n",
      "tf.Tensor([-0.310609    0.9450641   0.69586194 -0.9487002  -0.9586462 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "20/20 [==============================] - 0s 477us/step - loss: 18.8558 - reconstruction_loss: 7.1300 - kl_loss: 11.9460\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 0s 460us/step - loss: 17.5985 - reconstruction_loss: 5.9947 - kl_loss: 10.9378\n",
      "Success in episode 9 at time step 660\n",
      "Episode 10\n",
      "[-0.5995278  0.       ]\n",
      "[0.6379365  0.49749467]\n",
      "tf.Tensor([-0.95766777  0.3941255  -0.37302512 -0.70233625 -0.48940507], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "11/11 [==============================] - 0s 508us/step - loss: 12.0112 - reconstruction_loss: 4.9172 - kl_loss: 6.8543\n",
      "Epoch 2/2\n",
      "11/11 [==============================] - 0s 509us/step - loss: 10.5292 - reconstruction_loss: 3.8701 - kl_loss: 6.7893\n",
      "Success in episode 10 at time step 347\n",
      "Episode 11\n",
      "[-0.55990255  0.        ]\n",
      "[-0.60410505  0.60038473]\n",
      "tf.Tensor([ 0.4334197   0.89764506  0.9182931  -0.89183265 -0.94067025], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "15/15 [==============================] - 0s 611us/step - loss: 6.4572 - reconstruction_loss: 3.3261 - kl_loss: 3.0807\n",
      "Epoch 2/2\n",
      "15/15 [==============================] - 0s 581us/step - loss: 6.1785 - reconstruction_loss: 3.2316 - kl_loss: 3.1090\n",
      "Success in episode 11 at time step 476\n",
      "Episode 12\n",
      "[-0.5676446  0.       ]\n",
      "[0.78900151 0.01502983]\n",
      "tf.Tensor([ 0.9525033  -0.5266449  -0.90737504 -0.9485466  -0.9685088 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - 0s 756us/step - loss: 7.7062 - reconstruction_loss: 3.8728 - kl_loss: 4.3860\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 0s 908us/step - loss: 7.3972 - reconstruction_loss: 3.1801 - kl_loss: 4.4344\n",
      "Success in episode 12 at time step 125\n",
      "Episode 13\n",
      "[-0.4126645  0.       ]\n",
      "[0.6035577  0.39746463]\n",
      "tf.Tensor([ 0.94505864  0.8305527  -0.84912413 -0.9223308  -0.91720754], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 0s 781us/step - loss: 8.1907 - reconstruction_loss: 2.4208 - kl_loss: 5.7350\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.4131 - reconstruction_loss: 2.0390 - kl_loss: 5.7346\n",
      "Success in episode 13 at time step 101\n",
      "Episode 14\n",
      "[-0.57494265  0.        ]\n",
      "[0.05225397 0.75246499]\n",
      "tf.Tensor([ 0.9236813   0.88682705 -0.8156639  -0.9238964  -0.8818617 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 0s 896us/step - loss: 10.7618 - reconstruction_loss: 3.4984 - kl_loss: 6.9304\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 0s 692us/step - loss: 10.3217 - reconstruction_loss: 3.4507 - kl_loss: 6.9022\n",
      "Success in episode 14 at time step 199\n",
      "Episode 15\n",
      "[-0.4938598  0.       ]\n",
      "[-0.53897305  0.59568419]\n",
      "tf.Tensor([ 0.6923169  0.9413038  0.9228984 -0.9531834 -0.9176845], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "11/11 [==============================] - 0s 750us/step - loss: 11.6503 - reconstruction_loss: 3.0920 - kl_loss: 8.6630\n",
      "Epoch 2/2\n",
      "11/11 [==============================] - 0s 661us/step - loss: 12.0253 - reconstruction_loss: 2.8702 - kl_loss: 8.5575\n",
      "Success in episode 15 at time step 359\n",
      "Episode 16\n",
      "[-0.58367604  0.        ]\n",
      "[-0.22943367  0.84849797]\n",
      "tf.Tensor([ 0.887139    0.9392145  -0.5319459  -0.94324166 -0.92820805], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 0s 670us/step - loss: 8.8991 - reconstruction_loss: 2.4107 - kl_loss: 6.2945\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 0s 659us/step - loss: 8.4455 - reconstruction_loss: 2.4163 - kl_loss: 6.2123\n",
      "Success in episode 16 at time step 200\n",
      "Episode 17\n",
      "[-0.4923572  0.       ]\n",
      "[0.48803502 0.54621775]\n",
      "tf.Tensor([ 0.95160884 -0.59898406 -0.9622428  -0.9601188  -0.7568512 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 794us/step - loss: 8.7988 - reconstruction_loss: 2.3113 - kl_loss: 6.6859\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 741us/step - loss: 9.3523 - reconstruction_loss: 2.6106 - kl_loss: 6.6324\n",
      "Success in episode 17 at time step 166\n",
      "Episode 18\n",
      "[-0.4676559  0.       ]\n",
      "[0.55960618 0.32915288]\n",
      "tf.Tensor([ 0.9601318   0.76323575 -0.8307218  -0.9234122  -0.86427575], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 616us/step - loss: 9.1163 - reconstruction_loss: 2.5926 - kl_loss: 6.2077\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 654us/step - loss: 7.9493 - reconstruction_loss: 1.8056 - kl_loss: 6.1592\n",
      "Success in episode 18 at time step 158\n",
      "Episode 19\n",
      "[-0.55600256  0.        ]\n",
      "[0.78381184 0.43816678]\n",
      "tf.Tensor([ 0.94960546  0.93194854 -0.7137635  -0.91298646 -0.8813957 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "7/7 [==============================] - 0s 669us/step - loss: 7.3899 - reconstruction_loss: 2.3247 - kl_loss: 5.0661\n",
      "Epoch 2/2\n",
      "7/7 [==============================] - 0s 774us/step - loss: 7.0945 - reconstruction_loss: 2.2097 - kl_loss: 5.0609\n",
      "Success in episode 19 at time step 214\n",
      "Episode 20\n",
      "[-0.43542972  0.        ]\n",
      "[-0.77829979  0.38725577]\n",
      "tf.Tensor([ 0.67858493  0.937512    0.96516037  0.54972255 -0.9547544 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - 0s 756us/step - loss: 5.8008 - reconstruction_loss: 1.5050 - kl_loss: 4.2047\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 5.9445 - reconstruction_loss: 1.8158 - kl_loss: 4.1713\n",
      "Success in episode 20 at time step 150\n",
      "Episode 21\n",
      "[-0.55849165  0.        ]\n",
      "[-0.33124466  0.86650486]\n",
      "tf.Tensor([ 0.9371447   0.94848025  0.8995507  -0.7638814  -0.8855443 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 0s 836us/step - loss: 6.6571 - reconstruction_loss: 1.6020 - kl_loss: 5.1269\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.5744 - reconstruction_loss: 1.5278 - kl_loss: 5.1054\n",
      "Success in episode 21 at time step 109\n",
      "Episode 22\n",
      "[-0.4310394  0.       ]\n",
      "[-0.03981547  0.61139527]\n",
      "tf.Tensor([ 0.9779087  0.9653669  0.7095495 -0.6561639 -0.8852587], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 0s 876us/step - loss: 5.3512 - reconstruction_loss: 1.3716 - kl_loss: 4.0622\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 0s 897us/step - loss: 6.0304 - reconstruction_loss: 1.9029 - kl_loss: 4.0604\n",
      "Success in episode 22 at time step 112\n",
      "Episode 23\n",
      "[-0.5496855  0.       ]\n",
      "[-0.44668815  0.56953237]\n",
      "tf.Tensor([ 0.96393096  0.95517796  0.9484314  -0.02067748 -0.93797463], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "12/12 [==============================] - 0s 680us/step - loss: 9.4566 - reconstruction_loss: 2.6261 - kl_loss: 6.7383\n",
      "Epoch 2/2\n",
      "12/12 [==============================] - 0s 645us/step - loss: 8.8589 - reconstruction_loss: 2.1317 - kl_loss: 6.8827\n",
      "Success in episode 23 at time step 384\n",
      "Episode 24\n",
      "[-0.5740722  0.       ]\n",
      "[0.76662139 0.44852311]\n",
      "tf.Tensor([ 0.96741486  0.92653435 -0.6716142  -0.9289489  -0.81193256], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "13/13 [==============================] - 0s 504us/step - loss: 5.4406 - reconstruction_loss: 1.7470 - kl_loss: 3.6913\n",
      "Epoch 2/2\n",
      "13/13 [==============================] - 0s 539us/step - loss: 5.2857 - reconstruction_loss: 1.5390 - kl_loss: 3.6619\n",
      "Success in episode 24 at time step 391\n",
      "Episode 25\n",
      "[-0.47093832  0.        ]\n",
      "[0.34536269 0.62146267]\n",
      "tf.Tensor([ 0.982638   0.9438238 -0.2913136 -0.9403439 -0.8967593], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 622us/step - loss: 7.5697 - reconstruction_loss: 2.1730 - kl_loss: 5.3664\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 638us/step - loss: 6.7834 - reconstruction_loss: 1.7488 - kl_loss: 5.3519\n",
      "Success in episode 25 at time step 159\n",
      "Episode 26\n",
      "[-0.4050906  0.       ]\n",
      "[0.52380358 0.55880912]\n",
      "tf.Tensor([ 0.97054344  0.91447043 -0.82860225 -0.93091756 -0.85550815], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 695us/step - loss: 6.9088 - reconstruction_loss: 1.5761 - kl_loss: 5.1277\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 667us/step - loss: 6.9870 - reconstruction_loss: 1.7676 - kl_loss: 5.1074\n",
      "Success in episode 26 at time step 157\n",
      "Episode 27\n",
      "[-0.5262916  0.       ]\n",
      "[0.60023659 0.53565799]\n",
      "tf.Tensor([ 0.96012986 -0.0096777  -0.94669604 -0.948937   -0.85035473], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "7/7 [==============================] - 0s 828us/step - loss: 7.6614 - reconstruction_loss: 2.0994 - kl_loss: 5.5271\n",
      "Epoch 2/2\n",
      "7/7 [==============================] - 0s 672us/step - loss: 7.2678 - reconstruction_loss: 1.8238 - kl_loss: 5.5268\n",
      "Success in episode 27 at time step 215\n",
      "Episode 28\n",
      "[-0.47990215  0.        ]\n",
      "[-0.69654455  0.47187729]\n",
      "tf.Tensor([ 0.8633668   0.9329309   0.9395837  -0.7648681  -0.92263836], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 578us/step - loss: 5.7185 - reconstruction_loss: 1.4130 - kl_loss: 4.4546\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 682us/step - loss: 5.8526 - reconstruction_loss: 1.4291 - kl_loss: 4.4411\n",
      "Success in episode 28 at time step 270\n",
      "Episode 29\n",
      "[-0.47733557  0.        ]\n",
      "[0.72197514 0.24306388]\n",
      "tf.Tensor([-0.29253593 -0.960111   -0.96267974 -0.95452476 -0.83690506], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 0s 638us/step - loss: 8.2226 - reconstruction_loss: 1.9444 - kl_loss: 6.2108\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 0s 622us/step - loss: 8.2735 - reconstruction_loss: 1.7529 - kl_loss: 6.1656\n",
      "Success in episode 29 at time step 184\n",
      "Episode 30\n",
      "[-0.5131528  0.       ]\n",
      "[-0.14345096  0.80473539]\n",
      "tf.Tensor([ 0.9552281   0.9496022   0.01079097 -0.94117475 -0.94041866], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "24/24 [==============================] - 0s 542us/step - loss: 3.7798 - reconstruction_loss: 1.2655 - kl_loss: 2.5184\n",
      "Epoch 2/2\n",
      "24/24 [==============================] - 0s 510us/step - loss: 3.7290 - reconstruction_loss: 1.2098 - kl_loss: 2.5490\n",
      "Success in episode 30 at time step 768\n",
      "Episode 31\n",
      "[-0.46932176  0.        ]\n",
      "[0.39546656 0.66208924]\n",
      "tf.Tensor([ 0.9668821  -0.04248648 -0.93477327 -0.94676405 -0.8885452 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 0s 851us/step - loss: 6.7260 - reconstruction_loss: 1.5653 - kl_loss: 5.2926\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 0s 784us/step - loss: 6.4667 - reconstruction_loss: 1.3425 - kl_loss: 5.2772\n",
      "Success in episode 31 at time step 99\n",
      "Episode 32\n",
      "[-0.5092919  0.       ]\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 507us/step - loss: 7.0663 - reconstruction_loss: 1.4210 - kl_loss: 5.6891\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 431us/step - loss: 6.9905 - reconstruction_loss: 1.5410 - kl_loss: 5.4485\n",
      "No Success\n",
      "Episode 33\n",
      "[-0.541249  0.      ]\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 600us/step - loss: 4.6203 - reconstruction_loss: 1.3204 - kl_loss: 3.2881\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 550us/step - loss: 4.4882 - reconstruction_loss: 1.1874 - kl_loss: 3.3315\n",
      "No Success\n",
      "Episode 34\n",
      "[-0.42544827  0.        ]\n",
      "[-0.0741573   0.94230029]\n",
      "tf.Tensor([ 0.73010695 -0.5771215  -0.9590358  -0.973611   -0.9504563 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 0s 634us/step - loss: 7.4225 - reconstruction_loss: 1.1921 - kl_loss: 6.1865\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 0s 652us/step - loss: 7.2913 - reconstruction_loss: 1.2582 - kl_loss: 6.0974\n",
      "Success in episode 34 at time step 438\n",
      "Episode 35\n",
      "[-0.48182368  0.        ]\n",
      "[-0.54787218  0.75677811]\n",
      "tf.Tensor([ 0.76725364  0.93586665 -0.04508896 -0.95973086 -0.95905685], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 0s 902us/step - loss: 6.1304 - reconstruction_loss: 1.3611 - kl_loss: 4.7358\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 0s 729us/step - loss: 5.8535 - reconstruction_loss: 1.3062 - kl_loss: 4.6978\n",
      "Success in episode 35 at time step 204\n",
      "Episode 36\n",
      "[-0.45295024  0.        ]\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 530us/step - loss: 5.7639 - reconstruction_loss: 1.3331 - kl_loss: 4.5020\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 536us/step - loss: 5.7395 - reconstruction_loss: 1.2709 - kl_loss: 4.5028\n",
      "No Success\n",
      "Episode 37\n",
      "[-0.44485533  0.        ]\n",
      "[0.44641612 0.37350669]\n",
      "tf.Tensor([ 0.9651801   0.9173072  -0.9163242  -0.9164517  -0.61982554], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "7/7 [==============================] - 0s 630us/step - loss: 6.5600 - reconstruction_loss: 1.1956 - kl_loss: 5.5112\n",
      "Epoch 2/2\n",
      "7/7 [==============================] - 0s 588us/step - loss: 6.7416 - reconstruction_loss: 1.1619 - kl_loss: 5.4893\n",
      "Success in episode 37 at time step 226\n",
      "Episode 38\n",
      "[-0.57085204  0.        ]\n",
      "[0.48467547 0.29315904]\n",
      "tf.Tensor([ 0.9787136   0.9768982  -0.49663472 -0.94532764 -0.6978502 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "12/12 [==============================] - 0s 597us/step - loss: 6.4877 - reconstruction_loss: 1.1846 - kl_loss: 5.2208\n",
      "Epoch 2/2\n",
      "12/12 [==============================] - 0s 575us/step - loss: 6.3580 - reconstruction_loss: 1.2805 - kl_loss: 5.1756\n",
      "Success in episode 38 at time step 380\n",
      "Episode 39\n",
      "[-0.44514108  0.        ]\n",
      "[-0.76237081  0.42460001]\n",
      "tf.Tensor([ 0.89983445  0.949412    0.91550064  0.5047957  -0.9490105 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - 0s 757us/step - loss: 4.4097 - reconstruction_loss: 1.2832 - kl_loss: 3.1965\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 0s 775us/step - loss: 4.6610 - reconstruction_loss: 1.3046 - kl_loss: 3.2002\n",
      "Success in episode 39 at time step 149\n",
      "Episode 40\n",
      "[-0.45099804  0.        ]\n",
      "[0.49815578 0.49676182]\n",
      "tf.Tensor([ 0.9588886   0.94861776 -0.69989896 -0.9204575  -0.84000653], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.0808 - reconstruction_loss: 0.9404 - kl_loss: 4.2115\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 0s 832us/step - loss: 5.5306 - reconstruction_loss: 1.1334 - kl_loss: 4.2071\n",
      "Success in episode 40 at time step 99\n"
     ]
    }
   ],
   "source": [
    "# train the agent on the env\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "agent, results = train_single_agent(env, daifa, observation_max, observation_min, observation_noise_stddev, num_episodes=40, action_repeats=6, num_actions_to_execute=5, train_on_full_data=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test the models produced"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ethan/python_repos/gym/gym/core.py:330: DeprecationWarning: \u001B[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001B[0m\n",
      "  deprecation(\n",
      "/Users/Ethan/python_repos/gym/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001B[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001B[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "data": {
      "text/plain": "(10740, 2)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_seqs = 20\n",
    "seq_length = 300\n",
    "ob_dim = 2\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "observations = []\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, 1000, epsilon=0.1)\n",
    "\n",
    "    o = transform_observations(o, observation_max, observation_min, observation_noise_stddev)\n",
    "\n",
    "    train = np.concatenate([o[:-1], a], axis=1)\n",
    "    # train = o[:-1]\n",
    "    test = o[-1]\n",
    "\n",
    "    observations.append(o)\n",
    "    ob_seqs.append(train)\n",
    "    next_obs.append(test)\n",
    "\n",
    "# ob_seqs = np.array(ob_seqs)\n",
    "# next_obs = np.array(next_obs)\n",
    "\n",
    "observations = np.vstack(observations)\n",
    "# observations = observations.reshape((num_seqs*(seq_length+1), ob_dim))\n",
    "\n",
    "# ob_seqs_stddev = np.ones_like(ob_seqs_flat)\n",
    "# next_obs_stddev = np.ones_like(ob_seqs_flat)\n",
    "\n",
    "observations.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.10825755,  0.05147636],\n       [-0.15054854, -0.03395247],\n       [-0.16731468, -0.08817429],\n       ...,\n       [ 0.83856054,  0.35450622],\n       [ 0.77111532,  0.34275715],\n       [ 0.85586775,  0.30161132]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float32, numpy=9.67474>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(agent.model_vae.compute_loss(observations))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Test the models produced\n",
    "num_seqs = 20\n",
    "seq_length = 300\n",
    "ob_dim = 2\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "observations = []\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, 1000, epsilon=0.1)\n",
    "\n",
    "    o = transform_observations(o, observation_max, observation_min, observation_noise_stddev)\n",
    "\n",
    "    train = np.concatenate([o[:-1], a], axis=1)\n",
    "    # train = o[:-1]\n",
    "    test = o[-1]\n",
    "\n",
    "    observations.append(o)\n",
    "    ob_seqs.append(train)\n",
    "    next_obs.append(test)\n",
    "\n",
    "# ob_seqs = np.array(ob_seqs)\n",
    "# next_obs = np.array(next_obs)\n",
    "\n",
    "observations = np.vstack(observations)\n",
    "# observations = observations.reshape((num_seqs*(seq_length+1), ob_dim))\n",
    "\n",
    "# ob_seqs_stddev = np.ones_like(ob_seqs_flat)\n",
    "# next_obs_stddev = np.ones_like(ob_seqs_flat)\n",
    "\n",
    "observations.shape\n",
    "observations\n",
    "agent.model_vae(observations)\n",
    "## Test EFE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test EFE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.83333333, 0.        ])"
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = create_encoder(2, 2, [20])\n",
    "dec = create_decoder(2, 2, [20])\n",
    "vae = VAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=1)\n",
    "\n",
    "pl_hoz = 5\n",
    "latent_dim = 2\n",
    "\n",
    "tran = TransitionGRU(2, 1, 12, 2*pl_hoz*latent_dim, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.45, 0]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_model = PriorModelBellman(2)\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "observation_noise_stddev = [0, 0]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0,0])  # no noise on prior\n",
    "\n",
    "# without prior model\n",
    "daifa = DAIFAgentRecurrent(None,\n",
    "                           vae,\n",
    "                           tran,\n",
    "                           scaled_prior_mean,\n",
    "                           prior_stddev,\n",
    "                           planning_horizon=pl_hoz,\n",
    "                           use_kl_extrinsic=True,\n",
    "                           use_kl_intrinsic=True,\n",
    "                           use_FEEF=False,\n",
    "                           vae_train_epochs=1,\n",
    "                           tran_train_epochs=1,\n",
    "                           show_vae_training=False)\n",
    "\n",
    "# with prior model\n",
    "daifa = DAIFAgentRecurrent(prior_model,\n",
    "                           vae,\n",
    "                           tran,\n",
    "                           None,\n",
    "                           None,\n",
    "                           planning_horizon=pl_hoz,\n",
    "                           use_kl_extrinsic=True,\n",
    "                           use_kl_intrinsic=True,\n",
    "                           use_FEEF=False,\n",
    "                           vae_train_epochs=1,\n",
    "                           tran_train_epochs=1,\n",
    "                           show_vae_training=False)\n",
    "\n",
    "scaled_prior_mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "[0.32907545 0.81204165]\n",
      "tf.Tensor([0.93988144 0.9176549  0.9576125  0.92440426 0.50135976], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "12/12 [==============================] - 0s 647us/step - loss: 79.1247 - reconstruction_loss: 66.5922 - kl_loss: 6.1959\n",
      "Epoch 2/2\n",
      "12/12 [==============================] - 0s 544us/step - loss: 56.3993 - reconstruction_loss: 49.0732 - kl_loss: 5.4928\n",
      "Success in episode 1 at time step 389\n",
      "Episode 2\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 438us/step - loss: 70.1578 - reconstruction_loss: 65.3552 - kl_loss: 3.8945\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 442us/step - loss: 62.2310 - reconstruction_loss: 58.4824 - kl_loss: 3.3635\n",
      "No Success\n",
      "Episode 3\n",
      "[0.69670431 0.33783742]\n",
      "tf.Tensor([ 0.9314696  -0.9435271   0.9645834   0.8415556   0.56516707], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "10/10 [==============================] - 0s 606us/step - loss: 52.3677 - reconstruction_loss: 45.6785 - kl_loss: 3.5939\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 0s 501us/step - loss: 46.2414 - reconstruction_loss: 41.3540 - kl_loss: 3.5405\n",
      "Success in episode 3 at time step 306\n",
      "Episode 4\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 490us/step - loss: 17.5091 - reconstruction_loss: 12.6776 - kl_loss: 1.7703\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 470us/step - loss: 9.0485 - reconstruction_loss: 6.6526 - kl_loss: 1.8981\n",
      "No Success\n",
      "Episode 5\n",
      "[0.49734786 0.77757351]\n",
      "tf.Tensor([ 0.98152953 -0.9801048   0.346932    0.32506007 -0.20486811], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 0s 522us/step - loss: 51.1933 - reconstruction_loss: 45.8139 - kl_loss: 2.3554\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 0s 481us/step - loss: 39.7211 - reconstruction_loss: 36.3924 - kl_loss: 2.5372\n",
      "Success in episode 5 at time step 426\n",
      "Episode 6\n",
      "[-0.08916565  0.69457532]\n",
      "tf.Tensor([ 0.86979437  0.9163867   0.45106322 -0.9567182  -0.96376824], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "17/17 [==============================] - 0s 620us/step - loss: 30.2887 - reconstruction_loss: 26.7621 - kl_loss: 1.6930\n",
      "Epoch 2/2\n",
      "17/17 [==============================] - 0s 506us/step - loss: 24.3142 - reconstruction_loss: 21.4270 - kl_loss: 2.6086\n",
      "Success in episode 6 at time step 560\n",
      "Episode 7\n",
      "[0.7740761  0.43105478]\n",
      "tf.Tensor([-0.8406548   0.22958903 -0.86530244  0.16205291  0.9585254 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 502us/step - loss: 51.1668 - reconstruction_loss: 44.3108 - kl_loss: 4.4013\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 642us/step - loss: 43.8689 - reconstruction_loss: 40.3531 - kl_loss: 4.6428\n",
      "Success in episode 7 at time step 242\n",
      "Episode 8\n",
      "[0.60109328 0.73302718]\n",
      "tf.Tensor([-0.9034789  -0.93242174 -0.9142734  -0.9228895  -0.82804745], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "30/30 [==============================] - 0s 599us/step - loss: 26.6581 - reconstruction_loss: 23.5741 - kl_loss: 3.7185\n",
      "Epoch 2/2\n",
      "30/30 [==============================] - 0s 631us/step - loss: 25.3964 - reconstruction_loss: 22.4093 - kl_loss: 3.5270\n",
      "Success in episode 8 at time step 945\n",
      "Episode 9\n",
      "[0.58582333 0.70690177]\n",
      "tf.Tensor([-0.7801693  -0.82969654 -0.92583454 -0.9501423  -0.8357265 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 0s 526us/step - loss: 37.6207 - reconstruction_loss: 32.8728 - kl_loss: 5.0782\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 0s 585us/step - loss: 35.9430 - reconstruction_loss: 31.7605 - kl_loss: 4.9600\n",
      "Success in episode 9 at time step 446\n",
      "Episode 10\n",
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 468us/step - loss: 30.1776 - reconstruction_loss: 25.5544 - kl_loss: 3.9946\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 503us/step - loss: 26.9137 - reconstruction_loss: 18.8948 - kl_loss: 4.4838\n",
      "No Success\n",
      "Episode 11\n",
      "[-0.13406156  0.91068   ]\n",
      "tf.Tensor([0.9825429  0.450113   0.8094051  0.96760887 0.9726515 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "15/15 [==============================] - 0s 635us/step - loss: 19.5421 - reconstruction_loss: 12.5481 - kl_loss: 6.4961\n",
      "Epoch 2/2\n",
      "15/15 [==============================] - 0s 612us/step - loss: 15.8965 - reconstruction_loss: 7.9619 - kl_loss: 6.8670\n",
      "Success in episode 11 at time step 495\n",
      "Episode 12\n",
      "[-0.26456655  0.80451077]\n",
      "tf.Tensor([0.9721597  0.9052161  0.9302739  0.83734506 0.75346595], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "25/25 [==============================] - 0s 580us/step - loss: 12.4143 - reconstruction_loss: 5.5323 - kl_loss: 7.1294\n",
      "Epoch 2/2\n",
      "25/25 [==============================] - 0s 607us/step - loss: 11.0802 - reconstruction_loss: 3.7463 - kl_loss: 6.8431\n",
      "Success in episode 12 at time step 818\n",
      "Episode 13\n",
      "[0.11189345 0.84674417]\n",
      "tf.Tensor([ 0.9897314   0.5497189  -0.90938026  0.67785156  0.9646587 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 0s 638us/step - loss: 8.1991 - reconstruction_loss: 3.2571 - kl_loss: 4.5878\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 0s 620us/step - loss: 7.5046 - reconstruction_loss: 2.8409 - kl_loss: 4.5775\n",
      "Success in episode 13 at time step 192\n",
      "Episode 14\n",
      "[0.50627537 0.85736673]\n",
      "tf.Tensor([-0.95708704 -0.93841213 -0.939945   -0.30885416  0.9591544 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "10/10 [==============================] - 0s 524us/step - loss: 12.8243 - reconstruction_loss: 3.9857 - kl_loss: 8.7120\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 0s 645us/step - loss: 11.9485 - reconstruction_loss: 3.3041 - kl_loss: 8.4940\n",
      "Success in episode 14 at time step 307\n",
      "Episode 15\n",
      "[0.40779439 0.87726324]\n",
      "tf.Tensor([-0.89853    -0.92443955 -0.9282573   0.4178334   0.95529646], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "16/16 [==============================] - 0s 541us/step - loss: 6.3207 - reconstruction_loss: 1.3305 - kl_loss: 5.0124\n",
      "Epoch 2/2\n",
      "16/16 [==============================] - 0s 582us/step - loss: 6.2795 - reconstruction_loss: 1.4447 - kl_loss: 4.9020\n",
      "Success in episode 15 at time step 509\n",
      "Episode 16\n",
      "[-0.12792678  0.90065215]\n",
      "tf.Tensor([ 0.97663975  0.85461074 -0.6157359  -0.80765086  0.89361745], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 784us/step - loss: 9.5037 - reconstruction_loss: 3.4068 - kl_loss: 6.1400\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 830us/step - loss: 9.5505 - reconstruction_loss: 2.9323 - kl_loss: 6.2233\n",
      "Success in episode 16 at time step 175\n",
      "Episode 17\n",
      "[0.34461867 0.76592857]\n",
      "tf.Tensor([-0.71878654 -0.7026098  -0.9614596   0.92464733  0.9633947 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 0s 636us/step - loss: 10.0144 - reconstruction_loss: 2.2789 - kl_loss: 7.3443\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 0s 611us/step - loss: 9.1990 - reconstruction_loss: 2.2846 - kl_loss: 7.2655\n",
      "Success in episode 17 at time step 195\n",
      "Episode 18\n",
      "[0.22763537 0.87905425]\n",
      "tf.Tensor([-0.50013196 -0.8199611  -0.9188756  -0.9499112   0.9782911 ], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 0s 474us/step - loss: 6.2820 - reconstruction_loss: 1.0543 - kl_loss: 5.1769\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 0s 524us/step - loss: 6.0942 - reconstruction_loss: 1.0928 - kl_loss: 5.0239\n",
      "Success in episode 18 at time step 434\n",
      "Episode 19\n",
      "[0.82519335 0.04704075]\n",
      "tf.Tensor([ 0.9419391  -0.95463955 -0.9360158  -0.943113    0.44610092], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 587us/step - loss: 9.0316 - reconstruction_loss: 2.9396 - kl_loss: 6.2023\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 541us/step - loss: 8.5861 - reconstruction_loss: 2.1607 - kl_loss: 6.2835\n",
      "Success in episode 19 at time step 242\n",
      "Episode 20\n",
      "[0.56574249 0.72304362]\n",
      "tf.Tensor([-0.9569217  -0.91001046 -0.92691606 -0.58486927  0.96289206], shape=(5,), dtype=float32)\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 598us/step - loss: 6.3744 - reconstruction_loss: 1.6380 - kl_loss: 4.6993\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 674us/step - loss: 6.1429 - reconstruction_loss: 1.4956 - kl_loss: 4.6901\n",
      "Success in episode 20 at time step 147\n"
     ]
    }
   ],
   "source": [
    "# train the agent on the env\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "agent, results = train_agent(env, daifa, observation_max, observation_min, observation_noise_stddev, num_episodes=20, action_repeats=10, num_actions_to_execute=2, train_on_full_data=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "data": {
      "text/plain": "(12806, 2)"
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test the models produced\n",
    "num_seqs = 20\n",
    "seq_length = 300\n",
    "ob_dim = 2\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "observations = []\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, 1000, epsilon=0.1)\n",
    "\n",
    "    o = transform_observations(o, observation_max, observation_min, observation_noise_stddev)\n",
    "\n",
    "    train = np.concatenate([o[:-1], a], axis=1)\n",
    "    # train = o[:-1]\n",
    "    test = o[-1]\n",
    "\n",
    "    observations.append(o)\n",
    "    ob_seqs.append(train)\n",
    "    next_obs.append(test)\n",
    "\n",
    "# ob_seqs = np.array(ob_seqs)\n",
    "# next_obs = np.array(next_obs)\n",
    "\n",
    "observations = np.vstack(observations)\n",
    "# observations = observations.reshape((num_seqs*(seq_length+1), ob_dim))\n",
    "\n",
    "# ob_seqs_stddev = np.ones_like(ob_seqs_flat)\n",
    "# next_obs_stddev = np.ones_like(ob_seqs_flat)\n",
    "\n",
    "observations.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.27734923,  0.        ],\n       [-0.27835019, -0.01286914],\n       [-0.28034457, -0.02564205],\n       ...,\n       [ 0.78566315,  0.35808382],\n       [ 0.81395161,  0.36370895],\n       [ 0.8428795 ,  0.37193014]])"
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(12806, 2), dtype=float32, numpy=\narray([[-0.26162374, -0.03878228],\n       [-0.27726045, -0.06711522],\n       [-0.24541792, -0.04369228],\n       ...,\n       [ 0.7668527 ,  0.39962938],\n       [ 0.93341327,  0.4722877 ],\n       [ 0.8112131 ,  0.41610983]], dtype=float32)>"
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.model_vae(observations)\n",
    "## Test EFE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing the Identity VAE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "enc = identity_encoder\n",
    "dec = identity_decoder\n",
    "idvae = IdentityVAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "hidden_size = 2*2*15  # 2*latent_dim * planning_size\n",
    "tran = TransitionGRU(2, 1, 12, hidden_size, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.6, 0]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "observation_noise_stddev = [0, 0]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0,0])  # no noise on prior\n",
    "\n",
    "daifa = DAIFAgentRecurrent(None, idvae, tran, scaled_prior_mean, prior_stddev)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "agent, succeeded, time_to_success = train_agent(env, daifa, observation_max, observation_min, observation_noise_stddev, num_episodes=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out = agent.tran((ob_seqs[0:1], None))\n",
    "out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = ob_seqs[0:1, -1].reshape(1,1,3)\n",
    "h = out[3]\n",
    "h = h[0, -2, :]\n",
    "h = h.numpy().reshape(1,30)\n",
    "h"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agent.tran((t, h))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ob_seqs[0:1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test to see how the agent trains on standard observation data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "enc = identity_encoder\n",
    "dec = identity_decoder\n",
    "idvae = IdentityVAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "hidden_size = 2*2*15  # 2*latent_dim * planning_size\n",
    "tran = TransitionGRU(2, 1, 12, hidden_size, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.45, 0]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "observation_noise_stddev = [0, 0]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0,0])  # no noise on prior\n",
    "\n",
    "daifa = DAIFAgentRecurrent(None, idvae, tran, scaled_prior_mean, prior_stddev, vae_train_epochs=1, tran_train_epochs=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "success, agent, t, pre_obs, post_obs, acts = run_episode(env, daifa, observation_max, observation_min, observation_noise_stddev)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pre_np = np.array(pre_obs)\n",
    "a = np.array(acts)\n",
    "a.shape\n",
    "pre_a = np.concatenate([pre_np, a], axis=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(a.max(), a.min())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pre_a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "post_obs_to_predict = np.array(post_obs)[:, 14, :]\n",
    "post_obs_to_predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agent.tran((pre_a, None))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "post_obs_to_predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Examine training the model on the observation data\n",
    "\n",
    "Does it eventually converge to a good model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_train_runs = 1\n",
    "for i in range(num_train_runs):\n",
    "\n",
    "    for j in range(len(pre)):\n",
    "        pre = pre_obs[j]\n",
    "        post = post_obs[j]\n",
    "        actions = acts[j]\n",
    "\n",
    "        daifa.train(pre, post, actions, None, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daifa.cem_policy_optimisation(np.array([0.5, 0.1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daifa.cem_policy_optimisation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test the FEEF computations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  0.5]\n"
     ]
    }
   ],
   "source": [
    "# enc = create_encoder(2, 2, [20])\n",
    "# dec = create_decoder(2, 2, [20])\n",
    "# vae = VAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "enc = identity_encoder\n",
    "dec = identity_decoder\n",
    "idvae = IdentityVAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "tran = TransitionGRU(2, 1, 12, 60, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.6, 0]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "observation_noise_stddev = [0, 0]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0, 0])  # no noise on prior\n",
    "\n",
    "print(scaled_prior_mean)\n",
    "\n",
    "daifa = DAIFAgentRecurrent(None, idvae, tran, scaled_prior_mean, prior_stddev, planning_horizon=15, n_policy_candidates=70, n_policies=1500, n_cem_policy_iterations=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "WARNING:tensorflow:From /Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/tensorflow_probability/python/distributions/distribution.py:345: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`scale_identity_multiplier` is deprecated; please combine it into `scale_diag` directly instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-06 15:23:48.777636: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "agent, succeeded, time_to_success = train_agent(env, daifa, observation_max, observation_min, observation_noise_stddev,\n",
    "                                                num_episodes=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_policy(agent, env, policy, action_repeats):\n",
    "\n",
    "    observation = env.reset()\n",
    "    obs = transform_observations(observation, observation_max, observation_min, [0, 0])\n",
    "\n",
    "    z_t_minus_1 = obs\n",
    "    p, s = agent.cem_policy_optimisation(z_t_minus_1)\n",
    "    p\n",
    "    print(obs)\n",
    "    print(p)\n",
    "\n",
    "    for action in p:\n",
    "        for t in range(action_repeats):\n",
    "            res = env.step(np.array([action]))\n",
    "            print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "z_t_minus_1 = np.array([0, 0])\n",
    "p, s = agent.cem_policy_optimisation(z_t_minus_1)\n",
    "p\n",
    "\n",
    "agent.forward_policies(p, z_t_minus_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "test_policy(agent, env, p.numpy(), 6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "z_t_minus_1 = np.array([-0.27691475,  0.01688306])\n",
    "p, s = agent.cem_policy_optimisation(z_t_minus_1)\n",
    "p"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "\n",
    "from vae_recurrent import VAE\n",
    "\n",
    "\n",
    "class DAIFAgentRecurrent:\n",
    "\n",
    "    def __init__(self,\n",
    "                 prior_model,\n",
    "                 vae,\n",
    "                 tran,\n",
    "                 given_prior_mean,\n",
    "                 given_prior_stddev,\n",
    "                 planning_horizon=15,\n",
    "                 n_policies=1500,\n",
    "                 n_cem_policy_iterations=2,\n",
    "                 n_policy_candidates=70,\n",
    "                 tran_train_epochs=1,\n",
    "                 vae_train_epochs=1,\n",
    "                 agent_time_ratio=6,\n",
    "                 train_vae=True,\n",
    "                 train_tran=True):\n",
    "\n",
    "        super(DAIFAgentRecurrent, self).__init__()\n",
    "\n",
    "        self.prior_model = prior_model\n",
    "        self.planning_horizon = planning_horizon\n",
    "        self.n_policy_candidates = n_policy_candidates\n",
    "        self.n_policies = n_policies\n",
    "        self.n_cem_policy_iterations = n_cem_policy_iterations\n",
    "\n",
    "        self.vae_train_epochs = vae_train_epochs\n",
    "        self.tran_train_epochs = tran_train_epochs\n",
    "        self.train_vae = train_vae\n",
    "        self.train_tran = train_tran\n",
    "\n",
    "        self.given_prior_mean = given_prior_mean\n",
    "        self.given_prior_stddev = given_prior_stddev\n",
    "\n",
    "        # full vae\n",
    "        self.model_vae = vae\n",
    "        self.model_vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "        # transition\n",
    "        # takes action plus last state and outputs next latent state\n",
    "        self.tran = tran\n",
    "        self.tran.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "        self.hidden_state = None\n",
    "\n",
    "        # how much is the agents planning time compressed compared to the simulation time\n",
    "        self.agent_time_ratio = agent_time_ratio\n",
    "\n",
    "\n",
    "    def select_policy(self, observation):\n",
    "\n",
    "        policy_mean, policy_stddev = self.cem_policy_optimisation(observation)\n",
    "\n",
    "        # return a distribution that we can sample from\n",
    "        return tfp.distributions.MultivariateNormalDiag(loc=policy_mean, scale_diag=policy_stddev)\n",
    "\n",
    "\n",
    "    def train(self, pre_observations_raw, post_observations_raw, actions_complete, rewards, verbose=0):\n",
    "\n",
    "        # compress the observations based on the agents time compression factor\n",
    "        # pre_observations = pre_observations_raw[::self.agent_time_ratio]  # for example take every 6th element\n",
    "        # post_observations = np.array([post_observations_raw[i] for i in range(len(post_observations_raw)) if i % self.agent_time_ratio == self.agent_time_ratio - 1])\n",
    "        #\n",
    "        # print(pre_observations_raw)\n",
    "        # print(pre_observations)\n",
    "        # print(post_observations_raw)\n",
    "        # print(post_observations)\n",
    "\n",
    "        pre_observations = pre_observations_raw\n",
    "        post_observations = post_observations_raw\n",
    "\n",
    "        # only look at the first n actions that we took\n",
    "        actions = actions_complete[0: len(pre_observations)]\n",
    "\n",
    "        num_observations = pre_observations.shape[0]\n",
    "        observation_dim = pre_observations.shape[1]\n",
    "        action_dim = actions.shape[1]\n",
    "        # action_dim = 1  # TODO fix this to allow different actions\n",
    "\n",
    "        # find the actual observed latent states using the vae\n",
    "        pre_latent_mean, pre_latent_stddev, pre_latent = self.model_vae.encoder(pre_observations)\n",
    "        post_latent_mean, post_latent_stddev, post_latent = self.model_vae.encoder(post_observations)\n",
    "\n",
    "        # set up the input training data that we use to train the transition model\n",
    "        z_train = np.concatenate([np.array(pre_latent_mean), np.array(actions)], axis=1)\n",
    "\n",
    "        # we use the sequence to find the right hidden states to use as input\n",
    "        z_train_seq = z_train.reshape((1, num_observations, observation_dim + action_dim))\n",
    "        z_train_singles = z_train.reshape(num_observations, 1, observation_dim + action_dim)\n",
    "\n",
    "        # the previous hidden state is the memory after observing some sequences but it might be None\n",
    "        if self.hidden_state is None:\n",
    "            self.hidden_state = np.zeros((1, self.tran.hidden_units))\n",
    "\n",
    "        if self.train_tran:\n",
    "            # find the hidden states at t=0, t=1, t=2, ..., t=num_observations - 1\n",
    "            _, _, _, h_states = self.tran((z_train_seq, self.hidden_state))\n",
    "\n",
    "\n",
    "            # squeeze so we make the shape [num_observations, hidden_units]\n",
    "            h_states = tf.squeeze(h_states)\n",
    "\n",
    "            # exclude the last state as this will become the hidden state later on. next hidden state will become our new memory\n",
    "            h_states_for_training = h_states[:-1]\n",
    "            # next_hidden_state = h_states[-1]\n",
    "\n",
    "            # add the current hidden state we saved to the start. This has h0, h1, h2, .. h=num_observations - 1\n",
    "            h_states_for_training = tf.concat([self.hidden_state, h_states_for_training], axis=0)\n",
    "\n",
    "\n",
    "            # use the hidden states with the pre and post observations to train transition model\n",
    "            self.tran.fit((z_train_singles, h_states_for_training), (post_latent_mean, post_latent_stddev), epochs=self.tran_train_epochs, verbose=verbose)\n",
    "\n",
    "        # now find the new predicted hidden state that we will use for finding the policy\n",
    "        # TODO not sure if I should pass the old hidden state or reset it to 0\n",
    "        _, _, final_hidden_state, _ = self.tran((z_train_seq, self.hidden_state))\n",
    "        # _, _, final_hidden_state, _ = self.tran((z_train_seq, None))\n",
    "\n",
    "        self.hidden_state = final_hidden_state\n",
    "\n",
    "        #### TRAIN THE VAE ####\n",
    "        if self.train_vae:\n",
    "            # train the vae model on post_observations because these are all new\n",
    "            self.model_vae.fit(post_observations, epochs=self.vae_train_epochs, verbose=verbose)\n",
    "\n",
    "\n",
    "\n",
    "    def cem_policy_optimisation(self, z_t_minus_one):\n",
    "\n",
    "        # need to change these two if the policy dimension changes\n",
    "        mean_best_policies = tf.zeros(self.planning_horizon)\n",
    "        std_best_policies = tf.ones(self.planning_horizon)\n",
    "\n",
    "        for i in range(self.n_cem_policy_iterations):\n",
    "            policy_distr = tfp.distributions.MultivariateNormalDiag(loc=mean_best_policies, scale_diag=std_best_policies)\n",
    "            policies = policy_distr.sample([self.n_policies])\n",
    "            policies = tf.clip_by_value(policies, clip_value_min=-1, clip_value_max=1)\n",
    "\n",
    "            # project trajectory into the future using transition model and calculate FEEF for each policy\n",
    "            policy_results = self.forward_policies(policies.numpy(), z_t_minus_one)\n",
    "            FEEFs = self.evaluate_policy(*policy_results)\n",
    "\n",
    "            FEEFs = tf.convert_to_tensor(FEEFs)\n",
    "\n",
    "            # sum over the timesteps to get the FEEF for each policy\n",
    "            FEEFs_sum = tf.reduce_sum(FEEFs, axis=0)\n",
    "\n",
    "            # multiply by one to find largest value which is euqivalent to smallest FEEF with top_k\n",
    "            neg_FEEF_sum = -1*FEEFs_sum\n",
    "\n",
    "            result = tf.math.top_k(neg_FEEF_sum, self.n_policy_candidates, sorted=False)\n",
    "            min_FEEF_indices = result.indices\n",
    "\n",
    "            # update the policy distributions\n",
    "            mean_best_policies = tf.reduce_mean(tf.gather(policies, min_FEEF_indices), axis=0)\n",
    "            std_best_policies = tf.math.reduce_std(tf.gather(policies, min_FEEF_indices), axis=0)\n",
    "\n",
    "\n",
    "        # TODO not sure why we need all of this is with the x means? I think it's for training but maybe not\n",
    "\n",
    "        # One last forward pass to gather the stats of the policy mean\n",
    "        #FEEFs, next_x_means, next_x_stds = self._forward_policies(mean_best_policies.unsqueeze(1))\n",
    "        # return mean_best_policies, std_best_policies, FEEFs.detach().squeeze(1), next_x_means.detach().squeeze(1), next_x_stds.detach().squeeze(1)\n",
    "\n",
    "        print(z_t_minus_one)\n",
    "        print(mean_best_policies)\n",
    "        return mean_best_policies, std_best_policies\n",
    "\n",
    "\n",
    "    def forward_policies(self, policies, z_t_minus_one):\n",
    "        \"\"\"\n",
    "        Forward propogate a policy and compute the FEEF of each policy\n",
    "        :param z_t_minus_one:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # stack up the new observation to have shape [self.n_policies, len(z_t_minus_one)]\n",
    "        prev_latent_mean = np.stack([z_t_minus_one]*self.n_policies)\n",
    "\n",
    "        policy_posteriors = []\n",
    "        policy_sds = []\n",
    "        likelihoods = []\n",
    "        z_means = []\n",
    "        z_sds = []\n",
    "\n",
    "        # get the starting hidden state that coressponds to the memory stored by the previous sequences. Should have shape (1, self.tran.num_hidden_units) for the observed sequence\n",
    "        # extend the current hidden state to the number of policies present\n",
    "        if self.hidden_state is None:\n",
    "            cur_hidden_state = np.zeros((self.n_policies, self.tran.hidden_units))\n",
    "        else:\n",
    "            cur_hidden_state = np.vstack([self.hidden_state]*self.n_policies)\n",
    "\n",
    "        # print(cur_hidden_state)\n",
    "\n",
    "        # find the predicted latent states from the transition model\n",
    "        for t in range(self.planning_horizon):\n",
    "\n",
    "            ob_plus_action = np.concatenate([prev_latent_mean, policies[:, t].reshape(self.n_policies, 1)], axis=1)\n",
    "            tran_input = ob_plus_action.reshape((self.n_policies, 1, ob_plus_action.shape[1]))  # reshape to pass to GRU\n",
    "\n",
    "            next_latent_mean, next_latent_sd, next_hidden_state, _ = self.tran((tran_input, cur_hidden_state))  # shape = [num policies, latent dim\n",
    "\n",
    "            # update the hidden state for use with the next policies\n",
    "            cur_hidden_state = next_hidden_state\n",
    "\n",
    "            policy_posteriors.append(next_latent_mean)\n",
    "            policy_sds.append(next_latent_sd)\n",
    "\n",
    "            next_likelihoods = self.model_vae.decoder(next_latent_mean)\n",
    "            likelihoods.append(next_likelihoods)\n",
    "\n",
    "            next_posterior_means, next_posteriors_sds, next_posteriors_z = self.model_vae.encoder(next_likelihoods)\n",
    "            z_means.append(next_posterior_means)\n",
    "            z_sds.append(next_posteriors_sds)\n",
    "\n",
    "            prev_latent_mean = next_latent_mean\n",
    "\n",
    "        return policy_posteriors, policy_sds, likelihoods, z_means, z_sds\n",
    "\n",
    "\n",
    "    def evaluate_policy(self, policy_posteriors, policy_sd, predicted_likelihood, predicted_posterior, predicted_posterior_sd):\n",
    "\n",
    "        return self.FEEF(policy_posteriors, policy_sd, predicted_likelihood, predicted_posterior, predicted_posterior_sd)\n",
    "\n",
    "\n",
    "    def FEEF(self, policy_posteriors_list, policy_sd_list, predicted_likelihood_list, predicted_posterior_list, predicted_posterior_sd_list):\n",
    "        \"\"\"\n",
    "        Compute the FEEF for policy selection\n",
    "        :param policy_posteriors:\n",
    "        :param predicted_likelihood:\n",
    "        :param predicted_posterior:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        FEEFs = []\n",
    "\n",
    "        for t in range(self.planning_horizon):\n",
    "\n",
    "            # extract the values for each time step\n",
    "            predicted_likelihood = predicted_likelihood_list[t]\n",
    "            policy_posteriors = policy_posteriors_list[t]\n",
    "            policy_sd = policy_sd_list[t]\n",
    "            predicted_posterior = predicted_posterior_list[t]\n",
    "            predicted_posterior_sd = predicted_posterior_sd_list[t]\n",
    "\n",
    "            # !!!! evaluate the EXTRINSIC KL divergence !!!!\n",
    "\n",
    "            # convert to normal distributions\n",
    "            # TODO Why is the stddev 1s here? I think because we assume it is on the true state of the world.\n",
    "            likelihood_dist = tfp.distributions.MultivariateNormalDiag(loc=predicted_likelihood, scale_diag=np.ones_like(predicted_likelihood))\n",
    "\n",
    "            if self.prior_model is None:\n",
    "\n",
    "                # TODO how exactly is the prior defined? After you apply transformations what is the prior\n",
    "                # create the prior distribution\n",
    "                prior_preferences_mean = tf.convert_to_tensor(np.stack([self.given_prior_mean]*self.n_policies), dtype=\"float32\")\n",
    "                prior_preferences_stddev = tf.convert_to_tensor(np.stack([self.given_prior_stddev]*self.n_policies), dtype=\"float32\")\n",
    "\n",
    "                prior_dist = tfp.distributions.MultivariateNormalDiag(loc=prior_preferences_mean, scale_diag=prior_preferences_stddev)\n",
    "\n",
    "            # TODO Fix the learned prior model\n",
    "            else:\n",
    "                prior_dist = self.prior_model()\n",
    "\n",
    "            kl_extrinsic = tfp.distributions.kl_divergence(likelihood_dist, prior_dist)\n",
    "\n",
    "            # !!!! evaluate the KL INTRINSIC part !!!!\n",
    "            policy_posteriors_dist = tfp.distributions.MultivariateNormalDiag(loc=policy_posteriors, scale_diag=policy_sd)\n",
    "            predicted_posterior_dist = tfp.distributions.MultivariateNormalDiag(loc=predicted_posterior, scale_diag=predicted_posterior_sd)\n",
    "\n",
    "            kl_intrinsic = tfp.distributions.kl_divergence(predicted_posterior_dist, policy_posteriors_dist)\n",
    "\n",
    "            FEEF = kl_extrinsic - kl_intrinsic\n",
    "\n",
    "            FEEFs.append(FEEF)\n",
    "\n",
    "        return FEEFs\n",
    "\n",
    "\n",
    "    def EFE(self, policy_posteriors, predicted_likelihood, predicted_posterior):\n",
    "        \"\"\"\n",
    "        Compute the EFE for policy selection\n",
    "        :param policy_posteriors:\n",
    "        :param predicted_likelihood:\n",
    "        :param predicted_posterior:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing with a pretrained transition model\n",
    "\n",
    "This works well! So the problem can't lie with the transition model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# enc = create_encoder(2, 2, [20])\n",
    "# dec = create_decoder(2, 2, [20])\n",
    "# vae = VAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "enc = identity_encoder\n",
    "dec = identity_decoder\n",
    "idvae = IdentityVAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "tran = TransitionGRU(2, 1, 12, 60, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.6, 0.07]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "observation_noise_stddev = [0, 0]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0, 0])  # no noise on prior\n",
    "\n",
    "print(scaled_prior_mean)\n",
    "\n",
    "daifa = DAIFAgentRecurrent(None, idvae, tran, scaled_prior_mean, prior_stddev, train_vae=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [],
   "source": [
    "num_seqs = 200\n",
    "seq_length = 500\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "next_obs_stddev = []\n",
    "actions = []\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, seq_length, epsilon=0.2)\n",
    "\n",
    "    o = transform_observations(o, observation_max, observation_min, [0, 0])\n",
    "\n",
    "    # train = np.concatenate([o[:-1], a], axis=1)\n",
    "    train = o[:-1]\n",
    "    test = o[1:]\n",
    "\n",
    "    actions.append(a)\n",
    "    ob_seqs.append(train)\n",
    "    next_obs.append(test)\n",
    "\n",
    "    ob_seqs_stddev = np.ones_like(train)\n",
    "    next_stddev = np.ones_like(test)\n",
    "\n",
    "    next_obs_stddev.append(next_stddev)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 1ms/step - kl_loss: 0.1993\n",
      "16/16 [==============================] - 0s 1ms/step - kl_loss: 0.0497\n",
      "16/16 [==============================] - 0s 1ms/step - kl_loss: 0.0132\n",
      "16/16 [==============================] - 0s 1ms/step - kl_loss: 0.0103\n",
      "16/16 [==============================] - 0s 1ms/step - kl_loss: 0.0097\n",
      "6/6 [==============================] - 0s 1ms/step - kl_loss: 0.0108\n",
      "16/16 [==============================] - 0s 967us/step - kl_loss: 0.0029\n",
      "16/16 [==============================] - 0s 940us/step - kl_loss: 0.0020\n",
      "15/15 [==============================] - 0s 882us/step - kl_loss: 0.0047\n",
      "16/16 [==============================] - 0s 853us/step - kl_loss: 0.0054\n",
      "16/16 [==============================] - 0s 885us/step - kl_loss: 0.0074\n",
      "16/16 [==============================] - 0s 943us/step - kl_loss: 0.0113\n",
      "8/8 [==============================] - 0s 920us/step - kl_loss: 0.0256\n",
      "16/16 [==============================] - 0s 891us/step - kl_loss: 0.0049\n",
      "16/16 [==============================] - 0s 923us/step - kl_loss: 0.0037\n",
      "16/16 [==============================] - 0s 905us/step - kl_loss: 0.0038\n",
      "16/16 [==============================] - 0s 860us/step - kl_loss: 0.0033\n",
      "14/14 [==============================] - 0s 896us/step - kl_loss: 0.0033\n",
      "16/16 [==============================] - 0s 928us/step - kl_loss: 0.0012\n",
      "7/7 [==============================] - 0s 964us/step - kl_loss: 0.0033\n",
      "16/16 [==============================] - 0s 853us/step - kl_loss: 6.2965e-04\n",
      "16/16 [==============================] - 0s 895us/step - kl_loss: 3.8473e-04\n",
      "16/16 [==============================] - 0s 886us/step - kl_loss: 9.0204e-04\n",
      "16/16 [==============================] - 0s 866us/step - kl_loss: 3.5106e-04\n",
      "7/7 [==============================] - 0s 948us/step - kl_loss: 0.0014\n",
      "16/16 [==============================] - 0s 921us/step - kl_loss: 0.0011\n",
      "16/16 [==============================] - 0s 897us/step - kl_loss: 2.8698e-04\n",
      "16/16 [==============================] - 0s 918us/step - kl_loss: 3.7622e-04\n",
      "12/12 [==============================] - 0s 979us/step - kl_loss: 7.3435e-04\n",
      "16/16 [==============================] - 0s 872us/step - kl_loss: 6.9894e-04\n",
      "16/16 [==============================] - 0s 845us/step - kl_loss: 3.9676e-04\n",
      "16/16 [==============================] - 0s 873us/step - kl_loss: 9.3522e-04\n",
      "16/16 [==============================] - 0s 898us/step - kl_loss: 5.7943e-04\n",
      "16/16 [==============================] - 0s 861us/step - kl_loss: 3.5893e-04\n",
      "16/16 [==============================] - 0s 927us/step - kl_loss: 4.9170e-04\n",
      "16/16 [==============================] - 0s 875us/step - kl_loss: 2.7267e-04\n",
      "16/16 [==============================] - 0s 838us/step - kl_loss: 1.5856e-04\n",
      "6/6 [==============================] - 0s 1ms/step - kl_loss: 9.0418e-04\n",
      "16/16 [==============================] - 0s 886us/step - kl_loss: 5.7081e-04\n",
      "12/12 [==============================] - 0s 907us/step - kl_loss: 4.9615e-04\n",
      "16/16 [==============================] - 0s 878us/step - kl_loss: 6.9546e-04\n",
      "16/16 [==============================] - 0s 857us/step - kl_loss: 2.8895e-04\n",
      "13/13 [==============================] - 0s 899us/step - kl_loss: 7.5522e-04\n",
      "16/16 [==============================] - 0s 857us/step - kl_loss: 6.0688e-04\n",
      "11/11 [==============================] - 0s 921us/step - kl_loss: 5.8398e-04\n",
      "9/9 [==============================] - 0s 976us/step - kl_loss: 0.0012\n",
      "16/16 [==============================] - 0s 898us/step - kl_loss: 6.1929e-04\n",
      "16/16 [==============================] - 0s 836us/step - kl_loss: 2.2836e-04\n",
      "10/10 [==============================] - 0s 916us/step - kl_loss: 5.1460e-04\n",
      "16/16 [==============================] - 0s 867us/step - kl_loss: 4.9099e-04\n",
      "16/16 [==============================] - 0s 858us/step - kl_loss: 3.6082e-04\n",
      "16/16 [==============================] - 0s 889us/step - kl_loss: 3.1299e-04\n",
      "16/16 [==============================] - 0s 902us/step - kl_loss: 8.5156e-04\n",
      "16/16 [==============================] - 0s 921us/step - kl_loss: 0.0018\n",
      "16/16 [==============================] - 0s 852us/step - kl_loss: 0.0030\n",
      "10/10 [==============================] - 0s 915us/step - kl_loss: 0.0085\n",
      "16/16 [==============================] - 0s 897us/step - kl_loss: 0.0071\n",
      "16/16 [==============================] - 0s 917us/step - kl_loss: 0.0035\n",
      "16/16 [==============================] - 0s 873us/step - kl_loss: 0.0035\n",
      "16/16 [==============================] - 0s 890us/step - kl_loss: 0.0026\n",
      "16/16 [==============================] - 0s 882us/step - kl_loss: 0.0020\n",
      "7/7 [==============================] - 0s 966us/step - kl_loss: 0.0028\n",
      "16/16 [==============================] - 0s 896us/step - kl_loss: 0.0013\n",
      "12/12 [==============================] - 0s 911us/step - kl_loss: 0.0014\n",
      "14/14 [==============================] - 0s 918us/step - kl_loss: 0.0015\n",
      "16/16 [==============================] - 0s 880us/step - kl_loss: 8.1093e-04\n",
      "16/16 [==============================] - 0s 859us/step - kl_loss: 5.0124e-04\n",
      "16/16 [==============================] - 0s 862us/step - kl_loss: 2.6348e-04\n",
      "8/8 [==============================] - 0s 976us/step - kl_loss: 5.0341e-04\n",
      "10/10 [==============================] - 0s 871us/step - kl_loss: 4.9221e-04\n",
      "16/16 [==============================] - 0s 873us/step - kl_loss: 2.3029e-04\n",
      "16/16 [==============================] - 0s 906us/step - kl_loss: 6.5155e-05\n",
      "10/10 [==============================] - 0s 918us/step - kl_loss: 5.9321e-04\n",
      "16/16 [==============================] - 0s 912us/step - kl_loss: 3.2684e-04\n",
      "16/16 [==============================] - 0s 874us/step - kl_loss: 1.7592e-04\n",
      "16/16 [==============================] - 0s 863us/step - kl_loss: 1.6582e-04\n",
      "16/16 [==============================] - 0s 864us/step - kl_loss: 1.8564e-04\n",
      "16/16 [==============================] - 0s 925us/step - kl_loss: 1.4003e-04\n",
      "16/16 [==============================] - 0s 915us/step - kl_loss: 1.7503e-04\n",
      "12/12 [==============================] - 0s 975us/step - kl_loss: 2.7620e-04\n",
      "16/16 [==============================] - 0s 935us/step - kl_loss: 2.7183e-04\n",
      "11/11 [==============================] - 0s 942us/step - kl_loss: 4.2113e-04\n",
      "16/16 [==============================] - 0s 867us/step - kl_loss: 4.4761e-04\n",
      "12/12 [==============================] - 0s 916us/step - kl_loss: 2.7003e-04\n",
      "13/13 [==============================] - 0s 886us/step - kl_loss: 5.0503e-04\n",
      "12/12 [==============================] - 0s 891us/step - kl_loss: 4.9012e-04\n",
      "16/16 [==============================] - 0s 888us/step - kl_loss: 2.4893e-04\n",
      "16/16 [==============================] - 0s 1ms/step - kl_loss: 1.1987e-04\n",
      "16/16 [==============================] - 0s 875us/step - kl_loss: 2.8243e-04\n",
      "16/16 [==============================] - 0s 902us/step - kl_loss: 1.1809e-04\n",
      "16/16 [==============================] - 0s 875us/step - kl_loss: 7.0822e-05\n",
      "16/16 [==============================] - 0s 875us/step - kl_loss: 6.8286e-05\n",
      "16/16 [==============================] - 0s 900us/step - kl_loss: 2.7148e-04\n",
      "15/15 [==============================] - 0s 960us/step - kl_loss: 1.1328e-04\n",
      "16/16 [==============================] - 0s 859us/step - kl_loss: 1.6294e-04\n",
      "16/16 [==============================] - 0s 899us/step - kl_loss: 9.3267e-05\n",
      "13/13 [==============================] - 0s 930us/step - kl_loss: 2.7863e-04\n",
      "16/16 [==============================] - 0s 902us/step - kl_loss: 3.4847e-04\n",
      "16/16 [==============================] - 0s 909us/step - kl_loss: 6.9290e-05\n",
      "16/16 [==============================] - 0s 902us/step - kl_loss: 2.5452e-04\n",
      "16/16 [==============================] - 0s 904us/step - kl_loss: 2.0722e-04\n",
      "16/16 [==============================] - 0s 903us/step - kl_loss: 1.6057e-04\n",
      "16/16 [==============================] - 0s 996us/step - kl_loss: 1.6325e-04\n",
      "10/10 [==============================] - 0s 981us/step - kl_loss: 2.9550e-04\n",
      "16/16 [==============================] - 0s 905us/step - kl_loss: 2.2208e-04\n",
      "16/16 [==============================] - 0s 880us/step - kl_loss: 1.4792e-04\n",
      "14/14 [==============================] - 0s 876us/step - kl_loss: 2.6079e-04\n",
      "16/16 [==============================] - 0s 906us/step - kl_loss: 2.2629e-04\n",
      "16/16 [==============================] - 0s 927us/step - kl_loss: 1.7176e-04\n",
      "16/16 [==============================] - 0s 863us/step - kl_loss: 7.7746e-05\n",
      "16/16 [==============================] - 0s 907us/step - kl_loss: 4.9998e-05\n",
      "16/16 [==============================] - 0s 906us/step - kl_loss: 9.7333e-05\n",
      "16/16 [==============================] - 0s 875us/step - kl_loss: 9.3879e-06\n",
      "16/16 [==============================] - 0s 871us/step - kl_loss: 3.5369e-05\n",
      "16/16 [==============================] - 0s 881us/step - kl_loss: 6.1430e-05\n",
      "16/16 [==============================] - 0s 913us/step - kl_loss: 3.4472e-05\n",
      "16/16 [==============================] - 0s 881us/step - kl_loss: 4.7960e-05\n",
      "11/11 [==============================] - 0s 988us/step - kl_loss: 1.9969e-04\n",
      "16/16 [==============================] - 0s 886us/step - kl_loss: 1.3500e-04\n",
      "9/9 [==============================] - 0s 959us/step - kl_loss: 1.3400e-04\n",
      "15/15 [==============================] - 0s 927us/step - kl_loss: 1.8833e-04\n",
      "16/16 [==============================] - 0s 889us/step - kl_loss: 1.6533e-04\n",
      "16/16 [==============================] - 0s 855us/step - kl_loss: 4.5978e-05\n",
      "16/16 [==============================] - 0s 881us/step - kl_loss: 6.0070e-05\n",
      "16/16 [==============================] - 0s 878us/step - kl_loss: 1.2162e-04\n",
      "16/16 [==============================] - 0s 942us/step - kl_loss: 9.9278e-05\n",
      "16/16 [==============================] - 0s 919us/step - kl_loss: 6.8983e-05\n",
      "16/16 [==============================] - 0s 935us/step - kl_loss: 3.9110e-05\n",
      "16/16 [==============================] - 0s 885us/step - kl_loss: 3.2605e-05\n",
      "16/16 [==============================] - 0s 908us/step - kl_loss: 5.6698e-05\n",
      "16/16 [==============================] - 0s 912us/step - kl_loss: 4.7928e-05\n",
      "16/16 [==============================] - 0s 857us/step - kl_loss: 1.7173e-04\n",
      "10/10 [==============================] - 0s 866us/step - kl_loss: 1.5600e-04\n",
      "16/16 [==============================] - 0s 848us/step - kl_loss: 1.7683e-04\n",
      "10/10 [==============================] - 0s 940us/step - kl_loss: 1.8164e-04\n",
      "10/10 [==============================] - 0s 920us/step - kl_loss: 2.5693e-04\n",
      "16/16 [==============================] - 0s 887us/step - kl_loss: 1.4039e-04\n",
      "16/16 [==============================] - 0s 869us/step - kl_loss: 3.1678e-04\n",
      "16/16 [==============================] - 0s 877us/step - kl_loss: 2.0544e-04\n",
      "16/16 [==============================] - 0s 910us/step - kl_loss: 1.3164e-04\n",
      "16/16 [==============================] - 0s 920us/step - kl_loss: 3.7877e-05\n",
      "16/16 [==============================] - 0s 881us/step - kl_loss: 1.7913e-05\n",
      "16/16 [==============================] - 0s 896us/step - kl_loss: 8.9225e-06\n",
      "16/16 [==============================] - 0s 894us/step - kl_loss: 2.8919e-05\n",
      "16/16 [==============================] - 0s 862us/step - kl_loss: 8.2512e-05\n",
      "16/16 [==============================] - 0s 852us/step - kl_loss: 6.1667e-05\n",
      "16/16 [==============================] - 0s 885us/step - kl_loss: 6.0950e-05\n",
      "16/16 [==============================] - 0s 906us/step - kl_loss: 4.6845e-05\n",
      "16/16 [==============================] - 0s 872us/step - kl_loss: 1.2996e-04\n",
      "16/16 [==============================] - 0s 934us/step - kl_loss: 8.1739e-05\n",
      "11/11 [==============================] - 0s 936us/step - kl_loss: 1.4202e-04\n",
      "16/16 [==============================] - 0s 919us/step - kl_loss: 1.3208e-04\n",
      "16/16 [==============================] - 0s 857us/step - kl_loss: 2.5416e-05\n",
      "16/16 [==============================] - 0s 879us/step - kl_loss: 2.3686e-04\n",
      "16/16 [==============================] - 0s 893us/step - kl_loss: 8.3754e-05\n",
      "16/16 [==============================] - 0s 910us/step - kl_loss: 5.5621e-05\n",
      "16/16 [==============================] - 0s 908us/step - kl_loss: 4.7069e-05\n",
      "16/16 [==============================] - 0s 863us/step - kl_loss: 3.4773e-05\n",
      "16/16 [==============================] - 0s 862us/step - kl_loss: 6.9179e-05\n",
      "16/16 [==============================] - 0s 892us/step - kl_loss: 5.2090e-05\n",
      "14/14 [==============================] - 0s 910us/step - kl_loss: 2.1028e-04\n",
      "9/9 [==============================] - 0s 919us/step - kl_loss: 3.0514e-04\n",
      "16/16 [==============================] - 0s 907us/step - kl_loss: 1.1390e-04\n",
      "16/16 [==============================] - 0s 879us/step - kl_loss: 2.2734e-05\n",
      "16/16 [==============================] - 0s 883us/step - kl_loss: 2.9648e-05\n",
      "16/16 [==============================] - 0s 841us/step - kl_loss: 4.2551e-04\n",
      "16/16 [==============================] - 0s 858us/step - kl_loss: 8.8995e-05\n",
      "16/16 [==============================] - 0s 898us/step - kl_loss: 2.1523e-04\n",
      "16/16 [==============================] - 0s 878us/step - kl_loss: 2.3479e-04\n",
      "16/16 [==============================] - 0s 884us/step - kl_loss: 3.5033e-05\n",
      "16/16 [==============================] - 0s 893us/step - kl_loss: 2.2248e-05\n",
      "16/16 [==============================] - 0s 862us/step - kl_loss: 2.9066e-05\n",
      "16/16 [==============================] - 0s 865us/step - kl_loss: 2.1744e-05\n",
      "11/11 [==============================] - 0s 894us/step - kl_loss: 6.2629e-05\n",
      "16/16 [==============================] - 0s 853us/step - kl_loss: 2.1039e-04\n",
      "16/16 [==============================] - 0s 911us/step - kl_loss: 7.2563e-05\n",
      "16/16 [==============================] - 0s 911us/step - kl_loss: 7.8947e-05\n",
      "16/16 [==============================] - 0s 885us/step - kl_loss: 1.6788e-04\n",
      "16/16 [==============================] - 0s 873us/step - kl_loss: 3.6060e-04\n",
      "16/16 [==============================] - 0s 871us/step - kl_loss: 7.9603e-05\n",
      "16/16 [==============================] - 0s 888us/step - kl_loss: 3.5523e-05\n",
      "16/16 [==============================] - 0s 905us/step - kl_loss: 1.2547e-04\n",
      "16/16 [==============================] - 0s 884us/step - kl_loss: 2.6244e-04\n",
      "8/8 [==============================] - 0s 905us/step - kl_loss: 1.9605e-04\n",
      "16/16 [==============================] - 0s 880us/step - kl_loss: 7.6105e-05\n",
      "16/16 [==============================] - 0s 904us/step - kl_loss: 1.9218e-04\n",
      "16/16 [==============================] - 0s 873us/step - kl_loss: 1.0097e-04\n",
      "16/16 [==============================] - 0s 898us/step - kl_loss: 1.8222e-04\n",
      "16/16 [==============================] - 0s 913us/step - kl_loss: 5.0225e-05\n",
      "16/16 [==============================] - 0s 873us/step - kl_loss: 1.4844e-04\n",
      "12/12 [==============================] - 0s 916us/step - kl_loss: 7.4900e-05\n",
      "16/16 [==============================] - 0s 885us/step - kl_loss: 8.2255e-05\n",
      "7/7 [==============================] - 0s 998us/step - kl_loss: 1.0713e-04\n",
      "16/16 [==============================] - 0s 877us/step - kl_loss: 8.7325e-05\n",
      "16/16 [==============================] - 0s 884us/step - kl_loss: 2.1384e-05\n",
      "16/16 [==============================] - 0s 890us/step - kl_loss: 6.9913e-05\n",
      "16/16 [==============================] - 0s 861us/step - kl_loss: 4.8478e-05\n",
      "16/16 [==============================] - 0s 858us/step - kl_loss: 5.1530e-05\n",
      "16/16 [==============================] - 0s 928us/step - kl_loss: 9.6592e-06\n",
      "13/13 [==============================] - 0s 938us/step - kl_loss: 9.6443e-05\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_seqs):\n",
    "\n",
    "    pre = ob_seqs[i]\n",
    "    next = next_obs[i]\n",
    "    acts = actions[i]\n",
    "\n",
    "    next_sd = next_obs_stddev[i]\n",
    "\n",
    "    daifa.train(pre, next, acts, None, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [
    {
     "data": {
      "text/plain": "(20, 5, 3)"
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_seqs = 20\n",
    "seq_length = 150\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, seq_length, epsilon=0.1)\n",
    "\n",
    "    o = transform_observations(o, observation_max, observation_min, [0, 0])\n",
    "\n",
    "    train = np.concatenate([o[:-1], a], axis=1)\n",
    "    test = o[-1]\n",
    "\n",
    "    ob_seqs.append(train)\n",
    "    next_obs.append(test)\n",
    "\n",
    "ob_seqs = np.array(ob_seqs)[:, -5:, :]\n",
    "next_obs = np.array(next_obs)\n",
    "ob_seqs.shape\n",
    "\n",
    "ob_seqs_stddev = np.ones_like(ob_seqs)\n",
    "next_obs_stddev = np.ones_like(next_obs)\n",
    "\n",
    "ob_seqs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Tensor: shape=(20, 2), dtype=float32, numpy=\n array([[0.42757505, 0.6529479 ],\n        [0.38936174, 0.5224733 ],\n        [0.5177275 , 0.5719767 ],\n        [0.32569912, 0.5357033 ],\n        [0.5789795 , 0.37268484],\n        [0.50462687, 0.16914466],\n        [0.10576638, 0.2804633 ],\n        [0.50895584, 0.26160803],\n        [0.84278893, 0.7405859 ],\n        [0.41768757, 0.8168086 ],\n        [0.6252694 , 0.524398  ],\n        [0.29302755, 0.6640839 ],\n        [0.7982165 , 0.4708082 ],\n        [0.0011582 , 0.43203047],\n        [0.15381938, 0.3239351 ],\n        [0.51816386, 0.7722647 ],\n        [0.4246617 , 0.18837008],\n        [0.62402654, 0.48184252],\n        [0.6900874 , 0.6458197 ],\n        [0.48874134, 0.24390756]], dtype=float32)>,\n <tf.Tensor: shape=(20, 2), dtype=float32, numpy=\n array([[1.0015444 , 1.0040803 ],\n        [1.0029435 , 1.0013554 ],\n        [1.00249   , 1.0037054 ],\n        [1.0025867 , 1.0013175 ],\n        [1.0037783 , 1.0024655 ],\n        [1.0045325 , 0.9992334 ],\n        [1.0020174 , 1.0017799 ],\n        [1.0041207 , 1.0012053 ],\n        [1.0033425 , 1.0089743 ],\n        [1.0012552 , 1.0062354 ],\n        [1.0033436 , 1.0037761 ],\n        [1.0008956 , 1.0037417 ],\n        [1.0051221 , 1.0040122 ],\n        [1.0008185 , 1.0032822 ],\n        [1.0018778 , 1.0018895 ],\n        [0.99936193, 1.0098908 ],\n        [1.0041473 , 1.001115  ],\n        [1.0043585 , 1.0022985 ],\n        [1.0025626 , 1.0072029 ],\n        [1.0040324 , 1.0017579 ]], dtype=float32)>,\n <tf.Tensor: shape=(20, 60), dtype=float32, numpy=\n array([[ 0.15026245,  0.02147635,  0.08431074, ..., -0.10982125,\n          0.05334226,  0.06565161],\n        [ 0.1892961 ,  0.0171166 ,  0.14129707, ..., -0.02967911,\n          0.19479504,  0.10307508],\n        [ 0.1276658 ,  0.0259374 ,  0.09705178, ..., -0.09186851,\n          0.05516341,  0.06683648],\n        ...,\n        [ 0.12049596,  0.0347067 ,  0.12938446, ..., -0.06724519,\n          0.1028895 ,  0.08167858],\n        [ 0.067205  ,  0.0587694 ,  0.05941856, ..., -0.19308257,\n         -0.05885605,  0.03636646],\n        [-0.04927346,  0.04336642,  0.01616201, ..., -0.09991126,\n         -0.13079813,  0.00147478]], dtype=float32)>,\n <tf.Tensor: shape=(20, 5, 60), dtype=float32, numpy=\n array([[[ 0.04525499, -0.01716381,  0.02350051, ..., -0.04238965,\n           0.01428884,  0.0045097 ],\n         [ 0.09317333, -0.00512476,  0.05376579, ..., -0.07720339,\n           0.02760326,  0.0271852 ],\n         [ 0.12649374,  0.00985319,  0.0731228 , ..., -0.09722769,\n           0.03932348,  0.04809814],\n         [ 0.14352977,  0.01830245,  0.08136631, ..., -0.10614912,\n           0.04794318,  0.06033898],\n         [ 0.15026245,  0.02147635,  0.08431074, ..., -0.10982125,\n           0.05334226,  0.06565161]],\n \n        [[ 0.06360728, -0.0279705 ,  0.04693291, ...,  0.01876127,\n           0.07270339,  0.02625261],\n         [ 0.12016988, -0.01528889,  0.09293082, ...,  0.00722509,\n           0.12378819,  0.05685403],\n         [ 0.15799734,  0.00201168,  0.12204836, ..., -0.00917845,\n           0.15883154,  0.08118919],\n         [ 0.17884886,  0.0125097 ,  0.13581392, ..., -0.02153258,\n           0.1813325 ,  0.09584883],\n         [ 0.1892961 ,  0.0171166 ,  0.14129707, ..., -0.02967911,\n           0.19479504,  0.10307508]],\n \n        [[ 0.01899024, -0.00537003,  0.01712187, ..., -0.05791149,\n          -0.00749379, -0.00342179],\n         [ 0.05159665,  0.01008601,  0.04413131, ..., -0.09687613,\n          -0.01088502,  0.01538653],\n         [ 0.09476812,  0.01297409,  0.07409859, ..., -0.08821176,\n           0.01896192,  0.04428795],\n         [ 0.11822307,  0.02161739,  0.09018441, ..., -0.08948812,\n           0.0409235 ,  0.05975568],\n         [ 0.1276658 ,  0.0259374 ,  0.09705178, ..., -0.09186851,\n           0.05516341,  0.06683648]],\n \n        ...,\n \n        [[-0.01287574,  0.00913438,  0.01037965, ..., -0.07211688,\n          -0.03120288, -0.01136945],\n         [ 0.04945046, -0.00161371,  0.06758605, ..., -0.04407822,\n           0.02909646,  0.0303868 ],\n         [ 0.09147461,  0.0191132 ,  0.10595157, ..., -0.05436005,\n           0.06481314,  0.0583218 ],\n         [ 0.11274984,  0.03069214,  0.12332863, ..., -0.0628503 ,\n           0.08860222,  0.07462525],\n         [ 0.12049596,  0.0347067 ,  0.12938446, ..., -0.06724519,\n           0.1028895 ,  0.08167858]],\n \n        [[ 0.01436141, -0.00646611,  0.01604711, ..., -0.07796118,\n          -0.01446355, -0.00974533],\n         [ 0.05152211,  0.0144128 ,  0.04881622, ..., -0.12986496,\n          -0.0225791 ,  0.01168774],\n         [ 0.08065747,  0.03350948,  0.06986689, ..., -0.15249343,\n          -0.02346765,  0.03437518],\n         [ 0.09257582,  0.04136415,  0.07716379, ..., -0.15684438,\n          -0.02214691,  0.04622274],\n         [ 0.067205  ,  0.0587694 ,  0.05941856, ..., -0.19308257,\n          -0.05885605,  0.03636646]],\n \n        [[-0.04124852,  0.02623192, -0.00106705, ..., -0.07540748,\n          -0.05910962, -0.01571499],\n         [-0.0516727 ,  0.0423548 ,  0.00782672, ..., -0.10877656,\n          -0.10001399, -0.01105171],\n         [-0.05289169,  0.04889357,  0.01271122, ..., -0.11655216,\n          -0.12273175, -0.00386084],\n         [-0.04969812,  0.04598803,  0.01593486, ..., -0.10666266,\n          -0.12809363,  0.0011813 ],\n         [-0.04927346,  0.04336642,  0.01616201, ..., -0.09991126,\n          -0.13079813,  0.00147478]]], dtype=float32)>]"
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daifa.tran((ob_seqs, None))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.41424149, 0.64817536],\n       [0.37549612, 0.51434882],\n       [0.50395287, 0.56238058],\n       [0.31282919, 0.53150581],\n       [0.56830029, 0.36537232],\n       [0.49751557, 0.15729226],\n       [0.10200014, 0.28023718],\n       [0.49930485, 0.25297206],\n       [0.83264549, 0.76498072],\n       [0.40183171, 0.8195579 ],\n       [0.61205382, 0.51735449],\n       [0.28334383, 0.66585968],\n       [0.78955368, 0.48945753],\n       [0.        , 0.5       ],\n       [0.15014838, 0.32678897],\n       [0.5064109 , 0.78005801],\n       [0.41774712, 0.18253206],\n       [0.61022634, 0.47224011],\n       [0.67659513, 0.6480953 ],\n       [0.48181082, 0.23722683]])"
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_obs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "That looks fantastic!!! With enough data the transition model is training very well"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 60), dtype=float32, numpy=\narray([[ 0.1668222 ,  0.05080901,  0.20015422,  0.38899958, -0.08546768,\n        -0.04040675,  0.03512116,  0.00171472,  0.03852477,  0.20108685,\n        -0.03330585,  0.01087453, -0.03944991, -0.23539615,  0.19884759,\n         0.15129937,  0.08765514,  0.15757117, -0.16009761, -0.02254741,\n        -0.17335685, -0.09706004,  0.05607434,  0.03711884, -0.0560054 ,\n        -0.27313083,  0.02705026,  0.14458522, -0.25310335, -0.08086976,\n        -0.10635097, -0.28293777,  0.00502296,  0.2793439 ,  0.07475004,\n        -0.09199525, -0.23762226,  0.05454395, -0.07554322, -0.06423084,\n         0.11491245,  0.03344171, -0.03258195,  0.04890673,  0.07888647,\n         0.11464167,  0.31568897,  0.01460155, -0.23916677,  0.24096602,\n         0.1589966 ,  0.0215495 , -0.38883814,  0.2073881 ,  0.17495394,\n         0.30218056, -0.14856315, -0.09490789,  0.20044254,  0.12068783]],\n      dtype=float32)>"
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daifa.hidden_state"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4 0.5]\n",
      "tf.Tensor(\n",
      "[ 0.7089493   0.76423895  0.8047202   0.8124183   0.73879427  0.76978123\n",
      "  0.61311316  0.5821078   0.4306626   0.40520254  0.17977683  0.27913105\n",
      " -0.00298302  0.03768509  0.0850338 ], shape=(15,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(15,), dtype=float32, numpy=\narray([ 0.7089493 ,  0.76423895,  0.8047202 ,  0.8124183 ,  0.73879427,\n        0.76978123,  0.61311316,  0.5821078 ,  0.4306626 ,  0.40520254,\n        0.17977683,  0.27913105, -0.00298302,  0.03768509,  0.0850338 ],\n      dtype=float32)>"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_t_minus_1 = np.array([0.4, 0.5])\n",
    "daifa.hidden_state = None\n",
    "p, s = daifa.cem_policy_optimisation(z_t_minus_1)\n",
    "p"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.17485519, 0.28052184]], dtype=float32)>,\n <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.998175 , 0.9848511]], dtype=float32)>,\n <tf.Tensor: shape=(1, 60), dtype=float32, numpy=\n array([[ 0.06734794, -0.03086371,  0.04919352,  0.06776053,  0.05020184,\n         -0.02855486,  0.05532712,  0.00621268,  0.03898622,  0.06404883,\n         -0.06092996,  0.02080428, -0.03182369, -0.09051668,  0.02938318,\n          0.02920253,  0.09898859,  0.04242412, -0.0937261 , -0.07689307,\n         -0.04255384, -0.01035933,  0.0217123 ,  0.0560016 , -0.06113841,\n         -0.08259731, -0.04008626,  0.02852438, -0.09232952, -0.09844272,\n         -0.09578703, -0.0808928 ,  0.07631816,  0.10538951,  0.03266784,\n         -0.06981869, -0.13518177, -0.00443301, -0.0766279 ,  0.03137437,\n          0.10195947,  0.03933517,  0.01060682, -0.02867689,  0.05144734,\n          0.02094595,  0.07122529,  0.09150924, -0.11927285,  0.11849919,\n          0.06474774, -0.00642365, -0.15364884,  0.10189001,  0.09677684,\n          0.10298578,  0.00337658,  0.01931385,  0.07793737,  0.02707184]],\n       dtype=float32)>,\n <tf.Tensor: shape=(1, 1, 60), dtype=float32, numpy=\n array([[[ 0.06734794, -0.03086371,  0.04919352,  0.06776053,\n           0.05020184, -0.02855486,  0.05532712,  0.00621268,\n           0.03898622,  0.06404883, -0.06092996,  0.02080428,\n          -0.03182369, -0.09051668,  0.02938318,  0.02920253,\n           0.09898859,  0.04242412, -0.0937261 , -0.07689307,\n          -0.04255384, -0.01035933,  0.0217123 ,  0.0560016 ,\n          -0.06113841, -0.08259731, -0.04008626,  0.02852438,\n          -0.09232952, -0.09844272, -0.09578703, -0.0808928 ,\n           0.07631816,  0.10538951,  0.03266784, -0.06981869,\n          -0.13518177, -0.00443301, -0.0766279 ,  0.03137437,\n           0.10195947,  0.03933517,  0.01060682, -0.02867689,\n           0.05144734,  0.02094595,  0.07122529,  0.09150924,\n          -0.11927285,  0.11849919,  0.06474774, -0.00642365,\n          -0.15364884,  0.10189001,  0.09677684,  0.10298578,\n           0.00337658,  0.01931385,  0.07793737,  0.02707184]]],\n       dtype=float32)>]"
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daifa.tran((np.array([[[0.4, 0.5, 1]]]), None))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "[0.3531864 0.5      ]\n",
      "tf.Tensor(\n",
      "[0.75776505 0.808785   0.823482   0.7384236  0.66807634 0.75550365\n",
      " 0.65706307 0.57430935 0.44249344 0.50059706 0.30967107 0.3025037\n",
      " 0.23872639 0.13167822 0.03006317], shape=(15,), dtype=float32)\n",
      "[0.41072467 0.60575192]\n",
      "tf.Tensor(\n",
      "[0.80091256 0.831186   0.80336916 0.743643   0.67225486 0.7388898\n",
      " 0.6710419  0.49252346 0.45496187 0.39570916 0.33172902 0.4691094\n",
      " 0.18269321 0.02243686 0.13316137], shape=(15,), dtype=float32)\n",
      "[0.52321638 0.6161014 ]\n",
      "tf.Tensor(\n",
      "[0.7582315  0.7428887  0.78753793 0.70738727 0.6904973  0.6947737\n",
      " 0.7184091  0.63121426 0.51972836 0.44251725 0.4724567  0.35061508\n",
      " 0.20868196 0.29411447 0.1608929 ], shape=(15,), dtype=float32)\n",
      "[0.59332169 0.53282979]\n",
      "tf.Tensor(\n",
      "[ 0.8261601   0.7788568   0.7498009   0.68705684  0.71283436  0.7625619\n",
      "  0.6251273   0.59106356  0.47288027  0.37912145  0.37760547  0.27614397\n",
      "  0.17472365  0.0352636  -0.06415275], shape=(15,), dtype=float32)\n",
      "[0.57653528 0.43853916]\n",
      "tf.Tensor(\n",
      "[ 0.84993833  0.838954    0.836631    0.8009051   0.6381009   0.67451525\n",
      "  0.66360396  0.7313162   0.44090325  0.61107373  0.4429256   0.2499801\n",
      "  0.18311256  0.00455586 -0.03917548], shape=(15,), dtype=float32)\n",
      "[0.48622649 0.38311274]\n",
      "tf.Tensor(\n",
      "[0.8081694  0.80967754 0.7922341  0.7968606  0.7375868  0.6537518\n",
      " 0.64383316 0.62586427 0.55786794 0.3814907  0.40052238 0.48054183\n",
      " 0.37376764 0.13650063 0.09636682], shape=(15,), dtype=float32)\n",
      "[0.38618095 0.41815763]\n",
      "tf.Tensor(\n",
      "[0.808529   0.80657184 0.7916462  0.70533156 0.7616304  0.6811054\n",
      " 0.6398279  0.49607593 0.48863018 0.42573503 0.4255617  0.5032834\n",
      " 0.25781015 0.1669854  0.03199732], shape=(15,), dtype=float32)\n",
      "[0.36487361 0.53167849]\n",
      "tf.Tensor(\n",
      "[ 0.80258495  0.86818594  0.71748924  0.8466585   0.7656668   0.6802341\n",
      "  0.7175385   0.55456597  0.56965184  0.48494464  0.4133271   0.35727996\n",
      "  0.29771766  0.2542887  -0.04310569], shape=(15,), dtype=float32)\n",
      "[0.44369857 0.61764689]\n",
      "tf.Tensor(\n",
      "[0.8110079  0.6923667  0.79028475 0.6758299  0.71477115 0.7232198\n",
      " 0.6768123  0.6062628  0.5514061  0.47747606 0.4313433  0.3517048\n",
      " 0.39273486 0.17666398 0.08394014], shape=(15,), dtype=float32)\n",
      "[0.54803135 0.58811021]\n",
      "tf.Tensor(\n",
      "[0.77069455 0.7971718  0.76023203 0.76838154 0.70611453 0.7311224\n",
      " 0.6250644  0.6438176  0.47762975 0.5243256  0.41966495 0.36352235\n",
      " 0.40499055 0.01003213 0.061273  ], shape=(15,), dtype=float32)\n",
      "[0.58816123 0.5017748 ]\n",
      "tf.Tensor(\n",
      "[ 0.82042825  0.80002797  0.74095577  0.71816117  0.73239034  0.7092903\n",
      "  0.72302485  0.62576604  0.5700318   0.4367064   0.43498516  0.47891188\n",
      "  0.16538338  0.18202068 -0.19701585], shape=(15,), dtype=float32)\n",
      "[0.54586323 0.41759907]\n",
      "tf.Tensor(\n",
      "[0.7925538  0.797785   0.7362157  0.7193825  0.72075266 0.6847715\n",
      " 0.63142014 0.52450913 0.6858361  0.4741538  0.46578348 0.35045347\n",
      " 0.4875199  0.10972673 0.30347246], shape=(15,), dtype=float32)\n",
      "[0.44605739 0.38614578]\n",
      "tf.Tensor(\n",
      "[0.7413631  0.7655986  0.7876091  0.7940088  0.70736146 0.6543615\n",
      " 0.6855993  0.6544356  0.58999455 0.48650116 0.347798   0.12228234\n",
      " 0.24543785 0.20780389 0.03425851], shape=(15,), dtype=float32)\n",
      "[0.36494746 0.45144458]\n",
      "tf.Tensor(\n",
      "[0.8217085  0.73286784 0.7572981  0.7622988  0.7463897  0.71150637\n",
      " 0.5872628  0.6521302  0.51973563 0.41864827 0.4010417  0.27743676\n",
      " 0.38145977 0.16709988 0.10859277], shape=(15,), dtype=float32)\n",
      "[0.3799972  0.56624843]\n",
      "tf.Tensor(\n",
      "[0.7157361  0.8330341  0.7970764  0.7716476  0.79019064 0.6825232\n",
      " 0.58022153 0.49948868 0.45807794 0.5443946  0.4094528  0.3813852\n",
      " 0.3188499  0.09375567 0.2158043 ], shape=(15,), dtype=float32)\n",
      "[0.47352085 0.61658074]\n",
      "tf.Tensor(\n",
      "[0.7780647  0.80061483 0.722193   0.74317825 0.7437629  0.68641585\n",
      " 0.5962243  0.50690097 0.65318114 0.52816546 0.38895717 0.27855322\n",
      " 0.25044137 0.2727542  0.06080603], shape=(15,), dtype=float32)\n",
      "[0.56438515 0.56986869]\n",
      "tf.Tensor(\n",
      "[0.7811205  0.7339901  0.81370497 0.72263205 0.73430645 0.629454\n",
      " 0.6017497  0.6197657  0.56409466 0.43045133 0.26490685 0.2498877\n",
      " 0.31837606 0.00660494 0.18230386], shape=(15,), dtype=float32)\n",
      "[0.58373286 0.47584327]\n",
      "tf.Tensor(\n",
      "[ 0.786635    0.7676723   0.78109056  0.7734856   0.7349278   0.6434932\n",
      "  0.64729017  0.6477715   0.46817616  0.5103125   0.3484181   0.32719758\n",
      "  0.19347914  0.08783682 -0.12831853], shape=(15,), dtype=float32)\n",
      "[0.51849457 0.39698744]\n",
      "tf.Tensor(\n",
      "[0.7013822  0.82110566 0.8151903  0.83248204 0.69641477 0.7037499\n",
      " 0.65221685 0.62713647 0.6174364  0.46683326 0.47702065 0.45662794\n",
      " 0.22590521 0.12989476 0.18857364], shape=(15,), dtype=float32)\n",
      "[0.41009074 0.39329548]\n",
      "tf.Tensor(\n",
      "[0.78286713 0.75951535 0.79978824 0.7267528  0.71680486 0.65614986\n",
      " 0.6204901  0.54773957 0.50284386 0.5718347  0.25679275 0.19043566\n",
      " 0.2571739  0.09063831 0.13465643], shape=(15,), dtype=float32)\n",
      "[0.35496967 0.49114117]\n",
      "tf.Tensor(\n",
      "[ 0.7816021   0.81464404  0.8433688   0.76073045  0.763372    0.6750622\n",
      "  0.5641183   0.69435006  0.5063368   0.4080222   0.47917065  0.31884998\n",
      "  0.17305967 -0.06161011 -0.04073815], shape=(15,), dtype=float32)\n",
      "[0.40579482 0.60065321]\n",
      "tf.Tensor(\n",
      "[0.79529333 0.750566   0.79003304 0.76391315 0.73424697 0.6420629\n",
      " 0.6682913  0.6523948  0.5369906  0.5469905  0.33981997 0.26553097\n",
      " 0.0638757  0.28567824 0.23673962], shape=(15,), dtype=float32)\n",
      "[0.51507599 0.61200315]\n",
      "tf.Tensor(\n",
      "[ 0.79337245  0.7404581   0.7697803   0.73482007  0.70173734  0.73203075\n",
      "  0.5884999   0.60060364  0.46503568  0.4337764   0.4391953   0.34379748\n",
      "  0.26070306  0.07910137 -0.0782097 ], shape=(15,), dtype=float32)\n",
      "[0.58594846 0.53615845]\n",
      "tf.Tensor(\n",
      "[0.77882797 0.69763243 0.7354432  0.78261834 0.7548013  0.7395214\n",
      " 0.6853571  0.57952696 0.5142892  0.46434534 0.52490604 0.3411709\n",
      " 0.2709834  0.09081004 0.05274038], shape=(15,), dtype=float32)\n",
      "[0.57014214 0.43662953]\n",
      "tf.Tensor(\n",
      "[ 0.8492138   0.7675102   0.8595176   0.78523564  0.7543218   0.66763735\n",
      "  0.5548783   0.62393606  0.48151332  0.5518069   0.38802665  0.3985188\n",
      "  0.3526202   0.23939711 -0.12900242], shape=(15,), dtype=float32)\n",
      "[0.47905944 0.38159515]\n",
      "tf.Tensor(\n",
      "[ 0.82852745  0.81620026  0.76462984  0.6585787   0.680708    0.5028422\n",
      "  0.67517024  0.60897154  0.4863976   0.62219536  0.49263546  0.44589314\n",
      "  0.28722784  0.23585846 -0.02223484], shape=(15,), dtype=float32)\n",
      "[0.38228903 0.42519666]\n",
      "tf.Tensor(\n",
      "[0.79549915 0.73700064 0.78116643 0.7397113  0.7940053  0.78030664\n",
      " 0.5730892  0.49749538 0.5726207  0.3887233  0.46988285 0.3230513\n",
      " 0.03857424 0.06511506 0.09033238], shape=(15,), dtype=float32)\n",
      "[0.36676927 0.53437901]\n",
      "tf.Tensor(\n",
      "[0.8047022  0.75837153 0.8462696  0.7162242  0.72801363 0.65123004\n",
      " 0.59589547 0.54535824 0.6131784  0.4514287  0.6247042  0.36965016\n",
      " 0.20724636 0.18744104 0.0636511 ], shape=(15,), dtype=float32)\n",
      "[0.44490315 0.61066828]\n",
      "tf.Tensor(\n",
      "[0.81024164 0.7460855  0.7998578  0.74819976 0.7318434  0.7199478\n",
      " 0.6176514  0.6539627  0.45442376 0.54600036 0.46350846 0.27041775\n",
      " 0.35329205 0.08493165 0.01173883], shape=(15,), dtype=float32)\n",
      "[0.54393757 0.58586972]\n",
      "tf.Tensor(\n",
      "[0.83877844 0.7512684  0.8179611  0.7089987  0.62314284 0.6872689\n",
      " 0.666742   0.58867216 0.43242267 0.48708692 0.5365295  0.36782113\n",
      " 0.2323856  0.22591136 0.1930209 ], shape=(15,), dtype=float32)\n",
      "[0.58560245 0.50302988]\n",
      "tf.Tensor(\n",
      "[ 0.81615007  0.8337144   0.7280479   0.83652335  0.6593734   0.6673092\n",
      "  0.644081    0.6065941   0.49902397  0.597173    0.33554184  0.29067463\n",
      "  0.29533008  0.15974145 -0.04347519], shape=(15,), dtype=float32)\n",
      "[0.54541119 0.42172624]\n",
      "tf.Tensor(\n",
      "[0.77859366 0.7399454  0.80361915 0.8222891  0.6997945  0.7333289\n",
      " 0.5931555  0.5250654  0.38968724 0.4366026  0.41840667 0.2858042\n",
      " 0.20093226 0.11056146 0.28115508], shape=(15,), dtype=float32)\n",
      "[0.44752685 0.38479307]\n",
      "tf.Tensor(\n",
      "[ 0.82429093  0.7936777   0.8563681   0.7860239   0.7406905   0.5799222\n",
      "  0.7315543   0.5343847   0.460609    0.4562714   0.35923907  0.36962327\n",
      "  0.18014123  0.23509723 -0.02257505], shape=(15,), dtype=float32)\n",
      "[0.36856751 0.45480162]\n",
      "tf.Tensor(\n",
      "[0.8142052  0.7555646  0.8146456  0.76780176 0.7035508  0.6438452\n",
      " 0.6299063  0.6259845  0.56285286 0.4900472  0.4291155  0.2972585\n",
      " 0.23083456 0.0416389  0.11854338], shape=(15,), dtype=float32)\n",
      "[0.38437616 0.56566065]\n",
      "tf.Tensor(\n",
      "[0.8717742  0.79311955 0.8349144  0.7581415  0.6517145  0.639386\n",
      " 0.60070837 0.52159375 0.42648387 0.45765376 0.37017617 0.3854718\n",
      " 0.27083525 0.08882858 0.03711194], shape=(15,), dtype=float32)\n",
      "[0.48105746 0.61698049]\n",
      "tf.Tensor(\n",
      "[0.7816412  0.8154942  0.7475302  0.7307145  0.67497694 0.65167934\n",
      " 0.6135576  0.52580523 0.50448567 0.5064087  0.28986984 0.33856618\n",
      " 0.2111372  0.04163319 0.06080171], shape=(15,), dtype=float32)\n",
      "[0.56957929 0.56592761]\n",
      "tf.Tensor(\n",
      "[0.7415218  0.8276692  0.76559246 0.7420308  0.6718621  0.6524063\n",
      " 0.74649006 0.6595096  0.57205176 0.42472783 0.46960062 0.40188935\n",
      " 0.3381443  0.31225252 0.12252428], shape=(15,), dtype=float32)\n",
      "[0.58403423 0.47394873]\n",
      "tf.Tensor(\n",
      "[ 0.7820771   0.76585364  0.77992487  0.7481109   0.71760786  0.7291078\n",
      "  0.73734087  0.65609974  0.58259207  0.44035995  0.39198986  0.0941532\n",
      "  0.22869183 -0.15184657  0.09070029], shape=(15,), dtype=float32)\n",
      "[0.51688021 0.39510235]\n",
      "tf.Tensor(\n",
      "[0.7352284  0.75400406 0.78572464 0.801884   0.6663553  0.7583888\n",
      " 0.67039853 0.5376294  0.50376385 0.5414519  0.5258707  0.35912326\n",
      " 0.2996345  0.05289698 0.06059019], shape=(15,), dtype=float32)\n",
      "[0.40798668 0.39102628]\n",
      "tf.Tensor(\n",
      "[0.7611072  0.8020517  0.78023297 0.6550679  0.66480124 0.76778185\n",
      " 0.6363506  0.5958002  0.47454938 0.5027793  0.5354361  0.33032587\n",
      " 0.32072702 0.1383539  0.08724254], shape=(15,), dtype=float32)\n",
      "[0.3520312  0.49354863]\n",
      "tf.Tensor(\n",
      "[0.79392415 0.7739514  0.8184119  0.79044056 0.6628201  0.73477334\n",
      " 0.6351135  0.6286006  0.4333898  0.42271107 0.5196934  0.10632459\n",
      " 0.33844072 0.25389937 0.09108002], shape=(15,), dtype=float32)\n",
      "[0.40609846 0.60283605]\n",
      "tf.Tensor(\n",
      "[ 0.7884622   0.82729053  0.8360866   0.7258866   0.64380354  0.7157528\n",
      "  0.5779476   0.5710402   0.47314978  0.5921881   0.3813641   0.29816145\n",
      "  0.16894156  0.27616373 -0.02353296], shape=(15,), dtype=float32)\n",
      "[0.51798088 0.61750049]\n",
      "tf.Tensor(\n",
      "[ 0.81359965  0.763978    0.76793635  0.7462814   0.70802116  0.68962127\n",
      "  0.58806014  0.5863664   0.46981502  0.5895484   0.37318972  0.36630228\n",
      "  0.25067335  0.17080323 -0.03141759], shape=(15,), dtype=float32)\n",
      "[0.5938309  0.54126586]\n",
      "tf.Tensor(\n",
      "[0.8113294  0.768809   0.6856807  0.73540765 0.72331357 0.6783503\n",
      " 0.5949049  0.583399   0.61106104 0.5376641  0.33809215 0.40843654\n",
      " 0.18948479 0.06254447 0.08455604], shape=(15,), dtype=float32)\n",
      "[0.58345062 0.44372764]\n",
      "tf.Tensor(\n",
      "[0.8009942  0.8070976  0.7275021  0.69663674 0.71600336 0.70018804\n",
      " 0.65069294 0.66603565 0.7022384  0.45402578 0.34891218 0.22229828\n",
      " 0.2553366  0.20484611 0.02414317], shape=(15,), dtype=float32)\n",
      "[0.49264736 0.37778779]\n",
      "tf.Tensor(\n",
      "[0.74953175 0.75108176 0.7682707  0.7941111  0.6321828  0.7890561\n",
      " 0.59978455 0.5697439  0.5587085  0.5677614  0.34142888 0.45922023\n",
      " 0.34311283 0.18927541 0.04024025], shape=(15,), dtype=float32)\n",
      "[0.38186869 0.40307761]\n",
      "tf.Tensor(\n",
      "[0.8401727  0.83660525 0.7682112  0.7321585  0.7469177  0.6507884\n",
      " 0.6442639  0.64668775 0.45425525 0.34885836 0.329645   0.31632945\n",
      " 0.17799746 0.10585867 0.17687285], shape=(15,), dtype=float32)\n",
      "[0.35298689 0.53085447]\n",
      "tf.Tensor(\n",
      "[0.78200173 0.7954946  0.79973924 0.76843774 0.76992786 0.64292175\n",
      " 0.6476148  0.5449644  0.6215908  0.56584924 0.37136087 0.37221712\n",
      " 0.19877341 0.05788508 0.09599178], shape=(15,), dtype=float32)\n",
      "[0.43535255 0.62311142]\n",
      "tf.Tensor(\n",
      "[0.7988832  0.81995803 0.79670495 0.75617784 0.7537437  0.72877586\n",
      " 0.6120326  0.6481022  0.528509   0.44550523 0.54102105 0.4045983\n",
      " 0.20502405 0.10994437 0.01944509], shape=(15,), dtype=float32)\n",
      "[0.54961391 0.6057297 ]\n",
      "tf.Tensor(\n",
      "[0.82574815 0.8087345  0.79786146 0.726313   0.6651899  0.7448676\n",
      " 0.6447881  0.57326835 0.49473333 0.34929955 0.18304539 0.3073979\n",
      " 0.30910343 0.2195527  0.08602198], shape=(15,), dtype=float32)\n",
      "[0.60715892 0.51897679]\n",
      "tf.Tensor(\n",
      "[0.73939127 0.7683055  0.77412814 0.7428036  0.71010387 0.734558\n",
      " 0.6276515  0.5459412  0.57485867 0.42185855 0.32804263 0.21587849\n",
      " 0.03043543 0.26203704 0.07618994], shape=(15,), dtype=float32)\n",
      "[0.571388   0.41616956]\n",
      "tf.Tensor(\n",
      "[0.8084016  0.79118896 0.7125908  0.78489465 0.7554889  0.70314\n",
      " 0.6542661  0.6204031  0.5129748  0.53307694 0.3740126  0.1729145\n",
      " 0.2167828  0.13401434 0.3829881 ], shape=(15,), dtype=float32)\n",
      "[0.46168311 0.36681081]\n",
      "tf.Tensor(\n",
      "[ 0.80106664  0.8936466   0.76621354  0.7754078   0.77766734  0.63762605\n",
      "  0.644117    0.4937583   0.3810801   0.40484437  0.45562983  0.39988062\n",
      "  0.14110254  0.12532564 -0.0749072 ], shape=(15,), dtype=float32)\n",
      "[0.36223823 0.43672092]\n",
      "tf.Tensor(\n",
      "[ 0.8590739   0.85995823  0.7432653   0.7503428   0.80756474  0.72860914\n",
      "  0.69533503  0.65018004  0.58915186  0.49469632  0.26144204  0.31654248\n",
      "  0.1668773   0.16982254 -0.07862785], shape=(15,), dtype=float32)\n",
      "[0.37103283 0.57032034]\n",
      "tf.Tensor(\n",
      "[0.7883463  0.7421475  0.7198873  0.8076494  0.73724467 0.7076293\n",
      " 0.55192846 0.49001226 0.5639493  0.52365774 0.33413577 0.2639018\n",
      " 0.14376952 0.13097861 0.12782432], shape=(15,), dtype=float32)\n",
      "[0.47393083 0.62502963]\n",
      "tf.Tensor(\n",
      "[ 0.78464913  0.7832258   0.81469816  0.7778928   0.73397785  0.6671145\n",
      "  0.56024915  0.63776195  0.52743816  0.43552956  0.38730374  0.34354916\n",
      "  0.14792752 -0.00164434  0.15573315], shape=(15,), dtype=float32)\n",
      "[0.57156853 0.57477212]\n",
      "tf.Tensor(\n",
      "[0.8371124  0.72853917 0.8691501  0.73401505 0.6498376  0.73067075\n",
      " 0.63454086 0.55254984 0.5146528  0.4891952  0.43070522 0.43262103\n",
      " 0.1375717  0.04265443 0.3134485 ], shape=(15,), dtype=float32)\n",
      "[0.59580991 0.47936026]\n",
      "tf.Tensor(\n",
      "[ 0.81873614  0.83532137  0.7040841   0.7788191   0.6197398   0.61335325\n",
      "  0.68482035  0.5888923   0.61703384  0.4427971   0.6005854   0.20061466\n",
      "  0.14735143  0.22884987 -0.0335655 ], shape=(15,), dtype=float32)\n",
      "[0.5329938  0.39897234]\n",
      "tf.Tensor(\n",
      "[0.8065402  0.7822272  0.76538205 0.7681339  0.7753727  0.7742152\n",
      " 0.69478977 0.57195425 0.4704853  0.49332318 0.31115493 0.395126\n",
      " 0.28096202 0.04866501 0.1842206 ], shape=(15,), dtype=float32)\n",
      "[0.42374525 0.38484408]\n",
      "tf.Tensor(\n",
      "[0.85375875 0.85130006 0.82338494 0.7543496  0.5935664  0.68263274\n",
      " 0.6397417  0.6747055  0.4713774  0.47407013 0.29585087 0.24762736\n",
      " 0.16460706 0.19996603 0.0240241 ], shape=(15,), dtype=float32)\n",
      "[0.35941744 0.48232772]\n",
      "tf.Tensor(\n",
      "[0.8330857  0.7875589  0.7354576  0.7439057  0.73607373 0.72214407\n",
      " 0.57638764 0.573217   0.5422481  0.41029024 0.3359802  0.30563188\n",
      " 0.10840655 0.21389659 0.00672198], shape=(15,), dtype=float32)\n",
      "[0.40275122 0.59225201]\n",
      "tf.Tensor(\n",
      "[ 0.82999897  0.86564636  0.7875039   0.81777596  0.70565     0.67825115\n",
      "  0.61548394  0.5552539   0.42982295  0.41920453  0.4481033   0.38862363\n",
      "  0.21809898  0.06253474 -0.07581279], shape=(15,), dtype=float32)\n",
      "[0.51037026 0.6184226 ]\n",
      "tf.Tensor(\n",
      "[0.7676647  0.82916576 0.7767916  0.7539434  0.705458   0.64423805\n",
      " 0.69134396 0.44446015 0.62188345 0.49696687 0.4288368  0.4260155\n",
      " 0.28188017 0.08480137 0.05216508], shape=(15,), dtype=float32)\n",
      "[0.58867452 0.54802307]\n",
      "tf.Tensor(\n",
      "[0.8200514  0.8098292  0.80813813 0.74955344 0.6526869  0.66327983\n",
      " 0.609704   0.53753686 0.49178484 0.45022994 0.4564877  0.33983544\n",
      " 0.3784235  0.15109646 0.04174715], shape=(15,), dtype=float32)\n",
      "[0.58638319 0.45443259]\n",
      "tf.Tensor(\n",
      "[0.7696876  0.7509072  0.7973766  0.7715203  0.7091568  0.6614527\n",
      " 0.5852787  0.6455517  0.45499912 0.40769756 0.4184576  0.47384334\n",
      " 0.33827722 0.06488781 0.05048884], shape=(15,), dtype=float32)\n",
      "[0.50134118 0.37832446]\n",
      "tf.Tensor(\n",
      "[0.8192935  0.7438691  0.8174823  0.7081893  0.73018426 0.7355522\n",
      " 0.59525925 0.5514984  0.5196334  0.38062623 0.40469217 0.34332815\n",
      " 0.40626797 0.17307793 0.15640299], shape=(15,), dtype=float32)\n",
      "[0.38968613 0.39832184]\n",
      "tf.Tensor(\n",
      "[ 0.8166617   0.8328098   0.79810065  0.78592587  0.77027655  0.6313598\n",
      "  0.5805887   0.6444551   0.6290719   0.4495581   0.3667833   0.28382215\n",
      "  0.2628423  -0.02390542 -0.15235856], shape=(15,), dtype=float32)\n",
      "[0.35192616 0.51947195]\n",
      "tf.Tensor(\n",
      "[0.78434974 0.81409925 0.8017937  0.74562925 0.6691752  0.718595\n",
      " 0.60850894 0.50091076 0.5456703  0.45592985 0.43720937 0.29297298\n",
      " 0.25382063 0.32232195 0.18150227], shape=(15,), dtype=float32)\n",
      "[0.42643755 0.61913247]\n",
      "tf.Tensor(\n",
      "[0.7865445  0.8380168  0.7752155  0.7637406  0.7297546  0.70171916\n",
      " 0.6920485  0.54565537 0.52947325 0.47661933 0.4009594  0.3770377\n",
      " 0.32883    0.16308029 0.02899723], shape=(15,), dtype=float32)\n",
      "[0.54147191 0.61092481]\n",
      "tf.Tensor(\n",
      "[0.78888315 0.7469997  0.67738193 0.7490696  0.66438204 0.69212526\n",
      " 0.6257292  0.5625566  0.64628035 0.53416157 0.4505727  0.4250792\n",
      " 0.22938962 0.04641598 0.08701646], shape=(15,), dtype=float32)\n",
      "[0.60302623 0.52109476]\n",
      "tf.Tensor(\n",
      "[0.78477997 0.81664246 0.84776825 0.7173021  0.6917322  0.72397983\n",
      " 0.64939183 0.47706875 0.5227951  0.51427835 0.32041466 0.2011926\n",
      " 0.26265493 0.08005637 0.13914573], shape=(15,), dtype=float32)\n",
      "[0.57279901 0.42512558]\n",
      "tf.Tensor(\n",
      "[0.8355642  0.81322175 0.8219691  0.64820415 0.6749398  0.6151745\n",
      " 0.6576263  0.528807   0.5957073  0.31524938 0.5663655  0.27555418\n",
      " 0.14108284 0.23462236 0.08474787], shape=(15,), dtype=float32)\n",
      "[0.47154124 0.37436967]\n",
      "tf.Tensor(\n",
      "[ 0.77912587  0.8206091   0.8392971   0.6829742   0.81002873  0.71247864\n",
      "  0.6173976   0.53924984  0.5642729   0.44932613  0.42185163  0.31431144\n",
      "  0.1367163   0.162648   -0.05937104], shape=(15,), dtype=float32)\n",
      "[0.37085166 0.42617494]\n",
      "tf.Tensor(\n",
      "[ 0.7898823   0.7594188   0.79121584  0.78815037  0.7210286   0.71293074\n",
      "  0.6105649   0.70436573  0.4780255   0.39781225  0.34089234  0.3126574\n",
      "  0.20237492 -0.04093971  0.1548445 ], shape=(15,), dtype=float32)\n",
      "[0.36229389 0.54699585]\n",
      "tf.Tensor(\n",
      "[ 0.82355934  0.7344039   0.8172188   0.73402274  0.74502105  0.6534147\n",
      "  0.6435986   0.7128599   0.49431676  0.48380378  0.39066416  0.20980707\n",
      "  0.12757571  0.13026321 -0.0428597 ], shape=(15,), dtype=float32)\n",
      "[0.45297857 0.62130913]\n",
      "tf.Tensor(\n",
      "[ 0.7381621   0.71149874  0.7293028   0.7196442   0.6499199   0.7436134\n",
      "  0.6323719   0.70429844  0.6065198   0.37744427  0.3373286   0.3274003\n",
      "  0.21847181 -0.0329199   0.06734627], shape=(15,), dtype=float32)\n",
      "[0.55327263 0.58079277]\n",
      "tf.Tensor(\n",
      "[0.7875618  0.77709216 0.83968383 0.7608554  0.6851276  0.7055456\n",
      " 0.7077723  0.7634509  0.49213797 0.47112393 0.40849224 0.30878276\n",
      " 0.23586862 0.19032483 0.104571  ], shape=(15,), dtype=float32)\n",
      "[0.58605266 0.49302219]\n",
      "tf.Tensor(\n",
      "[ 0.77135384  0.77240855  0.76240754  0.7110033   0.7368906   0.73387945\n",
      "  0.7226573   0.69948393  0.53461146  0.4671657   0.29715195  0.20918204\n",
      "  0.28141868  0.21912421 -0.05751437], shape=(15,), dtype=float32)\n",
      "[0.53415447 0.40774971]\n",
      "tf.Tensor(\n",
      "[0.8164045  0.7889183  0.7453783  0.7584136  0.790255   0.69659835\n",
      " 0.55485296 0.5503677  0.4235517  0.59859073 0.27493244 0.30828068\n",
      " 0.2731018  0.03790416 0.07867999], shape=(15,), dtype=float32)\n",
      "[0.43198381 0.39000767]\n",
      "tf.Tensor(\n",
      "[ 0.84704113  0.84706455  0.757801    0.8020106   0.7303452   0.7478122\n",
      "  0.66020226  0.51668745  0.36881408  0.40496936  0.41804153  0.26775324\n",
      "  0.29054877  0.09941671 -0.02390235], shape=(15,), dtype=float32)\n",
      "[0.36699534 0.47671569]\n",
      "tf.Tensor(\n",
      "[0.777419   0.8151371  0.75728863 0.82728755 0.7308517  0.66778195\n",
      " 0.64413494 0.6297771  0.5729615  0.43044972 0.48582512 0.2614562\n",
      " 0.19151399 0.0993737  0.01213963], shape=(15,), dtype=float32)\n",
      "[0.40010066 0.58109861]\n",
      "tf.Tensor(\n",
      "[0.8289774  0.84249175 0.7708501  0.7566673  0.75550324 0.6980426\n",
      " 0.6896482  0.68317795 0.41909352 0.3745316  0.4521397  0.201769\n",
      " 0.19879925 0.13832897 0.14238796], shape=(15,), dtype=float32)\n",
      "[0.49982994 0.61265017]\n",
      "tf.Tensor(\n",
      "[0.78668094 0.8483236  0.76588315 0.74072427 0.69789535 0.76625866\n",
      " 0.5793121  0.65345925 0.49243197 0.5656529  0.30996072 0.2837328\n",
      " 0.3334923  0.18241735 0.21956131], shape=(15,), dtype=float32)\n",
      "[0.57826431 0.55251938]\n",
      "tf.Tensor(\n",
      "[0.7769138  0.7900274  0.787963   0.7225514  0.7607372  0.6719565\n",
      " 0.6733853  0.5608764  0.48230317 0.5253998  0.28176615 0.37010866\n",
      " 0.1746049  0.23498641 0.1128964 ], shape=(15,), dtype=float32)\n",
      "No Success\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "daifa.train_tran = False\n",
    "daifa.train_vae = False\n",
    "\n",
    "daifa.hidden_state = None\n",
    "\n",
    "agent, succeeded, time_to_success = train_agent(env, daifa, observation_max, observation_min, observation_noise_stddev,\n",
    "                                                num_episodes=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}