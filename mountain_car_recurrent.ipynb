{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Run The Agent on Mountain Car"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "from vae_recurrent import VAE, create_decoder, create_encoder\n",
    "from transition_gru import TransitionGRU\n",
    "# from recurrent_agent import DAIFAgentRecurrent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "from util import random_observation_sequence, transform_observations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What does the agent do?\n",
    "- The agent plans using a policy then executes that policy for 12 simulation timesteps, the first two actions of the policy are executed for 6 steps each\n",
    "\n",
    "What data does it accumulate?\n",
    "- It accumulates 12 observation actions pairs\n",
    "\n",
    "How is it trained?\n",
    "- VAE is trained to reproduce observations using the latent states\n",
    "- Transition is trained by taking previous hidden state and previous latent state and trying to predict the next latent state"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Online learning For all tasks, we initialize all the agents with random weights and learn online only. Training an agent for 150 epochs takes about 3 minutes on a single CPU core (Intel I7-4870HQ). In contrast, previous approaches using active inference [Ueltzh√∂ffer, 2018, Tschantz et al., 2019, 2020] and policy gradient methods (e.g., [Liu et al., 2017]) use (offline) policy replay and typically need hours of GPU-accelerated compute while achieving similar convergence. To our knowledge, this is the first model-based RL method to learn online using neural network representations. This is afforded by the high sample efficiency of the FEEF, which directs exploration towards states that are uncertain for both the encoder and transition models.\n",
    "\n",
    "\n",
    "Why this is true?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "# Hide GPU from visible devices\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [],
   "source": [
    "def run_episode(mcc_env, agent, obs_max, obs_min, observation_noise_stddev=[0.05, 0.05], policy_repeats=1, episode_length=1000):\n",
    "\n",
    "    # arrays to store observations, actions and rewards\n",
    "    all_pre_observations = []\n",
    "    all_post_observations = []\n",
    "    all_action = []\n",
    "    observation_sequence = []\n",
    "    reward_sequence = []\n",
    "\n",
    "    # get the first observation from the environment\n",
    "    first_observation, info = mcc_env.reset()\n",
    "    first_observation = np.array([first_observation, 0])\n",
    "\n",
    "    # apply noise to and scaling to first observation\n",
    "    first_observation_noisy = transform_observations(first_observation, obs_max, obs_min, observation_noise_stddev)\n",
    "\n",
    "    # find the first policy\n",
    "    policy_observation = first_observation_noisy\n",
    "    policy = agent.select_policy(policy_observation)\n",
    "\n",
    "    # loop until episode ends or the agent succeeds\n",
    "    t = 0\n",
    "    while True:\n",
    "\n",
    "        if t % 10 == 0:\n",
    "            print(t)\n",
    "\n",
    "        # get the actions from the policy and reshape to desired form\n",
    "        actions = policy.mean()\n",
    "        actions = tf.reshape(actions, (actions.shape[0], agent.tran.action_dim))  # [num_actions, action_dim]\n",
    "        actions = actions.numpy()\n",
    "\n",
    "        # agent executes policy and gathers observations\n",
    "        for action in actions:\n",
    "            observation, reward, done, info = mcc_env.step(action)  # action should be array to satisfy gym requirements\n",
    "\n",
    "            # all_observations.append(observation)\n",
    "            # all_action.append(action)\n",
    "\n",
    "            t += 1\n",
    "            if done:\n",
    "                if t < 999:\n",
    "                    print(policy)\n",
    "                return t < 999, agent, t, all_pre_observations, all_post_observations, all_action # the max for the environment\n",
    "\n",
    "            observation_sequence.append(observation)\n",
    "            reward_sequence.append(reward)\n",
    "\n",
    "        # scale and add noise to the observation\n",
    "        observation_sequence = transform_observations(observation_sequence, obs_max, obs_min, observation_noise_stddev)\n",
    "\n",
    "        # get the noisy observations for pre and post actions\n",
    "        pre_observation_sequence = np.vstack([policy_observation, observation_sequence[:-1]])\n",
    "        post_action_observation_sequence = observation_sequence\n",
    "\n",
    "        all_pre_observations.append(pre_observation_sequence)\n",
    "        all_post_observations.append(post_action_observation_sequence)\n",
    "        all_action.append(actions)\n",
    "\n",
    "        # print(\"pol\", policy_observation)\n",
    "        # print(\"obs\", observation_sequence)\n",
    "        # print(\"pre\", pre_observation_sequence)\n",
    "        # print(\"post\", post_action_observation_sequence)\n",
    "\n",
    "        # if time to train the agent\n",
    "        agent.train(pre_observation_sequence, post_action_observation_sequence, actions, reward_sequence)\n",
    "\n",
    "        # the new observation we use to select a policy is the last observation in observation_sequences\n",
    "        policy_observation = observation_sequence[-1]\n",
    "\n",
    "        # select a new policy and clear everything\n",
    "        policy = agent.select_policy(policy_observation)\n",
    "\n",
    "        # clear the observations\n",
    "        observation_sequence = []\n",
    "        reward_sequence = []\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "def train_agent(mcc_env, agent, obs_max, obs_min, observation_noise_stddev, episode_length=1000, num_episodes=100):\n",
    "\n",
    "    time_to_success = []\n",
    "    did_succeed = []\n",
    "\n",
    "    for n in range(num_episodes):\n",
    "        print(\"Episode\", n+1)\n",
    "        success, agent, t, *rest = run_episode(mcc_env, agent, obs_max, obs_min, observation_noise_stddev, episode_length)\n",
    "\n",
    "        did_succeed.append(success)\n",
    "        time_to_success.append(t)\n",
    "\n",
    "        if success:\n",
    "            print(\"Success in episode\", n+1, \"at time step\", t)\n",
    "        else:\n",
    "            print(\"No Success\")\n",
    "\n",
    "    return agent, did_succeed, time_to_success"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "\n",
    "from vae_recurrent import VAE\n",
    "\n",
    "\n",
    "class DAIFAgentRecurrent:\n",
    "\n",
    "    def __init__(self,\n",
    "                 prior_model,\n",
    "                 vae,\n",
    "                 tran,\n",
    "                 given_prior_mean,\n",
    "                 given_prior_stddev,\n",
    "                 planning_horizon=15,\n",
    "                 n_policies=1500,\n",
    "                 n_cem_policy_iterations=2,\n",
    "                 n_policy_candidates=70,\n",
    "                 tran_train_epochs=1,\n",
    "                 vae_train_epochs=1):\n",
    "\n",
    "        super(DAIFAgentRecurrent, self).__init__()\n",
    "\n",
    "        self.prior_model = prior_model\n",
    "        self.planning_horizon = planning_horizon\n",
    "        self.n_policy_candidates = n_policy_candidates\n",
    "        self.n_policies = n_policies\n",
    "        self.n_cem_policy_iterations = n_cem_policy_iterations\n",
    "\n",
    "        self.vae_train_epochs = vae_train_epochs\n",
    "        self.tran_train_epochs = tran_train_epochs\n",
    "\n",
    "        self.given_prior_mean = given_prior_mean\n",
    "        self.given_prior_stddev = given_prior_stddev\n",
    "\n",
    "        # full vae\n",
    "        self.model_vae = vae\n",
    "        self.model_vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "        # transition\n",
    "        # takes action plus last state and outputs next latent state\n",
    "        self.tran = tran\n",
    "        self.tran.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "        self.hidden_state = None\n",
    "\n",
    "\n",
    "    def select_policy(self, observation):\n",
    "\n",
    "        policy_mean, policy_stddev = self.cem_policy_optimisation(observation)\n",
    "\n",
    "        # return a distribution that we can sample from\n",
    "        return tfp.distributions.MultivariateNormalDiag(loc=policy_mean, scale_diag=policy_stddev)\n",
    "\n",
    "\n",
    "    def train(self, pre_observations, post_observations, actions, rewards, verbose=0):\n",
    "\n",
    "        num_observations = pre_observations.shape[0]\n",
    "        observation_dim = pre_observations.shape[1]\n",
    "        action_dim = actions.shape[1]\n",
    "        # action_dim = 1  # TODO fix this to allow different actions\n",
    "\n",
    "        # find the actual observed latent states using the vae\n",
    "        pre_latent_mean, pre_latent_stddev, pre_latent = self.model_vae.encoder(pre_observations)\n",
    "        post_latent_mean, post_latent_stddev, post_latent = self.model_vae.encoder(post_observations)\n",
    "\n",
    "        # set up the input training data that we use to train the transition model\n",
    "        z_train = np.concatenate([np.array(pre_latent_mean), np.array(actions)], axis=1)\n",
    "\n",
    "        # we use the sequence to find the right hidden states to use as input\n",
    "        z_train_seq = z_train.reshape((1, num_observations, observation_dim + action_dim))\n",
    "        z_train_singles = z_train.reshape(num_observations, 1, observation_dim + action_dim)\n",
    "\n",
    "        # the previous hidden state is the memory after observing some sequences but it might be None\n",
    "        if self.hidden_state is None:\n",
    "            self.hidden_state = np.zeros((1, self.tran.hidden_units))\n",
    "\n",
    "        # find the hidden states at t=0, t=1, t=2, ..., t=num_observations - 1\n",
    "        _, _, _, h_states = self.tran((z_train_seq, self.hidden_state))\n",
    "\n",
    "        # squeeze so we make the shape [num_observations, hidden_units]\n",
    "        h_states = tf.squeeze(h_states)\n",
    "\n",
    "        # exclude the last state as this will become the hidden state later on. next hidden state will become our new memory\n",
    "        h_states_for_training = h_states[:-1]\n",
    "        # next_hidden_state = h_states[-1]\n",
    "\n",
    "        # add the current hidden state we saved to the start. This has h0, h1, h2, .. h=num_observations - 1\n",
    "        h_states_for_training = tf.concat([self.hidden_state, h_states_for_training], axis=0)\n",
    "\n",
    "        # use the hidden states with the pre and post observations to train transition model\n",
    "        self.tran.fit((z_train_singles, h_states_for_training), (post_latent_mean, post_latent_stddev), epochs=self.tran_train_epochs, verbose=verbose)\n",
    "\n",
    "        # train the vae model on post_observations because these are all new\n",
    "        self.model_vae.fit(post_observations, epochs=self.vae_train_epochs, verbose=verbose)\n",
    "\n",
    "        # now find the new predicted hidden state that we will use for finding the policy\n",
    "        # _, _, final_hidden_state, _ = self.tran((z_train_seq, self.hidden_state))\n",
    "        _, _, final_hidden_state, _ = self.tran((z_train_seq, None))\n",
    "\n",
    "        self.hidden_state = final_hidden_state\n",
    "\n",
    "\n",
    "    def cem_policy_optimisation(self, z_t_minus_one):\n",
    "\n",
    "        # need to change these two if the policy dimension changes\n",
    "        mean_best_policies = tf.zeros(self.planning_horizon)\n",
    "        std_best_policies = tf.ones(self.planning_horizon)\n",
    "\n",
    "        for i in range(self.n_cem_policy_iterations):\n",
    "            policy_distr = tfp.distributions.MultivariateNormalDiag(loc=mean_best_policies, scale_diag=std_best_policies)\n",
    "            policies = policy_distr.sample([self.n_policies])\n",
    "            policies = tf.clip_by_value(policies, clip_value_min=-1, clip_value_max=1)\n",
    "\n",
    "            # project trajectory into the future using transition model and calculate FEEF for each policy\n",
    "            policy_results = self.forward_policies(policies.numpy(), z_t_minus_one)\n",
    "            FEEFs = self.evaluate_policy(*policy_results)\n",
    "\n",
    "            FEEFs = tf.convert_to_tensor(FEEFs)\n",
    "\n",
    "            # sum over the timesteps to get the FEEF for each policy\n",
    "            FEEFs_sum = tf.reduce_sum(FEEFs, axis=0)\n",
    "\n",
    "            # multiply by one to find largest value which is euqivalent to smallest FEEF with top_k\n",
    "            neg_FEEF_sum = -1*FEEFs_sum\n",
    "\n",
    "            result = tf.math.top_k(neg_FEEF_sum, self.n_policy_candidates, sorted=False)\n",
    "            min_FEEF_indices = result.indices\n",
    "\n",
    "            # update the policy distributions\n",
    "            mean_best_policies = tf.reduce_mean(tf.gather(policies, min_FEEF_indices), axis=0)\n",
    "            std_best_policies = tf.math.reduce_std(tf.gather(policies, min_FEEF_indices), axis=0)\n",
    "\n",
    "\n",
    "        # TODO not sure why we need all of this is with the x means? I think it's for training but maybe not\n",
    "\n",
    "        # One last forward pass to gather the stats of the policy mean\n",
    "        #FEEFs, next_x_means, next_x_stds = self._forward_policies(mean_best_policies.unsqueeze(1))\n",
    "        # return mean_best_policies, std_best_policies, FEEFs.detach().squeeze(1), next_x_means.detach().squeeze(1), next_x_stds.detach().squeeze(1)\n",
    "\n",
    "        return mean_best_policies, std_best_policies\n",
    "\n",
    "\n",
    "    def forward_policies(self, policies, z_t_minus_one):\n",
    "        \"\"\"\n",
    "        Forward propogate a policy and compute the FEEF of each policy\n",
    "        :param z_t_minus_one:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # stack up the new observation to have shape [self.n_policies, len(z_t_minus_one)]\n",
    "        prev_latent_mean = np.stack([z_t_minus_one]*self.n_policies)\n",
    "\n",
    "        policy_posteriors = []\n",
    "        policy_sds = []\n",
    "        likelihoods = []\n",
    "        z_means = []\n",
    "        z_sds = []\n",
    "\n",
    "        # get the starting hidden state that coressponds to the memory stored by the previous sequences. Should have shape (1, self.tran.num_hidden_units) for the observed sequence\n",
    "        # extend the current hidden state to the number of policies present\n",
    "        if self.hidden_state is None:\n",
    "            cur_hidden_state = np.zeros((self.n_policies, self.tran.hidden_units))\n",
    "        else:\n",
    "            cur_hidden_state = np.vstack([self.hidden_state]*self.n_policies)\n",
    "\n",
    "        # find the predicted latent states from the transition model\n",
    "        for t in range(self.planning_horizon):\n",
    "\n",
    "            ob_plus_action = np.concatenate([prev_latent_mean, policies[:, t].reshape(self.n_policies, 1)], axis=1)\n",
    "            tran_input = ob_plus_action.reshape((self.n_policies, 1, ob_plus_action.shape[1]))  # reshape to pass to GRU\n",
    "\n",
    "            next_latent_mean, next_latent_sd, next_hidden_state, _ = self.tran((tran_input, cur_hidden_state))  # shape = [num policies, latent dim\n",
    "\n",
    "            # update the hidden state for use with the next policies\n",
    "            cur_hidden_state = next_hidden_state\n",
    "\n",
    "            policy_posteriors.append(next_latent_mean)\n",
    "            policy_sds.append(next_latent_sd)\n",
    "\n",
    "            next_likelihoods = self.model_vae.decoder(next_latent_mean)\n",
    "            likelihoods.append(next_likelihoods)\n",
    "\n",
    "            next_posterior_means, next_posteriors_sds, next_posteriors_z = self.model_vae.encoder(next_likelihoods)\n",
    "            z_means.append(next_posterior_means)\n",
    "            z_sds.append(next_posteriors_sds)\n",
    "\n",
    "            prev_latent_mean = next_latent_mean\n",
    "\n",
    "        return policy_posteriors, policy_sds, likelihoods, z_means, z_sds\n",
    "\n",
    "\n",
    "    def evaluate_policy(self, policy_posteriors, policy_sd, predicted_likelihood, predicted_posterior, predicted_posterior_sd):\n",
    "\n",
    "        return self.FEEF(policy_posteriors, policy_sd, predicted_likelihood, predicted_posterior, predicted_posterior_sd)\n",
    "\n",
    "\n",
    "    def FEEF(self, policy_posteriors_list, policy_sd_list, predicted_likelihood_list, predicted_posterior_list, predicted_posterior_sd_list):\n",
    "        \"\"\"\n",
    "        Compute the FEEF for policy selection\n",
    "        :param policy_posteriors:\n",
    "        :param predicted_likelihood:\n",
    "        :param predicted_posterior:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        FEEFs = []\n",
    "\n",
    "        for t in range(self.planning_horizon):\n",
    "\n",
    "            # extract the values for each time step\n",
    "            predicted_likelihood = predicted_likelihood_list[t]\n",
    "            policy_posteriors = policy_posteriors_list[t]\n",
    "            policy_sd = policy_sd_list[t]\n",
    "            predicted_posterior = predicted_posterior_list[t]\n",
    "            predicted_posterior_sd = predicted_posterior_sd_list[t]\n",
    "\n",
    "            # !!!! evaluate the EXTRINSIC KL divergence !!!!\n",
    "\n",
    "            # convert to normal distributions\n",
    "            # TODO Why is the stddev 1s here? I think because we assume it is on the true state of the world.\n",
    "            likelihood_dist = tfp.distributions.MultivariateNormalDiag(loc=predicted_likelihood, scale_diag=np.ones_like(predicted_likelihood))\n",
    "\n",
    "            if self.prior_model is None:\n",
    "\n",
    "                # TODO how exactly is the prior defined? After you apply transformations what is the prior\n",
    "                # create the prior distribution\n",
    "                prior_preferences_mean = tf.convert_to_tensor(np.stack([self.given_prior_mean]*self.n_policies), dtype=\"float32\")\n",
    "                prior_preferences_stddev = tf.convert_to_tensor(np.stack([self.given_prior_stddev]*self.n_policies), dtype=\"float32\")\n",
    "\n",
    "                prior_dist = tfp.distributions.MultivariateNormalDiag(loc=prior_preferences_mean, scale_diag=prior_preferences_stddev)\n",
    "\n",
    "            # TODO Fix the learned prior model\n",
    "            else:\n",
    "                prior_dist = self.prior_model()\n",
    "\n",
    "            kl_extrinsic = tfp.distributions.kl_divergence(likelihood_dist, prior_dist)\n",
    "\n",
    "            # !!!! evaluate the KL INTRINSIC part !!!!\n",
    "            policy_posteriors_dist = tfp.distributions.MultivariateNormalDiag(loc=policy_posteriors, scale_diag=policy_sd)\n",
    "            predicted_posterior_dist = tfp.distributions.MultivariateNormalDiag(loc=predicted_posterior, scale_diag=predicted_posterior_sd)\n",
    "\n",
    "            kl_intrinsic = tfp.distributions.kl_divergence(predicted_posterior_dist, policy_posteriors_dist)\n",
    "\n",
    "            FEEF = kl_extrinsic - kl_intrinsic\n",
    "\n",
    "            FEEFs.append(FEEF)\n",
    "\n",
    "        return FEEFs\n",
    "\n",
    "\n",
    "    def EFE(self, policy_posteriors, predicted_likelihood, predicted_posterior):\n",
    "        \"\"\"\n",
    "        Compute the EFE for policy selection\n",
    "        :param policy_posteriors:\n",
    "        :param predicted_likelihood:\n",
    "        :param predicted_posterior:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pass\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [],
   "source": [
    "enc = create_encoder(2, 2, [20])\n",
    "dec = create_decoder(2, 2, [20])\n",
    "vae = VAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "tran = TransitionGRU(2, 1, 12, 60, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.45, 0]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "observation_noise_stddev = [0, 0]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0,0])  # no noise on prior\n",
    "\n",
    "daifa = DAIFAgentRecurrent(None, vae, tran, scaled_prior_mean, prior_stddev)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "0\n",
      "30\n",
      "60\n",
      "90\n",
      "120\n",
      "150\n",
      "180\n",
      "210\n",
      "240\n",
      "270\n",
      "300\n",
      "330\n",
      "360\n",
      "390\n",
      "420\n",
      "450\n",
      "480\n",
      "510\n",
      "540\n",
      "570\n",
      "600\n",
      "630\n",
      "660\n",
      "Success in episode 1 at time step 685\n",
      "Episode 2\n",
      "0\n",
      "30\n",
      "60\n",
      "90\n",
      "120\n",
      "150\n",
      "180\n",
      "210\n",
      "240\n",
      "270\n",
      "300\n",
      "330\n",
      "360\n",
      "390\n",
      "420\n",
      "450\n",
      "480\n",
      "510\n",
      "540\n",
      "570\n",
      "600\n",
      "630\n",
      "660\n",
      "690\n",
      "720\n",
      "750\n",
      "780\n",
      "810\n",
      "840\n",
      "870\n",
      "900\n",
      "930\n",
      "960\n",
      "990\n",
      "No Success\n",
      "Episode 3\n",
      "0\n",
      "30\n",
      "60\n",
      "90\n",
      "120\n",
      "150\n",
      "180\n",
      "210\n",
      "240\n",
      "270\n",
      "300\n",
      "330\n",
      "360\n",
      "390\n",
      "420\n",
      "450\n",
      "480\n",
      "510\n",
      "540\n",
      "570\n",
      "600\n",
      "630\n",
      "660\n",
      "690\n",
      "720\n",
      "750\n",
      "Success in episode 3 at time step 775\n",
      "Episode 4\n",
      "0\n",
      "30\n",
      "60\n",
      "90\n",
      "120\n",
      "150\n",
      "180\n",
      "Success in episode 4 at time step 207\n",
      "Episode 5\n",
      "0\n",
      "30\n",
      "60\n",
      "90\n",
      "120\n",
      "150\n",
      "180\n",
      "210\n",
      "240\n",
      "270\n",
      "300\n",
      "330\n",
      "360\n",
      "390\n",
      "420\n",
      "450\n",
      "480\n",
      "510\n",
      "540\n",
      "570\n",
      "600\n",
      "630\n",
      "660\n",
      "690\n",
      "720\n",
      "750\n",
      "780\n",
      "810\n",
      "840\n",
      "870\n",
      "900\n",
      "930\n",
      "960\n",
      "990\n",
      "No Success\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "agent, succeeded, time_to_success = train_agent(env, daifa, observation_max, observation_min, observation_noise_stddev, num_episodes=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(time_to_success), time_to_success))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test the models produced"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[-4.11200672e-01,  0.00000000e+00,  8.70453715e-02],\n        [-4.11897212e-01, -6.96533592e-04,  9.12484288e-01],\n        [-4.12047178e-01, -1.49977262e-04,  3.95269096e-02],\n        ...,\n        [-4.41741168e-01, -8.41731299e-03,  7.88793385e-01],\n        [-4.49583083e-01, -7.84190279e-03,  7.74584651e-01],\n        [-4.56813663e-01, -7.23059289e-03, -9.67206419e-01]],\n\n       [[-4.42160368e-01,  0.00000000e+00,  7.79280484e-01],\n        [-4.41596180e-01,  5.64190792e-04, -1.80532649e-01],\n        [-4.41911638e-01, -3.15442914e-04,  4.04548228e-01],\n        ...,\n        [-4.54894215e-01, -3.60563770e-03, -4.09378260e-01],\n        [-4.59625572e-01, -4.73134872e-03,  2.57950217e-01],\n        [-4.64446843e-01, -4.82128235e-03,  7.45288432e-01]],\n\n       [[-5.31784356e-01,  0.00000000e+00, -8.07618558e-01],\n        [-5.32934427e-01, -1.15004205e-03, -9.58793938e-01],\n        [-5.35452664e-01, -2.51822476e-03,  8.32027197e-01],\n        ...,\n        [-5.49402714e-01, -3.52771278e-03,  5.38599849e-01],\n        [-5.51929176e-01, -2.52647675e-03,  5.34258723e-01],\n        [-5.53442061e-01, -1.51286635e-03, -7.45886117e-02]],\n\n       ...,\n\n       [[-4.05252755e-01,  0.00000000e+00,  4.97133762e-01],\n        [-4.05376136e-01, -1.23364473e-04,  6.12330735e-01],\n        [-4.05449212e-01, -7.30657994e-05, -3.46867859e-01],\n        ...,\n        [-4.30010498e-01, -4.74722963e-03,  6.46200716e-01],\n        [-4.34481144e-01, -4.47065523e-03, -8.13225031e-01],\n        [-4.40832078e-01, -6.35094102e-03,  5.04606068e-01]],\n\n       [[-4.44294214e-01,  0.00000000e+00,  1.77968904e-01],\n        [-4.44616467e-01, -3.22235574e-04, -5.07374227e-01],\n        [-4.46286589e-01, -1.67013681e-03,  2.53477156e-01],\n        ...,\n        [-4.66115177e-01, -5.03586745e-03, -3.65933508e-01],\n        [-4.72128928e-01, -6.01376081e-03, -5.27584314e-01],\n        [-4.79318559e-01, -7.18962913e-03,  4.29459244e-01]],\n\n       [[-4.33897376e-01,  0.00000000e+00, -5.73874891e-01],\n        [-4.35422838e-01, -1.52548240e-03,  5.40350914e-01],\n        [-4.36791420e-01, -1.36858982e-03, -8.39764953e-01],\n        ...,\n        [-4.66481119e-01, -5.97175816e-03,  8.18254530e-01],\n        [-4.71651793e-01, -5.17066568e-03,  9.62782800e-01],\n        [-4.75766301e-01, -4.11451887e-03,  8.98469090e-02]]])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_seqs = 1200\n",
    "seq_length = 12\n",
    "ob_dim = 2\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, seq_length)\n",
    "\n",
    "    train = np.concatenate([o[:-1], a], axis=1)\n",
    "    # train = o[:-1]\n",
    "    test = o[-1]\n",
    "\n",
    "    ob_seqs.append(train)\n",
    "    next_obs.append(test)\n",
    "\n",
    "ob_seqs = np.array(ob_seqs)\n",
    "next_obs = np.array(next_obs)\n",
    "ob_seqs_flat.shape\n",
    "\n",
    "ob_seqs_stddev = np.ones_like(ob_seqs_flat)\n",
    "next_obs_stddev = np.ones_like(ob_seqs_flat)\n",
    "\n",
    "ob_seqs_flat.shape\n",
    "\n",
    "# ob_seqs = transform_observations(ob_seqs, observation_max, observation_min, [0,0])\n",
    "\n",
    "ob_seqs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[0.40084078, 0.5       ],\n        [0.40063332, 0.49733267],\n        [0.400818  , 0.5023744 ],\n        ...,\n        [0.40380593, 0.497436  ],\n        [0.40346972, 0.49567731],\n        [0.40299592, 0.49390817]],\n\n       [[0.35217812, 0.5       ],\n        [0.35297981, 0.51030741],\n        [0.35477814, 0.52312171],\n        ...,\n        [0.3731825 , 0.54759189],\n        [0.37696869, 0.54867963],\n        [0.38085253, 0.54993506]],\n\n       [[0.41825164, 0.5       ],\n        [0.41863805, 0.50496814],\n        [0.41943579, 0.5102566 ],\n        ...,\n        [0.40065185, 0.44231838],\n        [0.39516142, 0.4294088 ],\n        [0.38937611, 0.42561743]],\n\n       ...,\n\n       [[0.3980581 , 0.5       ],\n        [0.39853252, 0.50609965],\n        [0.39801534, 0.49335054],\n        ...,\n        [0.3892667 , 0.48345105],\n        [0.38794025, 0.48294551],\n        [0.38585978, 0.47325106]],\n\n       [[0.40699541, 0.5       ],\n        [0.40668881, 0.49605815],\n        [0.40552974, 0.48509772],\n        ...,\n        [0.39634106, 0.46771013],\n        [0.39338535, 0.46199792],\n        [0.39080326, 0.4668016 ]],\n\n       [[0.39247947, 0.5       ],\n        [0.39205342, 0.49452233],\n        [0.39149873, 0.49286828],\n        ...,\n        [0.38618453, 0.49045351],\n        [0.38557623, 0.49217914],\n        [0.38535579, 0.4971658 ]]])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob_seqs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(14400, 2), dtype=float32, numpy=\narray([[0.38556084, 0.4905334 ],\n       [0.39635327, 0.5072894 ],\n       [0.39426306, 0.50200635],\n       ...,\n       [0.38257498, 0.49608925],\n       [0.38280475, 0.4925485 ],\n       [0.38699824, 0.493933  ]], dtype=float32)>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.model_vae(ob_seqs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Tensor: shape=(14400, 2), dtype=float32, numpy=\n array([[ 0.002228  , -0.00141016],\n        [ 0.00227949, -0.00126522],\n        [ 0.00219531, -0.00140826],\n        ...,\n        [ 0.00458311, -0.00133375],\n        [ 0.00438524, -0.00022276],\n        [ 0.00410312,  0.0010559 ]], dtype=float32)>,\n <tf.Tensor: shape=(14400, 2), dtype=float32, numpy=\n array([[0.3420336 , 0.370421  ],\n        [0.34153882, 0.3700512 ],\n        [0.34208104, 0.37044674],\n        ...,\n        [0.33828744, 0.36833283],\n        [0.3355602 , 0.3661365 ],\n        [0.33252472, 0.36367458]], dtype=float32)>,\n <tf.Tensor: shape=(14400, 2), dtype=float32, numpy=\n array([[ 0.34037507,  0.03871249],\n        [-0.2799148 , -0.26680294],\n        [ 0.11989297, -0.16823176],\n        ...,\n        [ 0.6025474 , -0.47514677],\n        [ 0.12444279, -0.17091578],\n        [-0.2816515 , -0.8058164 ]], dtype=float32)>]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = agent.model_vae.encoder(ob_seqs)\n",
    "z"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(14400, 2), dtype=float32, numpy=\narray([[0.4300636 , 0.49906108],\n       [0.43326598, 0.49975306],\n       [0.43286473, 0.49547517],\n       ...,\n       [0.38715714, 0.5023156 ],\n       [0.35460785, 0.48577   ],\n       [0.42961854, 0.4994094 ]], dtype=float32)>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.model_vae.decoder(z[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing the Identity VAE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from identity_vae import IdentityVAE, identity_encoder, identity_decoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "def identity_encoder(inputs):\n",
    "\n",
    "    return [inputs, np.ones_like(inputs), inputs]\n",
    "\n",
    "\n",
    "def identity_decoder(inputs):\n",
    "    return inputs\n",
    "\n",
    "\n",
    "class IdentityVAE(keras.Model):\n",
    "    \"\"\"\n",
    "    Implements the identity mapping with standard deviation as all 1s\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, reg_mean, reg_stddev, llik_scaling=1, kl_scaling=1, **kwargs):\n",
    "        super(IdentityVAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "\n",
    "        self.reg_mean = reg_mean\n",
    "        self.reg_stddev = reg_stddev\n",
    "\n",
    "        self.llik_scaling = llik_scaling\n",
    "        self.kl_scaling = kl_scaling\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        return inputs\n",
    "\n",
    "    def train_step(self, data):\n",
    "        return {\n",
    "            \"total_loss\": 0\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [],
   "source": [
    "enc = identity_encoder\n",
    "dec = identity_decoder\n",
    "idvae = IdentityVAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "hidden_size = 2*2*15  # 2*latent_dim * planning_size\n",
    "tran = TransitionGRU(2, 1, 12, hidden_size, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.6, 0]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "observation_noise_stddev = [0, 0]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0,0])  # no noise on prior\n",
    "\n",
    "daifa = DAIFAgentRecurrent(None, idvae, tran, scaled_prior_mean, prior_stddev)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "0\n",
      "30\n",
      "60\n",
      "90\n",
      "120\n",
      "150\n",
      "180\n",
      "210\n",
      "240\n",
      "270\n",
      "300\n",
      "330\n",
      "360\n",
      "390\n",
      "420\n",
      "450\n",
      "480\n",
      "510\n",
      "540\n",
      "570\n",
      "600\n",
      "630\n",
      "660\n",
      "690\n",
      "720\n",
      "750\n",
      "780\n",
      "810\n",
      "840\n",
      "870\n",
      "900\n",
      "930\n",
      "960\n",
      "990\n",
      "No Success\n",
      "Episode 2\n",
      "0\n",
      "30\n",
      "60\n",
      "90\n",
      "120\n",
      "150\n",
      "180\n",
      "210\n",
      "240\n",
      "270\n",
      "300\n",
      "330\n",
      "360\n",
      "390\n",
      "420\n",
      "450\n",
      "480\n",
      "510\n",
      "540\n",
      "570\n",
      "600\n",
      "630\n",
      "660\n",
      "690\n",
      "720\n",
      "750\n",
      "780\n",
      "810\n",
      "840\n",
      "870\n",
      "900\n",
      "930\n",
      "960\n",
      "990\n",
      "No Success\n",
      "Episode 3\n",
      "0\n",
      "30\n",
      "60\n",
      "90\n",
      "120\n",
      "150\n",
      "180\n",
      "210\n",
      "240\n",
      "270\n",
      "300\n",
      "330\n",
      "360\n",
      "390\n",
      "420\n",
      "450\n",
      "480\n",
      "510\n",
      "540\n",
      "570\n",
      "600\n",
      "630\n",
      "660\n",
      "690\n",
      "720\n",
      "750\n",
      "780\n",
      "810\n",
      "840\n",
      "870\n",
      "900\n",
      "930\n",
      "960\n",
      "990\n",
      "No Success\n",
      "Episode 4\n",
      "0\n",
      "30\n",
      "60\n",
      "90\n",
      "120\n",
      "150\n",
      "180\n",
      "210\n",
      "240\n",
      "270\n",
      "300\n",
      "330\n",
      "360\n",
      "390\n",
      "420\n",
      "450\n",
      "480\n",
      "510\n",
      "540\n",
      "570\n",
      "600\n",
      "630\n",
      "660\n",
      "690\n",
      "720\n",
      "750\n",
      "780\n",
      "810\n",
      "840\n",
      "870\n",
      "900\n",
      "930\n",
      "960\n",
      "990\n",
      "No Success\n",
      "Episode 5\n",
      "0\n",
      "30\n",
      "60\n",
      "90\n",
      "120\n",
      "150\n",
      "180\n",
      "210\n",
      "240\n",
      "270\n",
      "300\n",
      "330\n",
      "360\n",
      "390\n",
      "420\n",
      "450\n",
      "480\n",
      "510\n",
      "540\n",
      "570\n",
      "600\n",
      "630\n",
      "660\n",
      "690\n",
      "720\n",
      "750\n",
      "780\n",
      "810\n",
      "840\n",
      "870\n",
      "900\n",
      "930\n",
      "960\n",
      "990\n",
      "No Success\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "agent, succeeded, time_to_success = train_agent(env, daifa, observation_max, observation_min, observation_noise_stddev, num_episodes=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.11003135,  0.20155026]], dtype=float32)>,\n <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[1.0919429, 1.079277 ]], dtype=float32)>,\n <tf.Tensor: shape=(1, 30), dtype=float32, numpy=\n array([[ 0.13321629,  0.18998466, -0.04438917, -0.09943078,  0.00196455,\n         -0.01206965, -0.06738807, -0.07661976, -0.01011051,  0.04110336,\n          0.05621128,  0.1290381 ,  0.11428525, -0.09795906,  0.01192785,\n         -0.07657307, -0.03584003,  0.03242199,  0.1649867 ,  0.13230848,\n         -0.01292835,  0.10172065,  0.00063759,  0.0078836 ,  0.05896772,\n          0.05756728, -0.04861826,  0.13609464,  0.02476548, -0.12826644]],\n       dtype=float32)>,\n <tf.Tensor: shape=(1, 12, 30), dtype=float32, numpy=\n array([[[ 0.02993285,  0.0584089 , -0.06604871, -0.01244637,\n           0.03883965, -0.00862625, -0.04777011, -0.02679116,\n           0.02655492, -0.01026066, -0.00338584,  0.0400382 ,\n           0.02580428, -0.02700949,  0.03005333, -0.06231052,\n           0.02042874,  0.03170346,  0.01725759,  0.02311235,\n          -0.01136224, -0.01577884, -0.0204687 ,  0.02267304,\n          -0.01052346,  0.03995842, -0.03623634,  0.0563735 ,\n           0.01381678, -0.03317134],\n         [-0.05757806,  0.06193969, -0.19755387,  0.07849635,\n           0.1365188 , -0.04206091, -0.17609455, -0.02492426,\n           0.06428064, -0.12912339, -0.07998116, -0.03675418,\n           0.0088076 ,  0.070372  ,  0.10822617, -0.13803798,\n           0.0753141 ,  0.04077582, -0.05527983, -0.02052924,\n          -0.0100184 , -0.0990475 , -0.06956937,  0.01344517,\n          -0.10624609,  0.11016845, -0.13923958,  0.10176744,\n           0.06214096,  0.07947291],\n         [ 0.00099901,  0.09952143, -0.14824131,  0.02585305,\n           0.10221602, -0.0442883 , -0.12741598, -0.02350589,\n           0.026786  , -0.08134897, -0.04198802,  0.00552457,\n           0.04902555,  0.02529751,  0.07201948, -0.09788638,\n           0.0557276 ,  0.02231066,  0.02245994,  0.03995773,\n          -0.00798372, -0.03630174, -0.05837115,  0.01601139,\n          -0.04588886,  0.08966936, -0.11233205,  0.11984468,\n           0.05223556,  0.03211146],\n         [ 0.13056414,  0.15770933, -0.03208573, -0.09412152,\n          -0.00040321, -0.0150306 , -0.02037024, -0.05669748,\n          -0.01246329,  0.05789402,  0.05151292,  0.11068421,\n           0.10361664, -0.10847199, -0.0139912 , -0.05460785,\n          -0.01755995,  0.02480903,  0.15080988,  0.12087379,\n          -0.01444255,  0.08911278,  0.00656739,  0.02471166,\n           0.065384  ,  0.0327174 , -0.01987515,  0.11488698,\n           0.00524353, -0.12582926],\n         [ 0.01298778,  0.13630316, -0.1446228 ,  0.00815834,\n           0.09997333, -0.0301115 , -0.13677147, -0.06812851,\n           0.04408252, -0.05589635, -0.01423288,  0.04939101,\n           0.04682423,  0.01076769,  0.06766423, -0.1473241 ,\n           0.03356869,  0.04862081,  0.03531548,  0.05376476,\n          -0.01768889, -0.01951584, -0.02800098,  0.00585246,\n          -0.03598902,  0.10595562, -0.10793811,  0.12354154,\n           0.05064462, -0.01240673],\n         [ 0.07330359,  0.15447232, -0.08333942, -0.04923895,\n           0.0606624 , -0.02127063, -0.08740459, -0.06939748,\n           0.01340953,  0.00152428,  0.01948027,  0.09104314,\n           0.07681479, -0.0373668 ,  0.02635962, -0.11271214,\n           0.00365028,  0.04004948,  0.0870456 ,  0.09172144,\n          -0.01808305,  0.02866448, -0.01241705,  0.01011548,\n           0.01043832,  0.08131259, -0.07196644,  0.12496414,\n           0.03628882, -0.07318825],\n         [ 0.03734447,  0.14597945, -0.11759739, -0.01829428,\n           0.09935425, -0.02888209, -0.12699488, -0.0710006 ,\n           0.02683912, -0.03742937, -0.00506961,  0.06909262,\n           0.05971799,  0.00547109,  0.05138927, -0.14258668,\n           0.02065498,  0.0446776 ,  0.04393144,  0.06882204,\n          -0.0182247 , -0.01379964, -0.02614267,  0.0031904 ,\n          -0.02663907,  0.10740516, -0.10177995,  0.12848705,\n           0.05412998, -0.03438263],\n         [ 0.16270661,  0.18657231, -0.00431888, -0.13235615,\n          -0.00586104, -0.00074702, -0.02557212, -0.08708885,\n          -0.01472374,  0.09258249,  0.07547513,  0.15639952,\n           0.11060534, -0.12592192, -0.03088356, -0.08332342,\n          -0.04971972,  0.04190058,  0.16453116,  0.13896067,\n          -0.0204513 ,  0.10521525,  0.02819687,  0.01530079,\n           0.07318588,  0.04397818, -0.0121417 ,  0.11991425,\n           0.00757522, -0.17858876],\n         [ 0.22484493,  0.20858577,  0.05814844, -0.19851099,\n          -0.04701352,  0.02908107,  0.01382463, -0.11616528,\n          -0.021896  ,  0.17429917,  0.12019748,  0.22188726,\n           0.11336438, -0.1918678 , -0.0752768 , -0.09128967,\n          -0.09525131,  0.0639796 ,  0.19484581,  0.16889994,\n          -0.02466266,  0.14270106,  0.07159502,  0.01703326,\n           0.11231714,  0.03028883,  0.03726358,  0.10982041,\n          -0.01558259, -0.2845045 ],\n         [ 0.02595747,  0.16657819, -0.12867297, -0.02110907,\n           0.08571127, -0.00248913, -0.15836923, -0.11288866,\n           0.05814869, -0.02862367,  0.01969401,  0.11813108,\n           0.02976075, -0.01222235,  0.07588079, -0.19390501,\n          -0.00498081,  0.0834351 ,  0.03469723,  0.07252499,\n          -0.01939243, -0.0064735 , -0.00967364, -0.00985854,\n          -0.0248526 ,  0.12533817, -0.10299043,  0.12411836,\n           0.05467749, -0.06470479],\n         [-0.04016694,  0.13788535, -0.20154014,  0.05386092,\n           0.15624952, -0.03871916, -0.22826102, -0.07615418,\n           0.05998917, -0.13080825, -0.05901396,  0.01611179,\n           0.02587488,  0.08561166,  0.12387015, -0.19843666,\n           0.04556194,  0.0584335 , -0.03487249,  0.02025423,\n          -0.01289217, -0.08300564, -0.06449609, -0.01476793,\n          -0.10265449,  0.1606046 , -0.17604604,  0.1427406 ,\n           0.09185451,  0.04602269],\n         [ 0.13321629,  0.18998466, -0.04438917, -0.09943078,\n           0.00196455, -0.01206965, -0.06738807, -0.07661976,\n          -0.01011051,  0.04110336,  0.05621128,  0.1290381 ,\n           0.11428525, -0.09795906,  0.01192785, -0.07657307,\n          -0.03584003,  0.03242199,  0.1649867 ,  0.13230848,\n          -0.01292835,  0.10172065,  0.00063759,  0.0078836 ,\n           0.05896772,  0.05756728, -0.04861826,  0.13609464,\n           0.02476548, -0.12826644]]], dtype=float32)>]"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = agent.tran((ob_seqs[0:1], None))\n",
    "out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.04016694,  0.13788535, -0.20154014,  0.05386092,  0.15624952,\n        -0.03871916, -0.22826102, -0.07615418,  0.05998917, -0.13080825,\n        -0.05901396,  0.01611179,  0.02587488,  0.08561166,  0.12387015,\n        -0.19843666,  0.04556194,  0.0584335 , -0.03487249,  0.02025423,\n        -0.01289217, -0.08300564, -0.06449609, -0.01476793, -0.10265449,\n         0.1606046 , -0.17604604,  0.1427406 ,  0.09185451,  0.04602269]],\n      dtype=float32)"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = ob_seqs[0:1, -1].reshape(1,1,3)\n",
    "h = out[3]\n",
    "h = h[0, -2, :]\n",
    "h = h.numpy().reshape(1,30)\n",
    "h"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.11003135,  0.20155026]], dtype=float32)>,\n <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[1.0919429, 1.079277 ]], dtype=float32)>,\n <tf.Tensor: shape=(1, 30), dtype=float32, numpy=\n array([[ 0.13321629,  0.18998466, -0.04438917, -0.09943078,  0.00196455,\n         -0.01206965, -0.06738807, -0.07661976, -0.01011051,  0.04110336,\n          0.05621128,  0.1290381 ,  0.11428525, -0.09795906,  0.01192785,\n         -0.07657307, -0.03584003,  0.03242199,  0.1649867 ,  0.13230848,\n         -0.01292835,  0.10172065,  0.00063759,  0.0078836 ,  0.05896772,\n          0.05756728, -0.04861826,  0.13609464,  0.02476548, -0.12826644]],\n       dtype=float32)>,\n <tf.Tensor: shape=(1, 1, 30), dtype=float32, numpy=\n array([[[ 0.13321629,  0.18998466, -0.04438917, -0.09943078,\n           0.00196455, -0.01206965, -0.06738807, -0.07661976,\n          -0.01011051,  0.04110336,  0.05621128,  0.1290381 ,\n           0.11428525, -0.09795906,  0.01192785, -0.07657307,\n          -0.03584003,  0.03242199,  0.1649867 ,  0.13230848,\n          -0.01292835,  0.10172065,  0.00063759,  0.0078836 ,\n           0.05896772,  0.05756728, -0.04861826,  0.13609464,\n           0.02476548, -0.12826644]]], dtype=float32)>]"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.tran((t, h))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ob_seqs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mob_seqs\u001B[49m[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ob_seqs' is not defined"
     ]
    }
   ],
   "source": [
    "ob_seqs[0:1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test to see how the agent trains on standard observation data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [
    "enc = identity_encoder\n",
    "dec = identity_decoder\n",
    "idvae = IdentityVAE(enc, dec, [0, 0], [0.3, 0.3], llik_scaling=100)\n",
    "\n",
    "hidden_size = 2*2*15  # 2*latent_dim * planning_size\n",
    "tran = TransitionGRU(2, 1, 12, hidden_size, 2)\n",
    "\n",
    "# unscaled prior mean and prior stddev\n",
    "prior_mean = [0.6, 0]\n",
    "prior_stddev = [1, 1]\n",
    "\n",
    "observation_max = np.array([0.6, 0.07])\n",
    "observation_min = np.array([-1.2, -0.07])\n",
    "\n",
    "observation_noise_stddev = [0, 0]\n",
    "\n",
    "scaled_prior_mean = transform_observations(prior_mean, observation_max, observation_min, [0,0])  # no noise on prior\n",
    "\n",
    "daifa = DAIFAgentRecurrent(None, idvae, tran, scaled_prior_mean, prior_stddev, vae_train_epochs=1, tran_train_epochs=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "30\n",
      "60\n",
      "90\n",
      "120\n",
      "150\n",
      "180\n",
      "210\n",
      "240\n",
      "270\n",
      "300\n",
      "330\n",
      "360\n",
      "390\n",
      "420\n",
      "450\n",
      "480\n",
      "510\n",
      "540\n",
      "570\n",
      "600\n",
      "630\n",
      "660\n",
      "690\n",
      "720\n",
      "750\n",
      "780\n",
      "810\n",
      "840\n",
      "870\n",
      "900\n",
      "930\n",
      "960\n",
      "990\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "success, agent, t, pre_obs, post_obs, acts = run_episode(env, daifa, observation_max, observation_min, observation_noise_stddev)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "pre_np = np.array(pre_obs)\n",
    "a = np.array(acts)\n",
    "a.shape\n",
    "pre_a = np.concatenate([pre_np, a], axis=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8098704 -0.06532676\n"
     ]
    }
   ],
   "source": [
    "print(a.max(), a.min())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[0.37008965, 0.5       , 0.64274138],\n        [0.37066795, 0.50743499, 0.55658776],\n        [0.37174838, 0.51389117, 0.65481091],\n        ...,\n        [0.41047474, 0.57226037, 0.52277917],\n        [0.41627194, 0.57453541, 0.52470559],\n        [0.4222051 , 0.57628357, 0.37393394]],\n\n       [[0.42810532, 0.5758599 , 0.69643861],\n        [0.43419865, 0.57834281, 0.68352282],\n        [0.44043066, 0.58012587, 0.69041729],\n        ...,\n        [0.4988479 , 0.56140433, 0.59778053],\n        [0.50326538, 0.55679618, 0.60766363],\n        [0.50730686, 0.55196177, 0.29275563]],\n\n       [[0.51068671, 0.54345512, 0.71056032],\n        [0.51373403, 0.53917979, 0.64313263],\n        [0.51637571, 0.53396438, 0.61633205],\n        ...,\n        [0.51848038, 0.47661969, 0.41549021],\n        [0.51604071, 0.46863281, 0.45536974],\n        [0.51302629, 0.46124309, 0.283014  ]],\n\n       ...,\n\n       [[0.51902043, 0.52036842, 0.76976782],\n        [0.52027577, 0.51614007, 0.68564558],\n        [0.52112542, 0.51092408, 0.71046662],\n        ...,\n        [0.50581347, 0.45327371, 0.42321566],\n        [0.50163482, 0.4462744 , 0.48510316],\n        [0.49698749, 0.44024871, 0.02759302]],\n\n       [[0.49151762, 0.42967318, 0.8000406 ],\n        [0.48590184, 0.427797  , 0.69543582],\n        [0.48008747, 0.42524395, 0.72683179],\n        ...,\n        [0.41667555, 0.41884794, 0.44241443],\n        [0.41042815, 0.41967643, 0.35740781],\n        [0.40422025, 0.42018404, 0.1487067 ]],\n\n       [[0.39792378, 0.41904549, 0.75880796],\n        [0.39209396, 0.42504522, 0.69213176],\n        [0.38671872, 0.43088967, 0.66640788],\n        ...,\n        [0.36231071, 0.50088702, 0.48592171],\n        [0.36288557, 0.50739085, 0.42316961],\n        [0.36390968, 0.51316705, 0.21686298]]])"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.42810532, 0.5758599 ],\n       [0.51068671, 0.54345512],\n       [0.50931002, 0.45221953],\n       [0.42358571, 0.41151359],\n       [0.36385255, 0.48845687],\n       [0.41928679, 0.5793542 ],\n       [0.51176256, 0.55046145],\n       [0.51612226, 0.45125959],\n       [0.42809368, 0.40711605],\n       [0.36297415, 0.4807838 ],\n       [0.41079962, 0.57215037],\n       [0.50237944, 0.55340252],\n       [0.51530115, 0.46191713],\n       [0.43562587, 0.40977219],\n       [0.36920734, 0.47506812],\n       [0.40700312, 0.56339959],\n       [0.4956689 , 0.55673263],\n       [0.51504541, 0.46971338],\n       [0.44361163, 0.41414712],\n       [0.37392667, 0.47021407],\n       [0.40472932, 0.56099515],\n       [0.48988603, 0.55681477],\n       [0.513942  , 0.47466574],\n       [0.44597241, 0.41866915],\n       [0.37727873, 0.46897353],\n       [0.40491911, 0.55493856],\n       [0.48499408, 0.55410988],\n       [0.50919015, 0.47715691],\n       [0.44699771, 0.42027778],\n       [0.37685666, 0.4646408 ],\n       [0.4013226 , 0.55570643],\n       [0.48648025, 0.56149114],\n       [0.51706974, 0.47973928],\n       [0.45409549, 0.41666832],\n       [0.37663186, 0.45648902],\n       [0.39231649, 0.54964942],\n       [0.47922549, 0.56718941],\n       [0.51924709, 0.49147052],\n       [0.46453978, 0.41845615],\n       [0.38296657, 0.44712665],\n       [0.38754725, 0.54175509],\n       [0.47101566, 0.57034665],\n       [0.52088235, 0.50081996],\n       [0.4724994 , 0.41899036],\n       [0.38480849, 0.43652156],\n       [0.37787375, 0.54014186],\n       [0.46650263, 0.57630284],\n       [0.52448234, 0.50651676],\n       [0.4807795 , 0.42013854],\n       [0.38625364, 0.4286503 ],\n       [0.37072676, 0.53348032],\n       [0.45750572, 0.58157883],\n       [0.52363857, 0.51193641],\n       [0.48661047, 0.42703592],\n       [0.39694335, 0.42853919],\n       [0.37388365, 0.51997265],\n       [0.4499277 , 0.57756473],\n       [0.5193425 , 0.51587622],\n       [0.48807406, 0.42949548],\n       [0.39740197, 0.42433574],\n       [0.37122472, 0.52076801],\n       [0.44857458, 0.57695733],\n       [0.51902043, 0.52036842],\n       [0.49151762, 0.42967318],\n       [0.39792378, 0.41904549],\n       [0.36520346, 0.51663429]])"
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_obs_to_predict = np.array(post_obs)[:, 14, :]\n",
    "post_obs_to_predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Tensor: shape=(66, 2), dtype=float32, numpy=\n array([[0.4335834 , 0.56521523],\n        [0.5122515 , 0.5295362 ],\n        [0.51478904, 0.44462413],\n        [0.44347557, 0.41256368],\n        [0.383164  , 0.48628917],\n        [0.4260966 , 0.5680216 ],\n        [0.5181996 , 0.5348844 ],\n        [0.5264323 , 0.44104174],\n        [0.4424122 , 0.40895247],\n        [0.38420513, 0.47790435],\n        [0.4277233 , 0.5596743 ],\n        [0.5128076 , 0.538141  ],\n        [0.52519715, 0.45137712],\n        [0.45522428, 0.40997675],\n        [0.3892485 , 0.4731649 ],\n        [0.4223162 , 0.5517151 ],\n        [0.50446856, 0.54205805],\n        [0.522131  , 0.4598966 ],\n        [0.45934907, 0.41366938],\n        [0.39034382, 0.46974748],\n        [0.415123  , 0.55189383],\n        [0.49791732, 0.5430331 ],\n        [0.52315855, 0.46357197],\n        [0.45980898, 0.4188894 ],\n        [0.39460406, 0.46837974],\n        [0.42059064, 0.5451353 ],\n        [0.4946693 , 0.54093736],\n        [0.5175607 , 0.46689713],\n        [0.46580005, 0.4187842 ],\n        [0.39957485, 0.46362427],\n        [0.4146205 , 0.5465214 ],\n        [0.49053243, 0.54863274],\n        [0.52474153, 0.4684622 ],\n        [0.46849853, 0.41575998],\n        [0.39764547, 0.45653152],\n        [0.40991077, 0.53955364],\n        [0.48664662, 0.5533775 ],\n        [0.5193668 , 0.48099416],\n        [0.48015976, 0.4157722 ],\n        [0.4028918 , 0.44667172],\n        [0.4047331 , 0.53366214],\n        [0.4738106 , 0.55826354],\n        [0.52258134, 0.48942593],\n        [0.4894658 , 0.41521114],\n        [0.40780059, 0.43638048],\n        [0.38921732, 0.5345061 ],\n        [0.4768501 , 0.56213534],\n        [0.5284387 , 0.49375898],\n        [0.49610656, 0.41558278],\n        [0.40856773, 0.42929885],\n        [0.3868105 , 0.52685   ],\n        [0.4678745 , 0.5671958 ],\n        [0.53226554, 0.49707684],\n        [0.4958061 , 0.42337653],\n        [0.41607773, 0.43051717],\n        [0.39658514, 0.5132288 ],\n        [0.45739624, 0.5649689 ],\n        [0.53346115, 0.5004597 ],\n        [0.50005674, 0.42419076],\n        [0.42160243, 0.42577726],\n        [0.3867506 , 0.51522905],\n        [0.46196985, 0.5631596 ],\n        [0.52865934, 0.50576687],\n        [0.50851446, 0.4226513 ],\n        [0.42311707, 0.41925052],\n        [0.38635004, 0.51085395]], dtype=float32)>,\n <tf.Tensor: shape=(66, 2), dtype=float32, numpy=\n array([[0.99356395, 1.0033652 ],\n        [0.9966783 , 1.0038822 ],\n        [0.9949304 , 1.0002915 ],\n        [0.98948455, 0.9983483 ],\n        [0.9880373 , 1.0002997 ],\n        [0.99195176, 1.003683  ],\n        [0.99569446, 1.0029051 ],\n        [0.99456704, 0.99959266],\n        [0.9886448 , 0.997924  ],\n        [0.9861564 , 0.99961126],\n        [0.9908817 , 1.0024914 ],\n        [0.996693  , 1.0023209 ],\n        [0.99451745, 1.0009286 ],\n        [0.990051  , 0.9985831 ],\n        [0.98699874, 0.99940336],\n        [0.9895779 , 1.0016457 ],\n        [0.99598587, 1.0032132 ],\n        [0.9957744 , 1.0005796 ],\n        [0.9897634 , 0.9984388 ],\n        [0.98769516, 1.0000045 ],\n        [0.99177426, 1.002091  ],\n        [0.9959623 , 1.0025886 ],\n        [0.9939278 , 1.0013951 ],\n        [0.9909717 , 0.99957836],\n        [0.9879322 , 1.0005703 ],\n        [0.9907637 , 1.0019658 ],\n        [0.99554753, 1.0027039 ],\n        [0.99519634, 1.0004063 ],\n        [0.99067193, 0.9981353 ],\n        [0.98835784, 0.99962515],\n        [0.9910858 , 1.0022018 ],\n        [0.99608654, 1.0031066 ],\n        [0.995567  , 1.000658  ],\n        [0.9908829 , 0.99822795],\n        [0.9882461 , 0.9987908 ],\n        [0.9890275 , 1.001404  ],\n        [0.9950521 , 1.0030775 ],\n        [0.99661815, 1.001139  ],\n        [0.9909045 , 0.99886507],\n        [0.9863141 , 0.99935186],\n        [0.9899773 , 1.0010997 ],\n        [0.9954982 , 1.0022657 ],\n        [0.99690324, 1.0015687 ],\n        [0.991679  , 0.9984541 ],\n        [0.98678565, 0.99812907],\n        [0.9906107 , 1.0015656 ],\n        [0.9950106 , 1.002261  ],\n        [0.99711466, 1.001726  ],\n        [0.9914013 , 0.9995291 ],\n        [0.98545843, 0.99940705],\n        [0.98873436, 1.0012671 ],\n        [0.9939272 , 1.0028934 ],\n        [0.99630606, 1.0004414 ],\n        [0.9933961 , 0.9996921 ],\n        [0.9887138 , 0.99903923],\n        [0.9879206 , 1.0013058 ],\n        [0.99417764, 1.0033696 ],\n        [0.9959742 , 1.0005254 ],\n        [0.99255073, 0.9987929 ],\n        [0.9893073 , 0.9984611 ],\n        [0.98781735, 1.0006741 ],\n        [0.99200296, 1.0032303 ],\n        [0.996231  , 1.0018178 ],\n        [0.9914634 , 0.9998772 ],\n        [0.987089  , 0.99838597],\n        [0.9878724 , 1.000988  ]], dtype=float32)>,\n <tf.Tensor: shape=(66, 60), dtype=float32, numpy=\n array([[-0.00412053, -0.0548397 , -0.02105086, ..., -0.18615234,\n         -0.1243834 ,  0.03703548],\n        [ 0.01227194, -0.04127496, -0.02165971, ..., -0.20673558,\n         -0.13424802,  0.0361875 ],\n        [ 0.02501806, -0.02425337, -0.01380702, ..., -0.20044836,\n         -0.12666067,  0.03333614],\n        ...,\n        [ 0.032469  , -0.01071232, -0.0078447 , ..., -0.18106137,\n         -0.13230857,  0.04622431],\n        [ 0.01669927, -0.02482074, -0.0066153 , ..., -0.16300215,\n         -0.11298063,  0.03715113],\n        [-0.0017443 , -0.04514889, -0.01285888, ..., -0.15903398,\n         -0.11555594,  0.04059453]], dtype=float32)>,\n <tf.Tensor: shape=(66, 15, 60), dtype=float32, numpy=\n array([[[-0.03244051, -0.04293223, -0.01032136, ..., -0.08151992,\n          -0.02342675,  0.00088571],\n         [-0.0341845 , -0.06092318, -0.00988075, ..., -0.12245784,\n          -0.04847908,  0.00394268],\n         [-0.0331136 , -0.07392804, -0.01127515, ..., -0.15342827,\n          -0.06141288, -0.00031245],\n         ...,\n         [-0.01253642, -0.06585434, -0.02158703, ..., -0.19162427,\n          -0.11396748,  0.02611647],\n         [-0.01049543, -0.06408856, -0.0226759 , ..., -0.19358799,\n          -0.11637782,  0.02735977],\n         [-0.00412053, -0.0548397 , -0.02105086, ..., -0.18615234,\n          -0.1243834 ,  0.03703548]],\n \n        [[-0.03410819, -0.04543843, -0.01188152, ..., -0.08917266,\n          -0.0277997 ,  0.00306407],\n         [-0.03734994, -0.06824173, -0.01347112, ..., -0.13989952,\n          -0.05254892,  0.00217712],\n         [-0.03322814, -0.07859623, -0.01365479, ..., -0.17055613,\n          -0.07007323,  0.00112065],\n         ...,\n         [ 0.00094837, -0.05882645, -0.02512814, ..., -0.22211805,\n          -0.12188726,  0.01996782],\n         [ 0.00190525, -0.05854829, -0.02642754, ..., -0.22481282,\n          -0.12191736,  0.01841984],\n         [ 0.01227194, -0.04127496, -0.02165971, ..., -0.20673558,\n          -0.13424802,  0.0361875 ]],\n \n        [[-0.02853591, -0.04163325, -0.00814577, ..., -0.09502032,\n          -0.02544583,  0.0068563 ],\n         [-0.02682905, -0.05917161, -0.00743338, ..., -0.14598632,\n          -0.05269429,  0.0088629 ],\n         [-0.01856716, -0.06422289, -0.00612724, ..., -0.17531049,\n          -0.07300429,  0.00956911],\n         ...,\n         [ 0.01427232, -0.04180268, -0.01746039, ..., -0.21667935,\n          -0.11725496,  0.01814013],\n         [ 0.01751623, -0.03649734, -0.01693931, ..., -0.2129779 ,\n          -0.11905645,  0.02168418],\n         [ 0.02501806, -0.02425337, -0.01380702, ..., -0.20044836,\n          -0.12666067,  0.03333614]],\n \n        ...,\n \n        [[-0.02927583, -0.04394017, -0.00872408, ..., -0.09931245,\n          -0.02078249,  0.00306813],\n         [-0.02752193, -0.06201773, -0.00801599, ..., -0.15110998,\n          -0.04701492,  0.00371979],\n         [-0.02110069, -0.07017399, -0.00771053, ..., -0.18387204,\n          -0.06451955,  0.00041101],\n         ...,\n         [ 0.01726429, -0.03745886, -0.01567594, ..., -0.21189702,\n          -0.11502871,  0.01841556],\n         [ 0.01821875, -0.03584571, -0.0164775 , ..., -0.21149017,\n          -0.11433437,  0.01816645],\n         [ 0.032469  , -0.01071232, -0.0078447 , ..., -0.18106137,\n          -0.13230857,  0.04622431]],\n \n        [[-0.0282876 , -0.04434773, -0.00781866, ..., -0.09914976,\n          -0.01133177, -0.00279203],\n         [-0.0268082 , -0.06211937, -0.00671278, ..., -0.14849041,\n          -0.03389686, -0.00431426],\n         [-0.02182906, -0.07096858, -0.00639208, ..., -0.17939225,\n          -0.04871727, -0.0094508 ],\n         ...,\n         [ 0.00414334, -0.04775853, -0.01327589, ..., -0.19216959,\n          -0.09574736,  0.01043641],\n         [ 0.00814041, -0.040219  , -0.01154546, ..., -0.18225175,\n          -0.10150395,  0.0192098 ],\n         [ 0.01669927, -0.02482074, -0.0066153 , ..., -0.16300215,\n          -0.11298063,  0.03715113]],\n \n        [[-0.03180883, -0.04594116, -0.00991276, ..., -0.09067608,\n          -0.01131774, -0.00663446],\n         [-0.03448872, -0.06708369, -0.01037207, ..., -0.13698879,\n          -0.03072704, -0.01030481],\n         [-0.03081094, -0.07547373, -0.00940067, ..., -0.16168383,\n          -0.04622322, -0.01158913],\n         ...,\n         [-0.01327306, -0.06422891, -0.01712672, ..., -0.17973131,\n          -0.09820023,  0.01711263],\n         [-0.01007425, -0.05909261, -0.01669533, ..., -0.17468408,\n          -0.10365151,  0.023746  ],\n         [-0.0017443 , -0.04514889, -0.01285888, ..., -0.15903398,\n          -0.11555594,  0.04059453]]], dtype=float32)>]"
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.tran((pre_a, None))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.42810532, 0.5758599 ],\n       [0.51068671, 0.54345512],\n       [0.50931002, 0.45221953],\n       [0.42358571, 0.41151359],\n       [0.36385255, 0.48845687],\n       [0.41928679, 0.5793542 ],\n       [0.51176256, 0.55046145],\n       [0.51612226, 0.45125959],\n       [0.42809368, 0.40711605],\n       [0.36297415, 0.4807838 ],\n       [0.41079962, 0.57215037],\n       [0.50237944, 0.55340252],\n       [0.51530115, 0.46191713],\n       [0.43562587, 0.40977219],\n       [0.36920734, 0.47506812],\n       [0.40700312, 0.56339959],\n       [0.4956689 , 0.55673263],\n       [0.51504541, 0.46971338],\n       [0.44361163, 0.41414712],\n       [0.37392667, 0.47021407],\n       [0.40472932, 0.56099515],\n       [0.48988603, 0.55681477],\n       [0.513942  , 0.47466574],\n       [0.44597241, 0.41866915],\n       [0.37727873, 0.46897353],\n       [0.40491911, 0.55493856],\n       [0.48499408, 0.55410988],\n       [0.50919015, 0.47715691],\n       [0.44699771, 0.42027778],\n       [0.37685666, 0.4646408 ],\n       [0.4013226 , 0.55570643],\n       [0.48648025, 0.56149114],\n       [0.51706974, 0.47973928],\n       [0.45409549, 0.41666832],\n       [0.37663186, 0.45648902],\n       [0.39231649, 0.54964942],\n       [0.47922549, 0.56718941],\n       [0.51924709, 0.49147052],\n       [0.46453978, 0.41845615],\n       [0.38296657, 0.44712665],\n       [0.38754725, 0.54175509],\n       [0.47101566, 0.57034665],\n       [0.52088235, 0.50081996],\n       [0.4724994 , 0.41899036],\n       [0.38480849, 0.43652156],\n       [0.37787375, 0.54014186],\n       [0.46650263, 0.57630284],\n       [0.52448234, 0.50651676],\n       [0.4807795 , 0.42013854],\n       [0.38625364, 0.4286503 ],\n       [0.37072676, 0.53348032],\n       [0.45750572, 0.58157883],\n       [0.52363857, 0.51193641],\n       [0.48661047, 0.42703592],\n       [0.39694335, 0.42853919],\n       [0.37388365, 0.51997265],\n       [0.4499277 , 0.57756473],\n       [0.5193425 , 0.51587622],\n       [0.48807406, 0.42949548],\n       [0.39740197, 0.42433574],\n       [0.37122472, 0.52076801],\n       [0.44857458, 0.57695733],\n       [0.51902043, 0.52036842],\n       [0.49151762, 0.42967318],\n       [0.39792378, 0.41904549],\n       [0.36520346, 0.51663429]])"
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_obs_to_predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Examine training the model on the observation data\n",
    "\n",
    "Does it eventually converge to a good model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 3ms/step - kl_loss: 4.7919e-04\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 5ms/step - kl_loss: 4.6558e-04\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0000e+00\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 3ms/step - kl_loss: 3.9567e-04\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.1613e-04\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0000e+00\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.7384e-04\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.4494e-04\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0000e+00\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1136e-04\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.1044e-04\n",
      "1/1 [==============================] - 0s 970us/step - total_loss: 0.0000e+00\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 8.0452e-04\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 7.8791e-04\n",
      "1/1 [==============================] - 0s 982us/step - total_loss: 0.0000e+00\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 4.4774e-04\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.9684e-04\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0000e+00\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.4286e-04\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 6.6104e-04\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0000e+00\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 8.8242e-04\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 8.2337e-04\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0000e+00\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.3909e-04\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.3650e-04\n",
      "1/1 [==============================] - 0s 912us/step - total_loss: 0.0000e+00\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 9.0806e-04\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 9.1419e-04\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0000e+00\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.5596e-04\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.2383e-04\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0000e+00\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.6261e-04\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.6076e-04\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0000e+00\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 3ms/step - kl_loss: 5.9985e-04\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 5.6483e-04\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0000e+00\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.4255e-04\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 3.4806e-04\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0000e+00\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0010\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 2ms/step - kl_loss: 0.0010\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "num_train_runs = 1\n",
    "for i in range(num_train_runs):\n",
    "\n",
    "    for j in range(len(pre)):\n",
    "        pre = pre_obs[j]\n",
    "        post = post_obs[j]\n",
    "        actions = acts[j]\n",
    "\n",
    "        daifa.train(pre, post, actions, None, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(15,), dtype=float32, numpy=\n array([ 0.8344159 ,  0.75534546,  0.6847398 ,  0.80220443,  0.6786175 ,\n         0.8187225 ,  0.5921203 ,  0.64381874,  0.5857641 ,  0.4067325 ,\n         0.4416599 ,  0.26479524,  0.4449845 ,  0.07807608, -0.05506114],\n       dtype=float32)>,\n <tf.Tensor: shape=(15,), dtype=float32, numpy=\n array([0.20074226, 0.2792185 , 0.32190827, 0.28694943, 0.37440932,\n        0.31017554, 0.39044052, 0.39928463, 0.4503296 , 0.4880389 ,\n        0.40736437, 0.52849865, 0.46789622, 0.59326804, 0.56217706],\n       dtype=float32)>)"
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daifa.cem_policy_optimisation(np.array([0.5, 0.1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method DAIFAgentRecurrent.cem_policy_optimisation of <__main__.DAIFAgentRecurrent object at 0x16cc659a0>>"
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daifa.cem_policy_optimisation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}