{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from vae import VAE, create_decoder, create_encoder\n",
    "from transition_gru import TransitionGRU\n",
    "from recurrent_agent import DAIFAgentRecurrent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from util import random_observation_sequence, transform_observations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "enc = create_encoder(2, 2, [20])\n",
    "dec = create_decoder(2, 2, [20])\n",
    "# tran = TransitionGRU(2, 1)\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TransitionGRU(keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dim, action_dim, seq_length, hidden_units, output_dim, batch_size=None, **kwargs):\n",
    "        super(TransitionGRU, self).__init__(**kwargs)\n",
    "\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.seq_length = seq_length\n",
    "        self.hidden_units = hidden_units\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.batch_size = batch_size  # this should be number of policies I think\n",
    "\n",
    "\n",
    "        inputs = layers.Input(shape=(None, self.latent_dim + self.action_dim))\n",
    "        initial_state_input = layers.Input((self.hidden_units, ))\n",
    "        h_states, final_state = layers.GRU(self.hidden_units, activation=\"tanh\", return_sequences=True, return_state=True, name=\"gru\")(inputs, initial_state=initial_state_input)\n",
    "\n",
    "        # TODO is this correctly getting the last hidden state or the first???\n",
    "        z_mean = layers.Dense(latent_dim, name=\"z_mean\")(final_state)  # all batch last time step all dimension\n",
    "        z_log_sd = layers.Dense(latent_dim, name=\"z_log_sd\")(final_state)\n",
    "        z_stddev = tf.exp(z_log_sd)\n",
    "\n",
    "        self.transition_model = keras.Model([inputs, initial_state_input], [z_mean, z_stddev, final_state, h_states], name=\"transition\")\n",
    "\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "\n",
    "        # extract the initial state and\n",
    "        x, initial_state = inputs\n",
    "        if initial_state is None:\n",
    "            initial_state = np.zeros((x.shape[0], self.hidden_units))  # start as zeros with number of examples times hidden dimension\n",
    "        return self.transition_model([x] + [initial_state])\n",
    "\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.kl_loss_tracker]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        inputs, targets = data\n",
    "        mu, stddev = targets\n",
    "        x, init_states = inputs\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_stddev, final_state, h_states = self.transition_model([x, init_states], training=True)  # Forward pass\n",
    "\n",
    "            # Compute the loss value\n",
    "            pred_dist = tfp.distributions.MultivariateNormalDiag(loc=z_mean, scale_diag=z_stddev)\n",
    "            true_dist = tfp.distributions.MultivariateNormalDiag(loc=mu, scale_diag=stddev)\n",
    "\n",
    "            # TODO make sure this is the correct order of terms\n",
    "            kl_loss = tfp.distributions.kl_divergence(pred_dist, true_dist)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(kl_loss, trainable_vars)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"kl_loss\": self.kl_loss_tracker.result()\n",
    "        }\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "data": {
      "text/plain": "(1200, 15, 3)"
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_seqs = 1200\n",
    "seq_length = 15\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, seq_length)\n",
    "\n",
    "    train = np.concatenate([o[:-1], a], axis=1)\n",
    "    test = o[-1]\n",
    "\n",
    "    ob_seqs.append(train)\n",
    "    next_obs.append(test)\n",
    "\n",
    "ob_seqs = np.array(ob_seqs)\n",
    "next_obs = np.array(next_obs)\n",
    "ob_seqs.shape\n",
    "\n",
    "ob_seqs_stddev = np.ones_like(ob_seqs)\n",
    "next_obs_stddev = np.ones_like(next_obs)\n",
    "\n",
    "ob_seqs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [
    {
     "data": {
      "text/plain": "(1200, 2)"
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_obs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "data": {
      "text/plain": "(1200, 2)"
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_obs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "m = TransitionGRU(2, 1, 10, 30, 2)\n",
    "\n",
    "m.compile(optimizer=\"Adam\")\n",
    "# m.build((None, None, 3))\n",
    "# m.summary()\n",
    "init_state = np.ones((1200, 30))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 10:39:53.999260: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-13 10:39:54.111664: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-13 10:39:54.176776: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 2s 10ms/step - kl_loss: 0.0461\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 2.7952e-04\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 2.0413e-04\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 1.5620e-04\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 1.1819e-04\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 8.9815e-05\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 5.7940e-05\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 1s 9ms/step - kl_loss: 3.4079e-05\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 2.4278e-05\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 2.0360e-05\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 1.7860e-05\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 1.6978e-05\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 1.5337e-05\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 1.3970e-05\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 1.3035e-05\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 1.2735e-05\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 1.1894e-05\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 1.1222e-05\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 1.0994e-05\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 1.0630e-05\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 9.6106e-06\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 1.0231e-05\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 8.9703e-06\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 8.4808e-06\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 8.7314e-06\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 8.1360e-06\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 7.3652e-06\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 7.2955e-06\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 6.7417e-06\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 1s 10ms/step - kl_loss: 6.1644e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2caaa9970>"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit((ob_seqs, init_state), (next_obs, next_obs_stddev), batch_size=12, epochs=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\narray([[-0.5678598 , -0.00945393],\n       [-0.55901635, -0.012023  ],\n       [-0.5301562 , -0.01353312],\n       [-0.59359   , -0.00653425],\n       [-0.57035166, -0.01022513],\n       [-0.55035514, -0.00929178],\n       [-0.5918224 , -0.00945896],\n       [-0.5339744 , -0.01118272],\n       [-0.5343139 , -0.00886616],\n       [-0.56937265, -0.00513634]], dtype=float32)>"
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = m((ob_seqs[0:10], None))\n",
    "res[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1200, 15, 30), dtype=float32, numpy=\narray([[[ 0.02425387,  0.0244065 , -0.0065957 , ...,  0.03684389,\n          0.04408829,  0.01370949],\n        [ 0.03664604,  0.05243195, -0.02360114, ...,  0.06099832,\n          0.08207779,  0.03359329],\n        [-0.02266573,  0.05749463, -0.0032896 , ...,  0.05033551,\n          0.03671521, -0.00574399],\n        ...,\n        [ 0.11681072,  0.2025671 , -0.22530966, ...,  0.16079979,\n          0.29863134,  0.2289128 ],\n        [ 0.1343703 ,  0.21245562, -0.24117123, ...,  0.14922248,\n          0.3282653 ,  0.2420348 ],\n        [-0.01704619,  0.17420371, -0.16205727, ...,  0.07216896,\n          0.1793234 ,  0.11629379]],\n\n       [[ 0.12727839,  0.06734122, -0.08327793, ...,  0.0805898 ,\n          0.1621858 ,  0.12308379],\n        [ 0.04225383,  0.06653474, -0.03929769, ...,  0.04112265,\n          0.0984662 ,  0.05112836],\n        [-0.04273536,  0.05595212,  0.00146029, ...,  0.02969554,\n          0.01936543, -0.01734672],\n        ...,\n        [ 0.02185168,  0.16817902, -0.16402374, ...,  0.11051741,\n          0.19367908,  0.14163885],\n        [ 0.07761728,  0.18516472, -0.20109178, ...,  0.13944635,\n          0.2559942 ,  0.19334239],\n        [-0.02839059,  0.15845239, -0.14379501, ...,  0.08374628,\n          0.14989465,  0.10145168]],\n\n       [[ 0.05100306,  0.03444925, -0.02896521, ...,  0.04431093,\n          0.07698172,  0.04217765],\n        [ 0.03820416,  0.05439247, -0.03121931, ...,  0.04921915,\n          0.08840368,  0.03815945],\n        [ 0.06356863,  0.08397652, -0.06395568, ...,  0.07476252,\n          0.13924864,  0.07647907],\n        ...,\n        [-0.11965656,  0.10262734, -0.05580285, ...,  0.06435022,\n          0.02009446, -0.00563882],\n        [ 0.00914173,  0.14684877, -0.14210624, ...,  0.14046262,\n          0.15332413,  0.13031901],\n        [ 0.06763794,  0.17193797, -0.1816722 , ...,  0.14947723,\n          0.22297955,  0.18303703]],\n\n       ...,\n\n       [[-0.04372145,  0.00243203,  0.03932127, ...,  0.01239466,\n         -0.0393562 , -0.04916946],\n        [ 0.09079059,  0.07562806, -0.06610758, ...,  0.10358188,\n          0.13415954,  0.0998489 ],\n        [ 0.06087787,  0.09183236, -0.06007827, ...,  0.08717391,\n          0.13125668,  0.08039555],\n        ...,\n        [-0.01844453,  0.15802605, -0.1360986 , ...,  0.12079965,\n          0.1484258 ,  0.10825581],\n        [ 0.03660604,  0.17756602, -0.17589894, ...,  0.14826475,\n          0.21047348,  0.16270773],\n        [ 0.1104444 ,  0.20756654, -0.22950043, ...,  0.16979946,\n          0.29265392,  0.2326007 ]],\n\n       [[ 0.0146969 ,  0.02103953,  0.00057214, ...,  0.03371371,\n          0.03237473,  0.00419586],\n        [-0.01047455,  0.03604913,  0.00835472, ...,  0.04482092,\n          0.02507105, -0.01139681],\n        [ 0.06549678,  0.08595152, -0.0606585 , ...,  0.10050848,\n          0.1318403 ,  0.08098943],\n        ...,\n        [-0.07442766,  0.13754216, -0.09759863, ...,  0.11315385,\n          0.07743528,  0.05875834],\n        [-0.12109578,  0.12568118, -0.07128202, ...,  0.10164538,\n          0.02284825,  0.02071561],\n        [-0.15274253,  0.11597212, -0.05101934, ...,  0.10283384,\n         -0.0188563 , -0.00447916]],\n\n       [[ 0.08791398,  0.04911041, -0.05168118, ...,  0.06346888,\n          0.1181243 ,  0.07868075],\n        [ 0.02963298,  0.05665366, -0.02464877, ...,  0.04440929,\n          0.08048858,  0.03229599],\n        [-0.01391914,  0.06112474, -0.01100596, ...,  0.04888795,\n          0.05055805,  0.00354986],\n        ...,\n        [ 0.08463195,  0.18664221, -0.20008945, ...,  0.14980014,\n          0.26010668,  0.19661582],\n        [ 0.02953581,  0.17451058, -0.17273231, ...,  0.1112011 ,\n          0.21284841,  0.14781848],\n        [ 0.01144606,  0.16745105, -0.16296513, ...,  0.10915829,\n          0.1965019 ,  0.13179201]]], dtype=float32)>"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "data": {
      "text/plain": "(10, 3)"
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob_seqs[0:10, 14, :].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1200, 30), dtype=float32, numpy=\narray([[-0.01704619,  0.17420371, -0.16205727, ...,  0.07216896,\n         0.1793234 ,  0.11629379],\n       [-0.02839059,  0.15845239, -0.14379501, ...,  0.08374628,\n         0.14989465,  0.10145168],\n       [ 0.06763794,  0.17193797, -0.1816722 , ...,  0.14947723,\n         0.22297955,  0.18303703],\n       ...,\n       [ 0.1104444 ,  0.20756654, -0.22950043, ...,  0.16979946,\n         0.29265392,  0.2326007 ],\n       [-0.15274253,  0.11597212, -0.05101934, ...,  0.10283384,\n        -0.0188563 , -0.00447916],\n       [ 0.01144606,  0.16745105, -0.16296513, ...,  0.10915829,\n         0.1965019 ,  0.13179201]], dtype=float32)>"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = m((ob_seqs, None))\n",
    "res[2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.56785977, -0.0094539 ]], dtype=float32)>,\n <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.99687016, 0.99474823]], dtype=float32)>,\n <tf.Tensor: shape=(1, 30), dtype=float32, numpy=\n array([[-0.0170462 ,  0.17420371, -0.16205727,  0.1459884 , -0.31527486,\n         -0.00659207,  0.0312416 ,  0.0813532 ,  0.11589594, -0.34983537,\n          0.09985405,  0.24849527, -0.12736231,  0.2578114 ,  0.06988851,\n          0.02357278, -0.15019439,  0.01852169, -0.2631799 ,  0.25204396,\n         -0.2779762 , -0.22705497,  0.35386953, -0.05633114,  0.06359442,\n         -0.03013663, -0.14228506,  0.07216896,  0.1793234 ,  0.11629379]],\n       dtype=float32)>,\n <tf.Tensor: shape=(1, 15, 30), dtype=float32, numpy=\n array([[[ 0.02425387,  0.0244065 , -0.0065957 ,  0.05379898,\n          -0.07875035, -0.04081128, -0.02774346,  0.00961666,\n           0.01717799, -0.05475242,  0.01146767,  0.09475566,\n          -0.0658425 ,  0.04575911,  0.01126339,  0.00800517,\n          -0.05507555, -0.04324805, -0.0456871 ,  0.03552081,\n          -0.06753452, -0.05934079,  0.05402073,  0.0130398 ,\n           0.02886777, -0.04089989, -0.05034254,  0.03684389,\n           0.04408829,  0.01370949],\n         [ 0.03664604,  0.05243195, -0.02360114,  0.07556027,\n          -0.12684691, -0.05171909, -0.03710177,  0.02216688,\n           0.03123551, -0.10161746,  0.02290663,  0.13793935,\n          -0.09862302,  0.07569419,  0.02031966,  0.00718615,\n          -0.09997815, -0.04999966, -0.09724846,  0.06707794,\n          -0.11967516, -0.09275512,  0.11128165,  0.01271209,\n           0.03902863, -0.052121  , -0.07013443,  0.06099832,\n           0.08207779,  0.03359329],\n         [-0.02266573,  0.05749463, -0.0032896 ,  0.123932  ,\n          -0.22518839, -0.10803854,  0.02214492, -0.02544929,\n           0.04714959, -0.11526269, -0.03213475,  0.21770146,\n          -0.16252518,  0.15607378,  0.0695889 ,  0.0663451 ,\n          -0.06447717, -0.0764636 , -0.10854498,  0.15102631,\n          -0.18863204, -0.18843555,  0.13358706,  0.01926097,\n           0.03198529, -0.09640081, -0.13808306,  0.05033551,\n           0.03671521, -0.00574401],\n         [-0.08244605,  0.05553357,  0.01746864,  0.15358704,\n          -0.29979613, -0.1615516 ,  0.07247119, -0.06665576,\n           0.06448126, -0.10965852, -0.08589872,  0.27978826,\n          -0.22265258,  0.22545841,  0.12312663,  0.12180942,\n          -0.02179298, -0.10131186, -0.1262971 ,  0.22698861,\n          -0.25651166, -0.27480233,  0.15811232,  0.01850893,\n           0.02643315, -0.14300211, -0.20052515,  0.04980414,\n          -0.01861446, -0.04424435],\n         [-0.05015598,  0.07785618, -0.01875409,  0.1155635 ,\n          -0.26429585, -0.12576665,  0.02759098, -0.01858484,\n           0.07667606, -0.1380311 , -0.04555153,  0.2512212 ,\n          -0.20827283,  0.21228012,  0.11800297,  0.08016147,\n          -0.07375389, -0.07558282, -0.19680294,  0.22211848,\n          -0.27293023, -0.24889617,  0.216292  , -0.00290755,\n           0.03899233, -0.13074766, -0.17521752,  0.09177198,\n           0.02881592,  0.00364872],\n         [-0.10868759,  0.07549414,  0.00149793,  0.1506335 ,\n          -0.33156908, -0.17002201,  0.08385757, -0.06171983,\n           0.08511676, -0.13225837, -0.09688298,  0.30851805,\n          -0.25800395,  0.27888677,  0.15995033,  0.13788447,\n          -0.01923446, -0.09409732, -0.1912607 ,  0.2871825 ,\n          -0.32065225, -0.32508215,  0.23152275, -0.00268184,\n           0.0339714 , -0.1679984 , -0.22726695,  0.07643776,\n          -0.02721524, -0.03404711],\n         [-0.0317499 ,  0.10997734, -0.0634978 ,  0.08214603,\n          -0.24685039, -0.08627439, -0.00056589,  0.03082497,\n           0.09248219, -0.18113247, -0.00876635,  0.22703007,\n          -0.19536148,  0.22847134,  0.11998671,  0.04101178,\n          -0.11194048, -0.04024297, -0.2675167 ,  0.24228689,\n          -0.3019045 , -0.23801582,  0.29291734, -0.03123601,\n           0.05614543, -0.11835797, -0.16274658,  0.12896611,\n           0.06858887,  0.05580891],\n         [ 0.06015655,  0.1559438 , -0.14054033,  0.02445018,\n          -0.16316092,  0.01745984, -0.07738657,  0.12794173,\n           0.09379633, -0.24926507,  0.09833357,  0.13168065,\n          -0.10880575,  0.16721147,  0.05634812, -0.05950722,\n          -0.2126452 ,  0.03270711, -0.3169526 ,  0.18350066,\n          -0.26978868, -0.13420437,  0.34807184, -0.05632738,\n           0.07887566, -0.03967084, -0.08508709,  0.16364367,\n           0.18294983,  0.15571973],\n         [ 0.07068849,  0.17030783, -0.16151717,  0.05065984,\n          -0.17233713,  0.03998004, -0.07235594,  0.13354689,\n           0.0954653 , -0.29093176,  0.1261484 ,  0.14595276,\n          -0.09665521,  0.16522937,  0.03754131, -0.05466141,\n          -0.22834803,  0.05038071, -0.3144011 ,  0.17625532,\n          -0.26077354, -0.13470253,  0.36019394, -0.0604053 ,\n           0.08101516, -0.01809638, -0.06859472,  0.14673711,\n           0.21597251,  0.16945367],\n         [ 0.07036843,  0.176781  , -0.17388423,  0.06722687,\n          -0.18577576,  0.04883978, -0.0655891 ,  0.13399778,\n           0.10066058, -0.3188555 ,  0.14271243,  0.15925464,\n          -0.09146007,  0.16702983,  0.03151941, -0.04715548,\n          -0.23544899,  0.05453558, -0.31224176,  0.17466736,\n          -0.2561254 , -0.14042282,  0.3676597 , -0.06338966,\n           0.07963379, -0.00722174, -0.0631606 ,  0.13499492,\n           0.23418757,  0.17257413],\n         [ 0.00148724,  0.16089053, -0.14258754,  0.12039727,\n          -0.26748112, -0.00902966,  0.0012437 ,  0.07720774,\n           0.10728277, -0.31029207,  0.08743425,  0.2330819 ,\n          -0.14107539,  0.22708382,  0.07128549,  0.02138963,\n          -0.16718021,  0.01595476, -0.27943894,  0.22892702,\n          -0.278935  , -0.2190426 ,  0.350868  , -0.0541179 ,\n           0.06610544, -0.04703597, -0.12059347,  0.10022796,\n           0.17378458,  0.11538691],\n         [ 0.03416958,  0.169899  , -0.16638975,  0.08355739,\n          -0.22922826,  0.02343554, -0.04017024,  0.11273517,\n           0.11425606, -0.3268768 ,  0.12544903,  0.19389176,\n          -0.11664231,  0.1994705 ,  0.05872775, -0.01360903,\n          -0.2102697 ,  0.03185202, -0.3077296 ,  0.20397347,\n          -0.27233824, -0.18493596,  0.3740829 , -0.06611589,\n           0.07367496, -0.02782698, -0.09482973,  0.12655051,\n           0.21096587,  0.14832513],\n         [ 0.11681071,  0.2025671 , -0.22530967,  0.018779  ,\n          -0.14803445,  0.10741105, -0.11454096,  0.19364831,\n           0.11519177, -0.36796704,  0.21205188,  0.09639657,\n          -0.0390529 ,  0.13627012,  0.00619441, -0.10354703,\n          -0.29793254,  0.08831955, -0.34515312,  0.1446159 ,\n          -0.24493478, -0.08502167,  0.40933973, -0.08381139,\n           0.09074419,  0.03973701, -0.02844772,  0.16079977,\n           0.29863134,  0.22891282],\n         [ 0.13437028,  0.21245562, -0.24117121,  0.0345514 ,\n          -0.1437477 ,  0.12865268, -0.12089475,  0.20316823,\n           0.1135418 , -0.39440352,  0.23806652,  0.10022706,\n          -0.02305629,  0.12144859, -0.01434406, -0.10923693,\n          -0.31592667,  0.10253409, -0.34465933,  0.12813544,\n          -0.2324109 , -0.0700687 ,  0.4102898 , -0.08379953,\n           0.09187506,  0.06093266, -0.00863887,  0.14922248,\n           0.3282653 ,  0.2420348 ],\n         [-0.0170462 ,  0.17420371, -0.16205727,  0.1459884 ,\n          -0.31527486, -0.00659207,  0.0312416 ,  0.0813532 ,\n           0.11589594, -0.34983537,  0.09985405,  0.24849527,\n          -0.12736231,  0.2578114 ,  0.06988851,  0.02357278,\n          -0.15019439,  0.01852169, -0.2631799 ,  0.25204396,\n          -0.2779762 , -0.22705497,  0.35386953, -0.05633114,\n           0.06359442, -0.03013663, -0.14228506,  0.07216896,\n           0.1793234 ,  0.11629379]]], dtype=float32)>]"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m((ob_seqs[0:1, :, :], None))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10, 30), dtype=float32, numpy=\narray([[ 1.76516443e-01,  1.54475287e-01, -5.12306057e-02,\n         1.64845765e-01,  2.68837273e-01, -9.95857716e-02,\n         7.79657215e-02, -1.10403851e-01, -1.08879849e-01,\n        -1.22801609e-01,  3.41023579e-02, -8.55413154e-02,\n         1.35252342e-01, -5.53389899e-02, -2.05101758e-01,\n         9.60189849e-02, -2.62633413e-01,  2.84929663e-01,\n         2.07988352e-01, -1.35656670e-01,  1.67700097e-01,\n        -9.03860945e-03,  9.67715830e-02,  1.41193375e-01,\n        -1.73646688e-01, -1.49096355e-01,  1.63787216e-01,\n         1.34333670e-01, -1.35705829e-01, -1.85656726e-01],\n       [-4.13602814e-02,  1.25444561e-01,  1.13072321e-01,\n         5.97583316e-02,  1.48286954e-01, -1.09492682e-01,\n        -6.71713203e-02, -1.93654671e-01, -2.18552351e-01,\n        -1.57539248e-01,  1.89289406e-01, -2.24954244e-02,\n         1.34446856e-03, -4.91290167e-03, -2.39228070e-01,\n         1.89485967e-01, -3.58797014e-01,  2.12003320e-01,\n         1.73161179e-01, -1.74037293e-02,  2.35086933e-01,\n         1.66546330e-01,  6.54298719e-03, -4.10530809e-03,\n        -1.17915958e-01, -9.32100192e-02,  4.06399406e-02,\n         7.91156292e-02, -2.43677154e-01, -1.27368137e-01],\n       [ 2.81382889e-01,  1.17578223e-01, -1.85535938e-01,\n         2.00099215e-01,  3.15667242e-01, -4.78077270e-02,\n         1.46022633e-01, -7.38283712e-03,  5.09952791e-02,\n        -4.10940647e-02, -1.42754361e-01, -1.28701478e-01,\n         2.07214519e-01, -8.16050097e-02, -1.16633378e-01,\n        -3.95942926e-02, -3.91100943e-02,  2.43596911e-01,\n         1.44907683e-01, -1.91436365e-01,  4.26150374e-02,\n        -1.69662550e-01,  1.63683251e-01,  2.08718389e-01,\n        -1.30512655e-01, -1.38146773e-01,  2.32993916e-01,\n         1.34349704e-01,  1.34581523e-02, -1.69510424e-01],\n       [ 1.20082729e-01,  1.10540807e-01, -5.93374036e-02,\n         1.27688557e-01,  2.40723699e-01, -7.01464489e-02,\n         4.10818867e-02, -8.89149383e-02, -5.34922816e-02,\n        -8.46743807e-02,  8.02180544e-03, -8.47702920e-02,\n         1.08117729e-01, -4.24028635e-02, -1.58087865e-01,\n         5.07575460e-02, -1.61226347e-01,  2.06676364e-01,\n         1.28565922e-01, -1.00202374e-01,  1.11518748e-01,\n        -2.21858956e-02,  9.35375094e-02,  1.05405793e-01,\n        -1.02943115e-01, -1.02941878e-01,  1.33810356e-01,\n         9.85499844e-02, -9.42967609e-02, -1.35432318e-01],\n       [ 2.16247663e-01,  1.61735490e-01, -8.57412592e-02,\n         1.84479952e-01,  2.99367696e-01, -9.70878154e-02,\n         1.07040174e-01, -9.27742645e-02, -8.04351270e-02,\n        -1.13324970e-01, -3.95290612e-04, -1.01600848e-01,\n         1.59728155e-01, -6.71925768e-02, -2.01515406e-01,\n         7.40275905e-02, -2.35547855e-01,  3.00055027e-01,\n         2.09132507e-01, -1.61824346e-01,  1.48260653e-01,\n        -4.64286543e-02,  1.18866831e-01,  1.71542272e-01,\n        -1.79323807e-01, -1.57467842e-01,  1.89275682e-01,\n         1.43474400e-01, -1.09945714e-01, -1.97782308e-01],\n       [ 2.18145680e-02,  1.26804203e-01,  6.52437359e-02,\n         9.36110318e-02,  1.19315296e-01, -1.09775573e-01,\n         3.22279491e-04, -1.40610144e-01, -1.84793606e-01,\n        -1.33521065e-01,  1.55127987e-01,  2.27492349e-03,\n         4.19824533e-02, -1.10433074e-02, -1.84901342e-01,\n         1.65828377e-01, -3.31817806e-01,  1.92203984e-01,\n         1.89598098e-01, -1.99044514e-02,  1.93873480e-01,\n         1.06925264e-01,  8.91592074e-03,  2.95092966e-02,\n        -1.13174811e-01, -1.00376599e-01,  3.24082375e-02,\n         8.48201215e-02, -2.09770009e-01, -1.23344645e-01],\n       [ 4.38388959e-02,  1.25905648e-01,  4.90262806e-02,\n         1.00507140e-01,  1.48731068e-01, -1.03156596e-01,\n         2.78516649e-03, -1.39116168e-01, -1.70174390e-01,\n        -1.30533487e-01,  1.30239591e-01, -1.97336618e-02,\n         5.15423678e-02, -1.86224785e-02, -1.90342173e-01,\n         1.49422094e-01, -3.11133325e-01,  2.08004937e-01,\n         1.83913141e-01, -4.36244421e-02,  1.92204013e-01,\n         9.11682323e-02,  2.59755589e-02,  4.54488397e-02,\n        -1.22074045e-01, -1.06720507e-01,  6.15940951e-02,\n         9.13821980e-02, -1.94245011e-01, -1.33368164e-01],\n       [ 7.38879442e-02,  1.47288069e-01,  2.40389761e-02,\n         1.18462510e-01,  2.40322039e-01, -1.07538894e-01,\n         3.91195435e-03, -1.61293074e-01, -1.60802007e-01,\n        -1.45191252e-01,  1.08859174e-01, -7.02042580e-02,\n         7.27136731e-02, -3.52072753e-02, -2.39911467e-01,\n         1.41168088e-01, -3.12043458e-01,  2.67553508e-01,\n         1.88617378e-01, -8.92047137e-02,  2.07704008e-01,\n         7.70498812e-02,  6.30298778e-02,  7.81086311e-02,\n        -1.53992355e-01, -1.25649065e-01,  1.16863705e-01,\n         1.11497059e-01, -1.90869197e-01, -1.65875569e-01],\n       [ 1.65080037e-02,  1.36792615e-01,  7.05268383e-02,\n         9.04287472e-02,  1.90204024e-01, -1.10336229e-01,\n        -3.17759365e-02, -1.79092839e-01, -1.94932684e-01,\n        -1.54077202e-01,  1.53120518e-01, -4.25316989e-02,\n         3.84271629e-02, -1.88411530e-02, -2.38790989e-01,\n         1.69334158e-01, -3.42844129e-01,  2.40169168e-01,\n         1.85814574e-01, -5.01604937e-02,  2.26077572e-01,\n         1.24349169e-01,  3.17309201e-02,  3.56961973e-02,\n        -1.39903158e-01, -1.11528829e-01,  7.62732551e-02,\n         9.65611264e-02, -2.21861988e-01, -1.46233305e-01],\n       [ 1.04240976e-01,  1.07855760e-01, -3.56726274e-02,\n         1.16603591e-01,  2.12640300e-01, -7.03378469e-02,\n         3.41112316e-02, -9.11225602e-02, -7.21139610e-02,\n        -8.57819021e-02,  2.63407752e-02, -7.14794695e-02,\n         8.80782306e-02, -3.97953950e-02, -1.57458737e-01,\n         6.15902990e-02, -1.74597472e-01,  1.97760105e-01,\n         1.30814448e-01, -9.46808159e-02,  1.17561847e-01,\n         2.01811519e-04,  7.89449885e-02,  9.49568227e-02,\n        -9.67098325e-02, -9.79141518e-02,  1.20785505e-01,\n         9.23914909e-02, -1.00200005e-01, -1.31955773e-01]], dtype=float32)>"
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10, 5, 30), dtype=float32, numpy=\narray([[[ 0.08676665,  0.0665729 , -0.01751424, ...,  0.04447326,\n         -0.01017037, -0.07514461],\n        [ 0.04867286,  0.10080533,  0.05040885, ...,  0.05720273,\n         -0.10691113, -0.10694263],\n        [ 0.15783645,  0.12385118, -0.07167391, ...,  0.10117968,\n         -0.06072072, -0.15788542],\n        [ 0.20955351,  0.14058515, -0.09838694, ...,  0.12855455,\n         -0.07163367, -0.1843247 ],\n        [ 0.17651644,  0.15447529, -0.05123061, ...,  0.13433367,\n         -0.13570583, -0.18565673]],\n\n       [[ 0.15751047,  0.06191986, -0.11045828, ...,  0.06034369,\n          0.04968761, -0.08267669],\n        [ 0.08696802,  0.09508388,  0.00635655, ...,  0.06304765,\n         -0.08224013, -0.10179211],\n        [-0.00656156,  0.11269982,  0.09019252, ...,  0.05995458,\n         -0.1843041 , -0.10718634],\n        [-0.00765619,  0.12198227,  0.07892087, ...,  0.07446641,\n         -0.1967938 , -0.12551175],\n        [-0.04136028,  0.12544456,  0.11307232, ...,  0.07911563,\n         -0.24367715, -0.12736814]],\n\n       [[ 0.0654822 ,  0.04603675, -0.02019159, ...,  0.03458467,\n         -0.00494482, -0.05615027],\n        [ 0.02963169,  0.06911003,  0.03688796, ...,  0.04226373,\n         -0.08085754, -0.07628305],\n        [ 0.14875518,  0.08675534, -0.09748881, ...,  0.08345044,\n         -0.01815838, -0.12202656],\n        [ 0.22461787,  0.10130457, -0.1470222 , ...,  0.11171595,\n         -0.00045018, -0.14903277],\n        [ 0.2813829 ,  0.11757822, -0.18553594, ...,  0.1343497 ,\n          0.01345815, -0.16951042]],\n\n       ...,\n\n       [[ 0.01138758,  0.06594153,  0.06079691, ...,  0.02745706,\n         -0.07131419, -0.0613976 ],\n        [ 0.1133985 ,  0.10062904, -0.03335091, ...,  0.07308456,\n         -0.04367607, -0.12349204],\n        [ 0.12810823,  0.1219304 , -0.0214082 , ...,  0.0938539 ,\n         -0.09146247, -0.15094784],\n        [ 0.05590968,  0.13613151,  0.05130692, ...,  0.09316534,\n         -0.18765175, -0.14898446],\n        [ 0.07388794,  0.14728807,  0.02403898, ...,  0.11149706,\n         -0.1908692 , -0.16587557]],\n\n       [[-0.00430473,  0.06369009,  0.07311291, ...,  0.02348907,\n         -0.08191951, -0.05665143],\n        [ 0.01665193,  0.09470273,  0.06379474, ...,  0.05007798,\n         -0.11159035, -0.10144422],\n        [ 0.11919916,  0.11477701, -0.03934913, ...,  0.09099355,\n         -0.07721686, -0.14831376],\n        [ 0.03471287,  0.12631682,  0.05983995, ...,  0.08653473,\n         -0.19563465, -0.13882914],\n        [ 0.016508  ,  0.13679262,  0.07052684, ...,  0.09656113,\n         -0.22186199, -0.1462333 ]],\n\n       [[ 0.06659523,  0.04576611, -0.02177596, ...,  0.0347688 ,\n         -0.00378654, -0.0561466 ],\n        [ 0.10270955,  0.07080364, -0.03481976, ...,  0.05856168,\n         -0.02290619, -0.09244213],\n        [ 0.12146673,  0.08763017, -0.04306478, ...,  0.0753734 ,\n         -0.0453965 , -0.11494676],\n        [ 0.05544448,  0.09791885,  0.02408727, ...,  0.07120994,\n         -0.12596752, -0.11006884],\n        [ 0.10424098,  0.10785576, -0.03567263, ...,  0.09239149,\n         -0.1002    , -0.13195577]]], dtype=float32)>"
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [],
   "source": [
    "# def gru(input_dim, seq_length, hidden_units, output_dim):\n",
    "#\n",
    "#     inputs = layers.Input(shape=(None, input_dim), batch_size=10)\n",
    "#     out_states, h_states, *everything_else = layers.GRU(hidden_units, activation=\"tanh\", stateful=True, return_sequences=True)(inputs)\n",
    "#     h = layers.Dense(output_dim)(out_states)\n",
    "#\n",
    "#     model = keras.Model(inputs, h)\n",
    "#\n",
    "#     return model, h_states\n",
    "\n",
    "\n",
    "input_dim = 3\n",
    "hidden_units = 30\n",
    "seq_length = 10\n",
    "output_dim = 2\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape=(None, input_dim))\n",
    "out_states = layers.GRU(2, activation=\"tanh\", stateful=False, return_sequences=True)(inputs)\n",
    "h = layers.Dense(output_dim)(out_states)\n",
    "\n",
    "m = keras.Model(inputs, [h, out_states])\n",
    "\n",
    "inputs2 = layers.Input(shape=(None, input_dim), batch_size=20)\n",
    "out_states2 = layers.GRU(2, activation=\"tanh\", stateful=False, return_sequences=False)(inputs2)\n",
    "h2 = layers.Dense(output_dim)(out_states2)\n",
    "\n",
    "m2 = keras.Model(inputs2, h2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_86 (InputLayer)       [(None, None, 3)]         0         \n",
      "                                                                 \n",
      " gru_77 (GRU)                (None, None, 2)           42        \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, None, 2)           6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48\n",
      "Trainable params: 48\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# m, h_states = gru(3, 10, 30, 2)\n",
    "\n",
    "m.compile(optimizer=\"Adam\", loss=tf.keras.losses.MeanSquaredError())\n",
    "m.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_77 (InputLayer)       [(20, None, 3)]           0         \n",
      "                                                                 \n",
      " gru_68 (GRU)                (20, 2)                   42        \n",
      "                                                                 \n",
      " dense_30 (Dense)            (20, 2)                   6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48\n",
      "Trainable params: 48\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m2.compile(optimizer=\"Adam\", loss=tf.keras.losses.MeanSquaredError())\n",
    "m2.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/losses.py\", line 1329, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 10 and 20 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](model_47/dense_37/BiasAdd, IteratorGetNext:1)' with input shapes: [20,10,2], [20,2].\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [257]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mob_seqs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnext_obs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/miniconda3/envs/tf_daif/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1147\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1145\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[1;32m   1146\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1147\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mag_error_metadata\u001B[38;5;241m.\u001B[39mto_exception(e)\n\u001B[1;32m   1148\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1149\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/losses.py\", line 1329, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 10 and 20 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](model_47/dense_37/BiasAdd, IteratorGetNext:1)' with input shapes: [20,10,2], [20,2].\n"
     ]
    }
   ],
   "source": [
    "m.fit(ob_seqs, next_obs, batch_size=20, epochs=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [],
   "source": [
    "res = m(ob_seqs[0:20])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(20, 10, 2), dtype=float32, numpy=\narray([[[-0.03126741, -0.05007739],\n        [-0.02838155, -0.00308725],\n        [-0.03572483, -0.00703882],\n        [-0.12308189, -0.33903465],\n        [-0.09099328, -0.21175347],\n        [-0.15656376, -0.48039535],\n        [-0.17280677, -0.56211597],\n        [-0.09679789, -0.25665036],\n        [-0.09596224, -0.23660131],\n        [-0.07447534, -0.14166676]],\n\n       [[-0.09012927, -0.25503004],\n        [-0.06786623, -0.12630445],\n        [-0.06517889, -0.0879531 ],\n        [-0.0753606 , -0.10781813],\n        [-0.15388907, -0.41995582],\n        [-0.16208252, -0.4539302 ],\n        [-0.09656087, -0.1943801 ],\n        [-0.12658402, -0.30111074],\n        [-0.09610697, -0.17922345],\n        [-0.1653356 , -0.4642073 ]],\n\n       [[ 0.00175663,  0.08846912],\n        [-0.10092825, -0.24563871],\n        [-0.12627089, -0.31458697],\n        [-0.09916592, -0.19435771],\n        [-0.07646907, -0.09792791],\n        [-0.09629729, -0.16202733],\n        [-0.15526322, -0.3981951 ],\n        [-0.15041025, -0.37874815],\n        [-0.16555643, -0.44270995],\n        [-0.15424441, -0.39805657]],\n\n       [[-0.05559677, -0.114306  ],\n        [-0.05309627, -0.05821501],\n        [-0.06697862, -0.08041988],\n        [-0.11861454, -0.2613883 ],\n        [-0.18375166, -0.53912365],\n        [-0.13234876, -0.32753512],\n        [-0.14975825, -0.38808283],\n        [-0.16772813, -0.46099067],\n        [-0.1698215 , -0.47187403],\n        [-0.18682246, -0.5511827 ]],\n\n       [[-0.02683863, -0.03241343],\n        [-0.04601305, -0.06600743],\n        [-0.11616534, -0.32101288],\n        [-0.12539746, -0.35442954],\n        [-0.11384073, -0.3060914 ],\n        [-0.16083421, -0.50225747],\n        [-0.07507323, -0.16183089],\n        [-0.11841389, -0.3188956 ],\n        [-0.07689033, -0.15191065],\n        [-0.08795822, -0.18345748]],\n\n       [[-0.11113231, -0.3459885 ],\n        [-0.12945993, -0.3778441 ],\n        [-0.15691273, -0.47091737],\n        [-0.08357789, -0.17035428],\n        [-0.12771066, -0.32659516],\n        [-0.17597365, -0.5304496 ],\n        [-0.15088888, -0.4296335 ],\n        [-0.16928668, -0.5068651 ],\n        [-0.11609668, -0.29051602],\n        [-0.14471343, -0.39758444]],\n\n       [[-0.01454503,  0.03097449],\n        [-0.06505491, -0.10465319],\n        [-0.04172009,  0.00499727],\n        [-0.13871731, -0.36197135],\n        [-0.17946213, -0.5297583 ],\n        [-0.19029255, -0.5816692 ],\n        [-0.10729083, -0.24426831],\n        [-0.13254653, -0.32787415],\n        [-0.15738037, -0.42411488],\n        [-0.20024134, -0.6235464 ]],\n\n       [[-0.06962761, -0.189089  ],\n        [-0.08679657, -0.2176365 ],\n        [-0.06476629, -0.1123548 ],\n        [-0.12339685, -0.32896462],\n        [-0.16230315, -0.4927285 ],\n        [-0.07863827, -0.1614941 ],\n        [-0.04199656, -0.01148651],\n        [-0.12740146, -0.3365214 ],\n        [-0.09122056, -0.19184011],\n        [-0.06407557, -0.08105886]],\n\n       [[-0.0396629 , -0.05467438],\n        [-0.08055241, -0.1562889 ],\n        [-0.13378234, -0.3377364 ],\n        [-0.15608938, -0.41607416],\n        [-0.17135471, -0.47672486],\n        [-0.11746837, -0.2599504 ],\n        [-0.10911839, -0.21805872],\n        [-0.18236391, -0.5322895 ],\n        [-0.12292831, -0.29057738],\n        [-0.17982782, -0.5270762 ]],\n\n       [[-0.01129261,  0.03342313],\n        [-0.00524811,  0.09605693],\n        [-0.09751295, -0.22578607],\n        [-0.12804948, -0.33487013],\n        [-0.129243  , -0.33538944],\n        [-0.09159243, -0.18456857],\n        [-0.05398838, -0.03655718],\n        [-0.10764925, -0.23263146],\n        [-0.15823598, -0.44169614],\n        [-0.10993534, -0.25132877]],\n\n       [[-0.0970405 , -0.2794001 ],\n        [-0.06236344, -0.10318777],\n        [-0.05349374, -0.04128466],\n        [-0.0495826 , -0.00873903],\n        [-0.05932139, -0.03171035],\n        [-0.11831719, -0.25058377],\n        [-0.1802275 , -0.5180704 ],\n        [-0.13452175, -0.3335041 ],\n        [-0.16311193, -0.44636813],\n        [-0.15366405, -0.40648672]],\n\n       [[-0.10654058, -0.3229653 ],\n        [-0.16499549, -0.5254493 ],\n        [-0.1692746 , -0.5278821 ],\n        [-0.18579766, -0.59405977],\n        [-0.09579277, -0.22238219],\n        [-0.16152014, -0.476794  ],\n        [-0.19253191, -0.6158315 ],\n        [-0.18847464, -0.6085158 ],\n        [-0.18930446, -0.6198137 ],\n        [-0.14495012, -0.43352586]],\n\n       [[-0.10695986, -0.3398793 ],\n        [-0.1567835 , -0.51559156],\n        [-0.0734017 , -0.16764104],\n        [-0.12234285, -0.33830747],\n        [-0.15669978, -0.47613004],\n        [-0.10675225, -0.27418932],\n        [-0.08018454, -0.15989682],\n        [-0.1398887 , -0.39186358],\n        [-0.18006757, -0.5721971 ],\n        [-0.10886352, -0.28720585]],\n\n       [[-0.02749902, -0.01930231],\n        [-0.05311171, -0.06767099],\n        [-0.10204615, -0.22767864],\n        [-0.17084165, -0.5088455 ],\n        [-0.10697522, -0.24954632],\n        [-0.06516865, -0.07953074],\n        [-0.07525846, -0.10378528],\n        [-0.09091106, -0.15474372],\n        [-0.07649007, -0.09700193],\n        [-0.1572655 , -0.42747858]],\n\n       [[-0.05225033, -0.11578608],\n        [-0.05895209, -0.098952  ],\n        [-0.11657491, -0.299158  ],\n        [-0.13991395, -0.3848863 ],\n        [-0.1263809 , -0.32722986],\n        [-0.12940817, -0.33485943],\n        [-0.08309075, -0.15178554],\n        [-0.05016572, -0.02134027],\n        [-0.09960923, -0.19972056],\n        [-0.06248416, -0.05807872]],\n\n       [[-0.08637046, -0.22937633],\n        [-0.10229586, -0.23954712],\n        [-0.15116447, -0.4092558 ],\n        [-0.12921005, -0.307701  ],\n        [-0.18912685, -0.56317383],\n        [-0.16242388, -0.4490231 ],\n        [-0.12458492, -0.2901017 ],\n        [-0.11919773, -0.25901568],\n        [-0.18726183, -0.55532265],\n        [-0.15325856, -0.41472003]],\n\n       [[-0.10604117, -0.34267917],\n        [-0.03887179, -0.05268725],\n        [-0.08524382, -0.20133244],\n        [-0.08744939, -0.1967244 ],\n        [-0.09643388, -0.22334453],\n        [-0.1570329 , -0.47413012],\n        [-0.17516741, -0.5652044 ],\n        [-0.18030803, -0.6023267 ],\n        [-0.10144447, -0.2809562 ],\n        [-0.0592957 , -0.0992988 ]],\n\n       [[-0.07023395, -0.18362851],\n        [-0.05919973, -0.10072781],\n        [-0.09670657, -0.2175601 ],\n        [-0.12868516, -0.33235887],\n        [-0.08405506, -0.15471658],\n        [-0.1619223 , -0.47241327],\n        [-0.16776007, -0.50221545],\n        [-0.1034639 , -0.24306779],\n        [-0.15037915, -0.42413858],\n        [-0.19071665, -0.6066944 ]],\n\n       [[ 0.00079125,  0.07487514],\n        [-0.03049744,  0.00528554],\n        [-0.07072724, -0.11872135],\n        [-0.07877124, -0.1356339 ],\n        [-0.16379905, -0.48684728],\n        [-0.14460017, -0.41139147],\n        [-0.09712082, -0.21835828],\n        [-0.06114332, -0.07148607],\n        [-0.06051059, -0.05717351],\n        [-0.15243773, -0.42743343]],\n\n       [[-0.02221906, -0.00395356],\n        [-0.01201968,  0.07394958],\n        [-0.11606462, -0.30094013],\n        [-0.08872025, -0.1811495 ],\n        [-0.06391786, -0.07601882],\n        [-0.07019082, -0.08841603],\n        [-0.09078026, -0.159136  ],\n        [-0.06396053, -0.05654741],\n        [-0.08589994, -0.13302778],\n        [-0.05743085, -0.02625139]]], dtype=float32)>"
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10, 10, 2), dtype=float32, numpy=\narray([[[-0.36397788,  0.0294749 ],\n        [-0.48029938,  0.01573997],\n        [-0.51549274, -0.00554507],\n        [-0.50096333, -0.02819019],\n        [-0.51849884, -0.03603037],\n        [-0.4956515 , -0.04518281],\n        [-0.4919299 , -0.04698842],\n        [-0.5167043 , -0.04562606],\n        [-0.5176949 , -0.04506196],\n        [-0.5242841 , -0.04514759]],\n\n       [[-0.3648733 ,  0.04206948],\n        [-0.4807293 ,  0.04454088],\n        [-0.51710445,  0.03400522],\n        [-0.5260778 ,  0.02312428],\n        [-0.5013063 ,  0.01332644],\n        [-0.50671595,  0.01171992],\n        [-0.52894664,  0.00859705],\n        [-0.5185139 ,  0.00654676],\n        [-0.52903926,  0.00418232],\n        [-0.50056595,  0.00295787]],\n\n       [[-0.35582137,  0.06193205],\n        [-0.4635372 ,  0.05734254],\n        [-0.50165814,  0.04938255],\n        [-0.52453876,  0.04110029],\n        [-0.5341751 ,  0.03280196],\n        [-0.5287185 ,  0.02695066],\n        [-0.5085621 ,  0.02464295],\n        [-0.51623905,  0.02477949],\n        [-0.51171356,  0.02451629],\n        [-0.5170272 ,  0.02416078]],\n\n       [[-0.36347923,  0.05691229],\n        [-0.48067915,  0.06080834],\n        [-0.51629937,  0.0509107 ],\n        [-0.5146694 ,  0.04058636],\n        [-0.4931925 ,  0.02981444],\n        [-0.5192418 ,  0.0284833 ],\n        [-0.51482946,  0.02600875],\n        [-0.509487  ,  0.02449078],\n        [-0.50999254,  0.02360039],\n        [-0.5020083 ,  0.02161226]],\n\n       [[-0.36336344,  0.03193593],\n        [-0.47798705,  0.01634251],\n        [-0.49627632, -0.01065315],\n        [-0.50714   , -0.0249239 ],\n        [-0.5143287 , -0.03361027],\n        [-0.49663463, -0.04228203],\n        [-0.52345884, -0.04417491],\n        [-0.5103134 , -0.04488222],\n        [-0.5239943 , -0.04553092],\n        [-0.5210364 , -0.04472711]],\n\n       [[-0.36420384,  0.03050906],\n        [-0.47005066,  0.02912151],\n        [-0.4933604 ,  0.01791096],\n        [-0.52525586,  0.01143312],\n        [-0.51342005,  0.00406701],\n        [-0.49653322, -0.00232583],\n        [-0.50967413, -0.00242265],\n        [-0.5025211 , -0.00473238],\n        [-0.52089024, -0.00633133],\n        [-0.5105833 , -0.00821032]],\n\n       [[-0.3592899 ,  0.05837873],\n        [-0.47449625,  0.05713591],\n        [-0.5202108 ,  0.04775243],\n        [-0.4998784 ,  0.03190187],\n        [-0.49602073,  0.02501975],\n        [-0.49635592,  0.0217083 ],\n        [-0.5260861 ,  0.01966117],\n        [-0.51770693,  0.01701247],\n        [-0.5106258 ,  0.01593107],\n        [-0.4895934 ,  0.01103553]],\n\n       [[-0.36588687,  0.02894703],\n        [-0.47565123,  0.01820762],\n        [-0.514848  ,  0.00344476],\n        [-0.5071501 , -0.01241258],\n        [-0.49831274, -0.0224922 ],\n        [-0.52561057, -0.02621452],\n        [-0.5336887 , -0.03154004],\n        [-0.5051036 , -0.03277329],\n        [-0.5218599 , -0.03175934],\n        [-0.529561  , -0.03260876]],\n\n       [[-0.36208293,  0.06034166],\n        [-0.47515383,  0.06254248],\n        [-0.4998143 ,  0.05188979],\n        [-0.50785875,  0.04361076],\n        [-0.5076397 ,  0.03737927],\n        [-0.52751046,  0.03244342],\n        [-0.52910596,  0.02708542],\n        [-0.4943607 ,  0.0206141 ],\n        [-0.52184284,  0.02115785],\n        [-0.49783346,  0.0181902 ]],\n\n       [[-0.36006317,  0.0466808 ],\n        [-0.4808289 ,  0.04173735],\n        [-0.49869117,  0.01861919],\n        [-0.50795   ,  0.00552239],\n        [-0.514347  , -0.00249341],\n        [-0.5267752 , -0.00865605],\n        [-0.5350935 , -0.01422167],\n        [-0.51781046, -0.01513254],\n        [-0.50285685, -0.01371899],\n        [-0.5220274 , -0.0123977 ]]], dtype=float32)>"
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}