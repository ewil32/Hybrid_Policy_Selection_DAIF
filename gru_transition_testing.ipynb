{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from vae import VAE, create_decoder, create_encoder\n",
    "from transition import TransitionModel\n",
    "from agent import DAIFAgent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from util import random_observation_sequence, transform_observations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 05:24:29.109269: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-12 05:24:29.109580: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "enc = create_encoder(2, 2, [20])\n",
    "dec = create_decoder(2, 2, [20])\n",
    "tran = TransitionModel(2, 1)\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TransitionGRU(keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dim, action_dim, seq_length, hidden_units, output_dim, stateful=True, **kwargs):\n",
    "        super(TransitionGRU, self).__init__(**kwargs)\n",
    "\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.seq_length = seq_length\n",
    "        self.hidden_units = hidden_units\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "\n",
    "        inputs = layers.Input(shape=(None, self.latent_dim + self.action_dim))\n",
    "        h_states, final_state = layers.GRU(hidden_units, activation=\"tanh\", return_sequences=True, return_state=True, stateful=stateful, name=\"gru\")(inputs)\n",
    "\n",
    "        # TODO is this correctly getting the last hidden state or the first???\n",
    "        z_mean = layers.Dense(latent_dim, name=\"z_mean\")(final_state)  # all batch last time step all dimension\n",
    "        z_log_sd = layers.Dense(latent_dim, name=\"z_log_sd\")(final_state)\n",
    "        z_stddev = tf.exp(z_log_sd)\n",
    "\n",
    "        self.transition_model = keras.Model(inputs, [z_mean, z_stddev, final_state, h_states], name=\"transition\")\n",
    "\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        return self.transition_model(inputs)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.kl_loss_tracker]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, y = data\n",
    "        mu, stddev = y\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_stddev, final_state, h_states = self.transition_model(x, training=True)  # Forward pass\n",
    "\n",
    "            # Compute the loss value\n",
    "            pred_dist = tfp.distributions.MultivariateNormalDiag(loc=z_mean, scale_diag=z_stddev)\n",
    "            true_dist = tfp.distributions.MultivariateNormalDiag(loc=mu, scale_diag=stddev)\n",
    "\n",
    "            # TODO make sure this is the correct order of terms\n",
    "            kl_loss = tfp.distributions.kl_divergence(pred_dist, true_dist)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(kl_loss, trainable_vars)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"kl_loss\": self.kl_loss_tracker.result()\n",
    "        }\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "(1000, 5, 3)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_seqs = 1000\n",
    "seq_length = 5\n",
    "ob_seqs = []\n",
    "next_obs = []\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    o, a, r = random_observation_sequence(env, seq_length)\n",
    "\n",
    "    train = np.concatenate([o[:-1], a], axis=1)\n",
    "    test = o[-1]\n",
    "\n",
    "    ob_seqs.append(train)\n",
    "    next_obs.append(test)\n",
    "\n",
    "ob_seqs = np.array(ob_seqs)\n",
    "next_obs = np.array(next_obs)\n",
    "ob_seqs.shape\n",
    "\n",
    "ob_seqs_stddev = np.ones_like(ob_seqs)\n",
    "next_obs_stddev = np.ones_like(next_obs)\n",
    "\n",
    "ob_seqs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "(1000, 2)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_obs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transition_gru_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transition (Functional)     [(None, 2),               3274      \n",
      "                              (None, 2),                         \n",
      "                              (None, 30),                        \n",
      "                              (None, None, 30)]                  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,276\n",
      "Trainable params: 3,274\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = TransitionGRU(2, 1, 10, 30, 2, stateful=False)\n",
    "\n",
    "m.compile(optimizer=\"Adam\")\n",
    "m.build((None, None, 3))\n",
    "m.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [29]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransition_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstates\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "m.transition_model.layers[1].reset_states()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 05:42:06.299927: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-12 05:42:06.428940: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-12 05:42:06.484667: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 8ms/step - kl_loss: 0.0600\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 0s 8ms/step - kl_loss: 0.0036\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 0s 8ms/step - kl_loss: 4.2326e-04\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 0s 8ms/step - kl_loss: 3.4201e-04\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 2.9370e-04\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 2.4913e-04\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 2.1128e-04\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 1.8043e-04\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 1.5401e-04\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 0s 8ms/step - kl_loss: 1.3160e-04\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 1.1469e-04\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 9.9641e-05\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 8.4298e-05\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 7.2784e-05\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 6.2863e-05\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 5.4952e-05\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 4.6651e-05\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 3.9517e-05\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 3.2908e-05\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 2.7343e-05\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 2.1881e-05\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 1.6645e-05\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 1.2878e-05\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 9.9723e-06\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 7.3464e-06\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 5.5172e-06\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 4.2490e-06\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 3.2177e-06\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 0s 7ms/step - kl_loss: 2.5842e-06\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 0s 8ms/step - kl_loss: 2.1192e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x17bb87370>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(ob_seqs, (next_obs, next_obs_stddev), batch_size=20, epochs=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\narray([[-5.8090693e-01,  8.7059429e-04],\n       [-5.2863246e-01,  3.1522992e-03],\n       [-4.3379432e-01, -8.7528732e-03],\n       [-4.3787414e-01, -5.1598563e-03],\n       [-5.8681363e-01,  2.7444272e-04],\n       [-4.9155015e-01, -2.5757030e-03],\n       [-5.0213182e-01, -1.5339281e-03],\n       [-5.7871789e-01,  3.1496743e-03],\n       [-5.5853301e-01,  3.3286274e-03],\n       [-4.2998409e-01, -4.8398916e-03]], dtype=float32)>"
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = m(ob_seqs[0:10])\n",
    "res[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-5.81220269e-01,  5.59085340e-04],\n       [-5.32187581e-01,  2.53276480e-03],\n       [-4.32790160e-01, -7.78845651e-03],\n       [-4.35192347e-01, -4.59486013e-03],\n       [-5.87698460e-01, -8.86931142e-04],\n       [-4.92360324e-01, -1.38492603e-03],\n       [-5.02152085e-01, -4.14562441e-04],\n       [-5.78702986e-01,  2.86695943e-03],\n       [-5.59793115e-01,  3.54842329e-03],\n       [-4.26397473e-01, -4.90277866e-03]])"
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_obs[0:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10, 30), dtype=float32, numpy=\narray([[ 1.76516443e-01,  1.54475287e-01, -5.12306057e-02,\n         1.64845765e-01,  2.68837273e-01, -9.95857716e-02,\n         7.79657215e-02, -1.10403851e-01, -1.08879849e-01,\n        -1.22801609e-01,  3.41023579e-02, -8.55413154e-02,\n         1.35252342e-01, -5.53389899e-02, -2.05101758e-01,\n         9.60189849e-02, -2.62633413e-01,  2.84929663e-01,\n         2.07988352e-01, -1.35656670e-01,  1.67700097e-01,\n        -9.03860945e-03,  9.67715830e-02,  1.41193375e-01,\n        -1.73646688e-01, -1.49096355e-01,  1.63787216e-01,\n         1.34333670e-01, -1.35705829e-01, -1.85656726e-01],\n       [-4.13602814e-02,  1.25444561e-01,  1.13072321e-01,\n         5.97583316e-02,  1.48286954e-01, -1.09492682e-01,\n        -6.71713203e-02, -1.93654671e-01, -2.18552351e-01,\n        -1.57539248e-01,  1.89289406e-01, -2.24954244e-02,\n         1.34446856e-03, -4.91290167e-03, -2.39228070e-01,\n         1.89485967e-01, -3.58797014e-01,  2.12003320e-01,\n         1.73161179e-01, -1.74037293e-02,  2.35086933e-01,\n         1.66546330e-01,  6.54298719e-03, -4.10530809e-03,\n        -1.17915958e-01, -9.32100192e-02,  4.06399406e-02,\n         7.91156292e-02, -2.43677154e-01, -1.27368137e-01],\n       [ 2.81382889e-01,  1.17578223e-01, -1.85535938e-01,\n         2.00099215e-01,  3.15667242e-01, -4.78077270e-02,\n         1.46022633e-01, -7.38283712e-03,  5.09952791e-02,\n        -4.10940647e-02, -1.42754361e-01, -1.28701478e-01,\n         2.07214519e-01, -8.16050097e-02, -1.16633378e-01,\n        -3.95942926e-02, -3.91100943e-02,  2.43596911e-01,\n         1.44907683e-01, -1.91436365e-01,  4.26150374e-02,\n        -1.69662550e-01,  1.63683251e-01,  2.08718389e-01,\n        -1.30512655e-01, -1.38146773e-01,  2.32993916e-01,\n         1.34349704e-01,  1.34581523e-02, -1.69510424e-01],\n       [ 1.20082729e-01,  1.10540807e-01, -5.93374036e-02,\n         1.27688557e-01,  2.40723699e-01, -7.01464489e-02,\n         4.10818867e-02, -8.89149383e-02, -5.34922816e-02,\n        -8.46743807e-02,  8.02180544e-03, -8.47702920e-02,\n         1.08117729e-01, -4.24028635e-02, -1.58087865e-01,\n         5.07575460e-02, -1.61226347e-01,  2.06676364e-01,\n         1.28565922e-01, -1.00202374e-01,  1.11518748e-01,\n        -2.21858956e-02,  9.35375094e-02,  1.05405793e-01,\n        -1.02943115e-01, -1.02941878e-01,  1.33810356e-01,\n         9.85499844e-02, -9.42967609e-02, -1.35432318e-01],\n       [ 2.16247663e-01,  1.61735490e-01, -8.57412592e-02,\n         1.84479952e-01,  2.99367696e-01, -9.70878154e-02,\n         1.07040174e-01, -9.27742645e-02, -8.04351270e-02,\n        -1.13324970e-01, -3.95290612e-04, -1.01600848e-01,\n         1.59728155e-01, -6.71925768e-02, -2.01515406e-01,\n         7.40275905e-02, -2.35547855e-01,  3.00055027e-01,\n         2.09132507e-01, -1.61824346e-01,  1.48260653e-01,\n        -4.64286543e-02,  1.18866831e-01,  1.71542272e-01,\n        -1.79323807e-01, -1.57467842e-01,  1.89275682e-01,\n         1.43474400e-01, -1.09945714e-01, -1.97782308e-01],\n       [ 2.18145680e-02,  1.26804203e-01,  6.52437359e-02,\n         9.36110318e-02,  1.19315296e-01, -1.09775573e-01,\n         3.22279491e-04, -1.40610144e-01, -1.84793606e-01,\n        -1.33521065e-01,  1.55127987e-01,  2.27492349e-03,\n         4.19824533e-02, -1.10433074e-02, -1.84901342e-01,\n         1.65828377e-01, -3.31817806e-01,  1.92203984e-01,\n         1.89598098e-01, -1.99044514e-02,  1.93873480e-01,\n         1.06925264e-01,  8.91592074e-03,  2.95092966e-02,\n        -1.13174811e-01, -1.00376599e-01,  3.24082375e-02,\n         8.48201215e-02, -2.09770009e-01, -1.23344645e-01],\n       [ 4.38388959e-02,  1.25905648e-01,  4.90262806e-02,\n         1.00507140e-01,  1.48731068e-01, -1.03156596e-01,\n         2.78516649e-03, -1.39116168e-01, -1.70174390e-01,\n        -1.30533487e-01,  1.30239591e-01, -1.97336618e-02,\n         5.15423678e-02, -1.86224785e-02, -1.90342173e-01,\n         1.49422094e-01, -3.11133325e-01,  2.08004937e-01,\n         1.83913141e-01, -4.36244421e-02,  1.92204013e-01,\n         9.11682323e-02,  2.59755589e-02,  4.54488397e-02,\n        -1.22074045e-01, -1.06720507e-01,  6.15940951e-02,\n         9.13821980e-02, -1.94245011e-01, -1.33368164e-01],\n       [ 7.38879442e-02,  1.47288069e-01,  2.40389761e-02,\n         1.18462510e-01,  2.40322039e-01, -1.07538894e-01,\n         3.91195435e-03, -1.61293074e-01, -1.60802007e-01,\n        -1.45191252e-01,  1.08859174e-01, -7.02042580e-02,\n         7.27136731e-02, -3.52072753e-02, -2.39911467e-01,\n         1.41168088e-01, -3.12043458e-01,  2.67553508e-01,\n         1.88617378e-01, -8.92047137e-02,  2.07704008e-01,\n         7.70498812e-02,  6.30298778e-02,  7.81086311e-02,\n        -1.53992355e-01, -1.25649065e-01,  1.16863705e-01,\n         1.11497059e-01, -1.90869197e-01, -1.65875569e-01],\n       [ 1.65080037e-02,  1.36792615e-01,  7.05268383e-02,\n         9.04287472e-02,  1.90204024e-01, -1.10336229e-01,\n        -3.17759365e-02, -1.79092839e-01, -1.94932684e-01,\n        -1.54077202e-01,  1.53120518e-01, -4.25316989e-02,\n         3.84271629e-02, -1.88411530e-02, -2.38790989e-01,\n         1.69334158e-01, -3.42844129e-01,  2.40169168e-01,\n         1.85814574e-01, -5.01604937e-02,  2.26077572e-01,\n         1.24349169e-01,  3.17309201e-02,  3.56961973e-02,\n        -1.39903158e-01, -1.11528829e-01,  7.62732551e-02,\n         9.65611264e-02, -2.21861988e-01, -1.46233305e-01],\n       [ 1.04240976e-01,  1.07855760e-01, -3.56726274e-02,\n         1.16603591e-01,  2.12640300e-01, -7.03378469e-02,\n         3.41112316e-02, -9.11225602e-02, -7.21139610e-02,\n        -8.57819021e-02,  2.63407752e-02, -7.14794695e-02,\n         8.80782306e-02, -3.97953950e-02, -1.57458737e-01,\n         6.15902990e-02, -1.74597472e-01,  1.97760105e-01,\n         1.30814448e-01, -9.46808159e-02,  1.17561847e-01,\n         2.01811519e-04,  7.89449885e-02,  9.49568227e-02,\n        -9.67098325e-02, -9.79141518e-02,  1.20785505e-01,\n         9.23914909e-02, -1.00200005e-01, -1.31955773e-01]], dtype=float32)>"
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10, 5, 30), dtype=float32, numpy=\narray([[[ 0.08676665,  0.0665729 , -0.01751424, ...,  0.04447326,\n         -0.01017037, -0.07514461],\n        [ 0.04867286,  0.10080533,  0.05040885, ...,  0.05720273,\n         -0.10691113, -0.10694263],\n        [ 0.15783645,  0.12385118, -0.07167391, ...,  0.10117968,\n         -0.06072072, -0.15788542],\n        [ 0.20955351,  0.14058515, -0.09838694, ...,  0.12855455,\n         -0.07163367, -0.1843247 ],\n        [ 0.17651644,  0.15447529, -0.05123061, ...,  0.13433367,\n         -0.13570583, -0.18565673]],\n\n       [[ 0.15751047,  0.06191986, -0.11045828, ...,  0.06034369,\n          0.04968761, -0.08267669],\n        [ 0.08696802,  0.09508388,  0.00635655, ...,  0.06304765,\n         -0.08224013, -0.10179211],\n        [-0.00656156,  0.11269982,  0.09019252, ...,  0.05995458,\n         -0.1843041 , -0.10718634],\n        [-0.00765619,  0.12198227,  0.07892087, ...,  0.07446641,\n         -0.1967938 , -0.12551175],\n        [-0.04136028,  0.12544456,  0.11307232, ...,  0.07911563,\n         -0.24367715, -0.12736814]],\n\n       [[ 0.0654822 ,  0.04603675, -0.02019159, ...,  0.03458467,\n         -0.00494482, -0.05615027],\n        [ 0.02963169,  0.06911003,  0.03688796, ...,  0.04226373,\n         -0.08085754, -0.07628305],\n        [ 0.14875518,  0.08675534, -0.09748881, ...,  0.08345044,\n         -0.01815838, -0.12202656],\n        [ 0.22461787,  0.10130457, -0.1470222 , ...,  0.11171595,\n         -0.00045018, -0.14903277],\n        [ 0.2813829 ,  0.11757822, -0.18553594, ...,  0.1343497 ,\n          0.01345815, -0.16951042]],\n\n       ...,\n\n       [[ 0.01138758,  0.06594153,  0.06079691, ...,  0.02745706,\n         -0.07131419, -0.0613976 ],\n        [ 0.1133985 ,  0.10062904, -0.03335091, ...,  0.07308456,\n         -0.04367607, -0.12349204],\n        [ 0.12810823,  0.1219304 , -0.0214082 , ...,  0.0938539 ,\n         -0.09146247, -0.15094784],\n        [ 0.05590968,  0.13613151,  0.05130692, ...,  0.09316534,\n         -0.18765175, -0.14898446],\n        [ 0.07388794,  0.14728807,  0.02403898, ...,  0.11149706,\n         -0.1908692 , -0.16587557]],\n\n       [[-0.00430473,  0.06369009,  0.07311291, ...,  0.02348907,\n         -0.08191951, -0.05665143],\n        [ 0.01665193,  0.09470273,  0.06379474, ...,  0.05007798,\n         -0.11159035, -0.10144422],\n        [ 0.11919916,  0.11477701, -0.03934913, ...,  0.09099355,\n         -0.07721686, -0.14831376],\n        [ 0.03471287,  0.12631682,  0.05983995, ...,  0.08653473,\n         -0.19563465, -0.13882914],\n        [ 0.016508  ,  0.13679262,  0.07052684, ...,  0.09656113,\n         -0.22186199, -0.1462333 ]],\n\n       [[ 0.06659523,  0.04576611, -0.02177596, ...,  0.0347688 ,\n         -0.00378654, -0.0561466 ],\n        [ 0.10270955,  0.07080364, -0.03481976, ...,  0.05856168,\n         -0.02290619, -0.09244213],\n        [ 0.12146673,  0.08763017, -0.04306478, ...,  0.0753734 ,\n         -0.0453965 , -0.11494676],\n        [ 0.05544448,  0.09791885,  0.02408727, ...,  0.07120994,\n         -0.12596752, -0.11006884],\n        [ 0.10424098,  0.10785576, -0.03567263, ...,  0.09239149,\n         -0.1002    , -0.13195577]]], dtype=float32)>"
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [],
   "source": [
    "# def gru(input_dim, seq_length, hidden_units, output_dim):\n",
    "#\n",
    "#     inputs = layers.Input(shape=(None, input_dim), batch_size=10)\n",
    "#     out_states, h_states, *everything_else = layers.GRU(hidden_units, activation=\"tanh\", stateful=True, return_sequences=True)(inputs)\n",
    "#     h = layers.Dense(output_dim)(out_states)\n",
    "#\n",
    "#     model = keras.Model(inputs, h)\n",
    "#\n",
    "#     return model, h_states\n",
    "\n",
    "\n",
    "input_dim = 3\n",
    "hidden_units = 30\n",
    "seq_length = 10\n",
    "output_dim = 2\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape=(None, input_dim))\n",
    "out_states = layers.GRU(2, activation=\"tanh\", stateful=False, return_sequences=True)(inputs)\n",
    "h = layers.Dense(output_dim)(out_states)\n",
    "\n",
    "m = keras.Model(inputs, [h, out_states])\n",
    "\n",
    "inputs2 = layers.Input(shape=(None, input_dim), batch_size=20)\n",
    "out_states2 = layers.GRU(2, activation=\"tanh\", stateful=False, return_sequences=False)(inputs2)\n",
    "h2 = layers.Dense(output_dim)(out_states2)\n",
    "\n",
    "m2 = keras.Model(inputs2, h2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_86 (InputLayer)       [(None, None, 3)]         0         \n",
      "                                                                 \n",
      " gru_77 (GRU)                (None, None, 2)           42        \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, None, 2)           6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48\n",
      "Trainable params: 48\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# m, h_states = gru(3, 10, 30, 2)\n",
    "\n",
    "m.compile(optimizer=\"Adam\", loss=tf.keras.losses.MeanSquaredError())\n",
    "m.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_77 (InputLayer)       [(20, None, 3)]           0         \n",
      "                                                                 \n",
      " gru_68 (GRU)                (20, 2)                   42        \n",
      "                                                                 \n",
      " dense_30 (Dense)            (20, 2)                   6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48\n",
      "Trainable params: 48\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m2.compile(optimizer=\"Adam\", loss=tf.keras.losses.MeanSquaredError())\n",
    "m2.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/losses.py\", line 1329, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 10 and 20 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](model_47/dense_37/BiasAdd, IteratorGetNext:1)' with input shapes: [20,10,2], [20,2].\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [257]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mob_seqs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnext_obs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/miniconda3/envs/tf_daif/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1147\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1145\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[1;32m   1146\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1147\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mag_error_metadata\u001B[38;5;241m.\u001B[39mto_exception(e)\n\u001B[1;32m   1148\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1149\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/Ethan/miniconda3/envs/tf_daif/lib/python3.8/site-packages/keras/losses.py\", line 1329, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 10 and 20 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](model_47/dense_37/BiasAdd, IteratorGetNext:1)' with input shapes: [20,10,2], [20,2].\n"
     ]
    }
   ],
   "source": [
    "m.fit(ob_seqs, next_obs, batch_size=20, epochs=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [],
   "source": [
    "res = m(ob_seqs[0:20])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(20, 10, 2), dtype=float32, numpy=\narray([[[-0.03126741, -0.05007739],\n        [-0.02838155, -0.00308725],\n        [-0.03572483, -0.00703882],\n        [-0.12308189, -0.33903465],\n        [-0.09099328, -0.21175347],\n        [-0.15656376, -0.48039535],\n        [-0.17280677, -0.56211597],\n        [-0.09679789, -0.25665036],\n        [-0.09596224, -0.23660131],\n        [-0.07447534, -0.14166676]],\n\n       [[-0.09012927, -0.25503004],\n        [-0.06786623, -0.12630445],\n        [-0.06517889, -0.0879531 ],\n        [-0.0753606 , -0.10781813],\n        [-0.15388907, -0.41995582],\n        [-0.16208252, -0.4539302 ],\n        [-0.09656087, -0.1943801 ],\n        [-0.12658402, -0.30111074],\n        [-0.09610697, -0.17922345],\n        [-0.1653356 , -0.4642073 ]],\n\n       [[ 0.00175663,  0.08846912],\n        [-0.10092825, -0.24563871],\n        [-0.12627089, -0.31458697],\n        [-0.09916592, -0.19435771],\n        [-0.07646907, -0.09792791],\n        [-0.09629729, -0.16202733],\n        [-0.15526322, -0.3981951 ],\n        [-0.15041025, -0.37874815],\n        [-0.16555643, -0.44270995],\n        [-0.15424441, -0.39805657]],\n\n       [[-0.05559677, -0.114306  ],\n        [-0.05309627, -0.05821501],\n        [-0.06697862, -0.08041988],\n        [-0.11861454, -0.2613883 ],\n        [-0.18375166, -0.53912365],\n        [-0.13234876, -0.32753512],\n        [-0.14975825, -0.38808283],\n        [-0.16772813, -0.46099067],\n        [-0.1698215 , -0.47187403],\n        [-0.18682246, -0.5511827 ]],\n\n       [[-0.02683863, -0.03241343],\n        [-0.04601305, -0.06600743],\n        [-0.11616534, -0.32101288],\n        [-0.12539746, -0.35442954],\n        [-0.11384073, -0.3060914 ],\n        [-0.16083421, -0.50225747],\n        [-0.07507323, -0.16183089],\n        [-0.11841389, -0.3188956 ],\n        [-0.07689033, -0.15191065],\n        [-0.08795822, -0.18345748]],\n\n       [[-0.11113231, -0.3459885 ],\n        [-0.12945993, -0.3778441 ],\n        [-0.15691273, -0.47091737],\n        [-0.08357789, -0.17035428],\n        [-0.12771066, -0.32659516],\n        [-0.17597365, -0.5304496 ],\n        [-0.15088888, -0.4296335 ],\n        [-0.16928668, -0.5068651 ],\n        [-0.11609668, -0.29051602],\n        [-0.14471343, -0.39758444]],\n\n       [[-0.01454503,  0.03097449],\n        [-0.06505491, -0.10465319],\n        [-0.04172009,  0.00499727],\n        [-0.13871731, -0.36197135],\n        [-0.17946213, -0.5297583 ],\n        [-0.19029255, -0.5816692 ],\n        [-0.10729083, -0.24426831],\n        [-0.13254653, -0.32787415],\n        [-0.15738037, -0.42411488],\n        [-0.20024134, -0.6235464 ]],\n\n       [[-0.06962761, -0.189089  ],\n        [-0.08679657, -0.2176365 ],\n        [-0.06476629, -0.1123548 ],\n        [-0.12339685, -0.32896462],\n        [-0.16230315, -0.4927285 ],\n        [-0.07863827, -0.1614941 ],\n        [-0.04199656, -0.01148651],\n        [-0.12740146, -0.3365214 ],\n        [-0.09122056, -0.19184011],\n        [-0.06407557, -0.08105886]],\n\n       [[-0.0396629 , -0.05467438],\n        [-0.08055241, -0.1562889 ],\n        [-0.13378234, -0.3377364 ],\n        [-0.15608938, -0.41607416],\n        [-0.17135471, -0.47672486],\n        [-0.11746837, -0.2599504 ],\n        [-0.10911839, -0.21805872],\n        [-0.18236391, -0.5322895 ],\n        [-0.12292831, -0.29057738],\n        [-0.17982782, -0.5270762 ]],\n\n       [[-0.01129261,  0.03342313],\n        [-0.00524811,  0.09605693],\n        [-0.09751295, -0.22578607],\n        [-0.12804948, -0.33487013],\n        [-0.129243  , -0.33538944],\n        [-0.09159243, -0.18456857],\n        [-0.05398838, -0.03655718],\n        [-0.10764925, -0.23263146],\n        [-0.15823598, -0.44169614],\n        [-0.10993534, -0.25132877]],\n\n       [[-0.0970405 , -0.2794001 ],\n        [-0.06236344, -0.10318777],\n        [-0.05349374, -0.04128466],\n        [-0.0495826 , -0.00873903],\n        [-0.05932139, -0.03171035],\n        [-0.11831719, -0.25058377],\n        [-0.1802275 , -0.5180704 ],\n        [-0.13452175, -0.3335041 ],\n        [-0.16311193, -0.44636813],\n        [-0.15366405, -0.40648672]],\n\n       [[-0.10654058, -0.3229653 ],\n        [-0.16499549, -0.5254493 ],\n        [-0.1692746 , -0.5278821 ],\n        [-0.18579766, -0.59405977],\n        [-0.09579277, -0.22238219],\n        [-0.16152014, -0.476794  ],\n        [-0.19253191, -0.6158315 ],\n        [-0.18847464, -0.6085158 ],\n        [-0.18930446, -0.6198137 ],\n        [-0.14495012, -0.43352586]],\n\n       [[-0.10695986, -0.3398793 ],\n        [-0.1567835 , -0.51559156],\n        [-0.0734017 , -0.16764104],\n        [-0.12234285, -0.33830747],\n        [-0.15669978, -0.47613004],\n        [-0.10675225, -0.27418932],\n        [-0.08018454, -0.15989682],\n        [-0.1398887 , -0.39186358],\n        [-0.18006757, -0.5721971 ],\n        [-0.10886352, -0.28720585]],\n\n       [[-0.02749902, -0.01930231],\n        [-0.05311171, -0.06767099],\n        [-0.10204615, -0.22767864],\n        [-0.17084165, -0.5088455 ],\n        [-0.10697522, -0.24954632],\n        [-0.06516865, -0.07953074],\n        [-0.07525846, -0.10378528],\n        [-0.09091106, -0.15474372],\n        [-0.07649007, -0.09700193],\n        [-0.1572655 , -0.42747858]],\n\n       [[-0.05225033, -0.11578608],\n        [-0.05895209, -0.098952  ],\n        [-0.11657491, -0.299158  ],\n        [-0.13991395, -0.3848863 ],\n        [-0.1263809 , -0.32722986],\n        [-0.12940817, -0.33485943],\n        [-0.08309075, -0.15178554],\n        [-0.05016572, -0.02134027],\n        [-0.09960923, -0.19972056],\n        [-0.06248416, -0.05807872]],\n\n       [[-0.08637046, -0.22937633],\n        [-0.10229586, -0.23954712],\n        [-0.15116447, -0.4092558 ],\n        [-0.12921005, -0.307701  ],\n        [-0.18912685, -0.56317383],\n        [-0.16242388, -0.4490231 ],\n        [-0.12458492, -0.2901017 ],\n        [-0.11919773, -0.25901568],\n        [-0.18726183, -0.55532265],\n        [-0.15325856, -0.41472003]],\n\n       [[-0.10604117, -0.34267917],\n        [-0.03887179, -0.05268725],\n        [-0.08524382, -0.20133244],\n        [-0.08744939, -0.1967244 ],\n        [-0.09643388, -0.22334453],\n        [-0.1570329 , -0.47413012],\n        [-0.17516741, -0.5652044 ],\n        [-0.18030803, -0.6023267 ],\n        [-0.10144447, -0.2809562 ],\n        [-0.0592957 , -0.0992988 ]],\n\n       [[-0.07023395, -0.18362851],\n        [-0.05919973, -0.10072781],\n        [-0.09670657, -0.2175601 ],\n        [-0.12868516, -0.33235887],\n        [-0.08405506, -0.15471658],\n        [-0.1619223 , -0.47241327],\n        [-0.16776007, -0.50221545],\n        [-0.1034639 , -0.24306779],\n        [-0.15037915, -0.42413858],\n        [-0.19071665, -0.6066944 ]],\n\n       [[ 0.00079125,  0.07487514],\n        [-0.03049744,  0.00528554],\n        [-0.07072724, -0.11872135],\n        [-0.07877124, -0.1356339 ],\n        [-0.16379905, -0.48684728],\n        [-0.14460017, -0.41139147],\n        [-0.09712082, -0.21835828],\n        [-0.06114332, -0.07148607],\n        [-0.06051059, -0.05717351],\n        [-0.15243773, -0.42743343]],\n\n       [[-0.02221906, -0.00395356],\n        [-0.01201968,  0.07394958],\n        [-0.11606462, -0.30094013],\n        [-0.08872025, -0.1811495 ],\n        [-0.06391786, -0.07601882],\n        [-0.07019082, -0.08841603],\n        [-0.09078026, -0.159136  ],\n        [-0.06396053, -0.05654741],\n        [-0.08589994, -0.13302778],\n        [-0.05743085, -0.02625139]]], dtype=float32)>"
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10, 10, 2), dtype=float32, numpy=\narray([[[-0.36397788,  0.0294749 ],\n        [-0.48029938,  0.01573997],\n        [-0.51549274, -0.00554507],\n        [-0.50096333, -0.02819019],\n        [-0.51849884, -0.03603037],\n        [-0.4956515 , -0.04518281],\n        [-0.4919299 , -0.04698842],\n        [-0.5167043 , -0.04562606],\n        [-0.5176949 , -0.04506196],\n        [-0.5242841 , -0.04514759]],\n\n       [[-0.3648733 ,  0.04206948],\n        [-0.4807293 ,  0.04454088],\n        [-0.51710445,  0.03400522],\n        [-0.5260778 ,  0.02312428],\n        [-0.5013063 ,  0.01332644],\n        [-0.50671595,  0.01171992],\n        [-0.52894664,  0.00859705],\n        [-0.5185139 ,  0.00654676],\n        [-0.52903926,  0.00418232],\n        [-0.50056595,  0.00295787]],\n\n       [[-0.35582137,  0.06193205],\n        [-0.4635372 ,  0.05734254],\n        [-0.50165814,  0.04938255],\n        [-0.52453876,  0.04110029],\n        [-0.5341751 ,  0.03280196],\n        [-0.5287185 ,  0.02695066],\n        [-0.5085621 ,  0.02464295],\n        [-0.51623905,  0.02477949],\n        [-0.51171356,  0.02451629],\n        [-0.5170272 ,  0.02416078]],\n\n       [[-0.36347923,  0.05691229],\n        [-0.48067915,  0.06080834],\n        [-0.51629937,  0.0509107 ],\n        [-0.5146694 ,  0.04058636],\n        [-0.4931925 ,  0.02981444],\n        [-0.5192418 ,  0.0284833 ],\n        [-0.51482946,  0.02600875],\n        [-0.509487  ,  0.02449078],\n        [-0.50999254,  0.02360039],\n        [-0.5020083 ,  0.02161226]],\n\n       [[-0.36336344,  0.03193593],\n        [-0.47798705,  0.01634251],\n        [-0.49627632, -0.01065315],\n        [-0.50714   , -0.0249239 ],\n        [-0.5143287 , -0.03361027],\n        [-0.49663463, -0.04228203],\n        [-0.52345884, -0.04417491],\n        [-0.5103134 , -0.04488222],\n        [-0.5239943 , -0.04553092],\n        [-0.5210364 , -0.04472711]],\n\n       [[-0.36420384,  0.03050906],\n        [-0.47005066,  0.02912151],\n        [-0.4933604 ,  0.01791096],\n        [-0.52525586,  0.01143312],\n        [-0.51342005,  0.00406701],\n        [-0.49653322, -0.00232583],\n        [-0.50967413, -0.00242265],\n        [-0.5025211 , -0.00473238],\n        [-0.52089024, -0.00633133],\n        [-0.5105833 , -0.00821032]],\n\n       [[-0.3592899 ,  0.05837873],\n        [-0.47449625,  0.05713591],\n        [-0.5202108 ,  0.04775243],\n        [-0.4998784 ,  0.03190187],\n        [-0.49602073,  0.02501975],\n        [-0.49635592,  0.0217083 ],\n        [-0.5260861 ,  0.01966117],\n        [-0.51770693,  0.01701247],\n        [-0.5106258 ,  0.01593107],\n        [-0.4895934 ,  0.01103553]],\n\n       [[-0.36588687,  0.02894703],\n        [-0.47565123,  0.01820762],\n        [-0.514848  ,  0.00344476],\n        [-0.5071501 , -0.01241258],\n        [-0.49831274, -0.0224922 ],\n        [-0.52561057, -0.02621452],\n        [-0.5336887 , -0.03154004],\n        [-0.5051036 , -0.03277329],\n        [-0.5218599 , -0.03175934],\n        [-0.529561  , -0.03260876]],\n\n       [[-0.36208293,  0.06034166],\n        [-0.47515383,  0.06254248],\n        [-0.4998143 ,  0.05188979],\n        [-0.50785875,  0.04361076],\n        [-0.5076397 ,  0.03737927],\n        [-0.52751046,  0.03244342],\n        [-0.52910596,  0.02708542],\n        [-0.4943607 ,  0.0206141 ],\n        [-0.52184284,  0.02115785],\n        [-0.49783346,  0.0181902 ]],\n\n       [[-0.36006317,  0.0466808 ],\n        [-0.4808289 ,  0.04173735],\n        [-0.49869117,  0.01861919],\n        [-0.50795   ,  0.00552239],\n        [-0.514347  , -0.00249341],\n        [-0.5267752 , -0.00865605],\n        [-0.5350935 , -0.01422167],\n        [-0.51781046, -0.01513254],\n        [-0.50285685, -0.01371899],\n        [-0.5220274 , -0.0123977 ]]], dtype=float32)>"
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}